,Sentence,Label
0,"We propose a Combinatorial visuaL Analytics system for Information Retrieval Evaluation (CLAIRE) which allows for exploring and making sense of the performances of a large amount of IR systems, in order to quickly and intuitively grasp which system configurations are preferred, what are the contributions of the different components and how these components interact together.",Model Construction or Optimization
1,"we performed a transcriptome analysis of glomerular tissues in 5 FSGS patients and 5 controls. Among the differentially expressed lncRNAs, the level of LOC105374325 showed the most significant increase in the glomerular tissues of FSGS patients.",Performance Evaluation
2,We conducted both in vitro and in vivo experiments to investigate the role of LOC105374325 in podocyte injury in FSGS patients.,Theory Proposal
3,"we report accumulation of actinoplanic acid A (2) and its novel demethyl analogue, which we have designated actinoplanic acid C, in the fermentation broth of S. rapamycinicus ATCC 29253. These compounds are unrelated to any of the secondary metabolites previously reported from this microorganism.",Theory Proposal
4,"we have identified the APL cluster in other bacterial genomes, without exception in the presence of the rapamycin pathway.",Theory Proposal
5,"we report the characterization of a novel butenolide signal transduction pathway, in which signal input is transmitted to nikkomycin biosynthesis via a newly discovered activator, CprC, of adpA.",Theory Proposal
6,"We have modeled human AA in mice by adaptation of historic вЂњrunt disease,вЂќ in which infusion of lymph node (LN) cells into recipients mismatched at major histocompatibility complex23,24 or minor histocompatibility antigen25 loci produces severe pancytopenia and BM failure.",Model Construction or Optimization
7,"Using these models, we recently reexamined the role of the IFN-Оі/IFN-Оі receptor signaling pathway in BM failure: IFN-Оів€’/в€’ donor T cells failed to induce BM destruction; IFN-Оі receptorв€’/в€’ recipient mice did not develop marrow failure when infused with major histocompatibility complexвЂ“mismatched FVB/N (FVB) LN cells.",Performance Evaluation
8,we used the same model systems and mice deficient in TNF-О± or TNF-О±R to study the specific roles of TNF-О±/TNF-О±R in BM failure.,Applications
9,We also examined marrow samples from AA patients and found increased macrophages with high levels of intracellular TNF-О± compared with healthy individuals.,Performance Evaluation
10,"we induced mGluR-LTD by addition of the group I mGluR agonist (RS)-dihydroxyphenylglycine (DHPG) (Palmer et al., 1997), a protocol that will activate mGluRs irrespective of synapse P(r).",Applications
11,We also activated mGluR1 synaptically by delivering theta burst stimulation (TBS) to afferent inputs.,Applications
12,"By combining, for the first time, multiphoton imaging of FM4-64 (FM) to record P(r) and SEP-GluA2 to measure AMPAR trafficking, we determined the relationship between AMPAR trafficking and P(r) at individual CA1 synapses.",Theory Proposal
13,Stopping antiangiogenic treatment after resistance leads to rebound tumor growth,Theory Proposal
14,Antiangiogenic drug resistance can induce transient pseudosenescent secretory phenotypes,Theory Proposal
15,Targeting SASP regulators like IL-6 and mTOR blunt withdrawal-mediated tumor growth,Theory Proposal
16,APP and PSEN1 mutant neurons have deficits in lysosome proteolysis,Theory Proposal
17,BACE1 inhibition rescues lysosome and autophagy defects,Theory Proposal
18,PSEN1 mutant phenotypes are rescued by genetic deletion of APP,Theory Proposal
19,Lysosome and autophagy defects are causes of neuronal dysfunction in AD,Theory Proposal
20,We examine the effect of voluntary disclosure on debt maturity and the role of ownership structure in this effect.,Theory Proposal
21,Debt maturity increases with the level of voluntary disclosure.,Theory Proposal
22,This increase is more pronounced when excess control rights are high.,Theory Proposal
23,Voluntary disclosure provides an efficient monitoring mechanism for lenders.,Theory Proposal
24,Hematopoietic stem and progenitor cells can serve as long-term reservoirs of HIV,Theory Proposal
25,HSPCs harbor both infectious and defective proviral genomes,Theory Proposal
26,HSPCs are an important source of residual plasma virus in treated people,Theory Proposal
27,Clonally amplified HIV proviruses contribute to residual plasma virus,Theory Proposal
28,"pgc, a germline RNA, is translationally regulated throughout Drosophila oogenesis",Theory Proposal
29,A conserved 10-nt sequence in the pgc 3вЂІ UTR is required for its regulation,Theory Proposal
30,"Pum and Bru, conserved RBPs, sequentially repress pgc translation via this sequence",Theory Proposal
31,A class of maternal RNAs are also regulated by Pum and Bru during oogenesis,Theory Proposal
32,The synthesis of most protein complex components during meiosis is imprecisely matched,Theory Proposal
33,The levels of most protein interaction partners are post-translationally adjusted,Theory Proposal
34,Ribosomal proteins are degraded and re-synthesized late in the meiotic program,Theory Proposal
35,Analysis of meiotic protein levels over time points to additional Ama1-APC/C targets,Theory Proposal
36,Disrupting the interaction of PI 3-kinase with RAS impairs EGF activation of AKT and RAC,Theory Proposal
37,Mice bred with RAS-binding-domain-defective PI 3-kinase and activated EGFR mutant,Theory Proposal
38,Abrogating RAS binding to PI 3-kinase blocks EGFR-induced lung tumor initiation,Theory Proposal
39,Blocking the RAS-PI 3-kinase interaction induces regression of EGFR-induced tumors,Theory Proposal
40,KCNH6 regulates insulin secretion and glucose hemostasis in humans and mice,Theory Proposal
41,KCNH6 dysfunction causes a phenotype from hyper- to hypoinsulinemia and diabetes,Theory Proposal
42,KCNH6 dysfunction increases intracellular calcium levels and hyperinsulinemia,Theory Proposal
43,Chronic elevation of intracellular calcium causes ОІ cell loss and hyperinsulinemia,Theory Proposal
44,A complex HER2+ breast cancer ecosystem is reconstituted and quantitatively described,Theory Proposal
45,The effects of the drug trastuzumab (Herceptin) are directly visualized ex vivo,Theory Proposal
46,Trastuzumab promotes long cancer-immune interactions and an ADCC immune response,Theory Proposal
47,Trastuzumab and CAFs have antagonist immunomodulation effects,Theory Proposal
48,Gene expression bursts from the HIV LTR promoter increase with T cell size,Theory Proposal
49,Larger T cells latently infected with HIV exclusively reactivate from latency,Theory Proposal
50,"Reactivation from HIV latency is cell-cycle dependent, with enhancement in G1",Theory Proposal
51,Checkpoint arrestors actively modulate cell cycle to bias viral decision-making,Theory Proposal
52,NFIA regulates pancreatic endocrine progenitor induction,Theory Proposal
53,Loss of NFIA leads to increased Dll1 endocytosis and decreased Notch cis-inhibition,Theory Proposal
54,NFIA-deficient cells have a gain in Notch signaling and cell fate defects,Theory Proposal
55,NFIA binds to the Mib1 promoter to regulate duct versus endocrine fate determination,Theory Proposal
56,REV-ERBО± is upregulated in TH17 cells,Theory Proposal
57,"REV-ERBО± deficiency exacerbates TH17-mediated diseases, including EAE and colitis",Theory Proposal
58,"REV-ERBО± competes with RORОіt to modulate TH17-signature genes, including Il17a",Theory Proposal
59,REV-ERBО±-specific ligands suppress the development and progression of autoimmunity,Theory Proposal
60,Treg cells infiltrate into psoriasiform skin lesions,Theory Proposal
61,Treg cells limit the exacerbation of skin inflammation and initiate disease remission,Theory Proposal
62,GM-CSF+CD4+ T cells emerge in Treg-cell-depleted skin,Theory Proposal
63,Neutralization of GM-CSF reverses exacerbated skin inflammation to wild-type levels,Theory Proposal
64,Cholesterol efflux and direct repression mediate LXRвЂ™s anti-inflammatory effects,Theory Proposal
65,LXR cis-repression involves direct binding of LXR to inflammatory gene enhancers,Theory Proposal
66,LXR agonist treatment suppresses neutrophil recruitment during inflammation,Theory Proposal
67,Targets of LXR repression are involved in neutrophil migration,Theory Proposal
68,PCNA interactome was comprehensively explored to reflect replisome dynamics,Theory Proposal
69,Replisome composition characteristically varies upon encountering different stresses,Theory Proposal
70,WIZ and SALL1 were examined for their roles in DNA replication and stress response,Theory Proposal
71,Peptides linked to neurodegenerative diseases reduce neuronal fitness in Drosophila,Theory Proposal
72,ОІ-amyloid-induced neuronal death is mediated by fitness regulators flower and azot,Theory Proposal
73,Suppression of fitness-based neuronal culling aggravates cognitive and motor decline,Theory Proposal
74,Neuronal death related to fitness-based selection has a beneficial net effect,Theory Proposal
75,Lymph node lymphatic endothelial cells (LN LECs) dramatically react to tumor stimuli,Theory Proposal
76,Cell adhesion molecules are among the strongest differentially regulated genes,Theory Proposal
77,Itga2b is upregulated and associated with fibrinogen in tumor-draining LN LECs,Theory Proposal
78,Itga2b mediates adhesion of LN LECs to fibrinogen,Theory Proposal
79,we describe the achievement of mesoscale skeletal muscle 3D constructs embedding differentiated muscle fibers and vascular networks exhibiting endothelial phenotypic specificity to muscle tissue.,Theory Proposal
80,"We demonstrate how this multicellular environment interacts with cells of mesenchymal origin. In particular, vascular networks mediate the recruitment of fibroblasts specifically derived from human muscles toward muscle fibers",Theory Proposal
81,"we analyze matrix deposition by muscle fibroblasts derived from patients with DMD, highlighting through our model differences that were not detectable in traditional 2D assays.",Model Construction or Optimization
82,E2F1 and its heterodimerization partner DP1 are required for myeloma cell proliferation,Theory Proposal
83,E2F1-DP1 heterodimers regulate promoter proximal transcription,Theory Proposal
84,E2F1 and BRD4 establish distinct regulatory axes in multiple myeloma,Theory Proposal
85,Combined inhibition of BRD4 and E2F co-operatively reduces myeloma tumor growth,Theory Proposal
86,LYN kinase is a downstream effector of the c-KIT receptor in normal breast cells,Theory Proposal
87,Loss of BRCA1 function hyperactivates LYN via prolyl isomerase 1 upregulation,Theory Proposal
88,The full-length LYN isoform promotes tumor cell invasion,Theory Proposal
89,Time to breast cancer death is shorter in tumors with a high LYNA::B isoform ratio,Theory Proposal
90,The chromatin and transcriptome of hPGCs resembles ground-state naive hESCs,Theory Proposal
91,TFAP2C is required for hPGC formation and expression of KLF4,Theory Proposal
92,The TFAP2C-regulated OCT4 naive enhancer is involved in hPGC formation,Theory Proposal
93,TNF receptor family member OX40 is a key molecule in NASH development,Theory Proposal
94,OX40 regulates both intrahepatic innate and adaptive immunity in NASH,Theory Proposal
95,OX40 promotes hepatic monocyte but not Kupffer cell M1 polarization in NASH,Theory Proposal
96,Plasma OX40 levels are positively associated with NASH in humans,Theory Proposal
97,Complement mutations occur at a significantly higher rate than background mutations,Theory Proposal
98,Complement component mutations are associated with poor overall survival,Theory Proposal
99,Tumors with complement component mutations harbor increased hypoxic signaling,Theory Proposal
100,Hypoxic colorectal cancer cells are resistant to complement-mediated cytotoxicity,Theory Proposal
101,GRFs control transcription initiation fidelity and suppress pervasive transcription,Theory Proposal
102,Ectopic initiation in the absence of Rap1 has variegated effects on gene expression,Theory Proposal
103,Ectopic transcription initiation correlates with altered nucleosome positioning,Theory Proposal
104,Rap1 suppresses transcription initiation by a steric hindrance mechanism,Theory Proposal
105,Four yeast quantitative traits are affected by thousands of small effect size genes,Theory Proposal
106,Alleles of small effect size genes can significantly contribute to trait variation,Theory Proposal
107,Small effect size genes are enriched in core cellular processes,Theory Proposal
108,The effects of these genes are quantitative trait specific,Theory Proposal
109,A Powassan virus LNP-mRNA vaccine induces potently neutralizing antibodies in mice,Theory Proposal
110,One dose of the mRNA vaccine protects against lethal Powassan virus challenge,Theory Proposal
111,The antibody response to the vaccine neutralizes other tick-borne flaviviruses,Theory Proposal
112,The vaccine cross-protects against disease following challenge with Langat virus,Theory Proposal
113,A hypomorphic point mutation in the Wars2 gene was identified,Theory Proposal
114,Mutant mice exhibit progressive tissue-specific pathologies,Theory Proposal
115,Variable activation of stress response pathways,Theory Proposal
116,Demonstrating pleiotropic effects,Theory Proposal
117,China's burgeoning rural e-commerce has triggered a new wave of rural rejuvenation.,Theory Proposal
118,Fully understanding how the space of flows affects rural economic space.,Theory Proposal
119,Analyzes the process and mechanism of e-commerce oriented rural economic restructuring from the perspective of elements flows.,Theory Proposal
120,Lattice expansion induced by ion implantation is about 20вЂЇnm.,Theory Proposal
121,Rarely point defects remained in the waveguide after annealing.,Theory Proposal
122,The relationship between ndpa and neff in waveguides was investigated.,Theory Proposal
123,MHC-I protein was present in the horse allantochorion on days 90вЂ“240 of pregnancy.,Theory Proposal
124,"During pregnancy, its expression was downregulated in fetal and maternal tissues.",Theory Proposal
125,MHC-I protein expression was upregulated in the allantochorion at parturition.,Theory Proposal
126,"At parturition, staining for MHC-I was detected in places of fetal-maternal contact.",Theory Proposal
127,Classical and non-classical MHC-I mRNA were detected in these tissues in all groups.,Theory Proposal
128,Ion beam induced luminescence provides in-situ information of recombination centers evolution with fluence during irradiation.,Theory Proposal
129,"Different ion species, energies are used to discuss the roles of electronic and nuclear energy deposition.",Theory Proposal
130,Other off-line method is employed to explain the cause of luminescence intensity decrease.,Algorithms/ Methods Construction or Optimization
131,AISI 5140 steel was treated by low-energy high-current implantation of nitrogen ions in gas-discharge plasma.,Theory Proposal
132,"Mechanical and tribological characteristics, structure and elemental composition of modified layers are presented.",Theory Proposal
133,500вЂЇВ°C treated specimen showed the best results of hardness and wear resistance.,Theory Proposal
134,The specimen temperature was set by changing the bias duty factor without change in its amplitude and maximum current.,Theory Proposal
135,Graphene Oxide foils were irradiated using 1.2вЂЇMeV He+ ions to various fluencies.,Theory Proposal
136,The composition and structure of pristine and irradiated GO were investigated.,Theory Proposal
137,Reduction of GO foil surface and growth of graphene domains were indicated.,Theory Proposal
138,The electric conductivity improvement is a growing function of the ion fluence.,Theory Proposal
139,Surface modification of triacetylcellulose was performed by low energy nitrogen ion irradiation.,Theory Proposal
140,The surface modified layer of triacetylcellulose was applied as a diaphragm for environmental cell.,Theory Proposal
141,Film thickness of surface modified layer formed by nitrogen ions irradiation at 1вЂЇkV was 12вЂЇnm.,Theory Proposal
142,The layer mainly contained amorphous carbon film including 1% nitrogenвЂ‘carbon atomic ratio.,Theory Proposal
143,The pressure resistances of the surface modified layer was around 0.1вЂЇMPa.,Theory Proposal
144,Comparative AP-MS reveals shared and virus-specific interactions,Theory Proposal
145,NS5 suppresses interferon stimulated genes by inhibiting PAF1C recruitment,Theory Proposal
146,Pharmacological modulation of the SEC61 translocon inhibits virus replication,Theory Proposal
147,Zika virus NS4A inhibits brain development in vivo in an ANKLE2-dependent manner,Theory Proposal
148,The О±V class of integrins are irisin receptors in osteocytes and adipose tissues,Theory Proposal
149,Irisin increases sclerostin expression in osteocytes to induce bone resorption,Theory Proposal
150,Genetic deletion of FNDC5 (or Irisin) completely blocks OVX-induced trabecular bone loss,Theory Proposal
151,Glycocalyx is present at the maternal-fetal interface of the human placenta.,Theory Proposal
152,A new method for the ultrastructural imaging of placental glycocalyx is presented.,Algorithms/ Methods Construction or Optimization
153,Visualisation of placental glycocalyx is enhanced by these methods.,Theory Proposal
154,These techniques can be used to study the role of the placental glycocaly,Theory Proposal
155,LincGET is asymmetrically expressed in the nucleus of two- to four-cell mouse embryos,Theory Proposal
156,LincGET overexpression biases blastomere fate toward inner cell mass (ICM),Theory Proposal
157,LincGET physically binds to CARM1,Theory Proposal
158,LincGET/CARM1 activates ICM-specific genes,Theory Proposal
159,CellMinerCDB integrates pharmacogenomic data of the major cancer cell line databases,Theory Proposal
160,It seamlessly enables genomic and drug data exploration within and across databases,Theory Proposal
161,It tests genomic data reproducibility and proposes drug response determinants,Dataset Creation or Resources
162,We expand the GDSC drug panel and advance LIX1L as a novel mesenchymal gene,Theory Proposal
163,Galectin-8 reinforces B cell arrest phases upon antigen recognition in vivo,Theory Proposal
164,Galectin-8 sustains BCR signaling during recognition of immobilized antigens,Theory Proposal
165,This enhances lysosome secretion and favors the proteolytic extraction of antigens,Theory Proposal
166,Galectin-8 improves the capacity of B cells to present antigens to helper T cells,Theory Proposal
167,Atypical protein kinase C (aPKC) expression is reduced in human serrated tumors,Theory Proposal
168,Deletion of both aPKCs in intestinal epithelium causes spontaneous serrated tumors,Theory Proposal
169,aPKC-deficient tumors display immunosuppression and stromal activation,Theory Proposal
170,"Loss of PKCО¶ impairs the CD8+ T cell response, triggering serrated tumor initiation",Theory Proposal
171,Human beige adipocytes are generated from iPSC-derived FOXF1+ mesoderm,Theory Proposal
172,iPSC-derived beige adipocytes express UCP1 and exhibit uncoupled respiratio,Theory Proposal
173,Reprogramming adipocyte precursors from diabetic patients improves beige adipogenesis,Theory Proposal
174,iPSC-derived beige adipocytes secrete factors that improve insulin sensitivity,Theory Proposal
175,A sustainable planning approach is developed for mining supply chains.,Theory Proposal
176,Potential of using wind and solar power generators in mine sites is discussed.,Theory Proposal
177,A multi-stage stochastic program is proposed with uncertain renewable resources.,Theory Proposal
178,A case study for a zinc mining supply chain in Iran is investigated.,Theory Proposal
179,S. enterica (Se) infection stimulates robust expansion of CXCR3+ Th1 cells,Theory Proposal
180,Granulomas bordered by CXCL9/10+ phagocytes form during Se infection,Theory Proposal
181,Se bacteria are in granuloma cores while Th1 cells are excluded to the borders,Theory Proposal
182,Se bacteria produce enzymes that neutralize the effects of nitric oxide,Theory Proposal
183,Single-cell transcriptome of embryonic mouse pancreas and hESC-derived cells,Theory Proposal
184,Identification of novel cell types during mouse pancreas development,Theory Proposal
185,Pseudotime analysis reveals developmental trajectories of endocrine cell lineage,Theory Proposal
186,hESC-derived endocrine cells resemble immature ОІ cells,Theory Proposal
187,Identified open chromatin domains associated with glucocorticoid response in ALL,Theory Proposal
188,Glucocorticoid-resistant ALL shows abnormal accessibility at GR-bound enhancers,Theory Proposal
189,GR and CTCF bind at a lymphocyte-specific enhancer for BIM to mediate DNA looping,Theory Proposal
190,The BIM enhancer is highly methylated in resistant ALL and non-lymphoid cell types,Theory Proposal
191,Profiling iPSC-derived VSMCs uncovers CAD risk haplotype-dependent phenotypes,Theory Proposal
192,"Deleting the risk haplotype rescues VSMC proliferation, adhesion, and contraction",Theory Proposal
193,"Risk-dependent gene networks drive cell state instability, partially through ANRIL",Theory Proposal
194,Evidence for cross-talk between CAD risk loci predicts vascular therapeutic targets,Theory Proposal
195,Plasma proteome profiling of independent Roux-en-Y gastric bypass cohorts,Theory Proposal
196,Global correlation maps of the plasma proteome reveal functional networks,Theory Proposal
197,Systemic inflammation and lipid transport are the major remodeled processes,Theory Proposal
198,Gastric bypass has specific and common effects to other weight loss interventions,Theory Proposal
199,IncI1 and IncIОі plasmids evolution and acquisition of clinically relevant antimicrobial resistance,Theory Proposal
200,Phylogenetic analysis performed on pMLST alleles of IncI1 and IncIОі plasmids identified major clusters,Theory Proposal
201,"IncI1 and IncIОі plasmids spread among Enterobacteriaceae from human, animal and environmental sources",Theory Proposal
202,MadID: mapping of protein-DNA interactions in vivo using proximity labeling,Theory Proposal
203,"Deeper and unbiased genome-wide coverage using M.EcoGII, a methyltransferase",Theory Proposal
204,Identification of binding sites in previously inaccessible regions of the genome,Theory Proposal
205,Identification of telomere-nuclear envelope contact sites,Theory Proposal
206,О”g NK cell expansion and acquisition of function are driven by concurrent CMV infection,Theory Proposal
207,О”g NK cells are distributed systemically but have the propensity to migrate to mucosal sites,Theory Proposal
208,О”g NK cells abandon Оі-chain/Syk signaling in lieu of the atypical CD3О¶-Zap70 signaling pathway,Theory Proposal
209,SIV infection subverts О”g NK cells by suppressing CD16-mediated CD3О¶-ZAP70 signaling,Theory Proposal
210,A series of oxadiazoles were identified that ameliorate О±-synuclein toxicity in yeast,Theory Proposal
211,Oxadiazoles directly inhibit yeast (Ole1) and human (SCD) stearoyl-CoA desaturases,Theory Proposal
212,Inhibiting Ole1 restored О±-synuclein localization and reversed trafficking defects,Theory Proposal
213,Inhibiting SCD protected human neurons from О±-synuclein toxicity,Theory Proposal
214,"The composition optimization of Co3в€’xFexO4/RGO (xвЂЇ=вЂЇ1.5, 2.25 and 2.5) were synthesized.",Theory Proposal
215,The Co3в€’xFexO4/RGO nanohybrids exhibit excellent microwave absorption properties.,Theory Proposal
216,Enhanced microwave absorbing mechanism was discussed in details.,Theory Proposal
217,Photocatalytic ability of BiFeO3-ZnO was investigated for conversion CO2 and CH4.,Theory Proposal
218,Photoactivity was assigned to effect of p-n heterojunction and vis-light sensitivity of BiFeO3.,Theory Proposal
219,Increasing BiFeO3 content led to an increase in charge separation and visible light activity.,Theory Proposal
220,The highest photocatalytic efficiency was achieved by composite sample with molar ratio 1:1,Performance Evaluation
221,Study progressive collapse for steel moment resisting and braced frames.,Theory Proposal
222,Explore progressive collapse due to seismic actions.,Theory Proposal
223,Investigate progressive collapse due to column loss scenarios according to the UFC guidelines.,Theory Proposal
224,SWAT model was modified to better simulate depressional wetlands.,Model Construction or Optimization
225,Modified model has improved structural and process representation of wetlands.,Performance Evaluation
226,Model was calibrated with streamflow and remotely sensed surface water extent data,Applications
227,Model successfully replicated streamflow and surface water extent data.,Applications
228,Model is a new tool to quantify wetland functions at broad spatial scales.,Model Construction or Optimization
229,A new cryptographic algorithm which has better authentication and encryption of data and uses quantum-inspired quantum walks.,Algorithms/ Methods Construction or Optimization
230,Secure transmission of data between different IOT devices is obtained by using the new cryptographic technique by using quantum hash functions by linkin blocks of chain,Theory Proposal
231,Message attacks and Impersonation attacks can be tackled by using the new cryptographic algorithm was stated in security analysis,Algorithms/ Methods Construction or Optimization
232,using the natural language dialogue for a dialog based indoor navigation system,Theory Proposal
233,New diseases information can be identified with the help of Blockchain based method.,Algorithms/ Methods Construction or Optimization
234,"Information collection , Information Query and Informationstorage can be done using the Blockchain which is authentic.",Theory Proposal
235,Detection of false and spam reviews by using collusive community detection framework,Model Construction or Optimization
236,Using the community-based and temporal abnormality features to differentiate spammers from othersВ ,Theory Proposal
237,Research topic treands can be identified by using the author-defined keyword frequency prediction.,Theory Proposal
238,"AKFP uses long short-term Memory and Temporal feature, Persistence, Community size, and Community development potential are used as inputs",Theory Proposal
239,A predictive model which helps in forecasting of a company success in the future,Model Construction or Optimization
240,"The forecasting of the company success results for precision, recall, and F1 scores were 57%, 34%, and 43%.",Performance Evaluation
241,An automatic proposal for quality and recency-based answer ranking.,Theory Proposal
242,"From evaluation of 9 L2R algorithms, shows Coordinate Ascent and LambdaMart have the best performance.",Performance Evaluation
243,Misinformation regarding Covid-19 are detected using DistilBERT and SHAP,Theory Proposal
244,DistilBERT model was used to check the performance of the selected data and the trust of users increased by SHARP,Algorithms/ Methods Construction or Optimization
245,A Blockchain-empowered COVID-19 contact tracing platform has been introduced.,Algorithms/ Methods Construction or Optimization
246,The platform uses user identity data and activity trace data on the blockchain using SSI proofs to track and identify locationwhich helps in identifying patientsВ ,Theory Proposal
247,Mutual authentication protocols for IOT systems for decentralized dataВ ,Theory Proposal
248,Using Block-chain the attacks against the RFID are tested and examinedВ ,Theory Proposal
249,BAN-Logic method is used to approve the closed loop and open loop authentication,Algorithms/ Methods Construction or Optimization
250,The efffects of online social support by holding public emotions and knowledge overcoming the Covid-19 pandemic,Theory Proposal
251,"Developed a model which addresses beliefs of the online social support, cognition and emotion. Crawling and content analysis are used to identify the different online support given or received by people from Baidu Covid-19 bar",Model Construction or Optimization
252,"Insights on reduce the negative effects of quarantine, consolidate the theoretical basis of the public's beliefs were obtained",Dataset Creation or Resources
253,"In realistic environments, a longitudinal study of cooperation during information-intensive projects.",Theory Proposal
254,"The data was collected by initial demographic questionnaires, pre- and post-trip interviews, and self-reported diaries during the travel and was analyzed by using iteravtive coding.",Theory Proposal
255,"Different CIB roles were identifyied which were self volunteered by the travelers including team player, all-rounder, influencer, authoritarian, supporter, and followers",Theory Proposal
256,An adaptive and continuous approach for storage requirements of smart-contracts,Theory Proposal
257,"a semantically distinct blockchain architecture, which includes a new type of node whose function is to improve the storage used by smart-contracts",Theory Proposal
258,A anti-leakage smart Ponzi schemes detection method named Al-SPSD designed to increase security in Blockchain,Algorithms/ Methods Construction or Optimization
259,"Al-SPSD is used to detect 1,621 active smart Ponzi schemes in Ethereum and with a f-score of 96 percent.",Applications
260,Detection of dangerous transactions which causes harm using the block chain technology in the real time,Theory Proposal
261,Fortification of the Etherium virtual machine is done for detection of fraud transactions which will interrupt the execution during the runtime.,Theory Proposal
262,"The strengthened FISCO-BCOS-evm has been implemented into the official release of FISCO-BCOS, which has been adopted by WeBank, a major Chinese bank.",Applications
263,Introduce the new task of changing the narrative perspectives of a text which changes the experiene gained while reading it,Theory Proposal
264,Developed an system which transforms a first person or a second person view into a third person viewВ ,Algorithms/ Methods Construction or Optimization
265,The results of above process shows a promissing approach as it shows that the text obtained is fluent and non-ambigious,Theory Proposal
266,The transformation opportunities are discovered using the heterogeneous network based transformation opportunity prediction tool.,Algorithms/ Methods Construction or Optimization
267,The explainable heterogeneous network-based transformation condition method describes the transformation conditions are required to complete the transformation.,Algorithms/ Methods Construction or Optimization
268,A decomposition based recommendation approach is proposed for address the scalability issues which arise when a customers join at rapid rate in recommendar systems,Theory Proposal
269,used the Voronoi diagram differentiate the usersвЂ™ space of the system coinsidering the location.,Dataset Creation or Resources
270,Improved the recommendation quality for the boundary users of a Voronoi cell,Algorithms/ Methods Construction or Optimization
271,"The scalability and efficacy of the approch is demonstrated by reducing the run time for baseline CF algorithm for MovieLens-100K, MovieLens-1M, Book-Crossing and TripAdvisor datasets",Algorithms/ Methods Construction or Optimization
272,Variances of Gaussian embeddings can be used to quantify semantic uncertainty.,Algorithms/ Methods Construction or Optimization
273,There exist Zipfian regularities between word frequencies and semantic breadth/uncertainty.,Theory Proposal
274,Zipfian patterns: more frequent words tends to be generic while less frequent ones tend to be specific.,Theory Proposal
275,Zipfian patterns can be leveraged to increase entailment detection performance.,Theory Proposal
276,"using a standardized category schema, we are able to identify dataset categories which favor the generalization potential of a model;",Dataset Creation or Resources
277,"we provide clear evidence that, in contrast to the argumentation in some recent works, e.g., GrГ¶ndahl, Pajola, Juuti, Conti, and Asokan (2018), the model itself is equally of high relevance for generalization;",Model Construction or Optimization
278,we identify the dataset features and models that are responsible for a higher degree of generalization.,Model Construction or Optimization
279,It allows the IoT manufacturers to protect their own name resolution process by individually choosing a name for the management company.,Theory Proposal
280,IoT-RU is a decentralized name resolution framework for IoT.,Model Construction or Optimization
281,A blockchain architecture for IoT that protects privacy through Hierarchical Identity Based Encryption (HIBE).,Theory Proposal
282,Many testings using Contiki OS are done to test the efficiency of the proposed architecture.,Performance Evaluation
283,Introduced an unique method for identifying and defining potentially discriminated user groups for a given recommendation algorithm.,Algorithms/ Methods Construction or Optimization
284,"What to do, to predict users movie ratings by using a collaborative filtering algorithm to classify users movie preferences",Algorithms/ Methods Construction or Optimization
285,"The MAE index of the conventional collaborative filtering system can be improved by 12.54 percent, the MAPE index by 17.68 percent, and the F1 index by 10.16 percent.",Performance Evaluation
286,В The Artificial Neural Network (ANN) is used to identify when and which nodes to remove during the consensus phase in ALICIA (Applied Intelligence in bloCkchaIn vAnet).,Algorithms/ Methods Construction or Optimization
287,"Hyperledger Fabric (HF), a blockchain platform established as part of the Hyperledger Project, is often used to implement the architecture, and uses the Practical Byzantine Fault Tolerance (PBFT) method to reach consensus because adding transactions to the blockchain does not need a large amount of computing capacity.",Algorithms/ Methods Construction or Optimization
288,The use of a decentralized authority to control multi-service networks and also this framework analyzes the offer and estimates the product price based on transaction complexity and computational effort.,Model Construction or Optimization
289,A hybrid Blockchain mechanism for securing a multi-national level IIoT with offices in different areas.,Applications
290,Utilize an off-chain storing mechanism to improve the scalability of the blockchain system.,Performance Evaluation
291,Develop a Decentralized Application (DApp) using Ethereum blockchain as a proof-of-concept of the proposed architecture.,Algorithms/ Methods Construction or Optimization
292,"Conduct numerous tests to check the viability, compute costs, measure execution times and gauge the scalability of the developed prototypical DApp.",Performance Evaluation
293,Analyze the robustness of the developed DApp against the most widespread security attacks.,Performance Evaluation
294,Utilize an off-chain storing mechanism to improve the scalability of the blockchain system.,Theory Proposal
295,Introduce a novel blockchain-based pragmatic architecture for secure sharing of studentsвЂ™ credentials among all the stakeholders in the education ecosystem.,Model Construction or Optimization
296,The blockchain technology to improve the information availability and accountability across multiple hops of large supply chains while carefully gauging data privacy and transparency.,Theory Proposal
297,"This research proposes an approach to encountering online review helpfulness problem from three qualitative perspectives - lexical, sequential and structural, with best of our knowledge, this is the first time in the literature where helpfulness of reviews is analysed from these perspectives.",Theory Proposal
298,The study implements a Dual CNN (D-CNN) model for analysing lexical perspective.,Dataset Creation or Resources
299,Structural perspective covers syntactic statistics of a review apart from the semantics of words.,Dataset Creation or Resources
300,This work addresses the discrepancies involved in the helpfulness voting mechanism by scoring reviews with human volunteers.,Theory Proposal
301,Temporal Changes in query activity is used for improving the result caching performance.,Theory Proposal
302,A new caching framework exploiting temporal variations in user query submissions is proposed.,Model Construction or Optimization
303,The proposed framework improves both hit rate and response time.,Model Construction or Optimization
304,The proposed technique is transferable to posting list caching and intersection caching.,Theory Proposal
305,QLLog can detect multiple types of log anomalies to reduce the false negative rate.,Theory Proposal
306,QLLog provides a feedback mechanism to update the detection model and the abnormal level of abnormal logs.,Model Construction or Optimization
307,"We summarize the existing log anomaly detection methods, compare and analyze the advantages and disadvantages of them. The experimental result proves the superiority of QLLog.",Algorithms/ Methods Construction or Optimization
308,"We propose a novel blockchain-based scheme, which securely executes the royalty transactions among various stakeholders in (OaG) industries.",Model Construction or Optimization
309,A new consensus mechanism Proof of Property (PoP) is designed for secure transaction between (OaG) company and landowners.,Model Construction or Optimization
310,We then analysed and compared the performance of the proposed scheme of royalty contract transactions with the existing state-of-the art proposals.,Performance Evaluation
311,The performance of the proposed scheme is validated using various security parameters in comparison to the existing methods.,Performance Evaluation
312,Identifying innovative ideas from different online reviews using deep learning,Applications
313,The long short-term memory (LSTM) model is used for identifying the innovation sentences,Model Construction or Optimization
314,"Validation of the model is done bys using Amazon reviews of 10,000 customers as it outperofrms baseline model",Performance Evaluation
315,This is the first to study the problem of co-clustering nodes on attributed HINs,Model Construction or Optimization
316,A Framework called as SCCAIN used to effectively co-cluster nodes of different types at the same time.,Model Construction or Optimization
317,"Aminer, DBLP, and a subset of the Alibaba consumer experience dataset were used in tests on three real-world datasets. SCCAIN is compared to different state-of-the-art models, and the experimental findings show that our model outperforms the baselines.",Performance Evaluation
318,Set the relevance matrix as sharing variables to improve the overall relevance metric and co-clustering.,Performance Evaluation
319,A network and domain-based algorithm (NDDSA) that assigns a score to each side effect to predict the side effects of new drug candidates before reaching the a clinical test,Algorithms/ Methods Construction or Optimization
320,A framework for understanding how eHealth literacy and content valence can affect users' willingness to post health articles on social media was proposed,Model Construction or Optimization
321,Users with a high level of eHealth literacy are more likely to share positive health articles when they have extreme confirmation bias.,Theory Proposal
322,Users with a high level of eHealth literacy are more likely to share negative health articles when they have moderate confirmation bias or no confirmation bias.,Theory Proposal
323,Users with a low level of eHealth literacy are more likely to share health articles regardless of positive or negative content valence when they have moderate positive confirmation bias.,Theory Proposal
324,"we propose blockchain-based privacy-preserving remote data integrity checking scheme without TTP, then we emphasize that our scheme is immune to privacy leakage from the third party and to collusion attacks of the cloud servers and the third party",Theory Proposal
325,"Our scheme establishes a model based on the blockchain technology (a public distributed ledger). Once reaching the consensus, everyone, including the verifier, has the access to query the proof of the data for unlimited times from the blockchain, and cannot manipulate the data on the blockchain",Model Construction or Optimization
326,"Our scheme provides a solution to ensure the privacy-preserving public verification as well as the batch verification for multi-user data or multi-data simultaneously. It is secure against the malicious server and immune to the delayed auditor. Otherwise, it reduces the cost of the communication and storage",Model Construction or Optimization
327,Blockchain-based privacy-preserving remote data integrity checking scheme for IoT information systems,Dataset Creation or Resources
328,define and solve the social influence based community detection problem in EBSNs,Dataset Creation or Resources
329,"propose to compute the structure-based social influence and behaviour-based social influence by considering both of the online social network structure and offline behaviours of EBSNs. In particular, we adopt the neighborhood overlap ratio between a pair of linked users to measure the structure-based social influence, and utilize the similarities of preferences on three aspects (i.e., topics, regions and organizers) through usersвЂ™ offline behaviours to measure the behaviour-based social influence",Theory Proposal
330,"Based on the obtained pairwise social influence, we devise a social influence based community detection (SICD) algorithm, in which a neighborhood based deep autoencoder is first proposed to learn the community-oriented latent representations of users, and then the widely used k-means clustering method is utilized to find communities.",Algorithms/ Methods Construction or Optimization
331,"evaluate the performance of our community detection algorithm on real-world dataset which is collected from DoubanEvent (i.e., the biggest event-based social network in China). Experimental results show that the proposed algorithm is suitable for community detection in EBSNs",Performance Evaluation
332,"the first time in the literature, we propose to learn the importance of aspects by re-ranking the candidate set for each aspect and leveraging QPPs. In the closest work to ours in the literature, Ozdemiray and Altingovde (2014) directly employed such QPP estimates as the aspect importance values, but they did not explore the idea of training a model to predict these values, as we do in the AspectRanker framework.",Theory Proposal
333,"adapt the LambdaMerge approach to search result diversification casting the diversification problem as a fusion task, namely the supervised merging of rankings per query aspect. Again, earlier works only considered traditional (unsupervised) merging strategies in this context (e.g., Ozdemiray & Altingovde, 2015), but did not exploit supervised learning. In our adaptation of LambdaMerge, we learn the aspectsвЂ™ importance based on the representation quality of each aspect in the candidate set (as in AspectRanker), and we optimize an objective function that takes into account the relevance (of a document) to multiple aspects of a query.",Algorithms/ Methods Construction or Optimization
334,"proposed frameworks, especially AspectRanker and LmDiv, outperform all three baselines in terms of various well-known metrics",Model Construction or Optimization
335,"the extractive text summarization was handled by three objectives based on the summarization dataset, the feature space and the methods used for determining an importance degree to sentences.",Algorithms/ Methods Construction or Optimization
336,"new benchmark dataset for studies on automatic text summarization, which contains both human-generated abstracts and extracts, was proposed",Dataset Creation or Resources
337,The extractive summarization problem was revisited,Dataset Creation or Resources
338,The syntactic and semantic feature spaces used in summarization were comprehensively investigated.,Performance Evaluation
339,An ensembled feature space was introduced on a new long short-term memory-based neural network model (LSTM-NN).,Model Construction or Optimization
340,"Experimental results showed that the use of ensemble feature space remarkably improved the single-use of syntactic or semantic features, and the proposed LSTM-NN also outperformed the state-of-the-art models for extractive summarization",Performance Evaluation
341,"We provide an inclusive, intelligent, semi-auto-constructed knowledge graph framework HKGB for the medical domain to build knowledge graphs.",Model Construction or Optimization
342,"We analyze the capabilities and requirements of clinicians, design the tasks to involve the clinicians, and implement a clinician-in-the-loop tool set.",Theory Proposal
343,We design an extensible mechanism to add a new disease to an existing knowledge graph,Model Construction or Optimization
344,We present a quantitative effort estimation algorithm to quantitatively evaluate the effort of clinicians who are involved,Algorithms/ Methods Construction or Optimization
345,"We create a health knowledge graph HuadingKG by HKGB, and develop three tools to apply HuadingKG in real applications.",Algorithms/ Methods Construction or Optimization
346,Introducing a robust decision-making procedure for selecting a model to explain the dynamic conversation topics. We design an adaptive framework to use gained knowledge for improving the results over time.,Model Construction or Optimization
347,Using neural network transfer learning techniques to enhance the framework ability to detect unrelated messages over twitter data streams.,Algorithms/ Methods Construction or Optimization
348,Create an automatic deep cleaning method to enhance the quality of data to perform better classification in a noisy environment.,Algorithms/ Methods Construction or Optimization
349,We present an extensive review of the state of the art in misogyny detection.,Dataset Creation or Resources
350,"We propose a state-of-the-art model to detect misogyny in social media, and test it on several benchmark datasets.",Model Construction or Optimization
351,We investigate the most predictive features to distinguish misogynistic content from not-misogynistic content.,Model Construction or Optimization
352,"We investigate the relationship between misogyny and other abusive phenomena by conducting a cross-domain classification setting, leveraging the knowledge transfer from other kinds of hateful language to detect misogyny and vice versa.",Theory Proposal
353,"We present the results of experiments in a cross-lingual setting, aiming at learning and generalizing knowledge about misogyny over datasets in different languages.",Dataset Creation or Resources
354,Information Extraction from Text Intensive and Visually Rich Banking Documents,Dataset Creation or Resources
355,First study to investigate deep learning algorithms in banking document understanding,Algorithms/ Methods Construction or Optimization
356,Automation of customer banking order documents reduced cycle times significantly,Theory Proposal
357,Investigated traditional and deep learning approaches in noisy text NER,Algorithms/ Methods Construction or Optimization
358,Novel graph-based complex relation extraction algorithm outperforms previous methods,Performance Evaluation
359,"N-ary, nested, document-level, and previously indeterminate quantity of complex relations extracted successfully",Algorithms/ Methods Construction or Optimization
360,Incorporating document layout information improves performances substantially,Dataset Creation or Resources
361,Relation gated LSTM (R-LSTM) architecture that uses an additional control input to regulate the LSTM hidden state,Model Construction or Optimization
362,Typed Dependency Tree-LSTM model using R-LSTMs for learning sentence semantic representation over the dependency parse tree.,Model Construction or Optimization
363,A qualitative analysis of the role of typed dependencies in language understanding,Theory Proposal
364,propose a novel neighborhood-based recommendation model. The core component of the model is a hybrid gated network that is invulnerable to neighborhood noises when exploiting neighborhood information for recommendation,Model Construction or Optimization
365,"first automatically separates similar neighbors from the dissimilar ones with a thresholding mechanism, and only aggregates those similar neighbors to produce the neighborhood representations. Then, it further filters out noises in the neighborhood by pooling representations of users and their neighborhood while considering the confidence level of the neighborhood information. Therefore, we are able to select the most informative neighbors and encode the credibility of neighborhood information for recommendation.",Model Construction or Optimization
366,"We explicitly preserve user-neighbor proximity for learning compact user representations. The user-neighbor similarities are captured by predicting users with their neighbors. Since the neighborhood representations are parameterized by the users, neighbors and the target items, user representations are learned by attending to the informative neighbors and specified for the recommendation task. We integrate the hybrid gated network and user-neighbor proximity components into a unified model, where they can mutually complement and reinforce each other to enhance the recommendation performance.",Model Construction or Optimization
367,"validate the effectiveness of the proposed model with three public datasets, and demonstrate its advantage over the state-of-the-art models. We also study different variants of the proposed model to justify the intuitions underlying each of its components.",Performance Evaluation
368,"stakeholder categorization and the topic analysis, resulting in a deeper understanding of privacy concerns of each type of stakeholders",Theory Proposal
369,"in an open social media platform, a variety of other stakeholders such as experts, privacy advocates, patient groups can also demonstrate their concerns, which demonstrates the feasibility of using social media for collecting views and opinions in this context",Theory Proposal
370,"We explore a new problem of Speakers Coreference Resolution in legal texts, and provide annotated dataset for further research.",Dataset Creation or Resources
371,"We investigate two different solutions to resolve coreference, and create document-level graphs to integrate contextual information. It enables us to effectively establish dependencies between entities and avoid making locally consistent but globally inconsistent decisions",Theory Proposal
372,"The proposed method achieves competitive performance, outperforming the baseline systems by a large margin, which can be applied in many downstream tasks such as question answering and text understanding.",Algorithms/ Methods Construction or Optimization
373,"We introduce GENE, a method for generating user networks conditioned on the joint representation of users, entities, and the inclination of users towards those entities (positive, neutral or negative).",Algorithms/ Methods Construction or Optimization
374,"Extensive experiments indicate that for the task of controversy detection, GENE creates a rich representation of user networks, conditioned on polarized entities, that outperforms both lexicon-based methods as well as graph representations which do not exploit the entities and polarization contexts.",Performance Evaluation
375,"In an early controversy detection setting,В GENEВ also shows superior performance compared to other methods, favoring the early forecast of polarization in a user network and the characterization of a scenario for the emergence of controversy",Performance Evaluation
376,We release a new dataset that includes news and conversational threads from which this study was conducted,Dataset Creation or Resources
377,Moment matching and geometry alignment are leveraged in a unified framework to handle multi-source domain adaptation problems,Model Construction or Optimization
378,"The first-order MMDs measure the discrepancies between different domains, while Laplacian graphs are constructed to preserve the geometric structure. Specifically, MMDs are minimized to reduce the distribution gap of the source and target domains, while the similarity and discriminability of sample relationship are preserved in the designed undirected graphs",Model Construction or Optimization
379,Both of moment matching and geometry alignment facilitate to learn a domain-invariant subspace where knowledge can be transferred across domains in the learned subspace.,Theory Proposal
380,"Based on the new representations learned in the common feature subspace, we propose two strategies (ALP-u and ALP-s) for pseudo-labeling in both low-dimensional subspace and high-dimensional RKHS. Predictions based on low-dimensional subspace avoid the curse of dimensionality (Duda, Hart, & Stork, 2012), while predictions on high-dimensional RKHS prevents the model from losing information in dimensionality reduction. Therefore, the accurate label prediction facilitate to update the subspace learning.",Algorithms/ Methods Construction or Optimization
381,"We carry out extensive experiments to demonstrate the effectiveness of ALP-u and ALP-s on different domain adaptation scenarios, including traditional single-source-to-single-target, multi-sources-to-single-target and multi-sources-to-multi-targets. Our work surpasses state-of-the-arts on three benchmark datasets notably.",Applications
382,"A novel broad-coverage, domain-independent, unsupervised phonetic encoder for Roman Hindi/Urdu word normalization is presented, which utilizes a transliteration based approach to assign the same matching code to lexical variations of a Roman Urdu word. This technique is referred to as the Transliteration based Encoding technique for Roman Urdu word Normalization (TERUN",Algorithms/ Methods Construction or Optimization
383,The impact of word standardization on Roman Urdu sentiment analysis classification accuracy is evaluated using TERUN and other established techniques.,Performance Evaluation
384,"TERUN outperformed the other techniques: Soundex, Metaphone, Double-Metaphone, Caverphone, New York State Identification and Intelligence System (NYSIIS) and KГ¶lner Phonetik (Kph), using accuracy as a performance measure. Also, statistical tests (t-test and confidence interval) show that the improvements are statistically significant.",Performance Evaluation
385,"TERUN and other established encoding techniques are intrinsically evaluated using 20,000 lexically variant words. The results clearly show the superiority of TERUN over the other encoding techniques.",Performance Evaluation
386,"TERUN is also extended from a corpus dependent to a broad-coverage corpus independent Roman Urdu word normalization technique. To do this, a dataset of 50,000 of the most frequent Urdu words was collected and annotated to a standard Roman form using comprehensive annotation guidelines defined explicitly for this purpose.",Dataset Creation or Resources
387,"The proposition of Drink2Vec and an assessment on the most effective way to integrate distributional semantics with external enrichment contextual strategies to improve the classification of alcohol-related tweets. Drink2Vec encompasses Drink2Symbol, a method that evolved from our previous work (GrzeГ§a et al., 2018",Algorithms/ Methods Construction or Optimization
388,"We demonstrate that drinking embeddings capture interesting nuances of alcohol consumption vocabulary, and that a stacking ensemble (Drink2Ensemble) balances the strengths of each method. Using our techniques, we outperformed existing baselines (GrzeГ§a, Becker, Galante, 2018, Hossain, Hu, Feizi, White, Luo, Kautz, 2016). These methods can be adapted to several other domains, such as the consumption of other types of drugs, gender and social harassment, gender discrimination or violence, flame or hate, among others;",Performance Evaluation
389,"An evaluation of the contribution of the underlying contextual enrichment strategies to this classification problem according to a broad experimental setting. It encompasses distinct classifiers used in winning solutions on Kaggle competitions, five datasets addressing different alcohol consumption behaviors, and an in-depth analysis of the contributions of each contextual enrichment strategy to alcohol-related texting, and their integration.",Performance Evaluation
390,"Two new datasets containing tweets mentioning alcohol and its consumption, which can be used in future studies related to the classification of alcohol-related tweets.",Dataset Creation or Resources
391,A prevention system to Fake News rather than only a detection system,Theory Proposal
392,A customized Proof-of-Authority protocol,Theory Proposal
393,An applicable scenario of Blockchain technology outside of its financial roots,Theory Proposal
394,"We define a new application-oriented variation of the event relatedness classification task, which merges different fine-grained event relation types reported elsewhere into one concept, and which focuses on linking automatically extracted event templates, potentially containing erroneous and incomplete information,",Model Construction or Optimization
395,"We explore and compare the relatedness classification performance on this new task across a range of shallow learning methods (including the current state-of-the-art methods) built on a set of linguistically lightweight features (some of which not presented elsewhere, e.g. HypernymOverlap via exploitation of BabelNet), being easily portable across languages,",Performance Evaluation
396,"We provide initial results of exploiting deep learning techniques for this purpose, and",Theory Proposal
397,We create and make available to the research community a new moderate-size event corpus annotated with event relatedness information that appears bigger than other relevant resources made available to the community.,Dataset Creation or Resources
398,a framework to analyze the emotional reactions on Twitter to mass violence events,Model Construction or Optimization
399,"The framework encompasses different aspects of the analysis: crawling of representative pre/post-event tweets, inference of usersвЂ™ demographics and location, and emotion classification. The framework addresses gaps of related work, which are limited to sentiment polarity mostly using sentiment lexicons, disregard the intrinsic properties of the users and the events, and typically address a single mass violent event",Model Construction or Optimization
400,"The framework could be used to derive conclusions on the emotional reactions to all sorts of mass traumatic events (e.g., pandemics, urban violence, natural disasters).",Applications
401,"new insights on the emotional impact to mass shootings, which detail the prevalent basic emotions, and their relation to age, gender and proximity to the event. The findings could be generalized due to the use of eight mass shooting events. As a by-product, we produced datasets publicly available under the terms established by current Twitter Data Policy. The datasets comprise the tweets analyzed, the automatically labeled instances used as training sets, and a manually annotated Gold Standard.",Dataset Creation or Resources
402,"a technique to automatically generate training seeds for the mass violence domain, and experiments with three deep learning strategies to develop an emotion classifier. CNN and biLSTM correspond to tailored solutions that explore distinct learning premises, and BERT represents a new tendency on NLP of developing models by fine-tuning large language representation models",Performance Evaluation
403,We assessed these modelsвЂ™ performance and analyzed the influential features for classification using model explainability scores. The guidelines provided by our work for emotion classification may encourage wider adoption of deep learning models for social studies that leverage emotion mining on Twitter data.,Performance Evaluation
404,"We propose an entity-aware enhanced word representation with rich context, which enables the downstream modules to learn robust semantic features",Algorithms/ Methods Construction or Optimization
405,"We combine the global gate structure and the PCNN (Zeng,В Liu, Chen, & Zhao, 2015) to better capture the global and local features of the sentence.",Algorithms/ Methods Construction or Optimization
406,"We introduce a gate mechanism after the max-pooling layer of the PCNN model, which assigns different weights to the three segments and highlights the effects of crucial segments.",Model Construction or Optimization
407,Our model is evaluated on a widely used benchmark dataset and outperforms most of the state-of-the-art methods.,Performance Evaluation
408,We propose a semantic rebasing mechanism to learn a sparse semantic graph structure over the training set to preserve similarity information shared by different modalities for binary code learning after geometric graph construction,Model Construction or Optimization
409,"Different from those existing unsupervised cross-modal hashing methods, our method focus on both similarity preserving and quantization to gain satisfied retrieval performance. Besides, the auto-encoding structure is included to improve our model, which is seldom used in cross-modal hashing.",Algorithms/ Methods Construction or Optimization
410,"Comprehensive experimental evaluations are conducted on four popular datasets, including (RasiwasiaВ etВ al., 2010), MIRFlickr-25KВ (Huiskes & Lew,В 2008), MSCOCOВ (LinВ etВ al., 2014) and NUS-WIDEВ (ChuaВ etВ al., 2009), showing the proposed model significantly outperforms the state-of-the-art unsupervised methods.",Performance Evaluation
411,"his paper reviews the existing microblog user geolocalisation methods, and summarizes a general framework for microblog user geolocalisation. Along with the framework, we review the studies on user geolocalisation from the aspects of data acquisition, data preprocessing, location representation, user geolocalisation methods categorization, and evaluation metrics.",Model Construction or Optimization
412,"Based on the input of the geolocalisation algorithm, we categorize microblog user geolocalisation methods into three categories: text-based methods, network-based methods, and multi-view based methods. We summarize the advantages and limitations of each type of method theoretically.",Algorithms/ Methods Construction or Optimization
413,We conduct a performance comparison of existing methods based on the results reported in existing literature with the most widely used real-world datasets and evaluation metrics. The advantages and disadvantages of existing methods are further uncovered by comparing them experimentally. Important research challenges that may need further attention are discussed according to our analysis.,Performance Evaluation
414,"Survey findings conclude that multiview-based methods are superior to the text-based methods as well as the network-based methods. Besides that, existing user geolocalisation methods cannot capture the user's home location change, resulting in the misjudged results. Also, how to locate users from multiple social platforms is relatively unaddressed. Hence, the geolocalization of users across multiple social platforms is one of the problems that deserve further research.",Performance Evaluation
415,A review on the methodological and psychometric quality of both the instruments for consumer health information needs and those for patient needs that contained health information needs sections was conducted;,Algorithms/ Methods Construction or Optimization
416,A two-phase literature search strategy was applied to retrieve relevant validation studies;,Theory Proposal
417,"Overall, both groups of questionnaire instruments were not well developed: only structural validity, internal consistency tests and content validity analysis were performed in about 50 percent of them, while other types of validations were missing in most of them;",Algorithms/ Methods Construction or Optimization
418,Instruments used for assessing patient needs were found to have better tests of construct validity and handling of floor and ceiling effects;,Theory Proposal
419,Theories and frameworks of information needs can be integrated within the development process to improve the design.,Theory Proposal
420,GSR measure tailored for SEs and its evaluation within the construct validity framework;,Model Construction or Optimization
421,"audit, in terms of GSR, of several widely-known and used ranking algorithms;",Algorithms/ Methods Construction or Optimization
422,"estimation of the impact of different WE debiasing approaches, both on ranking effectiveness and countering gender bias.",Model Construction or Optimization
423,Proposing a robust and non-convex semi-supervised solution to the opinion spam detection problem.,Algorithms/ Methods Construction or Optimization
424,Introducing Ramp loss function to decrease the effect of outliers and non-review opinions on the decision boundary of OC-SVM classifier.,Algorithms/ Methods Construction or Optimization
425,Only 3.2% of the reviewed articles defined consumer health information needs (CHIN).,Theory Proposal
426,All definitions defined CHIN from a cognitive perspective.,Dataset Creation or Resources
427,Emotional and social dimensions of CHIN were largely ignored in the included studies.,Theory Proposal
428,There was a lack of consensus in measuring CHIN among studies.,Theory Proposal
429,Health topics needed was the most commonly measured aspect.,Theory Proposal
430,Information needs are described as task-based activities.,Theory Proposal
431,Task-based information needs are dependent of both individual characteristics and work task context.,Theory Proposal
432,We introduce a novel differentiation between horizontal and vertical relationships for information needs.,Theory Proposal
433,Need of migrating from token-based representations to synset-based ones to achieve better performance on spam filtering.,Performance Evaluation
434,Review of current synset-based feature reduction schemes and representations.,Theory Proposal
435,Introducing SDRS feature reduction process based on the usage of NSGA-II algoritm and semantic taxonomic relations between tokens,Algorithms/ Methods Construction or Optimization
436,Design and execute a experimental protocol to test the suitability of SDRS dimensionality reduction method.,Performance Evaluation
437,Detecting shape of expertise is a practical and industry-motivated problem.,Theory Proposal
438,A CNN-based model was proposed in this study to detect usersвЂ™ shape of expertise.,Model Construction or Optimization
439,The proposed method is based on matching both latent vectors of users and queries.,Algorithms/ Methods Construction or Optimization
440,Social endorsement strongly negatively moderates the relationship between willingness to pay and payment behavior.,Theory Proposal
441,"Perceived quality of free content, perceived credibility of content creators, and perceived quantity of participants positively influence usersвЂ™ willingness to pay.",Theory Proposal
442,Perceived likeability of content creators has no significant influence on usersвЂ™ willingness to pay.,Theory Proposal
443,The relationship between perceived likeability of content creators and willingness to pay could be mediated by perceived credibility of content creators.,Theory Proposal
444,A novel method called CBRDQ is proposed to measure the qualities of investor sentiments about a specific stock.,Algorithms/ Methods Construction or Optimization
445,Different quality assessment methods are compared in a unifying stock recommendation framework.,Performance Evaluation
446,The proposed method is more appropriate for deriving sensible investment decisions than baselines.,Algorithms/ Methods Construction or Optimization
447,The effectiveness of CBRDQ confirms the variation of investorsвЂ™ expertise in different stocks.,Theory Proposal
448,Findings in this study have implications for trading practice and judgment of the quality of a review.,Theory Proposal
449,"Based on both technical indicators and news sentiments, the LSTM models outperform the MKL and the SVM in both prediction accuracy and F1 score.",Model Construction or Optimization
450,"The LSTM models incorporating both information sources outperform the models that only use either technical indicators or news sentiments, in both individual stock level and sector level.",Model Construction or Optimization
451,"Among the four sentiment dictionaries, finance domain specific sentiment dictionary (Loughran-McDonald Financial Dictionary) models the new sentiments better, which brings at most 120% prediction performance improvement, comparing with the other three dictionaries",Performance Evaluation
452,This paper investigates the effects of emotions in social media (ESM) on the stock market during the market crash using a cognition-based framework.,Model Construction or Optimization
453,"It is verified that ESM firstly influence the market cognition, and then influence the stock market during the market crash.",Theory Proposal
454,High arousal ESM increases the probability of market cognition of a crash state both in-crash and post-crash periods.,Theory Proposal
455,Positive valence ESM adjusts the market cognition to the stable state only in the later stage of the market crash,Theory Proposal
456,вЂњFearвЂќ and вЂњDisgustвЂќ are the two significant sub-categorical emotions correlated with the market cognition during the market crash.,Theory Proposal
457,"the model is built based on prior work on web credibility assessment and tested in the special case of good abandonment, which supplies an empirical validation to the existing theories of credibility study",Model Construction or Optimization
458,"he proposed model is validated and improved by search behavior in the scenario of good abandonment, which fills in the gap of understanding good abandonment behavior",Performance Evaluation
459,the difference of credibility assessment criteria between the proposed model and other models inspires the UI/UX design of the result page in different search scenarios.,Performance Evaluation
460,A novel topic-mining method is proposed to identify initiatorsвЂ™ intentions from a plethora of project descriptions.,Algorithms/ Methods Construction or Optimization
461,The spatial allocation of donations is investigated by exploring the spatial patterns of cross-regional donation flows.,Algorithms/ Methods Construction or Optimization
462,Most of the donations are used to fund neglected children in rural areas and neglected elders.,Theory Proposal
463,The flow of donations is not equitably distributed and tends to be concentrated in a few relatively developed regions.,Theory Proposal
464,Benefits of wikipedia for the automatic generation of educational domain modules.,Theory Proposal
465,A new representation formalism for multilingual domain modules.,Theory Proposal
466,Characteristics of wikipedia for identifying multilingual domain topics.,Theory Proposal
467,Characteristics of wikipedia for identifying pedagogical relationships among topics.,Theory Proposal
468,Characteristics of wikipedia for identifying multilingual learning objects.,Theory Proposal
469,Development of an analysis of how Wikipedia disease-related articles in English evolve over time.,Theory Proposal
470,"Historical information is extracted from the articles and how their content (references, characters, diagnostic-related terms) change over time is analysed",Dataset Creation or Resources
471,Most of the articles increase their content through time and this is not influenced by the number of references.,Theory Proposal
472,Hot topics/diseases attract highest number of editions and views.,Theory Proposal
473,"Less well-known diseases have abrupt changes, which might be consequence of having new knowledge about them.",Theory Proposal
474,We present an efficient strategy for augmenting existing paraphrase and non-paraphrase annotations in a consistent manner. This strategy generates additional annotations and enhances the performance of the data-hungry deep learning models.,Dataset Creation or Resources
475,We develop a multi-cascaded learning model for robust paraphrase detection in both clean and noisy texts. This model incorporates multiple learned and linguistic features in a wide and deep network for paraphrase detection.,Model Construction or Optimization
476,We address both clean and noisy texts in our presentation and show that the proposed model matches current best performances on benchmark datasets of both types.,Performance Evaluation
477,We analyze the impact of various data augmentation steps and different components of the multi-cascaded model on paraphrase detection performance.,Theory Proposal
478,We address the problem of generating SRs from spatial data streams and static data in real-time. This problem is related to computing topological relationships and distances between spatial objects in a timely manner. Our work is the first attempt to utilize hierarchical tree structures such as R-tree for generating SRs.,Algorithms/ Methods Construction or Optimization
479,We design a novel index structure based on R-tree with RRs called R3 index to store spatial objects and support SR generation. We devise an efficient and effective algorithm that leverages relationships and distances between the RRs to filter candidate objects and generate SRs.,Algorithms/ Methods Construction or Optimization
480,We evaluate the performance of the proposed approach using real-world datasets and report on the efficiency and effectiveness of the proposed approach.,Performance Evaluation
481,Heuristic operators are proposed for interesting class association rule mining.,Algorithms/ Methods Construction or Optimization
482,Our proposal remains focused and avoids the exponential curse of other alternatives.,Theory Proposal
483,Generated rule sets are more attractive for the subsequent expert inspection.,Theory Proposal
484,Interesting descriptions of certain colorectal cancer cases were obtained.,Theory Proposal
485,Infection diagnosis is critical in social environments; otherwise diseases may spread fast.,Theory Proposal
486,Clinical decision support system was developed for infection diagnosis in nursing homes using small data; AUROC of 0.734 achieved.,Theory Proposal
487,"In small data environments, external sources of data can improve diagnosis performance with little cost.",Theory Proposal
488,"When considering additional data (social data and weather information), AUROC increases up to 0.798.",Theory Proposal
489,"For diagnosis, smaller leads (historical data) is preferred, but larger leads improve the results when adding social data.",Theory Proposal
490,Umrah is a Religious ritual that can happen any time in the year. Many people gather in the holy city of Makkah in Saudi Arabia which represents a health hazard.,Theory Proposal
491,It is difficult to identify crowding seasons for Umrah.,Theory Proposal
492,Google Trends has been used in research to track people interest. It is used in this research to find Umrah monthly seasonality,Dataset Creation or Resources
493,Mass gathering is considered as intensifying factor for flu outbreaks,Theory Proposal
494,"In the Eastern Province of Saudi Arabia, there are seasons with more Umrah performers according to Google Trends. Mainly in the months of Rajab (7thВ month) and Ramadan (9thВ month), and ThuAlqidah (11thВ month) in the Islamic Lunar calendar.",Theory Proposal
495,The research found a correlation between these months and flu cases reported in the Province hospital. Peaks were noticed three months after seasons of gatherings,Theory Proposal
496,The paper provides a practical guideline on the effective features to use in the feature engineering paradigm for Chinese medical literature section identification. We also show that this traditional approach performs very well in this task as compared with deep learning methods,Algorithms/ Methods Construction or Optimization
497,The paper shows that it is important to consider the dependencies between sentences for section identification in both feature engineering and deep learning approaches,Algorithms/ Methods Construction or Optimization
498,"The deep learning model outperforms traditional models when this feature is considered. Although the dependencies of sentences are considered in previous feature engineering studies for section identification, they were not studied in a deep learning context. Moreover, most previous studies taking this approach are based on short texts, such as abstracts. Our study increases the generalizability of this finding to the full text of Chinese traditional medical documents",Performance Evaluation
499,"This paper proposes a SLSTM deep learning model that is very effective for section identification. While we believe there exist other more effective models to be explored in future research, our study shows the potential of this particular model, which may be applicable to other generic sentence classification problems.",Model Construction or Optimization
500,"We propose Rule Assembler, a configurable approach that is able to classify duplicate entities based on confidence scores, taking into account tunable parameters as well as user preferences;",Theory Proposal
501,"We propose four heuristics for turning the results produced by logical rules into confidence scores (i.e., a continuous quantification associated with the confidence produced by the rule regarding the duplicity of the entity pairs);",Theory Proposal
502,We propose a novel auto-tuning algorithm for classifying duplicate entities based on confidence scores;,Algorithms/ Methods Construction or Optimization
503,We propose an efficient algorithm for tuning the parameters of the Rule Assembler (considering scenarios in which training data is available);,Algorithms/ Methods Construction or Optimization
504,"We present an experimental evaluation of the proposed approach using both real-world and synthetic datasets, which indicates the usefulness and efficiency of the proposed approach, as well as its capacity to improve the results produced by baseline RbER algorithms in DNF and by the basic assembly approach (voting)",Performance Evaluation
505,"Four biomedical areas, including general and internal medicine and complementary and alternative medicine receive more Facebook attention.",Theory Proposal
506,No biomedical areas receive little Facebook attention.,Theory Proposal
507,The relationship between Facebook mentions and citations varies by field and public interest.,Theory Proposal
508,Facebook mentions predict future citations less well for fields with variable public interest.,Theory Proposal
509,We propose a model for live streaming recommendation to improve performance.,Model Construction or Optimization
510,We address the problem of how to simultaneously make predictions from both viewer and anchor sides.,Theory Proposal
511,We develop multiple mechanisms to help the two sides learn from each other to enhance mutual learning.,Model Construction or Optimization
512,Experiment study demonstrates the effectiveness of the proposed model and mechanisms.,Performance Evaluation
513,The objective of this study is to systematically investigate the determinants of successful medical crowdfunding projects in China by conducting a mixed-methods approach.,Algorithms/ Methods Construction or Optimization
514,Health-related characteristics were found to be the most significant trigger influencing the success of medical crowdfunding in China.,Theory Proposal
515,A number of demographic and social factors are also significantly related to the success of medical crowdfunding in China.,Theory Proposal
516,The study sheds light on the localized practices of medical crowdfunding in China with global insights.,Dataset Creation or Resources
517,Confidential information provenance for mHealth technologies.,Theory Proposal
518,Distributed data management via consortium blockchains.,Dataset Creation or Resources
519,Confidential smart-contract execution via trusted execution environments.,Dataset Creation or Resources
520,"В research of data behavior generated by smart contracts and users in Ethereum, including the trend of Balance and the changes of Ether, transaction activities generated by users and smart contracts.",Theory Proposal
521,"ased on our analysis of these contracts, we find that the transaction behavior has independent characteristics between different types of contracts",Theory Proposal
522,"We collected more than 10,000 smart contracts from Ethereum and manually analyzed the behavior of their transactions. We finally find out four behavior patterns that can help us to have a better understanding of the contractsвЂ™ transaction behavior, and they could be used to distinguish different types of contracts.",Theory Proposal
523,"To further research on this topic, we constructed 14 basic features to describe the transaction behavior. They are time-series data and constructed based on the major activities of a contract.",Algorithms/ Methods Construction or Optimization
524,We propose a data slicing approach for slicing the collected smart contracts to solve the problem of insufficient datasets. Then we use them for training an LSTM network and the results show the effectiveness of our approach.,Algorithms/ Methods Construction or Optimization
525,"In the academic context, focused on the peer seeking behavior in pages, movements and pathways from experimental situation.",Theory Proposal
526,"Three types for pathways are identified by cluster analysis, combined with questionnaires and interviews.",Algorithms/ Methods Construction or Optimization
527,The search intensions have an impact on the different pathways.,Theory Proposal
528,Implications for the interface design of ASNS are proposed based on the characteristics of searching process.,Theory Proposal
529,his paper addresses the problem of victim item deletion based sensitive pattern hiding using PSO.,Algorithms/ Methods Construction or Optimization
530,"In VIDPSO algorithm, victim items are chosen based on their participation in sensitive patterns. The priority is given to the item appearing in more number of sensitive patterns. Hence, the deletion of one victim item from a specified number of transactions masks more than one sensitive pattern. Therefore, it incurs less data loss.",Algorithms/ Methods Construction or Optimization
531,"In the dense dataset, the support count values of itemsets are generally high. Therefore, a large number of transactions need to be deleted to hide sensitive itemsets, which causes high misses cost and data loss. The proposed algorithm hides the sensitive patterns from dense datasets with less data loss and misses cost.",Algorithms/ Methods Construction or Optimization
532,"The deletion of transactions reduces the size of the dataset and also the value of minimum support count. So, it does not reduce the support count of itemsets large enough to convert sensitive frequent itemsets into infrequent ones, which leads to high hiding failure, especially in dense datasets. Hence, VIDPSO proves to be an effective algorithm to hide sensitive itemsets.",Performance Evaluation
533,The proposed VIDPSO algorithm has more exploration capability gained by introducing the idea of traversing new paths (transactions) in the velocity updating method. It helps to find an optimal solution with fast convergence.,Applications
534,Emotion-based approach for efficient search and media management represents an important part of personalized music information retrieval.,Theory Proposal
535,Efficient system for detecting affective music content on a dimensional model of emotions is developed.,Model Construction or Optimization
536,Proposed approach uses human cochlear model and Convolutional neural network to extract relevant music features.,Model Construction or Optimization
537,The experimental results prove the effectiveness of our proposal in all aspects of music emotion recognition.,Performance Evaluation
538,The transformative computing in advanced data analysis was proposed.,Theory Proposal
539,The advanced data analysis processes in different structures were described.,Theory Proposal
540,The possible application of transformative computing was presented,Theory Proposal
541,"We develop a new method MGAT, which incorporates attention mechanism into the graph neural network framework, to disentangle user preferences on different modalities.",Algorithms/ Methods Construction or Optimization
542,"Technically, the model introduces the gated attention mechanism to control and weight the information flow in multimodal interaction graphs, which facilitates the understanding of user behaviors.",Model Construction or Optimization
543,"We perform extensive experiments on two datasets to verify the rationality and effectiveness of MGAT. Moreover, because of user privacy, only user IDs are considered in this work. We will release the code and parameter settings upon acceptance.",Performance Evaluation
544,"To increase the identification of cancerous lesions in mammograms,",Theory Proposal
545,"Aimed to create the BDR-CNN-GCN system, which integrates multiple advanced neural networks they are graph convolutional network (GCN), convolutional neural network (CNN) & rank-based stochastic pooling (RSP) which are named as Net-0, Net-1вЂ¦Net-5.",Algorithms/ Methods Construction or Optimization
546,Among the six neural networks Net-5 is considered as the best as its results as good.,Performance Evaluation
547,This problem is addressed using a novel self-training method for optimizing GCN accuracy on semi-supervised classification tasks.,Algorithms/ Methods Construction or Optimization
548,A very optimistic study observations are identified using a margin score and a rank-based model. This framework can be used for a variety of GCNs.,Model Construction or Optimization
549,Four GCN variants are taken into account in the analysis. Self-training on variations including its four GCN models yielded the highest performance for rank aggregation.,Performance Evaluation
550,"The aim is to solve the issues which occurs with semi supervised learning, it is which Semi-supervised learning involves using both labelled as well as unlabeled samples to learn.",Algorithms/ Methods Construction or Optimization
551,The need for a standard evaluation parameter regarding sampling from unlabeled data to derive relevant unlabeled data points is one of the key problems of semi-supervised learning.,Theory Proposal
552,"For sampling from unlabeled data, the chosen strategy employs a neighborhood construction algorithm based on maximum data points and an Apollonius circle.",Algorithms/ Methods Construction or Optimization
553,"Glaucoma is an eye disease, it can be ditected by experts but considering china it is tough as it has huge population. Even though automatic diagnosis procedures are discovered, still the major concern introduced here is how to increase the accuracy of automated diagnosis by taking complexity into account and extracting crucial details from multimodal data such as patient symptoms, photographs, and texts.",Dataset Creation or Resources
554,"The methods used to solve are Bayesian deep multisource learning (BDMSL) model, multisource learning.",Model Construction or Optimization
555,"As per the results obtained from the data taken from an eye hospital in china, BDMSL model gives the accurate results after testing with both models.",Performance Evaluation
556,"Arabic sentiment analysis has gotten more recognition, with several methods demonstrating considerable success in identifying sentiment through various datasets. The main concern here is to identify the most effective method so as to identify the major field limitations in Arabic sentiment analysis and recommend the far more pressing suggestions for future analysis in this field.",Performance Evaluation
557,BERT-based models for Arabic SA is applied and their conduct is differentiated with current SA techniques. Result is that using Arabic basic BERT is preferable.,Performance Evaluation
558,"While gathering sentiments and producing investment decisions, forecasting and estimating the characteristics of investor sentiments is a crucial challenge. Here in this article it is said to be proved that the importance of concluding that the characteristics of a single user's feelings against dissimilar stocks are not the same.",Theory Proposal
559,Proposed a novel method called correlation-based robust dynamic qualities (CBRDQ) to model the qualities of investor sentiments more accurately by considering the correlations among stocks.,Algorithms/ Methods Construction or Optimization
560,"Based on a large-scale dataset from the real-world investor platform StockTwits, we evaluate CBRDQ and several conventional methods in a unifying stock recommendation framework",Performance Evaluation
561,Proposed a novel accuracy-diversity trade-off framework for RecSys via graph convolutions. The model operates on a NN graph to improve accuracy and on a FN graph to improve diversity.,Model Construction or Optimization
562,We develop design strategies that estimate the joint model parameters in view of both accuracy and diversity.,Model Construction or Optimization
563,We analyze the joint model in the graph-spectral domain to provide an alternative interpretation of how the proposed approach balances accuracy with diversity. T,Applications
564,"We evaluate two types of trade-offs: i) an accuracy-diversity trade-off w.r.t. catalog coverage (i.e., aggregated diversity), and ii) an accuracy-diversity trade-off w.r.t. list diversity (i.e., individual diversity).В ",Performance Evaluation
565,We first propose an unsupervised topic model named VAETM for short texts.,Model Construction or Optimization
566,We then consider label information in dataset to boost VAETM.,Dataset Creation or Resources
567,A KL-divergence-based algorithm is used to infer approximate posterior distribution.,Algorithms/ Methods Construction or Optimization
568,Extensive experiments demonstrate our models outperform state-of-the-art baselines.,Performance Evaluation
569,Inertia negatively influences perceived need and fitness app exploration.,Theory Proposal
570,Perceived need mediates the relationship between inertia and exploration.,Theory Proposal
571,Health goal weakens the relationship between inertia and perceived need.,Theory Proposal
572,Health goal weakens the direct effect of inertia on intention to explore.,Theory Proposal
573,Health goal weakens the indirect effect of inertia on IEFA via perceived need.,Theory Proposal
578,The objective of this study is to systematically investigate the determinants of successful medical crowdfunding projects in China by conducting a mixed-methods approach.,Theory Proposal
583,Distributed data management via consortium blockchains.,Theory Proposal
584,Confidential smart-contract execution via trusted execution environments.,Theory Proposal
587,We propose a data slicing approach for slicing the collected smart contracts to solve the problem of insufficient datasets. ,Algorithms/ Methods Construction or Optimization
588,Then we use them for training an LSTM network and the results show the effectiveness of our approach.,Dataset Creation or Resources
589,The decentralized management of the security-related information in the smart city ecosystem is discussed.,Theory Proposal
590,Blockchain-based identity management and access control is integrated within FIWARE,Performance Evaluation
591,The comparison of the proposed approach with the one using databases has been presented.,Theory Proposal
592,We explore the use of Variational Autoencoders for syntactic Web Service discovery.,Performance Evaluation
593,"We evaluate our approach using a 17113-service dataset, the largest among the research community.",Performance Evaluation
594,"Our approach outperforms service engines based on traditional dimensionality reduction techniques (LSA, LDA).",Performance Evaluation
595,Our approach outperforms service engines based on Word Embeddings.,Performance Evaluation
596,Average query processing times and VAE training times confirm that our approach is viable in practice.,Theory Proposal
601,Characteristics of wikipedia for identifying multilingual learning objects.,Dataset Creation or Resources
602,"This study contributes to generating the Roman Urdu corpus by annotating 10,021 reviews for the task of sentiment analysis.",Model Construction or Optimization
603,The deep learning models such as RCNN can help in text classification task for the under resource Urdu language.,Performance Evaluation
604,"The RCNN outperforms Rule-based and N-gram methods, due to its ability to learn a language-independent textual context.",Dataset Creation or Resources
605,"Our work has collected a massive P2P-domain dataset of online user reviews from Wangdaizhijia comprising of over 440000 online comments on about 6000 online P2P lending companies, which covers most of the China's P2P market.",Model Construction or Optimization
606,"As for predictive clues from the investor perspective, we model it as a keyword extraction issue and propose an improved EBCC sequence labeling model.",Algorithms/ Methods Construction or Optimization
607,"A novel method, named FS-MLC, for feature selection in Multi-label classification is proposed.",Algorithms/ Methods Construction or Optimization
608,FS-MLC uses clustering to find the similarity among features.,Algorithms/ Methods Construction or Optimization
609,It is a wrapper method that does not require generating the number of feature subsets linearly proportional to the number of labels in the dataset.,Performance Evaluation
610,It reduces the dimensionality of the dataset up to 23%-93%.,Performance Evaluation
611,The experimental results show an impressive prediction performance improvement of the associated classifiers.,Performance Evaluation
612,Need of migrating from token-based representations to synset-based ones to achieve better performance on spam filtering.,Theory Proposal
613,Review of current synset-based feature reduction schemes and representations.,Algorithms/ Methods Construction or Optimization
614,Introducing SDRS feature reduction process based on the usage of NSGA-II algoritm and semantic taxonomic relations between tokens.,Performance Evaluation
615,Design and execute a experimental protocol to test the suitability of SDRS dimensionality reduction method.,Theory Proposal
616,Detecting shape of expertise is a practical and industry-motivated problem.,Model Construction or Optimization
617,A CNN-based model was proposed in this study to detect usersвЂ™ shape of expertise.,Algorithms/ Methods Construction or Optimization
618,The proposed method is based on matching both latent vectors of users and queries.,Theory Proposal
623,"Crawl the web services or API from PW (i.e., online web repository) to generate datasets of services.",Applications
624,"Investigate various topic modeling methods to extract latent factors i.e., topics from the services so that services can be represented in the form of topic vectors and dimensionality reduction can be achieved by selecting relevant words in the topics.",Algorithms/ Methods Construction or Optimization
625,Deploy Gibbs Sampling algorithm for Dirichlet Multinomial Mixture (GSDMM) model on datasets for the representation of services and dimensionality reduction.,Algorithms/ Methods Construction or Optimization
626,"Apply various clustering methods on the services, which are represented as topic vectors by applying topic modeling and GSDMM methods, to group similar services into the same domain.",Performance Evaluation
627,Evaluate the performance of methods by applying intrinsic and extrinsic measures and determine the effective dimension reduction and clustering approach for web service.,Performance Evaluation
628,It analyzes the knowledge shared by employees and suppliers within an enterprise social network.,Theory Proposal
629,Internal and external social networks have a different and powerful impact on process improvement.,Theory Proposal
630,Internal and external social networks influence the average cycle time of handling claims.,Theory Proposal
631,Not all the characteristics of the social network influence process improvement.,Model Construction or Optimization
632,"A unified location recommendation framework that combines geographical, categorical, and social preferences with location popularity is proposed to measure usersвЂ™ check-in probability of unvisited locations.",Algorithms/ Methods Construction or Optimization
633,A novel method is developed based on category hierarchy to capture categorical preference by calculating the semantic similarity between location tags.,Algorithms/ Methods Construction or Optimization
634,"Unlike existing studies, location popularity is exploited as a global attribute of location in this study. The priority ranks of locations derived by all three types of preferences are further adjusted by location popularity.",Performance Evaluation
635,"The proposed recommendation approach is experimentally evaluated on two large-scale datasets collected from Weeplaces and Yelp; subsequently, it is compared with two state-of-the-art location recommendation baselines.",Performance Evaluation
637,The article scrutinizes influencing models and determinants in 229 big data studies.,Performance Evaluation
638,Big data adoption research (BDAD) is broadly dispersed across different domains.,Dataset Creation or Resources
639,The models emphasize mainly on variance-based relationships and snapshot prediction with little consensus.,Model Construction or Optimization
640,The analysis highlights vibrant determinants of BDAD within each model and level of analysis.,Performance Evaluation
641,Insights of this bibliometric study could guide rigorous big data research and practice in various contexts.,Dataset Creation or Resources
642,We formally introduce the task of predicting corpus-independent term specificity based on a collection of neural embeddings.,Model Construction or Optimization
643,"We propose a host of unsupervised specificity metrics for predicting specificity based on neural embeddings. Further, we show that our proposed neural embedding-based metrics are robust to the choice of the pre-trained embeddings by assessing them over three different pre-trained embeddings.",Model Construction or Optimization
644,We show how the proposed neural embedding-based specificity metrics can serve as pre-retrieval QPP methods. The proposed specificity metrics show promising performance when predicting query performance.,Algorithms/ Methods Construction or Optimization
645,We offer two gold standard test collections consisting of term specificity measurements defined in relation to Wikipedia and DMOZ categories. These collections are made publicly available for replication studies.,Dataset Creation or Resources
646,"We firstly propose to utilize global context to guide deformable convolution, which can obtain reasonable receptive fields with a global perspective.",Theory Proposal
647,We introduce the class-wise global context to handle intensity non- uniformities in cross-modal organ segmentation.,Model Construction or Optimization
648,A novel loss which focuses on the areas near the boundary is proposed here and can deal with the border blurs well.,Theory Proposal
649,We study the problem of video question answering from the viewpoint of modeling the rough video representation and the grounded video representation. The joint question-video representation based on rough representation and grounded representation of video is learned for answer predicting.,Theory Proposal
650,"We propose the grounded cross-attention network learning framework, which is a novel hierarchical cross-attention method with aВ ",Model Construction or Optimization
651,cross-attention layer and aВ ,Dataset Creation or Resources
652,cross-attention layer. The proposed GCANet adopts a novel mutual attention learning mechanism.,Model Construction or Optimization
653,We construct two large-scale datasets for video question answering. The extensive experiments validate the effectiveness of our method.,Dataset Creation or Resources
654,We construct two large-scale datasets for video question answering. The extensive experiments validate the effectiveness of our method.,Algorithms/ Methods Construction or Optimization
655,To study the irony detection problem for the English and the Spanish languages on two widely used corpora.,Dataset Creation or Resources
656,"To present an approach based on Transformer Encoders for contextualizing pre-trained Twitter word embeddings. This system was the first ranked system in the IroSVA competition and, to our knowledge, it has achieved the second-best result on the corpus of SemEval.",Model Construction or Optimization
657,To propose several analysis strategies towards the understanding of the behavior of Transformer Encoder models and the features captured by them when addressing the irony detection problem e.g. word polarity and relationships among words.,Model Construction or Optimization
658,"To provide, under request, the implementation of our system for research purposes.",Applications
659,A systematic literature review of social media bots detection methods based on Kichenham and Charters guidelines (2007).,Performance Evaluation
660,A refined taxonomy for social media bots detection methods is proposed.,Algorithms/ Methods Construction or Optimization
661,Comparisons between current detection methods are represented.,Performance Evaluation
662,Identification of some gaps in this research area to guide future researches.,Performance Evaluation
663,We propose and orchestrate new pre-processing steps for text classification pipelines.,Model Construction or Optimization
664,"We explore meta-feature representations, sparsification and selective sampling.",Algorithms/ Methods Construction or Optimization
665,We provide thorough evaluations of the trade-offs between costs and effectiveness.,Performance Evaluation
666,Our final representations are more effective than word embeddings (up to 46%).,Performance Evaluation
667,Our processes induce large reductions in computational costs and memory consumption.,Theory Proposal
668,We propose a novel visual dialog method with multi-level attention.,Algorithms/ Methods Construction or Optimization
669,Three high-level attention modules are devised to select important words.,Model Construction or Optimization
670,We also use attention to select relevant regions in the image.,Algorithms/ Methods Construction or Optimization
671,We show the multi-level attention is effective in the visual dialog.,Applications
672,"he model is built based on prior work on web credibility assessment and tested in the special case of good abandonment, which supplies an empirical validation to the existing theories of credibility study",Model Construction or Optimization
673,"the proposed model is validated and improved by search behavior in the scenario of good abandonment, which fills in the gap of understanding good abandonment behavior",Performance Evaluation
675,"This work contributes to the literature of information credibility by incorporating message format to prior studies, thus building a holistic framework",Model Construction or Optimization
676,"This study enriches the current knowledge about information credibility in microblog context by verifying the effects of key predictors of credibility from a nonlinear perspective, which is an early effort to explore nonlinear relationships in user evaluation of microblog information credibility.",Theory Proposal
677,This paper presents a new hybrid loss function that enables the text summarisation model to generate easy-to-read simplified summaries.,Algorithms/ Methods Construction or Optimization
678,A new evaluation measure for the combined tasks of summarisation and simplification has been proposed.,Algorithms/ Methods Construction or Optimization
679,A novel parallel corpus of 5204 articles with their associated summarised simplified text for the combined task of text summasization and simplification has been provided for future research.,Dataset Creation or Resources
681,"The proposed hybrid approach outperforms existing state-of-the-art neural text simplification and abstractive text summarisation models by 38.94% and 53.40%, respectively.",Performance Evaluation
682,We develop an encoder-decoder convolutional neural network (ED-Net).,Model Construction or Optimization
683,We introduce a synthetic loss function to overcome the data imbalanced problem.,Algorithms/ Methods Construction or Optimization
684,We propose a novel method using ED-Net for intracranial hemorrhage segmentation.,Algorithms/ Methods Construction or Optimization
685,We evaluate ED-Net on a multi-center intracranial hemorrhage clinical dataset.,Performance Evaluation
686,Both quantitative and visual results show ED-Net outperforms other methods.,Theory Proposal
687,"We propose the shallowest-possible, and perhaps the shallowest-ever, convolutional neural network model that can predict emotions from real-life, noisy, laggy, internet-based (in-the-wild) videos real-time, capturing nuances of emotions, i.e. value- and time-continuous affect prediction.",Model Construction or Optimization
688,"The research we present in this paper is directly relevant to healthcare for applications such as real-time patient monitoring, AI-assisted doctor-patient consultations.",Applications
689,"The proposed models are computationally inexpensive, can be embedded into devices such as smartglasses.",Model Construction or Optimization
690,We use a novel feature selection paradigm that is driven by feature attribution score computations.,Algorithms/ Methods Construction or Optimization
691,"We investigate and reason the AI performance, present computations on how exactly it utilises the input features to make affect-related predictions (Explainable AI).",Performance Evaluation
692,"We compute the relevance and utilisation of facial action unit (FAU)-derived features by the model, comparing it against the human perception of emotion expression.",Algorithms/ Methods Construction or Optimization
693,We extend this FAU-based вЂ™affectвЂ™ prediction approach to the FAU-based вЂ™pain-intensityвЂ™ prediction problem.,Algorithms/ Methods Construction or Optimization
694,"As FAUs can be extracted in near real-time, and because the models we developed are exceptionally shallow, this study paves the way for a robust, cross-cultural, end-to-end, in-the-wild real-time affect and pain prediction, that is also (nuanced or) value- and time-continuous.",Dataset Creation or Resources
695,We find that the relationship with same semantic but different entity directions are easily confused. The concept of discrimination is proposed and used to solve this issue.,Theory Proposal
696,"We combine the cross entropy function with the deformed max-margin function as a new loss function, which can improve the performance of the model.",Algorithms/ Methods Construction or Optimization
697,Experimental results demonstrate that the proposed Di-LCNN significantly outperforms the state-of-the-art models.,Performance Evaluation
698,"To the best of our knowledge, this is the first to study the problem of co-clustering nodes on attributed HINs. By designing the unified framework SCCAIN, we can effectively co-cluster nodes of different types at the same time.",Theory Proposal
699,Our work overcomes the mentioned challenges including the integration of structural and attributed information and the suitable sharing factors of co-clustering and relevance measure.,Performance Evaluation
700,We propose a novel relevance measure that utilizes multiple meta-paths with learnable weights for the structural relevance and a parameterized attributed relevance measure for attributes in different spaces.В ,Algorithms/ Methods Construction or Optimization
701,We alternately optimize overall relevance measure and co-clustering by setting the relevance matrix as sharing factors.,Algorithms/ Methods Construction or Optimization
702,"We perform extensive experiments on three real-world datasets, including Aminer, DBLP and a subset of Alibaba user activity dataset.В ",Performance Evaluation
703,We compare SCCAIN against the various state of the arts and the experimental results discriminate that our model outperforms the baselines.,Performance Evaluation
708,"In this paper, we propose blockchain-based privacy-preserving remote data integrity checking scheme without TTP, then we emphasize that our scheme is immune to privacy leakage from the third party and to collusion attacks of the cloud servers and the third party.",Model Construction or Optimization
709,"Our scheme establishes a model based on the blockchain technology (a public distributed ledger). Once reaching the consensus, everyone, including the verifier, has the access to query the proof of the data for unlimited times from the blockchain, and cannot manipulate the data on the blockchain.",Model Construction or Optimization
710,"Our scheme provides a solution to ensure the privacy-preserving public verification as well as the batch verification for multi-user data or multi-data simultaneously. It is secure against the malicious server and immune to the delayed auditor. Otherwise, it reduces the cost of the communication and storage.",Model Construction or Optimization
711,The security analysis and experiment results demonstrate that this protocol is suitable for a secure and practical real-world application.,Theory Proposal
712,We define and solve the social influence based community detection problem in EBSNs.,Theory Proposal
713,"In particular, we adopt the neighborhood overlap ratio between a pair of linked users to measure the structure-based social influence, and utilize the similarities of preferences on three aspects (i.e., topics, regions and organizers) through usersвЂ™ offline behaviours to measure the behaviour-based social influence",Algorithms/ Methods Construction or Optimization
715,"Besides, in order to derive the unified pairwise social influence, we propose to combine these two types of social influences through a weight function.",Theory Proposal
717,"We evaluate the performance of our community detection algorithm on real-world dataset which is collected from DoubanEvent (i.e., the biggest event-based social network in China). Experimental results show that the proposed algorithm is suitable for community detection in EBSNs.",Performance Evaluation
718,We leverage supervised learning methods to improve the effectiveness of explicit search result diversification.,Algorithms/ Methods Construction or Optimization
719,"We cast the diversification problem as that of learning a ranking model, based on the coverage of query aspects by each candidate document.",Model Construction or Optimization
720,We learn the importance of query aspects by re-ranking the candidate documents for each aspect and leveraging query performance predictors.,Theory Proposal
721,"We cast the diversification problem as a fusion task, namely, the supervised merging of rankings per query aspect.",Theory Proposal
722,"A new benchmark dataset for studies on automatic text summarization, which contains both human-generated abstracts and extracts, was proposed.",Dataset Creation or Resources
723,The extractive summarization problem was revisited.,Dataset Creation or Resources
726,"Experimental results showed that the use of ensemble feature space remarkably improved the single-use of syntactic or semantic features, and the proposed LSTM-NN also outperformed the state-of-the-art models for extractive summarization.",Performance Evaluation
728,"We analyze the capabilities and requirements of clinicians, design the tasks to involve the clinicians, and implement a clinician-in-the-loop tool set.",Algorithms/ Methods Construction or Optimization
729,We design an extensible mechanism to add a new disease to an existing knowledge graph.,Model Construction or Optimization
730,We present a quantitative effort estimation algorithm to quantitatively evaluate the effort of clinicians who are involved.,Algorithms/ Methods Construction or Optimization
731,"We create a health knowledge graph HuadingKG by HKGB, and develop three tools to apply HuadingKG in real applications.",Applications
733,Using neural network transfer learning techniques to enhance the framework ability to detect unrelated messages over twitter data streams.,Model Construction or Optimization
737,We investigate the most predictive features to distinguish misogynistic content from not-misogynistic content.,Performance Evaluation
738,"We investigate the relationship between misogyny and other abusive phenomena by conducting a cross-domain classification setting, leveraging the knowledge transfer from other kinds of hateful language to detect misogyny and vice versa.",Algorithms/ Methods Construction or Optimization
739,"We present the results of experiments in a cross-lingual setting, aiming at learning and generalizing knowledge about misogyny over datasets in different languages.",Theory Proposal
740,First study using visual and textual information for deep-learning based information extraction on text-intensive and visually rich scanned documents,Theory Proposal
743,Investigated traditional and deep learning approaches in noisy text NER,Applications
745,"N-ary, nested, document-level, and previously indeterminate quantity of complex relations extracted successfully",Performance Evaluation
746,Incorporating document layout information improves performances substantially,Performance Evaluation
747,"To propose a generic LSTM architecture that can capture the type of relationship between elements of the input sequence and,",Model Construction or Optimization
748,To develop a deep neural network model that can learn a better semantic representation of sentences using its dependency parse structure as well as the typed dependencies between words.,Model Construction or Optimization
750,We propose a novel neighborhood-based recommendation model. The core component of the model is a hybrid gated network that is invulnerable to neighborhood noises when exploiting neighborhood information for recommendation,Model Construction or Optimization
751,"it first automatically separates similar neighbors from the dissimilar ones with a thresholding mechanism, and only aggregates those similar neighbors to produce the neighborhood representations.В ",Model Construction or Optimization
752,"It further filters out noises in the neighborhood by pooling representations of users and their neighborhood while considering the confidence level of the neighborhood information. Therefore, we are able to select the most informative neighbors and encode the credibility of neighborhood information for recommendation.",Model Construction or Optimization
753,"We explicitly preserve user-neighbor proximity for learning compact user representations. The user-neighbor similarities are captured by predicting users with their neighbors. Since the neighborhood representations are parameterized by the users, neighbors and the target items, user representations are learned by attending to the informative neighbors and specified for the recommendation task.",Model Construction or Optimization
754,"We integrate the hybrid gated network and user-neighbor proximity components into a unified model, where they can mutually complement and reinforce each other to enhance the recommendation performance.",Model Construction or Optimization
755,"We validate the effectiveness of the proposed model with three public datasets, and demonstrate its advantage over the state-of-the-art models. We also study different variants of the proposed model to justify the intuitions underlying each of its components.",Performance Evaluation
756,10 categories of stakeholders expressed 9 types of privacy concerns in the Twitter discussions about the Australian My Health Record.,Dataset Creation or Resources
757,"Different roles of stakeholders demonstrate different focuses of privacy concerns, and it will be useful to involve them early in the rollout of personal health records.",Theory Proposal
758,"Stakeholders of personal health records shows enthusiasm for improving privacy issues, and social media can be a useful channel for collecting feedback.",Theory Proposal
759,We also discuss the implications for improving the consent model and third-party access of personal health records.,Model Construction or Optimization
761,"We investigate two different solutions to resolve coreference, and create document-level graphs to integrate contextual information. It enables us to effectively establish dependencies between entities and avoid making locally consistent but globally inconsistent decisions.",Dataset Creation or Resources
762,"The proposed method achieves competitive performance, outperforming the baseline systems by a large margin, which can be applied in many downstream tasks such as question answering and text understanding.",Performance Evaluation
764,"Extensive experiments indicate that for the task of controversy detection, GENE creates a rich representation of user networks, conditioned on polarized entities, that outperforms both lexicon-based methods as well as graph representations which do not exploit the entities and polarization contexts.",Theory Proposal
765,"In an early controversy detection setting, GENE also shows superior performance compared to other methods, favoring the early forecast of polarization in a user network and the characterization of a scenario for the emergence of controversy.",Performance Evaluation
766,We release a new dataset that includes news and conversational threads from which this study was conducted.,Dataset Creation or Resources
767,"Moment matching and geometry alignment are leveraged in a unified framework to handle multi-source domain adaptation problems. The first-order MMDs measure the discrepancies between different domains, while Laplacian graphs are constructed to preserve the geometric structure",Theory Proposal
768,"Specifically, MMDs are minimized to reduce the distribution gap of the source and target domains, while the similarity and discriminability of sample relationship are preserved in the designed undirected graphs.",Theory Proposal
770,"Based on the new representations learned in the common feature subspace, we propose two strategies (ALP-u and ALP-s) for pseudo-labeling in both low-dimensional subspace and high-dimensional RKHS.",Algorithms/ Methods Construction or Optimization
771,"We carry out extensive experiments to demonstrate the effectiveness of ALP-u and ALP-s on different domain adaptation scenarios, including traditional single-source-to-single-target, multi-sources-to-single-target and multi-sources-to-multi-targets. Our work surpasses state-of-the-arts on three benchmark datasets notably.",Performance Evaluation
774,"A novel broad-coverage, domain-independent, unsupervised phonetic encoder for Roman Hindi/Urdu word normalization is presented, which utilizes a transliteration based approach to assign the same matching code to lexical variations of a Roman Urdu word.В ",Model Construction or Optimization
775,This technique is referred to as the Transliteration based Encoding technique for Roman Urdu word Normalization (TERUN).,Model Construction or Optimization
776,"The impact of word standardization on Roman Urdu sentiment analysis classification accuracy is evaluated using TERUN and other established techniques. TERUN outperformed the other techniques: Soundex, Metaphone, Double-Metaphone, Caverphone, New York State Identification and Intelligence System (NYSIIS) and KГ¶lner Phonetik (Kph), using accuracy as a performance measure.",Performance Evaluation
780,"The proposition of Drink2Vec and an assessment on the most effective way to integrate distributional semantics with external enrichment contextual strategies to improve the classification of alcohol-related tweets. Drink2Vec encompasses Drink2Symbol, a method that evolved from our previous work",Algorithms/ Methods Construction or Optimization
781,"We demonstrate that drinking embeddings capture interesting nuances of alcohol consumption vocabulary, and that a stacking ensemble (Drink2Ensemble) balances the strengths of each method. Using our techniques, we outperformed existing baselines",Theory Proposal
782,"These methods can be adapted to several other domains, such as the consumption of other types of drugs, gender and social harassment, gender discrimination or violence, flame or hate, among others;",Algorithms/ Methods Construction or Optimization
783,An evaluation of the contribution of the underlying contextual enrichment strategies to this classification problem according to a broad experimental setting.В ,Performance Evaluation
784,"It encompasses distinct classifiers used in winning solutions on Kaggle competitions, five datasets addressing different alcohol consumption behaviors, and an in-depth analysis of the contributions of each contextual enrichment strategy to alcohol-related texting, and their integration.",Dataset Creation or Resources
786,A prevention system to Fake News rather than only a detection system,Model Construction or Optimization
787,A customized Proof-of-Authority protocol,Algorithms/ Methods Construction or Optimization
791,We provide initial results of exploiting deep learning techniques for this purpose,Performance Evaluation
794,a framework to analyze the emotional reactions to mass violent events on Twitter.,Model Construction or Optimization
795,use of the basic emotions to reveal the multiple dimensions of negative sentiment.,Theory Proposal
796,study of the influence of user and event properties on the emotional reaction.,Theory Proposal
797,analysis of eight mass shooting events to generalize the findings.,Theory Proposal
798,"experimented with CNN, biLSTM and BERT to develop emotion classifiers, trained automatically labeled datasets.",Model Construction or Optimization
799,"We propose an entity-aware enhanced word representation with rich context, which enables the downstream modules to learn robust semantic features.",Model Construction or Optimization
800,We combine the global gate structure and PCNN to better capture the global and local features of the sentence.,Model Construction or Optimization
801,"We introduce a gate mechanism after the max-pooling layer of PCNN model, which assigns different weights to the three segments and highlights the effect of crucial segments.",Model Construction or Optimization
802,Our model is evaluated on the widely used benchmark dataset and outperforms most of the stateof-the-art methods.,Performance Evaluation
803,A semantic rebasing mechanism is proposed to learn a sparse semantic graph structure to preserve similarity information of different modalities for binary code learning.,Algorithms/ Methods Construction or Optimization
804,The proposed method focuses on both similarity preserving and quantization to gain satisfied retrieval performance.,Algorithms/ Methods Construction or Optimization
805,Auto-encoding structure of both modalities is included to improve the performance.,Model Construction or Optimization
806,Extensive experiments on four popular datasets shows the effectiveness of the proposed method.,Performance Evaluation
807,"This paper reviews the existing microblog user geolocalisation methods, and summarizes a general framework for microblog user geolocalisation. Along with the framework, we review the studies on user geolocalisation from the aspects of data acquisition, data preprocessing, location representation, user geolocalisation methods categorization, and evaluation metrics.",Dataset Creation or Resources
809,We conduct a performance comparison of existing methods based on the results reported in existing literature with the most widely used real-world datasets and evaluation metrics.В ,Performance Evaluation
810,The advantages and disadvantages of existing methods are further uncovered by comparing them experimentally. Important research challenges that may need further attention are discussed according to our analysis.,Performance Evaluation
811,Survey findings conclude that multiview-based methods are superior to the text-based methods as well as the network-based methods.В ,Performance Evaluation
812,"Besides that, existing user geolocalisation methods cannot capture the user's home location change, resulting in the misjudged results. A",Theory Proposal
813,A review on the methodological and psychometric quality of both the instruments for consumer health information needs and those for patient needs that contained health information needs sections was conducted;,Dataset Creation or Resources
814,A two-phase literature search strategy was applied to retrieve relevant validation studies;,Model Construction or Optimization
815,"Overall, both groups of questionnaire instruments were not well developed: only structural validity, internal consistency tests and content validity analysis were performed in about 50 percent of them, while other types of validations were missing in most of them;",Performance Evaluation
816,Instruments used for assessing patient needs were found to have better tests of construct validity and handling of floor and ceiling effects;,Performance Evaluation
818,Gender Stereotype Reinforcement (GSR) measure tailored for Search Engines.,Model Construction or Optimization
819,Evaluation of GSR within the construct validity framework.,Performance Evaluation
820,"Audit, in terms of GSR, of several widely-known and used ranking algorithm.",Algorithms/ Methods Construction or Optimization
821,Estimation of the impact of different Word Embedding debiasing approaches both on ranking effectiveness and countering gender bias.,Theory Proposal
822,Quantitative and qualitative analysis showing suitability of shared IR test collection to analyze gender stereotype reinforcement.,Performance Evaluation
823,Ramp-one OC-SVM as a non-convex semi-supervised technique.,Model Construction or Optimization
824,The lack of labeled data for the deceptive opinions is addressed by R-OCSVM.,Algorithms/ Methods Construction or Optimization
825,The effect of noises and outliers in the training set is diminished by ramp loss function.,Algorithms/ Methods Construction or Optimization
826,The challenges and the future direction in opinion spam detection is discussed.,Dataset Creation or Resources
827,The proposed scheme provides more secure and reliable public auditing services for cloud storage.,Performance Evaluation
828,"In the scheme, only two entities (Cloud Service Provider and Data Owners) are involved, and blockchain technique instead of a Third Party Auditor is utilized to provide a better auditing service.",Performance Evaluation
829,"A security analysis is provided, and the network performance simulation is conducted on our scheme and others.",Performance Evaluation
830,"Our scheme outperforms others in terms of security and overheads on computation, communication and storage.",Performance Evaluation
831,"we define an action command ontology for the humanoid robot NAO containing all the physical movements that NAO can perform, all its body parts and all related words and synonyms;",Model Construction or Optimization
832,we develop an NLP engine to extract from natural language sentences actions to be mapped in the defined ontology and that the robot will perform;,Model Construction or Optimization
833,we define the concept of incompatibility among the actions of the robot and give the definition of the robot state;,Model Construction or Optimization
834,"we introduce two modes for NAO to operate, STATELESS and STATEFUL. When in STATEFUL mode, NAO performs a recognized action if and only if this is compatible with NAOвЂ™s current state;",Model Construction or Optimization
835,we provide new directions for the interaction between the user and a humanoid robot: the user will have to learn the incompatibilities of the robot postures when in STATEFUL mode if he/she wants the robot to perform any action command and the robot has available all the natural language commands given by the user for future forecasting of missing terms;,Dataset Creation or Resources
836,we run the NLP engine on cloud computing resources and a software layer on the NAO robot which is responsible to interact with the user and communicate with the NLP engine;,Dataset Creation or Resources
837,"we made publicly available the developed ontology, the NLP engine, and the developed software for the community;",Dataset Creation or Resources
838,we carried out a performance evaluation on five subjects in order to test our approach and identifying potential weakness of the system that we can improve as future development.,Performance Evaluation
839,A morpho-semantic knowledge graph CAMS-KG is built from vocalized Classical Arabic corpus.,Algorithms/ Methods Construction or Optimization
840,"CAMS-KG combines tools for morphological analysis and disambiguation, and implements a concordance builder tool, and KG representation.",Algorithms/ Methods Construction or Optimization
841,KG stores the extracted morpho-semantic knowledge: representing morphological categories and both morphological and semantic relations.,Algorithms/ Methods Construction or Optimization
842,BM25 ranking is used for retrieving related documents for a given query.,Algorithms/ Methods Construction or Optimization
843,"CAMS-KG is evaluated on two datasets (Tashkeela, and ZAD). Several query expansion strategies are experimented on 25 queries from ZAD dataset.",Performance Evaluation
844,Community characterization via content analysis.,Dataset Creation or Resources
845,Analysis and extraction of six syntactic and semantic features from tweets.,Dataset Creation or Resources
846,Identification of topics and proper nouns as characteristic features of a community.,Dataset Creation or Resources
847,The research provides insights on how people from specific communities share similar content.,Theory Proposal
848,First ever attempt to apply complex network theory for precise novel sense detection.,Theory Proposal
849,Complex network measures boosts the precision values from 0.23-0.32 to 0.74-0.86.,Performance Evaluation
850,Network measures are more useful than network embedding measures for this task.,Performance Evaluation
851,Gold standard dataset prepared by us for this task are made publicly available.,Dataset Creation or Resources
852,A word sequence-based adversarial network that exploits the semantics of the corpus by adapting global word embeddings to the context of analysis.,Model Construction or Optimization
853,Self-attentive discriminator to map the semantics of the generated text with real-world text.,Algorithms/ Methods Construction or Optimization
854,Evaluation framework based on quantitative and qualitative analyses.,Performance Evaluation
855,A word sequence-based adversarial network that balances both generator and discriminator towards reaching the Nash equilibrium.,Model Construction or Optimization
856,"We tackle the challenge of query suggestion in a novel way by proposing an Attention-based Hierarchical Neural Query Suggestion model, i.e., AHNQS, which adopts a hierarchical structure containing a user attention mechanism to better capture the userвЂ™s search intent.",Model Construction or Optimization
857,"We analyse the impact of session length on query suggestion performance and find that AHNQS consistently yields the best performance, especially with short search contexts.",Performance Evaluation
858,"We examine the performance of AHNQS with different numbers of usersвЂ™ sessions. We find that AHNQS always yields better performance over the best baseline model, especially for users with few search sessions.",Performance Evaluation
859,"We proposed a model that exploits Blockchain miner nodes for generating optimal scheduling solutions, namely PF-BTS.",Model Construction or Optimization
860,"PF-BTS preserves Data, Usage, Identity, and Location privacy of end- users, and enables fog components to perform cloud tasks at the edge of the network.",Theory Proposal
861,We deployed the Ant Colony Optimization algorithm in a Fog-Blockchain architecture.,Algorithms/ Methods Construction or Optimization
862,PF-BTS was experimentally proven to provide more optimal solutions than previously proposed Blockchain-based task scheduling models.,Performance Evaluation
863,Extensive survey carried out regarding the use of blockchain within information systems.,Dataset Creation or Resources
864,We conducted the first blockchain-based information system analysis.,Applications
865,We addressed all issues in the information systems management area.,Dataset Creation or Resources
866,"Based on the push-pull-mooring framework, we identified and classified factors that influenced askersвЂ™ to switch from free to paid Q&A services, using the critical incident technique.",Model Construction or Optimization
867,"We calculated the entropy weights of the 16 subcategories before and after the switch, using the entropy weight method.",Algorithms/ Methods Construction or Optimization
868,"AskersвЂ™ switching behavior was influenced by push factors (i.e., dissatisfaction with the free SQA service), pull factors (i.e., satisfaction with the paid SQA service), and mooring factors (i.e., social factors, personal factors, situational factors).",Theory Proposal
869,"The effects of these push, pull, and mooring factors vary significantly before and after a switch.",Theory Proposal
870,intensity of emotions mined from textual descriptions of crowdfunding campaigns are effective features to predict their success,Theory Proposal
871,pre-trained word embeddings can be used to create interpretable predictive models for crowdfunding campaigns success forecasting,Applications
872,predictive models interpretability opens to causal inference analysis and enables interdisciplinary studies,Applications
873,"We propose a Context-Controlled Topic-Aware (CCTA) model for response generation in open-domain dialog systems. It can produce context-dependent topic representations and conduct context-controlled topic transitions, which jointly lead to balanced improvements on both response informativeness and contextual coherence.",Model Construction or Optimization
874,"Inspired by human conversation patterns, we design a context-controlled topic transiting strategy. It not only can produce relevant transition words to enhance response quality, but also can work as an auxiliary learning task which in turn helps the learning process of response generation converge fast.",Model Construction or Optimization
875,We examine the performance of our CCTA model with extensive experiments on two benchmark conversation datasets. Experimental results validate the superiority of our proposal on response generation task against the state-of-the-art baselines.,Performance Evaluation
876,Extracting innovative ideas from online reviews is important for product development.,Theory Proposal
877,We introduce a novel deep learning approach to identify innovative ideas of products from online customer reviews.,Model Construction or Optimization
878,The approach ensembles multiple word embeddings.,Model Construction or Optimization
879,Results show that our model outperforms the baselines.,Performance Evaluation
880,Focal loss function is adopted to handle the class imbalance problem.,Applications
881,Consumers overestimate their expected search effort before using a review site.,Theory Proposal
882,"Compared to consumers who had used Yelp before, those who had never used Yelp expect their browsing duration and review counts to be 42% and 93% higher, respectively.",Theory Proposal
883,"Before making a decision, most consumers spend only five minutes or less, read five or fewer reviews, and browse seven to eight pages.",Theory Proposal
884,What information вЂњpatchesвЂќ consumers see within those limited ranges may significantly influence the restaurant choices .,Theory Proposal
885,"Based on the Elaboration Likelihood Model (ELM), the features of online health misinformation can be classified into two levels: central-level and peripheral-level.",Model Construction or Optimization
886,"We built a health misinformation detection model integrating the linguistic features, the topic features, the sentiment features, and the behavioral features.",Theory Proposal
887,"Four types of misinformation appear in online health communities: advertising, propaganda, misleading information, and unrelated information",Model Construction or Optimization
888,"The proposed model, as well as the features, were validated on a real-world dataset, being able to correctly detect about 85% of health misinformation.",Performance Evaluation
889,The behavioral features are more informative than linguistic features in detecting health misinformation in online health communities.,Theory Proposal
890,A research model based on S-O-R framework is proposed to examine the factors that influence health information avoidance intention during the COVID-19 pandemic.,Model Construction or Optimization
891,"Information avoidance in the COVID-19 pandemic is determined by consumersвЂ™ negative affect: sadness, anxiety, and cognitive dissonance.",Theory Proposal
892,Information avoidance intention influences consumersвЂ™ subsequent intentions of taking preventive behaviors during the COVID-19 pandemic.,Theory Proposal
893,Consumer's negative affect is influenced by perceived threat and perceived information overload during the COVID-19 pandemic.,Theory Proposal
894,We systematically investigate the impact of the state-of-the-art post-retrieval query performance prediction methods in the context of ad hoc table retrieval,Algorithms/ Methods Construction or Optimization
895,"We show how neural features derived from neural embedding techniques can be integrated into existing query performance predictors, leading to neural predictors",Applications
896,We evaluate our proposed neural predictors on a gold standard test collection derived from Wikipedia tables. We further analyze our findings from various perspectives and identify areas where neural predictors are able to provide effective performance improvements.,Performance Evaluation
897,"As far as we know, it is the first work to propose the phrase information network and employ it to fuse information networks. Following this inspiration, we propose the phrase network generation algorithm (PNG) and construct PFHIN, which seamlessly fuses text semantics with complex entities in CQA.",Model Construction or Optimization
898,We define the distance of entities with the same or different types in HIN and propose the optimal entity matching algorithm. The real question-answer matching case in CQA is described in detail.,Algorithms/ Methods Construction or Optimization
899,Abundant experiments demonstrate that our algorithm precedes the state-of-the-art answering methods in CQA.,Performance Evaluation
900,"We perform an in-depth meta-path analysis of the optimal matching answers. It is found that most meta-paths include the Phrase entity, which proves that phrases serve as a bridge that effectively connects different types of entities in CQA.",Theory Proposal
901,A high-performance pneumonia detection system was proposed in this paper.,Model Construction or Optimization
902,Transfer learning is used to obtain feature extractor.,Algorithms/ Methods Construction or Optimization
903,A novel graph-based feature reconstruction method was proposed.,Algorithms/ Methods Construction or Optimization
904,The proposed feature reconstruction is efficient yet transplantable to other scenarios.,Applications
905,"Propose MEPSR, which employs embedding methods, including deep learning based embedding and word embedding, to obtain effective representations from multi-context information.",Model Construction or Optimization
906,"Jointly model personalized place semantics and App usage sequences by sharing the App representations, which can introduce an inductive bias to improve generalization capability.",Model Construction or Optimization
907,Conduct extensive experiments on the Mobile Data Challenge (MDC) dataset to evaluate the effectiveness of MEPSR. Experimental results show that our method outperforms existing methods significantly.,Performance Evaluation
908,"Adapted pre-trained model (i.e. BERT, ELMo, and Word2vec) learned from Japanese data to our emoticon recommendation system.",Model Construction or Optimization
909,Empirically compared our proposed systems with baseline methods that learned surface patterns of texts and emoticons.,Algorithms/ Methods Construction or Optimization
910,Compared pre-trained models learned from different text domains to observe the difference in recommendation results.,Model Construction or Optimization
911,Team diversity should be considered when building online physician teams.,Theory Proposal
912,Reputation diversity and experience diversity help increase team performance.,Theory Proposal
913,Star physicians weaken the influence of reputation diversity on team performance.,Theory Proposal
914,Star physicians strengthen the influence of experience diversity on team performance.,Theory Proposal
915,Polarity determination using proposed domain specific lexicon delivers better performance than other lexicon based methods,Theory Proposal
916,Using star rating distribution is a novel lexicon building approach for sentiment analysis,Model Construction or Optimization
917,A robust set of experiments have been performed in this study by comparing this method with similar methods that use review labels for training lexicons across several datasets.,Algorithms/ Methods Construction or Optimization
918,Hybrid method using ML also illustrates the superiority of this method for building domain specific lexicons,Algorithms/ Methods Construction or Optimization
919,Experiments on popular datasets like Cornell movie reviews dataset and Large movie reviews dataset have also been performed to benchmark against other studies and demonstrate the superior performance of this method.,Performance Evaluation
920,"Examining the impact of social media overload on adaptive and maladaptive coping strategies, and subsequent discontinuous usage intention",Theory Proposal
921,Fatigue and flow experience play important moderating roles,Theory Proposal
922,Stress dynamics and coping theory is applied to explain the hypotheses.,Theory Proposal
923,"A framework is proposed uniting theories from musicology, psychology and sociology.",Model Construction or Optimization
924,In-depth interviews with students in twenty universities verified the framework.,Performance Evaluation
925,Results reveal how students use music for learning and well-being.,Theory Proposal
926,Findings yield implications for the design of online music services and systems.,Theory Proposal
927,"We propose a method to combine distributed phrase vectors and component word vectors into new phrase vectors by using an automatic encoder. Since this method effectively combines the external context information and internal context information of a phrase, the phrase embedding generated by this method is better than that generated by the distributional and compositional methods.",Algorithms/ Methods Construction or Optimization
928,"We use two neural network-based autoencoders to implement the above method. The non-linear transformation of the neural network can achieve complex mapping from input embeddings to new phrase embeddings. Therefore, our method is superior to the previous hybrid method based on linear transformation.",Algorithms/ Methods Construction or Optimization
929,"When using only component word embeddings as input, the proposed AE-ALF model consisting of LSTM, FCNN, and AM can effectively learn the order information and semantic information of the component words. Therefore, the semantic representation ability is better than the previous compositional models, and it can also effectively solve the problem of data sparseness.",Performance Evaluation
930,A dynamic citation perspective for distinguishing scientific breakthroughs from ordinary scientific works is proposed.,Theory Proposal
931,Breakthrough works show slower but enduring take-off and denser networks of following works.,Theory Proposal
932,"Two significant traits of scientific breakthroughs are revealed, namely, prematurity and fruitfulness.",Theory Proposal
933,Three metrics show particular promise for early identification of breakthrough works.,Theory Proposal
934,This paper explores the width of the citation impact of scientific publications.,Theory Proposal
935,This paper uses the whole Web of Science as the empirical study dataset and thus examines all disciplines instead of only a few.,Dataset Creation or Resources
936,"We present B-FERL; a decentralized security framework for in-vehicle networks. B-FERL ascertains the integrity of in-vehicle ECUs and highlights the existence of threats in a smart vehicle. To achieve this, we define a two-tier blockchain-based architecture, which introduces an initialization operation used to create record vehicles for authentication purposes and a challengeвЂ“response mechanism where the integrity of a vehicleвЂ™s internal network is queried when it connects to an RSU to ensure its security.",Model Construction or Optimization
937,"We conduct a qualitative evaluation of B-FERL to evaluate its resilience to identified attacks. We also conduct a comparative evaluation with existing approaches and highlight the practical benefits of B-FERL. Finally, we characterize the performance of B-FERL via simulations using the CORE simulator against key performance measures such as the time and storage overheads for smart vehicles and RSUs",Performance Evaluation
938,"Our proposal is tailored to meet the integrity requirement for securing smart vehicles and the availability requirement for securing vehicular networks and we provide succinct discussion on the applicability of our proposal to achieve various critical automotive functions such as vehicular forensics, secure vehicular communication and trust management",Theory Proposal
939,Increasing volume of civil complaints necessitated automatic classification.,Theory Proposal
940,Literature understudied a classification framework of unstructured real data.,Theory Proposal
941,Five stepwise models were applied for the classification accuracy.,Model Construction or Optimization
942,"SMOTE-ENN, balancing categories, significantly improved the accuracy.",Theory Proposal
943,"We formulate the general response selection system into a four-module architecture in DCM. Taking BERT as the backbone encoder, we investigate a variety of strategies to perform response selection with comprehensive comparisons.",Model Construction or Optimization
944,We introduce the next utterance prediction pre-training scheme for multi-turn response selection. This NUP based pre-training could empower DCM to exploit context continuity underlying the multi-turn dialogue for better contextual information extraction.,Model Construction or Optimization
945,"Empirical results on three public datasets show that our proposed model outperforms baseline models significantly, achieving new state-of-the-art performance for multi-turn response selection",Performance Evaluation
946,"EtherTwin, a blockchain-based Decentralized Application (DApp) for secure information management of Industry 4.0 assets using Digital Twins.",Applications
947,"Secure information management, ensuring confidentiality through fine-grained access control and encryption, as well as providing integrity and availability based on the blockchain.",Theory Proposal
948,Quantitative and qualitative evaluation including performance/cost measurements as well as a real-world industry use case and expert interviews.,Performance Evaluation
949,We create four open-source datasets for identifying the gender of named entities.,Dataset Creation or Resources
950,Propose a novel transformer-based architecture for gender tagging of named entities.,Model Construction or Optimization
951,Present multiple supervised and unsupervised learning baselines for gender inference.,Algorithms/ Methods Construction or Optimization
952,Context-sensitive supervised learning outperforms database-reliant gender tagging.,Performance Evaluation
953,We present a novel multimodal fake news detection model based on CARN and MCN.,Model Construction or Optimization
954,The CARN is introduced to fuse the relevant information between different modalities and keep the unique properties for each modality.,Dataset Creation or Resources
955,"To mitigate the influence of noise information which may be generated by crossmodal fusion, the MCN is introduced to extract feature representations from original and fused textual information simultaneously.",Model Construction or Optimization
956,We conduct extensive experiments on four real-world datasets and demonstrate that the proposed model outperforms state-of-the-art methods and learn more discriminable feature representations.,Performance Evaluation
957,We contribute a large scale multimodal fake news dataset from Weibo platform and will make it available to the public,Dataset Creation or Resources
958,We study the impact on review helpfulness of author/item content deviations.,Dataset Creation or Resources
959,We compare helpfulness prediction models based on linear and non-linear regression.,Performance Evaluation
960,Our models integrate author/item deviations with traditional helpfulness determinants.,Model Construction or Optimization
961,An experimental validation shows that our models outperform the selected baselines.,Performance Evaluation
962,We improve collaborative item recommendation using predicted review helpfulness.,Theory Proposal
963,"We decompose the transaction latency into three phases, each phase involves several substeps for fine-grained analysis. In each phase, we indicate the configuration parameters that may affect the transaction latency.",Theory Proposal
964,"We present an analytical model to calculate the average transaction latency in Fabric blockchains with single and multiple channels. Besides, we give a quantitative latency analysis of two typical consensus mechanisms in Fabric blockchain,В i.e SoloВ andВ PBFTВ consensus.",Model Construction or Optimization
965,"We conduct a series of experiments to evaluate the validity of the proposed analytical model, and the results show that our model predicts the experimental results with an error less than 6.1%.",Performance Evaluation
966,We identify performance bottlenecks based on the analytical model and provide feasible insights for Fabric blockchain deployment.,Performance Evaluation
967,User participation and use characteristics vary by discipline in ResearchGate.,Theory Proposal
969,Life sciences & biomedicine has the largest user body with active interactions.,Dataset Creation or Resources
971,Positive RG metric and research level correlation applies across disciplines.,Theory Proposal
973,Use characteristics are consistent with information behaviors by disciplines.,Theory Proposal
975,"We propose a multi-level similarity method, which can jointly model the semantic-level, structural-level and contextual-level information and improve the robustness of visual and textual representations.",Algorithms/ Methods Construction or Optimization
976,"We extract the semantic labels in the text dataset and treat them as multiple labels of the corresponding image. Then, the semantic information is modeled by utilizing multi-label convolutional neural network. Moreover, we conduct graph structure to model the relationship of objects and words within image-text pair and improve the retrieval performance by re-ranking mechanism",Model Construction or Optimization
977,"We evaluate our method on two large-scale datasets, Flickr30k and MSCOCO. The extensive experimental results demonstrate the superiority of our method comparing to the state-of-the-art methods for image-text retrieval task.",Performance Evaluation
978,Co-LSTM is a classifier for sentiment analysis of social media reviews.,Algorithms/ Methods Construction or Optimization
979,Co-LSTM leverages the best features of both convolutional neural network and Long short-term memory in order to model the classifier,Algorithms/ Methods Construction or Optimization
980,Word embedding model has been applied in constructing vocabulary dictionary.,Model Construction or Optimization
981,Co-LSTM is compared with other machine learning and deep learning models.,Performance Evaluation
982,"We analyze the Thai QA dataset and discuss how it is different from SQuAD, an English QA dataset. Then, we proposeВ WabiQA, a novel Thai QA system that implements a BM25F-based document retriever and a bi-directional LSTM document reader. Our document reader is adapted from DrQA (ChenВ etВ al., 2017), a recent end-to-end QA system for the English language.",Model Construction or Optimization
983,"We compare different document retrieval methods, including Google Search API, TF-IDF, and BM25F, and also study the impacts of using different features in the proposed bi-directional LSTM reader.",Performance Evaluation
984,"We provide analyses of the effects of document scopes, number of relevant documents, and sizes of training data on the end-to-end performance ofВ WabiQA. As an external evaluation,В WabiQAВ won the first prize award from ThailandвЂ™s National Software Contest 20192. Our system outperforms the next best competitorsвЂ™ systems by 19.99 percentage points in terms of document retrieval accuracy, and 33.10 percentage points in terms of answer prediction F1.",Performance Evaluation
985,We demonstrate an application ofВ WabiQAВ by developing a prototype mobile application that aims to facilitate Thai users with visual impairment using voice-to-speech technology and an intelligent question-answer categorization,Applications
986,We make the source code and partial data (created by ourselves) available for research purposes at:В https://github.com/suppawong/wabiqa.,Dataset Creation or Resources
987,This research puts forward a novel algorithm called nSAIS for inducing suffix array using external memory.,Algorithms/ Methods Construction or Optimization
988,"The time, space and IO complexities of nSAIS are linearly proportional to the input size.",Theory Proposal
989,The constant factor for the space complexity of nSAIS is not more than 6.82.,Theory Proposal
990,A program of the algorithm nSAIS is engineered for performance evaluation.,Algorithms/ Methods Construction or Optimization
991,nSAIS is rather general for the datasets of different sizes and characteristics.,Dataset Creation or Resources
992,This paper is the first to constrain the learning procedure in matrix factorization by using imputed data.,Theory Proposal
993,This paper is the first to discuss the relation between imputed data and recommendation quality.,Theory Proposal
994,"We propose an assumption that is based on preference analysis in matrix factorization model. This assumption lets the learning preferences be correctly constrained, thus leading to a more accurate learned model.",Model Construction or Optimization
995,"We design two learning models according to the assumption. One firstly makes the original preferences get close to preliminary preferences, and then creates the concatenated preferences. The other one firstly creates the concatenated preferences, and then makes the original, preliminary and concatenated preferences get close to each other.",Model Construction or Optimization
996,"Exhaustive experiments are conducted on five datasets: MovieLens 100k, MovieLens 1M, Netflix, Filmtrust and Jester. Experiment results show that PDMF outperforms the state-of-the-art methods by more than 10% in recommendation accuracy.",Performance Evaluation
997,Integrating traditional centrality and spectral modularity methods to explore intensive focal structures in social networks.,Algorithms/ Methods Construction or Optimization
998,Applying decomposition optimization method to maximize the individual centrality measure and the network modularity value in the network level in complex social networks.,Algorithms/ Methods Construction or Optimization
999,Measuring the influence generated by each focal structure on the individual level and the network level.,Performance Evaluation
1000,Applying the DCFM to measure the power generated by each focal structure.,Model Construction or Optimization
1001,Applying Newman-Girvan modularity method and depth-first search and linear graph algorithm to validate our results.,Algorithms/ Methods Construction or Optimization
1002,Evaluating model performance- apply to different social and real-world networks.,Performance Evaluation
1003,"Implementing a toy example as a complexity analysis, and a real-world Twitter network.",Applications
1004,"Applying different centrality methods (degree, betweenness, closeness, eigenvector) and compare their results.",Algorithms/ Methods Construction or Optimization
1005,The accuracy of certain timestamps like the backdate timestamps generated on the Ethereum blockchain and to resolve the problem a decentalised timestamping is used.,Model Construction or Optimization
1006,Decentralized timestamps have the ability to be more accurate than RFC3161 timestamps.,Theory Proposal
1007,We present an efficient strategy for augmenting existing paraphrase and non-paraphrase annotations in a consistent manner.,Algorithms/ Methods Construction or Optimization
1008,We develop a multi-cascaded learning model for robust paraphrase detection in both clean and noisy texts.В ,Model Construction or Optimization
1010,We analyze the impact of various data augmentation steps and different components of the multi-cascaded model on paraphrase detection performance.,Performance Evaluation
1011,We address the problem of generating SRs from spatial data streams and static data in real-time.,Theory Proposal
1012,We design a novel index structure based on R-tree with RRs called R3 index to store spatial objects and support SR generation.,Model Construction or Optimization
1015,Our proposal remains focused and avoids the exponential curse of other alternatives.,Dataset Creation or Resources
1018,Clinical decision support system was developed for infection diagnosis in nursing homes using small data; AUROC of 0.734 achieved.,Dataset Creation or Resources
1020,"When considering additional data (social data and weather information), AUROC increases up to 0.798.",Performance Evaluation
1021,"For diagnosis, smaller leads (historical data) is preferred, but larger leads improve the results when adding social data.",Performance Evaluation
1022,"We propose a novel pipeline for the task of text classification, i.e., Pre-train Interact Fine-tune (PIF).",Algorithms/ Methods Construction or Optimization
1023,"To the best of our knowledge, ours is the first attempt to model word interactions for text representation.",Model Construction or Optimization
1024,We introduce a two-perspective interaction representation for text classification.,Model Construction or Optimization
1025,We propose the Hybrid Language Model Pretrain-finetuning.,Model Construction or Optimization
1026,We find that our proposal outperforms the state-of-the-art methods for text classification in terms of accuracy.,Performance Evaluation
1029,Proposed approach uses human cochlear model and Convolutional neural network to extract relevant music features.,Applications
1031,We introduce the progress in fashion research in recent years.,Dataset Creation or Resources
1032,"We provide a taxonomy of these fashion studies which include low-level fashion recognition, middle-level fashion understanding and high-level fashion applications.",Applications
1033,We discuss the challenges that when the fashion industry faces AI technologies.,Dataset Creation or Resources
1034,We proposed a new index named Supply-Demand Matching Efficiency (SDME) to measure the supply and demand matching efficiency for online technology trading platforms (OTTPs).В ,Algorithms/ Methods Construction or Optimization
1035,"Technically, it is based on semantic similarity of technology supply and demand texts with Word2Vec and Cosine similarity algorithms, which fully excavated semantic features of technology supply and demand texts, thus providing ideas for tacit knowledge mining and knowledge matching of technology supply and demand texts.",Algorithms/ Methods Construction or Optimization
1036,it provided ideas for estimating the trade possibility of technology supply and demand on OTTPs before technology trade occurs.,Dataset Creation or Resources
1037,"We measured the SDME of the three representative OTTPs. The three OTTPs are sorted by the SDME from high to low: Zhejiang Market (Government-Owned, Government-Operated, GOGO), Technology E Market (Government-Owned, Contractor-Operated, GOCO) and Keyi Market (Market-Owned, Market-Operated, MOMO), indicating that government plays an important role in promoting the SDME by attracting effective technology suppliers and demanders to participate in online trade and standardizing information expression.В ",Algorithms/ Methods Construction or Optimization
1038,"By comparing the SDME and the newly announced signing rate of each OTTP, we found that the OTTP with high SDME also has high signing rate, and the changing trend of the two is consistent.",Performance Evaluation
1039,"We analyzed the topic distribution of technology supply and demand of OTTPs with TextRank and Latent Dirichlet Allocation (LDA), and calculated the topic differences of each OTTP.В ",Algorithms/ Methods Construction or Optimization
1040,"The Technology E Market and Zhejiang Market have low topic differences and high SDME, while Keyi Market has high topic differences and low SDME, which indicated that the topic differences have a negative effect on SDME.",Performance Evaluation
1041,The transformative computing in advanced data analysis was proposed.,Dataset Creation or Resources
1042,The advanced data analysis processes in different structures were described.,Dataset Creation or Resources
1043,The possible application of transformative computing was presented.,Dataset Creation or Resources
1047,"This paper investigated the task of enriching cross-lingual links for online wikis, which is a significant step and a pretty good starting point for cross-lingual knowledge graph construction.",Theory Proposal
1048,"we propose two end-to-end neural matching models for matching entity descriptions and images, and then jointly train them with handcraft features. To the best of our knowledge, it is the first to utilize multi-modal information to enrich cross-lingual entity links.",Model Construction or Optimization
1049,An unsupervised domain adaption method for 3D object retrieval by jointly learning the deep 3D representation and domain alignment in the end-to-end manner is proposed.,Algorithms/ Methods Construction or Optimization
1050,The proposed method can reduce statistical domain divergence and improve the feature representation from different domains.,Algorithms/ Methods Construction or Optimization
1051,"The proposed method focuses on the cross-domain retrieval task, which can effectively use the exist 3D object dataset to explore the generation ability of methods for another dataset.",Algorithms/ Methods Construction or Optimization
1052,The experimental results on CAD Object to CAD Object and RGB-D Object to CAD Object retrieval show the superiority of the proposed method.,Performance Evaluation
1053,IR models can be adapted as standalone algorithms to effectively recommend contacts in social networks.,Algorithms/ Methods Construction or Optimization
1054,IR models are shown to be even more effective as neighbor selection methods in kNN.,Performance Evaluation
1055,We achieve further effectiveness enhancements by learning to rank upon IR models.,Performance Evaluation
1056,We test the researched approaches extensively in five network samples of different kind from Twitter and Facebook.,Applications
1057,"Some bibliographic databases try to merge citations, but do so inadequately.",Theory Proposal
1058,We design corresponding citation merging schemes for arXiv-deposited articles.,Applications
1059,"We investigated 2,662 e-prints in the вЂњDigital LibrariesвЂќ subject in arXiv.org",Dataset Creation or Resources
1060,We use empirical testing to prove the feasibility of schemes proposed in this paper.,Algorithms/ Methods Construction or Optimization
1061,This is the first study to systematically explore the citation merging of articles.,Theory Proposal
1062,A novel variant of information entropy named permutation ratio entropy (PRE) was employed to identify three typical ECG RR interval series.,Algorithms/ Methods Construction or Optimization
1063,The PRE can more correctly yield higher entropy values for the normal sinus rhythm (NSR) RR interval series than that for the congestive heart failure (CHF) and arrhythmia (ARR) RR interval series.,Applications
1064,"The PRE can more correctly identify three RR interval series (i.e., NSR, CHF and ARR) than SmpE and PE",Applications
1065,"Determining proper parameters of three entropy methods (i.e., SmpE, PE and PRE) for discerning NSR, CHF and ARR RR interval series.",Algorithms/ Methods Construction or Optimization
1066,"OHIs can provide social value for third-party patients, but physicians tend to provide uncertain information.",Theory Proposal
1067,Informational and emotional support from previous OHIs can contribute to their social value.,Theory Proposal
1068,Information uncertainty strengthens the effect of treatment information and weakens the effect of emotional support.,Theory Proposal
1069,People's movie purchase intention can be extracted from YouTube trailer reviews.,Theory Proposal
1070,Purchase intention is highly correlated with box-office revenue and can be used to improve the prediction accuracy of box-office revenue prediction.,Theory Proposal
1071,"Multiple linear regression perfomed better than support vector machines, neural network, and random forest in movie revenue prediction.",Performance Evaluation
1072,Semantic indexing with MeSH descriptors may aggregate several distinct concepts.,Applications
1073,Concept-occurrence is a good heuristic for fine-grained semantic indexing.,Theory Proposal
1074,Models trained with concept-occurrence as weak supervision can achieve good accuracy.,Theory Proposal
1075,Lexical and semantic features combined can lead to improved predictive performance.,Theory Proposal
1076,"Under-sampling the major class in training data, can also lead to further improvement.",Theory Proposal
1077,Introduce the concept of immersion from the game community to the SQA community for the first time.,Theory Proposal
1078,Established three dimensions of immersion level in the SQA community.,Dataset Creation or Resources
1079,Built an evaluation system of user participation level in SQA community from the immersion perspective.,Model Construction or Optimization
1080,Verify the evaluation system on a data set containing 4 million user behavior data.,Dataset Creation or Resources
1081,Comprehensively evaluated the contribution level and functional complementary relationship of users with different roles in the knowledge question-and-answer community.,Performance Evaluation
1082,We perform a study on the tagging behavior of sellers in an e-commerce platform.,Theory Proposal
1083,We design new tag quality attributes that exploit the collective behavior of users.,Algorithms/ Methods Construction or Optimization
1084,Our attributes exploit the synergy between search and quality of textual content.,Applications
1085,Queries and clicks can offer useful data for recommending quality tags for products.,Applications
1086,"Our best method, a deep L2R framework, greatly outperforms state-of-the-art methods.",Performance Evaluation
1087,We present an Open Data approach to process and enrich citizen-generated content.,Algorithms/ Methods Construction or Optimization
1088,We propose a novel controversy metric for conversation threads.,Algorithms/ Methods Construction or Optimization
1089,We present an in-depth analysis of citizen discussion in an e-participatory platform.,Dataset Creation or Resources
1090,We provide a large dataset of semantically annotated citizen proposals and debates.,Dataset Creation or Resources
1091,"Automatic crisis management, using natural language processing techniques, is a quite hot research topic.",Theory Proposal
1092,"Characterization of crisis-related messages according to three dimensionsrelatedness, intentions to act and urgency.",Theory Proposal
1093,The first French manually annotated crisis dataset.,Dataset Creation or Resources
1094,"Experiments with binary classification (useful vs. non useful), three classes (non useful vs. urgent vs. non urgent) and multiclass classifications (i.e., intention to act categories) using traditional feature-based machine learning and new deep learning architectures by developing a domain shift approach over pre-trained word embeddings and incorporating different metadata information in a multi-input architecture.",Algorithms/ Methods Construction or Optimization
1095,"A scheme cross trajectories, vessel attributes and the movement context for detecting rare behaviors through preprocessing, kNN-based clustering, and verification.",Model Construction or Optimization
1096,Only extremely few anomalies are useful which are rare behaviors.,Theory Proposal
1097,The interactive detection process requires an instant response that is a big challenge for.,Theory Proposal
1098,"The more similar trajectories gather in an Area of Interest, the less probability of anomalies they are.",Theory Proposal
1099,The small reachability distance values have limited effect on lrd.,Theory Proposal
1100,In their study they classified online health disinformation in to two levels : central levels and peripheral level based on the elaboration likelihood model,Dataset Creation or Resources
1101,For best auditing scheme they used block chain technique which is a secured and coherent for cloud storage platform instead of third party auditor,Dataset Creation or Resources
1103,"Our scheme uses automatically chosen DOs from the blockchain network to conduct the auditing, significantly reduces the 51% risk of the auditor being breached",Performance Evaluation
1104,"For summarizing English language, a variety of approaches are available. Although there are no freely available methods for the Urdu script.",Theory Proposal
1105,The famous approaches like global weight and local weight are used in experiment by contributing equal amount to ground truth data and made script files available to public and researchersВ ,Algorithms/ Methods Construction or Optimization
1106,A word sequence-based adversarial network that exploits the semantics of the corpus by adapting global word embeddings to the context of analysis.,Algorithms/ Methods Construction or Optimization
1108,Evaluation framework based on quantitative and qualitative analyses.,Model Construction or Optimization
1110,Development of an analysis of how Wikipedia disease-related articles in English evolve over time.,Algorithms/ Methods Construction or Optimization
1111,"Historical information is extracted from the articles and how their content (references, characters, diagnostic-related terms) change over time is analysed.",Applications
1115,We proposeВ an original set of roles with their justification in sociological modelsВ allowing us to differentiate users considering their especially important characteristic dimensions,Theory Proposal
1116,We conduct experiments to allow us to define patterns describing stability and variability of given roles вЂ“ chances of obtaining the given role or chances of keeping or obtaining an influential role,Algorithms/ Methods Construction or Optimization
1117,We find temporal patterns of frequent transitions between roles of users on the social portal,Theory Proposal
1118,"We propose Rule Assembler, a configurable approach that is able to classify duplicate entities based on confidence scores, taking into account tunable parameters as well as user preferences;",Model Construction or Optimization
1119,"We propose four heuristics for turning the results produced by logical rules into confidence scores (i.e., a continuous quantification associated with the confidence produced by the rule regarding the duplicity of the entity pairs);",Algorithms/ Methods Construction or Optimization
1122,"A new approach that redefines the classical generation of item rankings by considering the order (sequentiality) in neighbor-based recommender systems, borrowing ideas from Aggregated Search",Model Construction or Optimization
1123,A thorough comparison between our approach and other classical algorithms used in the recommendation area analyzing different perspectives of evaluation (relevance and freshness) under time-aware evaluation methodologies on three real-world datasets.,Performance Evaluation
1124,"Using a measure of ICT incivility aggression, we measured the enactment of incivility behaviors through ICT.",Applications
1125,We provide a framework for studying the impact of ICT incivility aggression on both the work and family domains through affective states.,Model Construction or Optimization
1126,Our model improves theoretical and empirical understanding of how ICT incivility operates.,Performance Evaluation
1127,Our results may support organizations seeking to formulate policies and practices that discourage ICT incivility aggression.,Theory Proposal
1130,Conduct extensive experiments on the Mobile Data Challenge (MDC) dataset to evaluate the effectiveness of MEPSR.В ,Performance Evaluation
1135,enhancing the lexicon creation techniques using reviews with valency labels further by making use of probability distribution of key words across all star rating points of labelled reviews to build domain specific lexicons;В ,Theory Proposal
1136,comparing the performance against other lexical methods using star ratings across nine datasets,Performance Evaluation
1138,Fatigue and flow experience play important moderating roles..,Theory Proposal
1141,In-depth interviews with students in twenty universities verified the framework.,Applications
1142,Results reveal how students use music for learning and well-being.,Dataset Creation or Resources
1143,Findings yield implications for the design of online music services and systems.,Dataset Creation or Resources
1144,We propose an autoencoder-based method to generate phrase embedding.,Algorithms/ Methods Construction or Optimization
1145,"The method uses full connected network, LSTM and attention to get phrase embedding.",Algorithms/ Methods Construction or Optimization
1146,The method can learn the order and semantic information of component words.,Algorithms/ Methods Construction or Optimization
1147,The proposed method performs best on phrase similarity and classification tasks.,Performance Evaluation
1148,The method can utilize the external and internal contextual information of phrases.,Algorithms/ Methods Construction or Optimization
1152,Three metrics show particular promise for early identification of breakthrough works.,Dataset Creation or Resources
1153,We collected 576 frequent Chinese Internet slang expressions as a Chinese slang lexicon.,Dataset Creation or Resources
1154,We converted the 109 Weibo emojis into textual features creating Chinese emoji lexicon.,Dataset Creation or Resources
1155,We empirically confirmed inherent humor characteristic to Chinese culture visible on Weibo and divided Weibo posts into four categories.,Applications
1156,"We proposed HEMOS, a fine-grained humor detecting method for sentiment analysis of social media.",Algorithms/ Methods Construction or Optimization
1157,We propose a Hierarchical Compare Aggregate (HCA) model for question retrieval in CQA,Model Construction or Optimization
1158,The HCA-model can handle the lengthy question with multiple noisy sentences,Model Construction or Optimization
1159,The HCA-model achieves the best results in the both public-domain SemEval datasets and the domain-specific AskUbuntu dataset,Performance Evaluation
1160,"We contribute a multi-domain and multi-modality event dataset, consisting of news articles contributed by journalists on different news media sites and images shared by amateur users on social media providing official and folk perspectives of events",Dataset Creation or Resources
1161,"We investigate a number of approaches focusing on cross-modal retrieval and cross-domain event discovery on the MMED dataset and conduct a series of quantitative and qualitative analyses, which can be used as a benchmark for comparisons.",Applications
1162,This paper showcases the usage of author sequence in publication bylines in mapping knowledge domains and in co-citation analysis.,Dataset Creation or Resources
1163,This paper combines both quantitative and qualitative methods in evaluating knowledge domain maps.,Dataset Creation or Resources
1164,This paper offers a new framework of evaluating knowledge domain maps.,Model Construction or Optimization
1165,This paper summarizes previous studies regarding author co-citation analysis in a good manner.,Theory Proposal
1166,We propose an event network structure for extracting temporal and causal relations.,Model Construction or Optimization
1167,"By adopting open information extraction, we identify relation across multiple sentences.",Theory Proposal
1168,Our approach is able to identify temporal and causal relations in an unsupervised manner.,Model Construction or Optimization
1169,Our work is able to identify both directly and indirectly observable relations.,Theory Proposal
1170,Most existing deep supervised hashing methods mainly focus on how to effectively preserve the similarity information of semantic labels while ignoring discrimination information in the labels.,Theory Proposal
1171,A novel discriminative dual-stream deep hashing method is proposed to integrate the pairwise similarity loss and the classification loss into a unified framework to take full advantage of label information.,Algorithms/ Methods Construction or Optimization
1172,The proposed method enlarges the margin between the different classes so that can generate discrimination of learned binary codes for better image retrieval performance.,Algorithms/ Methods Construction or Optimization
1173,Extensive experiments show that the proposed method consistently outperforms current state-of- the-art methods on three benchmark datasets for image retrieval task.,Performance Evaluation
1174,A sequential search pattern analysis and clustering approach is proposed to analyze consumersвЂ™ search behavior throughout the entire shopping process from the perspective of need-states.,Model Construction or Optimization
1175,We adopt maximal repeat patterns and lag sequential analysis to analyze the sequence of search paths and significant search patterns.,Algorithms/ Methods Construction or Optimization
1176,"We identify four groups of consumers who browse for information, adopt recommendations, consult reviews, and conduct searches with different levels of need-states.",Dataset Creation or Resources
1177,Each group employs its own particular web features to facilitate the shopping process.,Theory Proposal
1178,We study how does a reviewer's emotional expression implied in online reviews influence the reader's perceived usefulness.,Applications
1179,Reveal that fear-embedded reviews are perceived to be more reviewer`s cognitive effort than angry-embedded reviews.,Theory Proposal
1180,Reveal that pride-embedded reviews are perceived to more reviewer`s cognitive effort than surprise-embedded reviews.,Theory Proposal
1181,Show the impacts of different emotional expressions on perceived of reviewer`s cognitive effort is moderated by the gender of readers.,Theory Proposal
1182,Social spam evolution is leading to a marked deterioration in the performance of state-of-the-art supervised classifiers.,Theory Proposal
1183,The Markov Random Fields formalism allows a hybrid social spam detection model that exploits both users features and their content-based similarity.,Model Construction or Optimization
1184,Users content can be exploited to define robust similarity measures.,Theory Proposal
1185,Biased and inaccurate prior predictions on users classes can be effectively used in the context of probabilistic graphical models as demonstrated by the significant increase in recall obtained by the proposed approach.,Theory Proposal
1186,Outfit recommender systems based on multimodal item representations work best.,Theory Proposal
1187,Outfit recommendation needs effective fusion of shared and complementary features.,Theory Proposal
1188,Unimodal attention mechanisms can focus on fine-grained and complementary features.,Theory Proposal
1189,Deep learning based recommender system for outfit recommendation.,Model Construction or Optimization
1190,"An unsupervised, language independent framework for generic extractive multi-document summarization",Model Construction or Optimization
1191,Bridging the gap between short texts and the conventional text processing methods by expanding sentences with respect to word sense disambiguation and tuning of conceptual densities in the sentences.,Applications
1192,The proposed approach is able to dynamically determine the number of clusters and their initial centroids aiming to identify the main concepts of the documents.,Model Construction or Optimization
1193,"Producing Summaries with respect to information significance, minimum redundancy, maximum coverage, and cohesion.",Dataset Creation or Resources
1194,Able to learn a context-aware semantic model for more accurately estimating semantic similarities.,Model Construction or Optimization
1195,Relevance matching plays a more important role than semantic matching in information retrieval.,Theory Proposal
1196,"The proposed framework, which combines relevance matching and semantic matching, is more effective than using either relevance matching or semantic matching.",Performance Evaluation
1197,Five enhanced models are generated by merging the framework with probability-based PRF models and language-model-based PRF models.,Model Construction or Optimization
1198,Our PRF framework combines relevance matching and semantic matching to improve the quality of the feedback documents.,Model Construction or Optimization
1199,Digital forensics can effectively extract activity timelines that help user-centred archival practice.,Theory Proposal
1200,Data exploration of hard drive activities can reveal clues about the artist's life and creative processes.,Theory Proposal
1201,"Data exploration of hard drive activities can uncover the life cycle of files, and identify relationships between files.",Theory Proposal
1202,Analysis of hard drive metadata can help identify file formats and the software environment in which the artist worked.,Theory Proposal
1203,Metadata visualisations facilitate multiple levels of content access without the demand for specialist subject knowledge.,Theory Proposal
1204,An original framework of semi-supervised learning is presented for POI recommendation,Model Construction or Optimization
1205,Multiple factors are jointly studied to excavate complex spatio-temporal patterns of visiting behaviors.,Applications
1206,A network embedding method is proposed to learn the vectors of users and POIs in an embedding space with low dimensionality.,Algorithms/ Methods Construction or Optimization
1207,A dynamic factor graph model is proposed to model different factors including the correlation of usersвЂ™ vectors and POIsвЂ™ vectors.,Model Construction or Optimization
1208,"Leverage regions to capture the spatial information in mouse interaction data, which could reserve more details of the interaction processes between users and SERPs;",Dataset Creation or Resources
1209,"Propose a data augmentation strategy MFP to generate new mouse interaction sequences, which could increase the pattern variations on mouse interaction sequences;",Model Construction or Optimization
1210,"Propose RALSTM to learn the representations of mouse interaction sequences, which could capture the interactive relations between regions and actions without subjecting the network to higher training complexity.",Model Construction or Optimization
1211,Noisy terms in social media posts must be semantically analysed to gain full insights.,Theory Proposal
1212,Better understanding and interpretation of social media feeds is critical for techniques building on them.,Theory Proposal
1213,Localized knowledge sources can fully capture social media noisy terms from a particular location.,Theory Proposal
1214,Resolving ambiguity in the use of slangs/ acronyms/abbreviation lead to improved accuracy.,Theory Proposal
1215,A credibility assessment model of good abandonment results in mobile search is proposed and validated in multiple dimensions.,Theory Proposal
1216,Six credibility measures are verified to have an effect on usersвЂ™ credibility assessment when they get good abandonment results in mobile search.,Theory Proposal
1217,How these measures help users to judge the credibility of results is explained.,Dataset Creation or Resources
1218,Suggestions on enhancing the credibility of results in mobile search were proposed based on the model.,Model Construction or Optimization
1219,A new theoretical framework is developed to explore microblog information credibility by incorporating message format.,Model Construction or Optimization
1220,"Argument quality has a decreasing incremental effect on microblog information credibility, suggesting that argument quality is a hygiene factor.",Theory Proposal
1221,"Source credibility was found to have a positive and linear effect on microblog information credibility, consistent with the role of a bivalent factor.",Performance Evaluation
1222,Multimedia diagnosticity was found to have an increasing incremental effect on microblog information credibility.,Performance Evaluation
1231,Both quantitative and visual results show ED-Net outperforms other methods.,Performance Evaluation
1235,"We compute the relevance and utilisation of facial action unit (FAU)-derived features by the model, comparing it against the human perception of emotion expression.",Applications
1236,We extend this FAU-based вЂ™affectвЂ™ prediction approach to the FAU-based вЂ™pain-intensityвЂ™ prediction problem.,Dataset Creation or Resources
1238,"We combine the cross entropy function with the deformed max-margin function as a new loss function, which can improve the performance of the model.",Model Construction or Optimization
1240,Designing a learnable overall relevance measure that makes full use of structural and attributed information by integrating HeteSim and attribute projection.,Algorithms/ Methods Construction or Optimization
1241,Proposing a constrained negative matrix tri-factorization which utilizes pairwise constraints to cluster nodes of different types at the same time and give a closed solution.,Algorithms/ Methods Construction or Optimization
1242,Modeling a unified framework to simultaneously co-cluster different-type nodes and mine the latent relevance between heterogeneous clusters on realworld attributed HINs such as e-commerce platforms and bibliographic networks.,Model Construction or Optimization
1253,The syntactic and semantic feature spaces used in summarization were comprehensively investigated.,Dataset Creation or Resources
1256,"We provide an inclusive, intelligent, semi-auto-constructed knowledge graph framework HKGB for the medical domain to build knowledge graphs.",Algorithms/ Methods Construction or Optimization
1258,We design an extensible mechanism to add a new disease to an existing knowledge graph.,Algorithms/ Methods Construction or Optimization
1261,There is a continuous rise in using social bots and trolls in Twitter and other online social networks.,Theory Proposal
1262,Social bots are not homogeneous; they are used for different goals which social botsвЂ™ characteristics.,Theory Proposal
1263,"Social bots can be more active than humans in creating tweets, but they can be less active in some other activities related to Twitter-account interactions with friends and followers or how often such accounts change their status.",Theory Proposal
1264,"Although social bots can vary in behavior based on their goals, content-based analysis indicates that social bots tend to be more formal in their language in comparison to human accounts, which can be identified through the use of slurs, slang, X-rated words, and the like.",Theory Proposal
1265,Most knowledge bases focus on entity facts abandoning procedural knowledge.,Theory Proposal
1266,Much of the commonsense knowledge about the real world is in the form of procedures or sequences of actions.,Theory Proposal
1267,Automatically build procedural knowledge for the health domain from on-line communities.,Applications
1268,Used open information extraction tool and a pipeline to build the procedural knowledge base,Model Construction or Optimization
1269,"A semantically organized knowledge base of 71,200 health-related task frames.",Dataset Creation or Resources
1270,Propose a novel recommender system finds the best list of items for users using GA.,Model Construction or Optimization
1271,The recommender system generates the recommendation using multi-filtering criteria.,Model Construction or Optimization
1272,Propose a multi-objective GA has n-fitness functions based on n-filtering criteria.,Algorithms/ Methods Construction or Optimization
1273,The GA hierarchically evaluates the individuals using three fitness functions.,Applications
1274,Adopt the multi-ratings criteria idea to evaluate the individuals based on n-rates.,Performance Evaluation
1275,Alleviate cold start and sparsity issues of collaborative filtering.,Dataset Creation or Resources
1276,The security problems related to a federated trust management supported by the blockchain within the context of the IoT is formulated;,Applications
1277,"The interactions of the edge node with the IoT node is modelled as a signalling game, which is studied and a solution is formulated as a Perfect Bayesian Equilibrium",Model Construction or Optimization
1278,The evolutionary game and Dempster-Shafer theory are combined so as to achieve a robust evidence aggregation and realise robust trust estimation,Theory Proposal
1279,An empirical assessment is presented with an implementation realised with Hyperledger platform.,Applications
1280,A new multi-sentence video captioning algorithm is proposed.,Algorithms/ Methods Construction or Optimization
1281,A new content-oriented beam search approach and a multi-stage refining method are used.,Algorithms/ Methods Construction or Optimization
1282,The structural dictionary of sentences is used to update the probabilities of words.,Dataset Creation or Resources
1283,An object detector is used to enhance the effectiveness of the algorithm.,Algorithms/ Methods Construction or Optimization
1284,Proposing a new text graph representation model and proposing an algorithm to construct it from the input text.,Model Construction or Optimization
1285,Proposing a new method to dynamically compute weight values for the graph nodes. The method is based on the characteristics of the input document. The weights are adjusted based on the distribution of words and their frequencies in the input text.,Algorithms/ Methods Construction or Optimization
1286,Proposing a graph search algorithm to search for the candidate nodes and edges in the text graph. The selected nodes and edges represent the important phrases in the input text.В ,Algorithms/ Methods Construction or Optimization
1287,"This algorithm is a generic algorithm that can be used in many applications such as single and multi-document summarization, key phrases extraction, highlights generation, etc.",Algorithms/ Methods Construction or Optimization
1288,"Proposing a sentence selection algorithm that ranks candidate sentences, groups these sentences in a set of clusters using the K-means clustering algorithm, and selects the top-ranked sentences from each cluster for the final generated summary.",Algorithms/ Methods Construction or Optimization
1289,Combining a set of extractive ATS methods to benefit from their advantages and overcome drawbacks of every single method.,Algorithms/ Methods Construction or Optimization
1291,A systematic review on social media analytics-based BI studies is presented.,Dataset Creation or Resources
1292,Social media platforms that are in use in BI research are classified and analyzed.,Dataset Creation or Resources
1293,Dominant methodologies or algorithms for BI research are classified and analyzed.,Dataset Creation or Resources
1294,Types of intelligent information social media-based BI studies identify are analyzed.,Dataset Creation or Resources
1295,Promising directions of the research stream are intended for researchers and practitioners.,Dataset Creation or Resources
1296,"we estimate the implicit city-level geographic coordinate context of a Twitter user given her/his historical tweets, which is valuable when geotagged tweets or Twitter user location profiles are unavailable or unreliable (a common situation in practice)",Model Construction or Optimization
1297,"we propose a new unsupervised clustering approach for the user location estimation, based on GT noun city distributions, city polygons, a synthetic sampling and three clustering algorithms: Gaussian Mixture Models (GMM), K-means and Density-Based Spatial Clustering of Applications with Noise (DBSCAN)",Algorithms/ Methods Construction or Optimization
1298,"we create a recent Twitter user dataset with ground truth city-level locations for 3,268 worldwide users, to compare the proposed approach with a WD method that uses GMM and labeled tweets",Dataset Creation or Resources
1299,Proposed two models Time Decay Features Cascade Model (TDF-C) and Time Decay Features Cascade Threshold Model (TDF-CT).,Model Construction or Optimization
1300,"Models integrate temporal, structural, profile and interaction characteristics of the social network in diffusion process.",Model Construction or Optimization
1301,"TDF-CT handles the limitations of the contemporary diffusion models, i.e., Independent Cascade and Linear Threshold.",Model Construction or Optimization
1302,"TDF-C and TDF-CT outperformed Independent Cascade, Time Constant Cascade, Time Decay Cascade & Time-Depth Decay Cascade.",Performance Evaluation
1303,TDF-C and TDF-CT improve the influence propagation upto 39% with respect to contemporary models.,Performance Evaluation
1304,"investigate the issue of predicting the success of video segments, which can assist viewers in finding appealing shots.",Theory Proposal
1305,"time-sync comments information mining, is used to understand the audience better",Theory Proposal
1306,"A distributed intelligent framework for real-time social big data analytics that ingests, stores, processes, indexes, and visualizes massive amounts of data.",Model Construction or Optimization
1307,"For improving decision-making processes in the sense of big data, the framework uses distributed machine learning and deep learning techniques.",Model Construction or Optimization
1308,propose a sentiment analysis method based on using fastText with recurrent neural network variants to efficiently represent textual data.,Algorithms/ Methods Construction or Optimization
1309,"For sentiment analysis, we devised a solution to boost the efficiency of well-known Recurrent neural network models such as LSTM, BiLSTM, and GRU.",Model Construction or Optimization
1310,"using freely accessible public data, new deep learning methods for accurate detection and recognition of professionally unreported drug side effects",Algorithms/ Methods Construction or Optimization
1311,use of bidirectional Encoder Representations from Transformers for ADE detection and extraction,Algorithms/ Methods Construction or Optimization
1312,Identification of different sources of eyewitnesses reports in twitter during a disasterВ ,Theory Proposal
1313,uses different characteristics and labeled data to train several machine learning classifiers,Algorithms/ Methods Construction or Optimization
1314,Based on microblog proposed a content-location-aware public welfare activity information push systemВ ,Model Construction or Optimization
1315,Propose a subject model and keyword search-based approach for identifying users who are specifically interested in learning about public welfare activities.,Model Construction or Optimization
1316,"By comparing the correlations between seed users and local users, a distance metric learning-based approach is used to achieve a specific number of local possible users.",Algorithms/ Methods Construction or Optimization
1317,"A new graph-based paradigm called ""Multi-iterative Graph-based opinion Spam Detection"" (MGSD) is proposed, in which all different forms of entities are considered at the same time within a single system.",Model Construction or Optimization
1318,"By using the feature fusion technique to evaluate the most appropriate combination of weighted features, the usefulness of the features is assessed.",Model Construction or Optimization
1319,"A new system called as SNSJam was proposed Using several data sources, including Twitter and Instagram, a system to identify and forecast road traffic jams has been developed.",Model Construction or Optimization
1320,A Location recognizer that uses the text of posts and/or GPS coordinates to identify locations. It is first system that define and support user-defined locations.,Model Construction or Optimization
1321,"To detect traffic jams, a context-aware classifier is used. The classifier will decide what is causing traffic jams.В ",Algorithms/ Methods Construction or Optimization
1322,a fine-grained emotion prediction model for real-time multimodal data using a hybrid deep learning approach,Model Construction or Optimization
1323,Sentiment for textual modality is calculated using a convolution neural network (ConvNet) enriched with SentiCircle's qualitative semantics.,Model Construction or Optimization
1324,"The proposed model's accuracy is approximately 91 percent, which is an increase over the accuracy obtained by the text and image modules separately.",Performance Evaluation
1325,"Detecting, monitoring, and forecasting incidents from a number of news feeds",Dataset Creation or Resources
1326,"Discrete dynamic topic modeling and Hidden Markov Model for event detection and tracking are used, Using the crowdsourcing platform called crowdflowerВ a set of heterogeneous news streams where the news records are classified at the level of fine-granularity events",Dataset Creation or Resources
1327,"A novel entropy-based privacy-preserving MCCF architecture is proposed, which enables users and sub-criteria to manage privacy-specific parameters dynamically.",Model Construction or Optimization
1328,"Although retaining the same degree of privacy as the conventional privacy security situation, the proposed entropy-based privacy-preserving system will make substantially more precise forecasts.",Theory Proposal
1329,improve the state-of-the-art query performance prediction (QPP) effectiveness,Performance Evaluation
1330,"A generative model of query specificity, namely estimating d(Q, Q), based on the application of embedded word vectors",Model Construction or Optimization
1331,"A multi-centrality index (MCI) method, which seeks to find the best combination of word rankings based on a number of different centrality measures",Algorithms/ Methods Construction or Optimization
1332,"Betweenness, Clustering Coefficient, Closeness, Degree, Eccentricity, Eigenvector, K-Core, PageRank, Structural Holes are analyzed locating keywords by co-occurrence Documents are represented by word-graphs.",Applications
1333,The proposed MCI approach significantly outperforms the individual centralities,Performance Evaluation
1334,Disnormative needs for information were examined among drug users in dark web,Dataset Creation or Resources
1335,The articulation of such needs is determined by the requirement of secrecy.,Theory Proposal
1336,"Information need is triggered by physiological, affective and cognitive factors.",Theory Proposal
1337,Such factors appear in diverse combinations but physiological factor is primary.,Theory Proposal
1338,"The amount of time spent on previous search results could be an indicator of potential problems in articulation of needs into queries, perceiving useless results, and not getting useful sources in the following search stage in an information search process.",Theory Proposal
1339,"While performing social tasks, users mostly searched with an entirely new query, whereas, for cognitive and moderate to high complexity tasks, users used both new and substituted queries as well.",Theory Proposal
1340,"From usersвЂ™ search behaviors, it is possible to predict the potential problem that they are going to face in the future.",Theory Proposal
1341,"UserвЂ™s search behaviors can map an information searcherвЂ™s situational need, along with his/her perception of barriers and helps in different stages of an information search process.",Theory Proposal
1342,"By combining perceived problem(s) and search behavioral features, it is possible to infer usersвЂ™ needed help(s) in search with a certain level of accuracy (78%).",Theory Proposal
1343,An empirical Bayesian approach for making probabilistic predictions of events such as social unrest from online social network data.,Algorithms/ Methods Construction or Optimization
1344,A framework for predictive modelling from social networks by combining machine learning tools,Model Construction or Optimization
1345,"Analysis of datasets relating to social unrest in Australia during 2017/18, including a dataset used to classify protest-relevant tweets included with the paper.",Dataset Creation or Resources
1346,We propose an attention-based Hierarchical LSTM network to identify successful persuasion from CMV conversations. We use this model to predict whether a particular chain of comments is going to persuade the OP or not. This model jointly learns the binary classification of persuasion guided by О”-score and regression task of predicting the karma score for each comment.,Model Construction or Optimization
1347,"We incorporate an attention mechanism in our model which weighs sentences in a comment accordingly; we use these weights to identify argumentative sentences. To the best of our knowledge, this is the first attempt to train a neural network for a supervised task (persuasion prediction) and force it to learn an unsupervised task (argumentative sentence identification).",Model Construction or Optimization
1348,"We propose a novel algorithm to detect argument components from argumentative sentences. This algorithm exploits some linguistic rules to identify a subset of argument components and finds the closure using similarity measurements. We employ Dynamic Time Warping distance (a measurement of geometric similarity between variable length time series data) to compute the similarity between text segments taken as time series. To the best of our knowledge, this is the first semi-supervised approach for argument mining from social media conversations",Algorithms/ Methods Construction or Optimization
1349,"Despite the importance of identifying leading VCs, this research topic is rarely mentioned in the relevant literature. As we know, this paper is the first study to identify leading VCs.",Theory Proposal
1350,"This paper incorporates with several different centrality measures of co-investment network of VCs, and then proposes a new approach based on the weighted k-means to rank VCs at both group and individual levels and identify the leading VCs",Theory Proposal
1351,"The approach not only shows alternative groupings based on multiple evaluation criteria, but also ranks them according to their comprehensive score which is the weighted sum of these criteria.",Dataset Creation or Resources
1352,"Empirical analysis shows the efficiency and practicability of the proposed approach to identify leading Chinese VCs. It indicates that the proposed method is worth considering, especially as is helpful for social scientists to understand leading VCs based on the results of analyzing historical data of investment events.",Performance Evaluation
1353,"Combination of tensor factorization with classification, achieving class-aware factorization of tensorial data.",Theory Proposal
1354,"Demonstration of the benefits of using the proposed method to rank social network users according to their class, using real-world datasets.",Algorithms/ Methods Construction or Optimization
1355,"We formulate the two-phase objective function under FriedkinвЂ“Johnsen model, where a nodeвЂ™s final opinion in the first phase acts as its initial bias for the second phase, and the effectiveness of a campвЂ™s investment on the node depends on this initial bias",Algorithms/ Methods Construction or Optimization
1356,"For the non-competitive case, we develop a polynomial time algorithm for determining an optimal way to split a campвЂ™s budget between the two phases and the nodes to be invested on in the two phasesВ ",Algorithms/ Methods Construction or Optimization
1357,"For the competitive case involving both the camps, we show the existence of Nash equilibrium, and that it can be computed in polynomial time under reasonable assumptions",Algorithms/ Methods Construction or Optimization
1358,"Using simulations, we illustrate our analytically derived results on real-world network datasets, and quantify the effects of the initial biases and the weightage attributed by nodes to their initial biases, as well as that of a camp deviating from its equilibrium strategy",Algorithms/ Methods Construction or Optimization
1359,"we study, for the first time in the literature, the problem of bribing users in the recommender systems context, identifying under which conditions sellers can make effective attacks;",Theory Proposal
1360,we propose a novel hybrid Collaborative Filtering algorithm to counter bribing;,Algorithms/ Methods Construction or Optimization
1361,"we identify, from the point of view of a seller of an itemВ i, which users are profitable to bribe in the following cases: (i) bribe a user that already ratedВ iВ to increase his/her rating; (ii) bribe a user that did not rateВ iВ to rate it; (iii) bribe a user that rated a competitor product to decrease his/her rating; (iv) bribe a user to rate a related item;",Theory Proposal
1362,we show that our algorithm is as effective as the state-of-the-art approaches while being more efficient,Performance Evaluation
1363,"we illustrate our framework, by studying the impact of bribing in our algorithm and a real-world system (the SVD recommender systemВ (Salakhutdinov & Mnih,В 2007)), considering the MovieLens 100k and 1M datasets, showing that our approach is more robust against bribery.",Model Construction or Optimization
1364,"We are one of very few works in the literature to perform fine-grained (i.e., attraction-level, with at least monthly granularity) predictions of visitation counts and exploit social media data to improve such predictions. And we do this for more than one hundred attractions while most works focus on a single or just a few attractions.",Theory Proposal
1365,"We incorporate both environmental and social media features in order to predict touristic demands, creating robust forecasting models. This is especially useful in the case of touristic places with low availability of visitation census (e.g., due to high costs of surveys and the difficulty to access remote places to collect data).",Model Construction or Optimization
1366,"We collect, join and analyze five different datasets вЂ“ TripAdvisor reviews and ratings, U.S National Park Service, U.S national climate data center, Department for Digital, Culture, Media and Sport of England and finally U.K national weather service covering two types of attractions (indoor and outdoor attractions). We made these datasets available online in our data in brief paper (Khatibi, Belem, da Silva, Almeida, & Goncalves, 2019) for future experiments in the area of fine-grained tourism analysis using social media and environmental data.",Dataset Creation or Resources
1367,"We compare the effectiveness of five different machine learning techniques, namely, Linear Regression, Support Vector Regression, General Regression Neural Network, SARIMA and SARIMAX, for the tourism demand prediction task in all considered scenarios",Algorithms/ Methods Construction or Optimization
1368,"We propose a community detection method that considers usersвЂ™ topical interests and their temporal evolution in tandem by learning neural user representations, which embeds users in an embedding space where those users who have similar inclination towards similar topics in similar time intervals will be embedded close to each other.",Algorithms/ Methods Construction or Optimization
1369,We employ neural graph embedding techniques to embed information from usersвЂ™ social network structure into user representations.,Algorithms/ Methods Construction or Optimization
1370,"We build a single set of multimodal embeddings from embeddings of temporal social content and social network structure through their linear interpolation in order to elucidate the contribution of usersвЂ™ temporal content on the one hand, and social network structure, on the other hand, for finding user communities.",Algorithms/ Methods Construction or Optimization
1371,"We identify temporal content-based user communities which are topically, temporally and structurally cohesive, based on our multimodal user embeddings.",Algorithms/ Methods Construction or Optimization
1372,"We demonstrate the performance of the various variations of our work in the context of news recommendation and user prediction, and compare them to the state of the art on a Twitter dataset.",Performance Evaluation
1373,We define the novel attributed group (AG) query problem over attributed graphs and we propose new objective functions to rank the results.,Theory Proposal
1374,"We prove that optimizing these objectives is NP-hard. Thus, we propose approximation algorithms with a guaranteed ratio of two to find the answers efficiently.",Algorithms/ Methods Construction or Optimization
1375,"Since the total number of answers is exponential in the number of query keywords and the size of the group, we propose a procedure to find approximate top-kВ groups with polynomial delay.",Model Construction or Optimization
1376,"We experimentally compare our methods against existing approaches on real-world large graphs, showing that our algorithms efficiently find compact groups with the desired size and keyword coverage.",Performance Evaluation
1377,Example seed nodes may be too few and non-central to help produce high quality community ranks.,Theory Proposal
1378,Finding more seed nodes can improve the quality of ranking algorithms.,Theory Proposal
1379,Proposed a novel seed oversampling method to find more seed nodes,Algorithms/ Methods Construction or Optimization
1380,Proposed a boosting scheme to combine seed oversampling iterations,Model Construction or Optimization
1381,Produced higher quality ranks compared to the neighborhood inflation heuristic.,Model Construction or Optimization
1382,We devise probabilistic meta paths representation learning for churn prediction.,Model Construction or Optimization
1383,We propose a random walks sampling method based on the corresponding Markov models.,Algorithms/ Methods Construction or Optimization
1384,Experiments on real-life datasets show the benefit of probabilistic meta path RL,Applications
1385,We obtain promising insights on meta path type and predictive outcome interplay.,Applications
1386,Our method alleviates RL computational requirements by random walk sampling.,Algorithms/ Methods Construction or Optimization
1387,we constructed the largest network evolution corpora that is publicly available.,Model Construction or Optimization
1388,"The dataset consists of billions of records that we used to construct and analyze the evolution process of over 38,000 complex networks and the topological properties of more than 2.5 million graphs over long periods of times. This dataset can immensely aid researchers in investigating and understanding complex dynamic systems",Dataset Creation or Resources
1389,we observed that time is a crucial factor in the way a network evolves. Vertices tend to connect to other vertices that join the network at a similar time.,Theory Proposal
1390,"we found that the rate new vertices join a network is a central factor in molding a networkвЂ™s topology. We identified six common patterns in which vertices tend to join a network (seeВ Fig.В 2). Moreover, we observed that different vertex-join patterns influence the structure and properties of a network",Theory Proposal
1391,"we discovered that network stars (high-degree vertices) tend to emerge in networks that are growing rapidly. For slow-growing networks, most stars emerged a short time after the network became active and kept their place, while for fast-growing networks, stars emerged at any timeВ ",Theory Proposal
1392,"we developed a simple model, utilizing all the above observations, that uses real-world big data to confirm and explain our observations. Our Temporal Preferential Attachment (TPA) model improves upon previous models because it more correctly represents real-world data, especially for networks that are growing quickly, and can be used in a more flexible manner. Furthermore, our model gives insights on the changing popularity of network stars",Model Construction or Optimization
1393,A new method for extracting science claims in news headlines.,Algorithms/ Methods Construction or Optimization
1394,The new method is tailored to the language style of news headlines.,Algorithms/ Methods Construction or Optimization
1395,The first step toward comparing health claims in news and original papers.,Dataset Creation or Resources
1396,We address the limitations in traditional multiple inheritance-based and MICA-based approaches,Dataset Creation or Resources
1397,We highlight some new structural issues in WCG in terms of branching factors and multiple inheritances.,Theory Proposal
1398,We introduce a new IC-based function to compute the semantic contribution weight of a category in WCG,Algorithms/ Methods Construction or Optimization
1399,We present a new multiple inheritance-based SS approach called Neighborhood Ancestor Semantic Contribution (NASC),Model Construction or Optimization
1400,We evaluate our methods in gold standard word similarity benchmarks,Performance Evaluation
1401,The quantitative analysis in terms of topic words and their correlation for mining and analysis of foreign relations is lacked and needed.,Theory Proposal
1402,A framework for studying foreign relations is proposed and tested with British parliamentary texts,Model Construction or Optimization
1403,Five communities are identified and the distribution of topics related to China is extremely unbalanced and highly concentrated.,Theory Proposal
1404,Evolution patterns of main topics are widely different in terms of continuity and development trends.,Theory Proposal
1405,"The case study on UK-China relations contribute to deepen the understanding of international relations between the two countries, so as to provide valuable references and suggestions for the government and researchers.",Theory Proposal
1406,"We propose a novel alternative loss function termed Incremental Focal Loss (IFL), which is demonstrated to apparently boost training of GANs.",Algorithms/ Methods Construction or Optimization
1407,We proposed an enhanced self-attention (ESA) mechanism to improve the representational capacity of deep features in the generator.,Algorithms/ Methods Construction or Optimization
1408,"Both IFL and ESA can be applied to various unsupervised or conditional GANs, and are promising to improve the quality of generated images.",Applications
1409,We propose a novel crowd-powered model to detect appropriateness of the videos on social media,Model Construction or Optimization
1410,Our experiments with 47 crowd contributors demonstrate the effectiveness of the proposed approach.,Performance Evaluation
1411,The approach detects the unsafe videos with high accuracy (95%) and point out the portion of inappropriateness.,Performance Evaluation
1412,"Using Prolog to process XQuery is faster than using native XML tools, for queries that search by key or position on small datasets.",Theory Proposal
1413,"For large datasets, or for queries that search for substrings, native XML approaches are the best option.",Theory Proposal
1414,Results show that it is worth investing in an algorithm to automatically translate XQuery into Prolog queries.,Theory Proposal
1415,We developed a coherent IT-enabled crowdsourcing (CS) conceptual framework.,Model Construction or Optimization
1416,The main elements of a CS process are identified.,Dataset Creation or Resources
1417,"The framework defines CS as a legitimate, IT-enabled form of problem-solving.",Model Construction or Optimization
1418,The framework extends the IS field and helps us better understand this phenomenon.,Theory Proposal
1419,Our results can help organizations to leverage CS more efficiently.,Applications
1420,Proposing a fusion approach for retrieving candidates in cross-lingual plagiarism detection that combines a conceptual-based and keyword-based retrieval models.,Algorithms/ Methods Construction or Optimization
1421,Providing a dynamic fusion measure that presents a specific interpolation factor for each sample of suspicious documents.,Algorithms/ Methods Construction or Optimization
1422,"Comprehensive assessment of the performance of conceptual models, especially the ESA model in the retrieval of candidates for cross-language plagiarism.",Performance Evaluation
1423,Study the impact of using peak-and-plateau strategy as post processing on the output of the proposed retrieval model.,Model Construction or Optimization
1424,Comparing the performance of the proposed model with the state-of-the-art approaches in cross-lingual candidate retrieval.,Performance Evaluation
1425,Human-human and human-bot conversation on Twitter can be characterized by specific patterns that emerge as bot and human accounts exchange emotion-conveying messages.,Theory Proposal
1426,"These patters come in form of statistically-significant subgraphs that we callВ emotion-exchange motifs, which are an extension of the traditional network motifs.",Applications
1427,"There are distinct emotion-exchange motifs that are characteristic for a human-like communication. These motifs include self-loops, reciprocal edges, and transitive triads.",Theory Proposal
1428,"Human users tend to use self-loops when communicating anger, a mechanism used to bypass the 140-character restriction on Twitter.",Theory Proposal
1429,"As they communicate with humans, bot accounts form only a smaller subset of emotion-exchange motifs that, unlike the ones found in a human-human communication, involve only one-way edges (message chain motifs, broadcasting motifs, and a message-receiver motifs without reciprocal edges).",Theory Proposal
1430,"Specific to the events considered in this study (riot events), bots were responsible for a dissemination of messages conveyingВ fear. These messages receives a considerable high number of retweets in our data-sets. The use of fear is also evident in the fear-exchange motifs where bots consistently take over a message-sender role (whereas a human is consistently a message receiver).",Theory Proposal
1431,"We design a multi-modal product title compression framework named TOPIC to consider multiple modalities of inputs for better short product titles generation. To the best of our knowledge, this is the first work to incorporate visual and textual features to boost the performance of product title compression in e-commerce.",Model Construction or Optimization
1432,"We present a cross- and intr-modal attention unit, which is able to encode the visual and textual information as context simultaneously. Meanwhile, considering that extractive-based methods may have the reorder problem, we further introduce the reinforcement learning to solve this problem",Model Construction or Optimization
1433,"We construct a multi-modal product title compression corpus from a real e-commerce platform. The experimental results on this dataset demonstrate that our proposed system outperforms the state-of-the-art methods. Meanwhile, we have released the dataset and implementation to facilitate the research community",Model Construction or Optimization
1434,We introduce two new large well-annotated corpora of Arabic text collected from several news portals. All datasets are available for the research community on Arabic computational linguistics,Dataset Creation or Resources
1435,"As far as we know, a thorough deep learning-based models has not been systematically studied for Arabic text classification.",Model Construction or Optimization
1436,We also integrate word embedding to enable the classifiers achieve superior performance.,Algorithms/ Methods Construction or Optimization
1437,"Finally, we conduct extensive experiments to show the effectiveness of the proposed datasets and deep learning models. The models achieve superior performance and the significant results affirm the suitability of such classifiers.",Performance Evaluation
1438,Differentiating two modes of private information disclosure on social network sites: active sharing and passive providing.,Applications
1439,"Active sharing is more likely to be driven by factors such as perceived benefits, social network size, and personalization.",Theory Proposal
1440,"Passive providing is more likely to be affected by factors such as quality of privacy policy, and perceived risks.",Theory Proposal
1441,"Gender has a positive impact on active sharing, but no significant impact on passive providing.",Performance Evaluation
1442,"Age has a negative impact on passive providing, but no significant impact on active sharing.",Performance Evaluation
1443,"We build a dataset, which includes video and time-sync comments, for segment popularity prediction.",Dataset Creation or Resources
1444,"We study the problem of video segment popularity prediction, which can help audiences to find attractive shots.",Theory Proposal
1445,"With the help of time-sync comments information mining, the model can better understanding the audiences.",Model Construction or Optimization
1446,Combining visual and text information can make results more precise.,Theory Proposal
1447,"We present an effective distributed intelligent system for real-time social big data analytics, which is dedicated to ingest, store, process, index, and visualize huge amount of information.",Model Construction or Optimization
1448,The system takes advantage of distributed machine learning and deep learning techniques for enhancing decision-making processes in the context of big data.,Model Construction or Optimization
1449,We propose an efficient strategy based on FastText word embedding and Recurrent neural network variants to learn textual data representations efficiently.,Algorithms/ Methods Construction or Optimization
1450,"We devise a solution to improve the performance of well-known Recurrent neural network models called LSTM, BiLSTM and GRU for sentiment analysis.",Algorithms/ Methods Construction or Optimization
1451,The experimental results prove the effectiveness of our proposal,Performance Evaluation
1452,Previous pharmacovigilance research fails to accurately discover drug side effects.,Theory Proposal
1453,We introduce a novel adverse drug event extraction algorithm using deep learning.,Algorithms/ Methods Construction or Optimization
1454,We introduce the use of novel contextual word and sentence embeddings.,Algorithms/ Methods Construction or Optimization
1455,Results show that our model outperforms current pharmacovigilance models.,Performance Evaluation
1456,This model can be applied to a wide variety of information extraction tasks.,Model Construction or Optimization
1457,"Designing a taxonomy consisting of different sub-types of eyewitnesses i.e., direct eyewitness, indirect eyewitness, vulnerable direct eyewitness.",Model Construction or Optimization
1458,"A generalized methodology, which can be applied on textual data from other domains to extract eyewitness reports, that uses textual content-based features and domain-expert features without relying on platform-specific features such as Twitter metadata.",Algorithms/ Methods Construction or Optimization
1459,Combining textual and domain-expert features to train and evaluate automatic machine learning classifiers on real-world disaster-related Twitter datasets.,Algorithms/ Methods Construction or Optimization
1460,"Last but not least, we offer all the labeled data obtained through crowdsourcing and manual analysis to the research community to further develop and extend this line of research. The dataset will be shared at the CrisisNLP repository:В https://crisisnlp.qcri.org/.",Dataset Creation or Resources
1461,Abstract and precise relevance criteria for emergency services and classifiers.,Algorithms/ Methods Construction or Optimization
1462,Batch learning for relevance classification using precise relevance criteria.,Algorithms/ Methods Construction or Optimization
1463,Active learning for rapid classification during time-critical disasters.,Algorithms/ Methods Construction or Optimization
1464,Feedback learning allowing users to correct misclassifications reactively.,Algorithms/ Methods Construction or Optimization
1465,Incremental learning for real-time classifier quality prediction during labeling.,Algorithms/ Methods Construction or Optimization
1466,"Propose CLAP, which can seek a certain number of local potential users for a PWAP, and push the corresponding information to them.",Algorithms/ Methods Construction or Optimization
1467,"Propose a topic model and keyword search based method to discover users who are explicitly interested in PWAs, which can work without tags and complete microblog contents.",Model Construction or Optimization
1468,"Propose a distance metric learning based method to obtain a certain number of local potential users, which can accurately measure the similarities between seed users and local users.",Algorithms/ Methods Construction or Optimization
1469,"A novel heterogeneous graph (MGSD) model is proposed to illustrate the intra- and inter-relationships among entities (e.g., to capture both singleton and multiple spam entities).",Model Construction or Optimization
1470,"Various sets of existing content, behaviour and relation-based features are exploited, with a new set of features defined to improve spamming detection accuracy. Importance of the features is analysed (the featuresвЂ™ weight) by applying the feature fusion technique to determine the most effective combination of weighted features.",Algorithms/ Methods Construction or Optimization
1471,"A multi-iterative algorithm is designed to update the spamicity of entities during a finite number of iterations based on the spamicity score of their adjacent neighbours. The relationships among neighboursвЂ™ nodes though cannot be captured if only the spamicity score of each entity, without considering its neighbours, is calculated.",Algorithms/ Methods Construction or Optimization
1472,Top web search results from search engines are topically biased.,Theory Proposal
1473,Diversity fairness can improve diversity and relevance in retrieval results,Theory Proposal
1474,Performance of fair ranking strategies depend on fairness constraint and data.,Theory Proposal
1475,"The lower the diversity bias, the higher the relevance, diversity and novelty.",Theory Proposal
1476,"We propose SNSJam, which is a system to detect and predict road traffic jams by leveraging multiple data sources, specifically Twitter and Instagram.",Model Construction or Optimization
1477,"SNSJam supports multiple languages, specifically Arabic and English. It also supports Standard Arabic and UAE local Dialect.",Model Construction or Optimization
1478,"We developed a location recognizer that identifies locations from the text of posts and/or GPS locations. Additionally, SNSJam supports user-defined locations, which are common names among people but different from the official names. SNSJam is the first such system to define and support user-defined locations.",Algorithms/ Methods Construction or Optimization
1479,We developed a context-aware classifier to detect traffic jams. The classifier is able to identify the cause of traffic jams. The detected traffic jams can be visualized through a dynamic map.,Algorithms/ Methods Construction or Optimization
1480,SNSJam employs a linear regression model to predict future traffic jams by leveraging current and historical posts.,Model Construction or Optimization
1481,Expounds the aesthetics of sentiments in social psychology.,Theory Proposal
1482,"A Context-aware decision level fusion model for multimodal sentiment analysis in multimodal text, m, where m ОµВ {text, image, info-graphic} is proposed.",Model Construction or Optimization
1483,The textual modality sentiment is determined using a convolution neural network (ConvNet) enriched with the contextual semantics of SentiCircle.,Model Construction or Optimization
1484,Support vector machine (SVM) classifier trained using bag-of-visual-words (BoVW) for predicting the visual content sentiment.,Algorithms/ Methods Construction or Optimization
1485,"A Boolean system with a logical OR operation is augmented to the architecture for multi-class sentiment classification into five fine-grain levels, namely, highly positive, positive, neutral, negative and highly negative.",Model Construction or Optimization
1486,We combine visual attention and textual attention to forma dual attention mechanism to guide the image caption generation.,Algorithms/ Methods Construction or Optimization
1487,We adopt FCN to predict image tagsand fuse tag generation and image caption generation to train encode-decode model.,Model Construction or Optimization
1488,Our proposed model achieves state-of-the-artperformance in AIC-ICC image Chinese caption dataset.,Performance Evaluation
1489,"The proposal of a novel neural pseudo relevance feedback (NPRF) framework that enables the integration of PRF for neural retrieval. To the best of our knowledge, this is the first neural retrieval model that integrates PRF information by end-to-end learning.",Model Construction or Optimization
1490,"Three instantiations of the NPRF framework are introduced based on state-of-the-art neural IR models, namely the unigram DRMM and KNRM models, and the n-gram PACRR model.",Model Construction or Optimization
1491,"Thorough experiments support the frameworkвЂ™s intuition and showcase its ability in enhancing the retrieval performance of neural retrieval. In addition, analysis indicates reduced training and validation losses by our NPRF framework, leading to significantly improved effectiveness of the learned ranking functions.",Model Construction or Optimization
1492,The similarity between review title and content was examined.,Applications
1493,Text similarity between title and content affects review helpfulness.,Theory Proposal
1494,Consistence between title sentiment and review sentiment was tested.,Applications
1495,Sentiment consistence moderated relationships between text similarity and review helpfulness.,Theory Proposal
1496,"Using complex system simulation model to dynamically deduce the dissemination effect of network public opinion by government, media and netizens in the event of emergencies",Model Construction or Optimization
1497,Using social network analysis method to study the law and effect of network public opinion communication from the perspective of network space structure,Algorithms/ Methods Construction or Optimization
1498,Change the parameters of the main body and analyze the evolution trend of the network public opinion of the emergency.,Applications
1499,Provide policy support for the government in dealing with unexpected crisis management.,Model Construction or Optimization
1500,We propose the problem of recreational queries in information retrieval and propose a solution that combines search query logs with LBSNs.,Theory Proposal
1501,We describe a taxonomy for recreational queries derived from real world data by examining a real-world query log,Theory Proposal
1502,"We introduce a relevance model that incorporates spatial, temporal information, and social data.",Model Construction or Optimization
1503,We detail the offline evaluation of the POIs proposed by our techniques. This topic is usually not covered nor described in detailed in related work. We showed that assessing POIs is very complex and propose design alternatives that work well.,Algorithms/ Methods Construction or Optimization
1504,"To summarize, we present an end-to-end data driven system that uses LBSN data to solve a common web search scenario.",Model Construction or Optimization
1505,"Develops multimodal classification of memes using image, text, and face encoding.",Algorithms/ Methods Construction or Optimization
1506,Uses graph learning to create the evolutionary tree for memes.,Algorithms/ Methods Construction or Optimization
1507,Applies this to a large online conversation around a political event (2018 US mid-term elections).,Applications
1508,Outlines technique for meme OCR pre-processing.,Algorithms/ Methods Construction or Optimization
1509,"A conceptual definition of Taylor's Q1 level of вЂњvisceralвЂќ information need, which the searcher is not aware of, based in how humans intersect with the world of information.",Theory Proposal
1510,"An operational definition of Taylor's Q1 level of information need, based on Belkin's ASK concept of information.",Dataset Creation or Resources
1511,The article defines the searcher's search situation using Taylor's Q4 level of her compromised information need.,Dataset Creation or Resources
1512,The article outlines how an information system can shift the searcher from an ineffectual transactional Q4 level state of information to a relational Q1 level of the searcher's real information need.,Theory Proposal
1513,Important for search engine development which offers users an effective Q1 level information need actualization method.,Algorithms/ Methods Construction or Optimization
1514,Young fathers often have unexpressed and unaddressed information needs.,Theory Proposal
1515,Information inequality for young fathers was influenced by gender several levels.,Theory Proposal
1516,Young fathers encounter barriers when accessing parenting services.,Theory Proposal
1517,Young mothers often serve as information intermediaries for young fathers.,Theory Proposal
1518,Young fathers avoid asking for support to adhere to traditional masculine values.,Theory Proposal
1519,Disnormative needs for information were examined among drug users in dark web.,Theory Proposal
1533,Information needs are described as task-based activities.,Dataset Creation or Resources
1534,Task-based information needs are dependent of both individual characteristics and work task context.,Dataset Creation or Resources
1537,A framework for predictive modelling from social networks by combining machine learning tools.,Model Construction or Optimization
1540,"This paper incorporates with several different centrality measures of co-investment network of VCs, and then proposes a new approach based on the weighted k-means to rank VCs at both group and individual levels and identify the leading VCs.",Algorithms/ Methods Construction or Optimization
1541,"The approach not only shows alternative groupings based on multiple evaluation criteria, but also ranks them according to their comprehensive score which is the weighted sum of these criteria.",Applications
1542,"Empirical analysis shows the efficiency and practicability of the proposed approach to identify leading Chinese VCs. It indicates that the proposed method is worth considering, especially as is helpful for social scientists to understand leading VCs based on the results of analyzing historical data of investment events.",Algorithms/ Methods Construction or Optimization
1543,Introduced a new semi-supervised tensor factorization approach.,Algorithms/ Methods Construction or Optimization
1544,Presented a joint optimization method which combines tensor factorization and a classification error term.,Algorithms/ Methods Construction or Optimization
1545,Demonstrated effective performance in multiple real-world datasets.,Performance Evaluation
1546,"we study, for the first time in the literature, the problem of bribing users in the recommender systems context, identifying under which conditions sellers can make effective attacks",Theory Proposal
1547,we propose a novel hybrid Collaborative Filtering algorithm to counter bribing,Algorithms/ Methods Construction or Optimization
1548,we show that our algorithm is as effective as the state-of-the-art approaches while being more efficient;,Algorithms/ Methods Construction or Optimization
1549,"We are one of very few works in the literature to perform fine-grained (i.e., attraction-level, with at least monthly granularity) predictions of visitation counts and exploit social media data to improve such predictions.В ",Model Construction or Optimization
1550,"We incorporate both environmental and social media features in order to predict touristic demands, creating robust forecasting models.В ",Model Construction or Optimization
1551,we propose a new method for learning neural embeddings for users based on their temporal content similarity,Algorithms/ Methods Construction or Optimization
1552,we learn user embeddings based on their social network connections (links) through neural graph embeddings,Algorithms/ Methods Construction or Optimization
1553,we systematically interpolate temporal content-based embeddings and social link-based embeddings to capture both social network connections and temporal content evolution for representing users,Applications
1554,we systematically evaluate the quality of each embedding type in isolation and also when interpolated together and demonstrate their performance on a Twitter dataset under two different application scenarios,Performance Evaluation
1555,We define the novel attributed group (AG) query problem over attributed graphs and we propose new objective functions to rank the results.,Algorithms/ Methods Construction or Optimization
1557,"ince the total number of answers is exponential in the number of query keywords and the size of the group, we propose a procedure to find approximate top-kВ groups with polynomial delay.",Model Construction or Optimization
1561,Produced higher quality ranks compared to the neighborhood inflation heuristic.,Applications
1565,"We constructed the largest publicly available network evolution dataset to date, which contains 38,000 real-world networks and 2.5 million graphs.",Dataset Creation or Resources
1566,A novel flexible network-generation model based on large-scale real-world data is presented.,Model Construction or Optimization
1567,Links are most prevalent among vertices that join a network at a similar time.,Theory Proposal
1568,The rate that new vertices join a network is a central factor in molding a networkвЂ™s topology.,Theory Proposal
1569,The emergence of network stars (high-degree vertices) is correlated with fast-growing networks.,Theory Proposal
1570,Document clustering with document embedding representations combined with k-means clustering delivered the best performance.,Performance Evaluation
1571,The epochs required for optimal training of document embeddings is in general inversely proportional to the document length.,Theory Proposal
1572,The Adjusted Rand Index and Adjusted Mutual Information are the most appropriate extrinsic evaluation measures for clustering.,Performance Evaluation
1573,Document clusters can be interpreted by top terms extracted from combining TF-IDF scores withВ word embeddingВ similarities.,Theory Proposal
1574,"We propose a novel Neural Opinion Dynamics (NOD) model that jointly models usersвЂ™ posts, neighborhood and topical contextual information using an attention mechanism.",Model Construction or Optimization
1575,Experimental results on twoВ Twitter datasetsВ show that the proposed approach outperforms the state-of-the-art approaches and is effective in tracking the user-level opinion dynamics.,Performance Evaluation
1576,"Unlike previous approaches, a userвЂ™s sequential posting behavior is simulated by a GRU, which fully exploits the temporal contextual information for online learning.",Theory Proposal
1577,We propose a new semi-supervised learning solution for breaking news rumor detection by combining anВ unsupervised learningВ objective with a supervised learning objective,Algorithms/ Methods Construction or Optimization
1578,a new strategy to updateВ word embeddingsВ on the fly with the training process to mitigate the cross-topic and OOV issue in breaking news rumor detection.,Model Construction or Optimization
1582,We propose a novel crowd-powered model to detect appropriateness of the videos on social media.,Model Construction or Optimization
1585,"we define an action command ontology for the humanoid robot NAO containing all the physical movements that NAO can perform, all its body parts and all related words and synonyms",Algorithms/ Methods Construction or Optimization
1586,we develop an NLP engine to extract from natural language sentences actions to be mapped in the defined ontology and that the robot will perform,Model Construction or Optimization
1587,we define the concept of incompatibility among the actions of the robot and give the definition of the robot state,Theory Proposal
1588,"we introduce two modes for NAO to operate, STATELESS and STATEFUL. When in STATEFUL mode, NAO performs a recognized action if and only if this is compatible with NAOвЂ™s current state",Theory Proposal
1590,we run the NLP engine on cloud computing resources and a software layer on the NAO robot which is responsible to interact with the user and communicate with the NLP engine,Applications
1591,"we made publicly available the developed ontology, the NLP engine, and the developed software for the community",Dataset Creation or Resources
1596,BM25 ranking is used for retrieving related documents for a given query.,Dataset Creation or Resources
1598,Community characterization via content analysis.,Theory Proposal
1599,Analysis and extraction of six syntactic and semantic features from tweets.,Algorithms/ Methods Construction or Optimization
1600,Identification of topics and proper nouns as characteristic features of a community.,Theory Proposal
1601,The research provides insights on how people from specific communities share similar content.,Dataset Creation or Resources
1602,This work introduces a new task that addresses lifelog mining on the real world social media data.В ,Theory Proposal
1603,We propose a comprehensive system for the extraction. Related subtasks in the extraction workflow are formulated and modeled with a multimodal joint learning approach. Experimental results show promising performances are achieved in all the subtasks.,Model Construction or Optimization
1604,"We demonstrate how to construct a personal knowledge base for general life events, providing complementary information for recall and retrieval.В ",Theory Proposal
1605,We release the lifelog dataset in our website.,Dataset Creation or Resources
1606,First ever attempt to apply complex network theory for precise novel sense detection.,Applications
1617,"We propose a healthy recipe recommendation framework (NutRec), which first builds a healthy pseudo-recipe considering the nutritional values and then scans the recipe dataset for items resembling the pseudo-recipe. Our proposed NutRec relies not only on the relations between the ingredients themselves but also on those of their quantities, which ultimately dictate the healthiness of a recipe. To the best of our knowledge, no prior study has incorporated these features.",Model Construction or Optimization
1618,"The pseudo-recipe is a list of ingredients with their quantities, and the nutritional values of the pseudo-recipe should match the predefined targets as best as possible. To generate the pseudo-recipe, we first propose an embedding-based ingredient predictor, which embeds all the ingredients into a latent space and predicts the supplemented ingredients based on the distances of ingredient representations; we then propose an amount predictor to compute the quantities of the supplemented ingredients.",Algorithms/ Methods Construction or Optimization
1619,"We conduct extensive experiments with two real recipe datasets, and the experimental results confirm the superiority of our methods over the baselines. To facilitate the community research, we have publicly released the datasets",Performance Evaluation
1620,We introduce some typical IR tasks addressed by neural ranking models and discuss major characteristics and challenges.,Dataset Creation or Resources
1621,"We introduce a unified formulation over neural ranking models, and review existing models based on this formulation.",Model Construction or Optimization
1622,We survey published empirical results on the ad-hoc retrieval and QA tasks to conduct a comprehensive comparison.,Performance Evaluation
1623,We discuss several trending topics that are important or might be promising in the future.,Dataset Creation or Resources
1624,We proposed a new model named HoAFM to encode high-order feature interactions into feature representations in an explicit and efficient manner.,Model Construction or Optimization
1625,We highlight the varying importance of interactions via two bit-wise attention mechanism.,Algorithms/ Methods Construction or Optimization
1626,We perform extensive experiments on two datasets to verify the effectiveness of HoAFM for CTR prediction. We have released the code to facilitate further development on high-order feature interactions modeling,Performance Evaluation
1627,We propose the CRCF - the Contextual Recurrent Collaborative Filtering framework - which leverages usersвЂ™ preferred context and the contextual information associated with the usersвЂ™ sequence of checkins to model the usersвЂ™ short-term preferences using a GRU-based RNN component.,Model Construction or Optimization
1628,CRCF integrates the state-of-the-art Contextual Recurrent Architecture (CARA) to effectively capture the usersвЂ™ short-term preferences from their sequence of checkins by incorporating the contextual information associated with their successive checkins.,Model Construction or Optimization
1629,We show that high quality venue recommendations for both normal and cold-start users can be generated by the proposed CRCF model.,Performance Evaluation
1630,We show that sequential geo-based negative sampling approach can improve the effectiveness and robustness of a state-of-the-art neural-network based venue recommendation approach.,Theory Proposal
1631,"We propose to leverage class ties to enhance relation extraction. Combined with CNN, an effective deep ranking based multi-label learning model with regularization technique is introduced to exploit class ties.",Model Construction or Optimization
1632,We adopt the cost-sensitive learning to relieve the class imbalance problem and experimental results show the effectiveness of our method.,Performance Evaluation
1633,We propose an Attentive Recurrent Neural Network (Ante-RNN) for the dynamic explainable recommendation which could provide multi-model explanations according to the user dynamic preference.В ,Model Construction or Optimization
1634,"In order to alleviate the issues caused by the monotonic assumption of RNN, a hybrid attention mechanism is developed to capture the userвЂ™s long-term dynamic interest over different topics and strengthen the short-term interest simultaneously.В ",Model Construction or Optimization
1635,"To the best of our knowledge, it is the first time to jointly explore multi-modal and adaptive explanations in a unified framework for the personalized recommendation.",Model Construction or Optimization
1636,"More importantly, our proposed dynamic contextual attention scheme incorporates diverse temporal factors of the userвЂ™s clicking sequence of items (e.g. time interval and the time of week) to further improve the recommendation performance.",Model Construction or Optimization
1637,"We analyze and study a variety of fusion strategies for mutual association learning across modalities, and find that the attention-based fusion robustly achieves the best results.",Performance Evaluation
1638,We conduct extensive experiments on two real large-scale datasets. The results show that Ante-RNN outperforms state-of-the-art baselines in terms of Recall and NDCG on both datasets.,Performance Evaluation
1639,We propose a novel approach to tackle large-scale image retrieval on deep-learned image descriptors by transforming the vectorial descriptors into surrogate text encodings.,Algorithms/ Methods Construction or Optimization
1640,This transformation is based on a scalar quantization approach that is specifically designed to generate text suitable for scalable indexing in secondary memory.,Algorithms/ Methods Construction or Optimization
1641,"Our approach allows us to conveniently reuse mature and scalable full-text search engine technology (e.g. Elasticsearch, Apache Lucene) for retrieving images on a large scale without the need for dedicated structures.",Theory Proposal
1642,We compare our proposal to other works in a unified framework for representing surrogate text representation transformations.,Performance Evaluation
1643,"We performed an extensive experimental evaluation to assess the effectiveness and efficiency of our proposal, and compare it to other state-of-the-art vector-tailored indexing approaches.",Performance Evaluation
1644,"В a reproducibility study of two state-of-the-art supervised and unsupervised NeuIR models, where we present the issues we encountered during their reproducibility",Model Construction or Optimization
1645,"a performance comparison with other lexical, semantic and state-of-the-art models, showing that traditional lexical models are still highly competitive with DRMM and NVSM",Performance Evaluation
1646,"an application of DRMM and NVSM on collections from heterogeneous search domains and in different languages, which helped us to analyze the cases where DRMM and NVSM can be recommended",Applications
1647,"an evaluation of the impact of varying word embedding models on DRMM, showing how relevance-based representations generally outperform semantic-based ones",Performance Evaluation
1648,"a topic-by-topic evaluation of the selected NeuIR approaches, comparing their performance to the well-known BM25 lexical model, where we perform an in-depth analysis of the different cases where DRMM and NVSM outperform the BM25 model or fail to do so.",Performance Evaluation
1649,A novel discrete supervised hashing method is proposed for cross-modal retrieval.В ,Algorithms/ Methods Construction or Optimization
1650,"We utilize semantic label to guide the hashing learning process and make full use of the supervised information. In this way, it maintains label consistency to ensure the effectiveness of hash code learning.",Algorithms/ Methods Construction or Optimization
1651,We maintain non-linear manifold structure of data when learning hash codes to effectively construct the approximate relationship between neighbors.В ,Algorithms/ Methods Construction or Optimization
1652,В It captures the feature based similarity consistency of heterogeneous cross-modal data and enhances the discriminative capability of hash codes.,Algorithms/ Methods Construction or Optimization
1653,"Instead of relaxing discrete constraints or learning the hash codes bit by bit, we generate the discrete binary codes directly by an iterative quantization method. Therefore, LCLCH can avoid large quantization error and make the optimization process more efficient.",Algorithms/ Methods Construction or Optimization
1654,node2hash is the first semantic text hashing model that explicitly models document and their connections.,Model Construction or Optimization
1655,node2hash is an unsupervised hashing method that combines the advantage of generative modeling and deep learning.,Algorithms/ Methods Construction or Optimization
1656,"node2hash is applicable to datasets whose explicit connections are observed, and implicit one can be inferred.",Applications
1657,An approach like sentiment analysis is used and proposed a image - text consistency driven multimodal for social media,Model Construction or Optimization
1658,the proposed approach explores the correlation between the image and the text to effectively exploit the information from both visual content and textual content from image-text posts,Model Construction or Optimization
1659,the proposed approach performs a multimodal adaptive sentiment analysis by incorporating the image-text correlation model into the conventional SentiBank framework.,Model Construction or Optimization
1660,introduced a fuzzy topic modeling approach for text mining over short text documents.В ,Model Construction or Optimization
1661,a novel fuzzy topic modeling (FTM) approach is presented to ameliorate the sparsity problem from short text documents,Model Construction or Optimization
1662,FTM approach is proposed using the fuzzy perspective for discovering the hidden features from short text data.,Model Construction or Optimization
1663,"This paper presents a benchmark namely вЂњRTAnewsвЂќ, of multi-label Arabic texts for text categorization. The benchmark, namely вЂњRTAnewsвЂќВ ",Algorithms/ Methods Construction or Optimization
1664,introduced an extensive comparison of the multi-label learning methods for Arabic text categorization using RTAnews.,Performance Evaluation
1665,proposed a weighted semantic graph where each sentence is modeled as aВ multi-node vertexВ containing the Wikipedia concepts of its semantic arguments.,Algorithms/ Methods Construction or Optimization
1666,implemented a single & multi-document summariser using the weighted semantic graph representation.,Algorithms/ Methods Construction or Optimization
1667,evaluated the summarization system using the standard publicly available dataset from Document Understanding Conference 2002 (DUC 2002).,Performance Evaluation
1668,propose a new feature selection method HRFS based on Hebb rule. The proposed method is demonstrated effective to select discriminative terms.,Algorithms/ Methods Construction or Optimization
1669,proposed method is also efficient because it can be described in the view ofВ matrix operationВ to decrease complexity of feature selection.,Performance Evaluation
1670,The main contribution of the proposed methodology is to enable the comprehensive evaluation of online contents and the alignment of these contents with supporting literature.,Model Construction or Optimization
1671,The novel method is used to evaluate the online visibility of biomedical text mining tools.,Algorithms/ Methods Construction or Optimization
1672,"Proposed a novel deep-learning-based method in which a unified feature set which is representative of word embedding, sentiment knowledge, sentiment shifter rules,",Algorithms/ Methods Construction or Optimization
1673,"statistical and linguistic knowledge, has not been thoroughly studied for a sentiment analysis.",Algorithms/ Methods Construction or Optimization
1674,"integrated multiple strategies to handle: types of sentences, contextual polarity, word sense variations, sentiment shifter rules, integration of sentiment information and word embeddings, sentiment score calculation, word order information andВ semantic relationshipsВ between words, which enable our method to achieve superior performance.",Algorithms/ Methods Construction or Optimization
1675,"A hybrid vector is constructed for the representation of each sentence using the sentiment-based, word embedding-based, statistical and linguistic knowledge-based feature vectors.",Algorithms/ Methods Construction or Optimization
1676,"The method integrates several sentiment lexicons in order to tackle the word coverage limit. On the other hand, various sentiment dictionaries complement each other.",Algorithms/ Methods Construction or Optimization
1677,"studied two cases of implicit dimensions identification, where there is no precise agreement on the classified subjects inside the intended narrative.",Theory Proposal
1678,"showed howВ unlabeled data, which is typically more available inВ classification tasksВ than labeled data, can be effectively utilized to enhance performance in theВ text classificationВ domain",Applications
1679,showed how unlabeled pre-trainedВ word embeddingsВ can be used to improveВ classification accuracyВ combined with LSTM models.,Model Construction or Optimization
1680,a new topic model extracting groups of semantically related terms based on a semantic clustering of terms,Model Construction or Optimization
1681,"a natural hypergraph model representing nodes as sentences and each hyperedge as a theme, namely a group of sentences sharing a topic",Model Construction or Optimization
1682,two scalable sentence selection algorithms based on the theory of hypergraph transversals for the extraction of a subset of jointly relevant sentences.,Algorithms/ Methods Construction or Optimization
1683,analyzed the characteristics of various social conversational features by exploiting language usage patterns.,Algorithms/ Methods Construction or Optimization
1684,proposed various methods of text refinement suitable for language identification,Algorithms/ Methods Construction or Optimization
1685,the effects of the proposed refinement methods are investigated using variousВ sentence levelВ language identification frameworks.,Performance Evaluation
1686,"proposed Crime Base, an entity relationship based system to extract and integrate crime related text and image data from online newspapers with a focus towards reducing duplicity and",Model Construction or Optimization
1687,loss of information in the knowledge base.,Model Construction or Optimization
1688,The proposed system also presents an integrated view of these entities and their relations in the form of a knowledge base using OWL.,Dataset Creation or Resources
1689,Effective named entity recognition using rule-based approach.,Model Construction or Optimization
1690,Development of a crime knowledge base using ontology representation model.,Model Construction or Optimization
1691,provided a comprehensive overview of existing metrics for summary evaluation and discussed several limitations of existing frameworks for summary evaluation.,Performance Evaluation
1692,introduced an automatic framework for the evaluation of metrics that does not require any human annotation,Model Construction or Optimization
1693,evaluated the existing assessment metrics on a Wikipedia data set and a collection of scientific articles using this framework.,Performance Evaluation
1694,"developed a usefulness model as indicated by information use in the context of essay writing, parameterized by query and click variables.",Model Construction or Optimization
1695,"showed that for the task in question, the number of clicks is by far the strongest predictor of result usefulness while increasing dwell time predicts decreasing usefulness",Theory Proposal
1696,and we reconcile the latter finding with contradictory results from the literature.,Theory Proposal
1697,showed that the simpler Reuse Events model has a greater explanatory power compared to the Reuse Amount model based on the number of words obtained from search results for an essay.,Performance Evaluation
1698,"proposed a new measure of search result usefulness, based on the contribution of a search result as a source to the text representing a task.",Theory Proposal
1699,"study aims to integrate diverse data within narrative multimedia (i.e., artworks containing stories and distributed through multimedia) into a unified character networkВ ",Dataset Creation or Resources
1700,"(i.e., a social network between characters that appear in the story).",Dataset Creation or Resources
1701,attempted to enhance the accuracy and semantic richness of existing character networks that confine themselves to a particular data source.В ,Dataset Creation or Resources
1702,proposed story synchronization for (i) improving the accuracy of data extracted from the narrative multimedia and (ii) integrating the data into the unified character network.В ,Algorithms/ Methods Construction or Optimization
1703,"verified the efficacy of the proposed methods using movies in the real world, which are among the most accessible and popular narrative multimedia.",Performance Evaluation
1704,reviewed research problems related to automatic keyword extraction and text summarization.В ,Dataset Creation or Resources
1705,used both supervised and unsupervised methods in order to identify keywords from emails.,Algorithms/ Methods Construction or Optimization
1706,"Results are compared with other AKE systems including KEA, SZTERGAK, SingleRank and ExpandRank.",Performance Evaluation
1707,proposed three novel methods for attention-based models to incorporate sentiment features instead of feature-vector concatenation.,Algorithms/ Methods Construction or Optimization
1708,Learning deep features on sentiment tweets corpora and transferring them into the attention-based neural model is the most effective way to detect both explicit and implicit context incongruity.,Theory Proposal
1709,contrasted the human-labeled and hashtag-labeled datasets for evaluation of irony detection models.В ,Performance Evaluation
1712,we define the concept of incompatibility among the actions of the robot and give the definition of the robot state;,Theory Proposal
1713,"we introduce two modes for NAO to operate, STATELESS and STATEFUL. When in STATEFUL mode, NAO performs a recognized action if and only if this is compatible with NAOвЂ™s current state",Model Construction or Optimization
1714,we provide new directions for the interaction between the user and a humanoid robot: the user will have to learn the incompatibilities of the robot postures when in STATEFUL mode if he/she wants the robot to perform any action command and the robot has available all the natural language commands given by the user for future forecasting of missing terms,Applications
1715,we run the NLP engine on cloud computing resources and a software layer on the NAO robot which is responsible to interact with the user and communicate with the NLP engine;,Applications
1718,"In this paper, we explore a different direction, and propose a content-based approach to community detection.В ",Theory Proposal
1719,This work introduces a new task that addresses lifelog mining on the real world social media data.,Dataset Creation or Resources
1721,"We demonstrate how to construct a personal knowledge base for general life events, providing complementary information for recall and retrieval.",Theory Proposal
1722,our main contribution is to unfold their tremendous benefit in improving the precision of novel sense detection.,Dataset Creation or Resources
1723,one of our contributions as well which will help the community to move further in this otherwise difficult task.,Dataset Creation or Resources
1728,Black WikipediansвЂ™ perceived social presence is a strong but an indirect factor on content contribution.,Theory Proposal
1729,"In contrast to previous studies, entertainment does not significantly motivate Black WikipediansвЂ™ content contribution.",Theory Proposal
1730,Asylum seekers regularly encounter many different types of misinformation.,Theory Proposal
1731,"Information must be studied as a nuanced concept (accurate, mis- and disinformation).",Theory Proposal
1732,Social and cultural factors influence how the accuracy of information is perceived.,Theory Proposal
1733,Studying vulnerable groupsвЂ™ information perception is important.,Theory Proposal
1734,Receiver perception should be compared to normative views of misinformation.,Theory Proposal
1735,ReportingВ on a qualitative study with 16 Chinese older adults who were recent immigrants to Australia and Canada,Theory Proposal
1736,Migrating late in life presents some unique characteristics and challenges.,Theory Proposal
1737,We extend the translocal meaning making framework by assessing whether social imaginaries can be shared across contexts.,Model Construction or Optimization
1738,"Findings include daily rituals and coping mechanisms of the late-life migrants, and associated information activities.",Theory Proposal
1739,We draw implications for understanding this under-studied migrant population and designing information support forВ them.,Dataset Creation or Resources
1740,Virtual reality in aged care engages residents who might otherwise self-isolate.,Theory Proposal
1741,Residents enjoyed the richer interactions and variety offered by virtual reality.,Theory Proposal
1742,Results suggest residents with dementia may react adversely to head mounted displays.,Theory Proposal
1743,Our proposed approach investigates the application of hate speech detection approach to vulnerable community identification.,Theory Proposal
1744,"We successfully identify a potentially vulnerable community in terms of hatred on social media, by using the example of Amharic text data on Facebook.",Theory Proposal
1745,"We collected and annotated Amharic data for the task of hate speech detection, aligned wiith multicultural societies like euthopia",Dataset Creation or Resources
1746,We utilize Apache Spark distributed platform for data pre-processing and feature extraction since social media data is very noisy and large that needs efficient tools to facilitate efficient processing.,Model Construction or Optimization
1747,Latina immigrants to the U.S. Midwest have at least three intersectional identities.,Theory Proposal
1748,ICTs support information seeking and use along with connectedness.,Theory Proposal
1749,"Digital inclusion efforts must account for language, family and gender roles.",Theory Proposal
1750,Utilization of negative class information in text classification.,Theory Proposal
1751,Naive Bayes classification using negative class information.,Theory Proposal
1752,Log-odd rate of positive and negative class probabilities.,Theory Proposal
1753,we propose an experimental system at http://hlcs.sytes.net/ltr.,Model Construction or Optimization
1754,The time factor can rank the blog topic based on the popularity of the post.,Theory Proposal
1755,We can add a few computation time to improve significantly blog search performance.,Theory Proposal
1756,"In this work, we study query performance prediction (QPP) in the microblog search domain; a domain in which QPP is still understudied.",Theory Proposal
1757,"Our study is considered the most comprehensive in this domain in terms of the number of predictors, retrieval models, and test collections used.",Performance Evaluation
1758,Our results show that using expanded queries in predicting the performance of query expansion retrieval models gives much better prediction quality than using the original unexpanded queries.,Performance Evaluation
1759,We found that temporal predictors that ignore the fact that not all queries are temporal are not very effective. We also noticed that the prediction of a set of best-performing predictors is much more effective over temporal queries than non-temporal ones.,Performance Evaluation
1760,The strong performance of our proposed predictors shows their high potential to be utilized to improve microblog search and other closely-related tasks such as tweet timeline generation.,Performance Evaluation
1761,Global query semantics modeled from the standpoint of prospect vocabulary terms,Model Construction or Optimization
1762,Selective semantic exploration strategy adds new terms related to more relevant topics.,Theory Proposal
1763,Disambiguation issues addressed without exogenous resources,Theory Proposal
1764,Significant results improving both recall and precision metrics without relevance feedback.,Theory Proposal
1765,Query properties allow users to exchange their expertise in MLCIR.,Theory Proposal
1766,An intersecting results history allows users to exchange their expertise in MLCIR.,Theory Proposal
1767,Users must be easily able to identify each team membersвЂ™ role and actions.,Theory Proposal
1768,An MLCIR interface should not overload users with too much awareness information.,Theory Proposal
1769,A number of design suggestions are proposed to help develop new MLCIR interfaces.,Theory Proposal
1770,Address the problem of low response rate in social Q&A that happens on a Chinese microblogging site.,Theory Proposal
1771,Propose 17 factors from both the questioner and the question's perspectives and investigate their effectiveness in determine whether or not a question will be answered.,Theory Proposal
1772,"Build a model to differentiate questions with high probabilities of being responded from those with low probabilities of being answered, which achieved a prediction accuracy of 74%.",Model Construction or Optimization
1773,Our results show that whether or not a question will be answered depend more on the questioner than the question.,Theory Proposal
1774,Propose the potential implication of improving visibility of users with low social capital to increase their question's response probability.,Theory Proposal
1775,Relationships among frequency-based and network-based metrics are examined on both empirical and simulated co-word networks.,Performance Evaluation
1776,"All seven metrics are strongly correlated, and according to the strength of correlations, the metrics can be categorized into three groups.",Theory Proposal
1777,Different disciplines do not influence the relationships among the metrics.,Theory Proposal
1778,Network topology properties influence the relationships among the metrics.,Theory Proposal
1779,A simulation method for co-word networks is proposed.,Algorithms/ Methods Construction or Optimization
1780,We verify whether 24 distance measures used frequently respect some useful theoretical properties.,Theory Proposal
1781,We verify empirically the effectiveness of 24 distance measures based on 13 test collections used in author profiling tasks.,Applications
1782,We measure the effectiveness impact of changing the text genre between the learning and testing phase in the context of author profiling problems.,Performance Evaluation
1783,"This study suggests item-network-based collaborative filtering.
",Theory Proposal
1784,The method focuses on a user's item network to remedy the existing limitations.,Algorithms/ Methods Construction or Optimization
1785,Centrality indicators of the item network are utilized for recommendations,Algorithms/ Methods Construction or Optimization
1786,The evaluation test results with sample data show potentials of our method.,Performance Evaluation
1787,вЂ‹This research aims to prove that the Web page is not the best atomic search unit,Theory Proposal
1788,"PREFCA, a portal retrieval engine based on formal concept analysis, is proposed.
",Model Construction or Optimization
1789,"PREFCA has three phases: information extraction, lattice construction, and information retrieval.",Theory Proposal
1790,PREFCA proposes a new portal ranking technique for portal retrieval.,Theory Proposal
1791,PREFCA proves that portal retrieval achieves better results than page retrieval.,Performance Evaluation
1792,We studied eye-movement behavior in different information-seeking tasks.,Dataset Creation or Resources
1793,We found three patterns of information seeking based on usersвЂ™ personality facets.,Theory Proposal
1794,Personality traits drive information seeking differently depending on the task.,Theory Proposal
1795,Eye-movement parameters can predict these patterns in different information-seeking behaviors.,Theory Proposal
1796,Prior domain knowledge improves older adultsвЂ™ query and navigation strategies and copes with the age-related decline of cognitive flexibility.,Theory Proposal
1797,"Unlike prior results, older adults were outperformed by young ones in open-ended information problems.",Theory Proposal
1798,"In open-ended information problems, older adults did not benefit from their prior knowledge and produced semantically less relevant queries as compared to fact-finding problems.",Theory Proposal
1799,This paper describes a generic framework for generating comprehension questions from short edited texts using coherence relations.,Theory Proposal
1800,"We present a simple, unsupervised but robust and accurate syntactic method for achieving the first objective and a modified hierarchical lexical method for the second objective.",Algorithms/ Methods Construction or Optimization
1801,we present a large-scale and indepth computational readability study for Arabic,Dataset Creation or Resources
1802,we worked with an annotated corpus of human tutoring sessions from which we identified effective sessions based on human expert judgments,Algorithms/ Methods Construction or Optimization
1803,"we discuss one of the aspects of essay-writing, namely style, and how we can predict it automatically",Theory Proposal
1804,"We describe the task definition, data preparation, performance metrics, and evaluation results.",Performance Evaluation
1805,This paper introduces our system at NLPTEA2018 Chinese Grammatical Error Diagnosis task. We will describe how to combine the knowledge that learned from large scale text data and handcraft heuristics with deep learning framework,Algorithms/ Methods Construction or Optimization
1806,"This paper introduces the DM NLP teamвЂ™s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners",Algorithms/ Methods Construction or Optimization
1807,we employ the sequence to sequence learning to model the task of grammar error correction.,Model Construction or Optimization
1808,we propose a sequence labeling method based on the Policy Gradient LSTM model and apply it to this task to solve the above problems.,Model Construction or Optimization
1809," In this paper, we report on a user study on language learnersвЂ™ perceived usefulness of the application",Model Construction or Optimization
1810,"the domain of multi-perspective elaboration is used to illustrate that while Natural Language Processing (NLP) techniques are able to aid in the evaluation and implementation of key tool learning design objectives, that principled and critical analysis of learner impact is required in order to select appropriate techniques.",Algorithms/ Methods Construction or Optimization
1811,we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task,Algorithms/ Methods Construction or Optimization
1812,This paper describes two models that employ word frequency embeddings to deal with the problem of readability assessment in multiple languages,Model Construction or Optimization
1813,provide a tool that enriches the traditional language learning setting in an enjoyable way and helps to avoid problems with learner motivation that can be encountered in language classes.,Algorithms/ Methods Construction or Optimization
1814,"This work presents an exploratory approach to the computational study of written language, oriented towards improving literacy acquisition in school-age children.",Algorithms/ Methods Construction or Optimization
1815,"This study assesses an index for measuring the pronunciation difficulty of sentences (henceforth, pronounceability) based on the normalized edit distance from a reference sentence to a transcription of learnersвЂ™ pronunciation.",Theory Proposal
1816,In this paper we report how we build a system and how to test it with a translated corpus from two publicly available English corpus,Theory Proposal
1817,"This study explores the use of natural language processing techniques to enhance bilingual lexical access beyond simple equivalents, to enable translators to navigate along a wider cross-lingual lexical space and more examples showing different translation strategies, which is essential for them to learn to produce not only faithful but also fluent translations.",Algorithms/ Methods Construction or Optimization
1818,we propose methods to measure the bias and systematically remove its effects from a statistical model that learns the instructorвЂ™s intervention decision.,Algorithms/ Methods Construction or Optimization
1819,This paper studies how to integrate heterogeneous features such as a neural image feature generated from the image of the Web page by a variant of CNN (convolutional neural network) as well as text features extracted from the body text of the HTML file of the Web page.,Dataset Creation or Resources
1820,"In this paper we formalize the problem automatic fill-in-the-blank question generation using two standard NLP machine learning schemes, proposing concrete deep learning models for each.",Algorithms/ Methods Construction or Optimization
1821,"this study aims to propose a proper short text clustering module for the IRS, and demonstrate our implemented techniques through real-world examples, so as to provide experiences and insights for further study.",Theory Proposal
1822,"we use both a conventional linear CRF model (Lafferty et al., 2001) with specific feature engineering and a LSTM-CRF model to solve CGED task",Model Construction or Optimization
1823,"we regard CGED task as a sequence labeling problem(Zheng et al., 2016) and propose a CGED model with contextualized character representation.",Model Construction or Optimization
1824,we regarded the CGED 2018 shared task as a character-based sequence labeling task. We proposed a Bidirectional LSTM CRF(BiLSTM-CRF) neural network that combines LSTM and CRF for sequence labeling without any hand-craft features.,Dataset Creation or Resources
1825,"This paper proposes a integrated approach of combining CRFs, statistical information from Google ngrams and rule-based expert knowledge to detect the four types of errors.",Model Construction or Optimization
1826,we build a Chinese Grammatical Error Diagnosis system in the NLPTEA2018 CGED shared task,Applications
1827,The main goal of Chinese grammatical error diagnosis task is to detect word errors in the sentences written by Chinese-learning students.,Theory Proposal
1828,"We present an approach for recursively splitting and rephrasing complex English sentences into a novel semantic hierarchy of simplified sentences, with each of them presenting a more regular structure that may facilitate a wide variety of artificial intelligence tasks, such as machine translation (MT) or information extraction (IE)",Algorithms/ Methods Construction or Optimization
1829," We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic.",Model Construction or Optimization
1830,"We present the zero-shot entity linking task, where mentions must be linked to unseen entities without in-domain labeled data.",Algorithms/ Methods Construction or Optimization
1831,We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER).,Algorithms/ Methods Construction or Optimization
1832,"we introduce an efficient knowledge distillation (KD) technique that transfers knowledge from a syntactic language model trained on a small corpus to an LSTM language model, hence enabling the LSTM to develop a more structurally sensitive representation of the larger training data it learns from",Performance Evaluation
1833,"we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by the PRPN to a Tree-LSTM model with discrete parsing actions. Its policy is then refined by GumbelSoftmax training towards a semantically oriented objective.",Model Construction or Optimization
1834," we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articlesвЂ™ authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women.",Applications
1835,"we study a broader range  of pre-training conditions and experiment over a variety of languages, both jointly and individually.
",Theory Proposal
1836,We present a new method for sentiment lexicon induction that is designed to be applicable to the entire range of typological diversity of the worldвЂ™s languages,Algorithms/ Methods Construction or Optimization
1837,"In this paper, we propose a tree communication model using graph convolutional neural network and graph recurrent neural network, which allows rich information exchange between phrases constituent tree.",Model Construction or Optimization
1838,"we design the gated unit networks to incorporate corresponding word representation into the decoder, and position-aware attention to pay more attention to the adjacent words of a target word.",Algorithms/ Methods Construction or Optimization
1839,"In this paper, we propose a reinforced bidirectional attention network approach to tackle the above two challenges",Theory Proposal
1840,"In this work, we present ELI5: a Long Form Question Answering dataset that emphasizes the dual challenges of isolating relevant information within long source documents and generating paragraph-length explanations in response to complex, diverse questions",Dataset Creation or Resources
1841,"In this paper, we focus on the following two major characteristics of the TQA dataset. In this work, we introduce a novel algorithm
for solving the textbook question answering
(TQA) task which describes more realistic QA
problems compared to other recent tasks.",Algorithms/ Methods Construction or Optimization
1842,We present a novel approach to improve VQA performance that exploits this connection by jointly generating captions that are targeted to help answer a specific visual question.,Model Construction or Optimization
1843,this paper proposes a multi-grained attention method. It learns explicit wordobject correspondence by two types of wordlevel attention complementary to the sentenceimage association.,Algorithms/ Methods Construction or Optimization
1844,"We investigate catastrophic forgetting in the context of multimodal models for Visual Question Answering (Antol et al., 2015) motivated by evidence from psycholinguistics.",Performance Evaluation
1845,"we propose a combined Visual and Textual Question Answering (VTQA) model which takes as input a paragraph caption as well as the corresponding image, and answers the given question based on both inputs.",Model Construction or Optimization
1846,"In this work, we aim to enhance the word representations and the interactions between the source and target words, while using even fewer parameters.",Algorithms/ Methods Construction or Optimization
1847,In this work we present a new dataset of literary eventsвЂ”events that are depicted as taking place within the imagined space of a novel.,Dataset Creation or Resources
1848,we propose a novel word reordering detection task to quantify how well the word order information learned by SAN and RNN.,Theory Proposal
1849,In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP,Model Construction or Optimization
1850,we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT.,Model Construction or Optimization
1851,"In this position paper, we argue that the community needs to make three substantive changes: (1) expanding our scope of problems to tackle both more subtle and more serious forms of abuse, (2) developing proactive technologies that counter or inhibit abuse before it harms, and (3) reframing our effort within a framework of justice to promote healthy communities.",Theory Proposal
1852,"we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in",Theory Proposal
1853,"We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework",Theory Proposal
1854,we propose a hierarchical graph representation by leveraging the structural property of dialog acts.,Theory Proposal
1855,"we propose a novel incremental learning framework to design task-oriented dialogue systems, or for short Incremental Dialogue System (IDS),",Theory Proposal
1856,"In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context.",Model Construction or Optimization
1857,"In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialogue NLI can be used to improve the consistency of a dialogue model, and evaluate the method with human evaluation and with automatic metrics on a suite of evaluation sets designed to measure a dialogue modelвЂ™s consistency.",Performance Evaluation
1858,"we measure budget in terms of the number of real user interactions. That is, we strive to optimize a dialogue agent via a fixed, small number of interactions with real users.",Theory Proposal
1859,"In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from conditional language models",Algorithms/ Methods Construction or Optimization
1860," In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation",Algorithms/ Methods Construction or Optimization
1861,we present a Vocabulary Pyramid Network (VPN) which is able to incorporate multi-pass encoding and decoding with multi-level vocabularies into response generation,Algorithms/ Methods Construction or Optimization
1862,we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections,Theory Proposal
1863,"In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic)",Algorithms/ Methods Construction or Optimization
1864,"we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation. Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation",Model Construction or Optimization
1865,"In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture",Model Construction or Optimization
1866,"This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined",Algorithms/ Methods Construction or Optimization
1867,"We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure.",Dataset Creation or Resources
1868,"in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues.",Algorithms/ Methods Construction or Optimization
1869,"We explore the modelвЂ™s behaviour on this task in detail, and conclude that its ability to model
humans is considerably weaker than K&C suggest.",Model Construction or Optimization
1870,"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation.",Theory Proposal
1871,"We propose two end-to-end metaphor identification models2 , detecting metaphors based on MIP and SPV, respectively",Model Construction or Optimization
1872,"this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes",Theory Proposal
1873,"We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants.",Theory Proposal
1874," We evaluate here an out-of-the-box CNN on the most challenging SCAN tasks, and we uncover the surprising fact that CNNs are dramatically better than RNNs at compositional generalization",Performance Evaluation
1875," In this paper, we present a computational model which successfully identifies known universals, including Greenberg universals, but also uncovers new ones, worthy of further linguistic investigation",Model Construction or Optimization
1876,"In this paper, we sought to fill this gap by employing a systematic approach that samples both over the space of algorithms and the space of human languages.",Algorithms/ Methods Construction or Optimization
1877,"we introduce a collection of large written corpora that we annotated using state-of-the-art parsers trained on Universal Dependencies (UD) treebanks (Nivre et al., 2018).",Algorithms/ Methods Construction or Optimization
1878," In this paper, we present a novel approach
for incorporating external knowledge in Recurrent Neural Networks (RNNs).",Algorithms/ Methods Construction or Optimization
1879,"We present a corpus of over 8,000 annotated text passages with ambiguous pronominal anaphora. These instances are both challenging and realistic",Dataset Creation or Resources
1880,. In this paper we propose Self Attentive Revision Encoder (StRE) which leverages orthographic similarity of lexical units toward predicting the quality of new edits.,Theory Proposal
1881,"We propose an unsupervised method for collecting quantitative information from large amounts of web data, and use it to create a new, very large resource consisting of distributions over physical quantities associated with objects, adjectives, and verbs which we call Distribution over Quantities (DOQ)",Algorithms/ Methods Construction or Optimization
1882,"In our work, we target for the single-round non-task-oriented short-text conversation data collected from social media platforms",Dataset Creation or Resources
1883,"we design a rubric for scoring an important, yet unexplored dimension of persuasive essay quality, thesis strength, and annotate a corpus of essays with thesis strength scores",Model Construction or Optimization
1884,"With this paper, we publish and analyze deISEAR, a German corpus of emotional event descriptions, and its English companion enISEAR, each containing 1001 instances",Theory Proposal
1885,"This paper presents a multilingual corpus with semantic annotation of collocations in English, Portuguese, and Spanish.",Theory Proposal
1886,"In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense.",Theory Proposal
1887,"We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. In this work we describe the creation of a large
dataset of funny short texts in Russian. ",Dataset Creation or Resources
1888,"In this work, we present a method to decouple the language from the problem by learning language agnostic representations and therefore allowing training a model in one language and applying to a different one in a zero shot fashion.",Algorithms/ Methods Construction or Optimization
1889,we propose a generative model that aggregates short texts into clusters by leveraging the associated meta information.,Model Construction or Optimization
1890,we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation.,Model Construction or Optimization
1891,In this paper we introduce a new anomaly detection methodвЂ”Context Vector Data Description (CVDD)вЂ”which builds upon word embedding models to learn multiple sentence representations that capture multiple semantic contexts via the self-attention mechanism,Algorithms/ Methods Construction or Optimization
1892,"This paper presents a new method for Bilingual Lexicon Induction (BLI), which we call Hubless Nearest Neighbor (HNN).",Algorithms/ Methods Construction or Optimization
1893,we introduce a noise detection component in our model: it lets the model detect and disregard examples which are likely to be noisy,Model Construction or Optimization
1894,"e, we introduce a new approach that learns an AL query strategy directly for the target problem of interest",Algorithms/ Methods Construction or Optimization
1895,"we propose a novel hierarchical attention-based architecture to serve as the neural regression function, with which the context information of a word is encoded and aggregated from K observations.",Theory Proposal
1896,"this work, we propose a new method for constructing diachronic words embeddings, which we show to be competitive with prior approaches",Algorithms/ Methods Construction or Optimization
1897,We present a novel neural network architecture to simultaneously learn a two-part representation which is based on the principle of segregating source specific representation from the common representation,Algorithms/ Methods Construction or Optimization
1898,"In this study, we propose to use a block-regularized 3 Г— 2 CV (3 Г— 2 BCV) in model comparison because it could regularize the difference in certain frequency distributions over linguistic units between training and validation sets and yield stable estimators of P, R, and F1.",Model Construction or Optimization
1899,"In this paper, we propose an iterative inference algorithm based on gradient search, which is the first inference algorithm that can be broadly applied to any neural sequence generative models for text infilling tasks",Model Construction or Optimization
1900,We present here a general-purpose addition to the standard seq2seq framework that aims to simultaneously tackle all of the above issues,Algorithms/ Methods Construction or Optimization
1901,"In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora",Algorithms/ Methods Construction or Optimization
1902,We propose a neural architecture for cross-document coreference resolution.,Theory Proposal
1903,We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST).,Performance Evaluation
1904,"In this work, we explore this property in a multi-task learning framework for IDRR in which the relations and the connectives are simultaneously predicted, and the mapping is leveraged to transfer knowledge between the two prediction tasks via the embeddings of relations and connectives. We propose several techniques to enable such knowledge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset).",Theory Proposal
1905,we explore the hypothesis that linguistic deficits drive the error patterns of speaker commitment models by analyzing the linguistic correlates of model errors on a challenging naturalistic dataset,Dataset Creation or Resources
1906,"In this paper, we suggest to view learning event embedding as a multi-relational problem, which allows us to capture different aspects of event pairs",Theory Proposal
1907,"In this paper, we propose a method for whyquestion answering (why-QA) that uses an adversarial learning framework.",Algorithms/ Methods Construction or Optimization
1908,"k, we propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer",Theory Proposal
1909,we present a detailed analysis of why single-hop reasoning works so well,Model Construction or Optimization
1910,"We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets",Model Construction or Optimization
1911,we propose an adaptive decoding method to avoid such intermediate representations.,Algorithms/ Methods Construction or Optimization
1912,"This paper tackles this gap and performs an in-depth investigation of the characteristics of legal and illegal text in the Darknet, comparing it to a clear net website with similar content as a control condition.",Performance Evaluation
1913," In this paper, we propose a weakly-supervised information extraction framework for automated CTA transcript parsing",Theory Proposal
1914,"In this paper, we first build a novel boundary during searching for new concepts via external knowledge base and then utilize heterogeneous features to verify the highquality results.",Algorithms/ Methods Construction or Optimization
1915,"We show that the imperceptibility of several existing linguistic steganographic systems (Fang et al., 2017; Yang et al., 2018) relies on implicit assumptions on statistical behaviors of fluent text",Theory Proposal
1916,"We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classification; (2) multi-label classification; (3) case importance prediction",Performance Evaluation
1917,"We propose an approach to improving the robustness of NMT models, which consists of two parts: (1) attack the translation model with adversarial source examples; (2) defend the translation model with adversarial target inputs to improve its robustness against the adversarial source inputs.",Model Construction or Optimization
1918,"In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum.",Model Construction or Optimization
1919,"In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity",Algorithms/ Methods Construction or Optimization
1920,"This paper proposes a novel AutoML strategy based on probabilistic grammatical evolution, which is evaluated on the health domain by facing the knowledge discovery challenge in Spanish text documents",Performance Evaluation
1921,"this paper proposes a в€†-learning approach to distill discrimination and generalization knowledge by effectively decoupling, incrementally learning and adaptively fusing event representation",Theory Proposal
1922,"In this paper, we proposed the multi-granularity lattice framework (MG lattice), a unified model comprehensively utilizes both internal information and external knowledge, to conduct the Chinese RE task.",Model Construction or Optimization
1923,"we propose A2N, an effective model (Section 2) which, conditioned on the query, uses a bi-linear attention on the graph neighborhood of an entity to generate an embedding representation of the entity.",Model Construction or Optimization
1924,"In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively.",Theory Proposal
1925,"In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes.",Model Construction or Optimization
1926,"We consider a novel question answering (QA) task where the machine needs to read from large streaming data (long documents or videos) without knowing when the questions will be given, which is difficult to solve with existing QA methods due to their lack of scalability.",Algorithms/ Methods Construction or Optimization
1927,"In this paper, we introduce query-agnostic indexable representations of document phrases that can drastically speed up open-domain QA",Theory Proposal
1928,"In this work, we propose neural variational language model (NVLM), which enables the sharing of grammar knowledge among different corpora.",Model Construction or Optimization
1929,"We present a new dataset with 1,390 examples from 7 application domains (e.g. a calendar or a file manager), each example consisting of a triplet: (a) the applicationвЂ™s initial state, (b) an instruction, to be carried out in the context of that state, and (c) the state of the application after carrying out the instruction",Dataset Creation or Resources
1930,"We conduct the first large-scale systematic study of candidate pretraining tasks, comparing 19 different tasks both as alternatives and complements to language modeling",Dataset Creation or Resources
1931,"In this work, we focus on complex question semantic parsing and propose a novel Hierarchical Semantic Parsing (HSP) method, which utilizes the decompositionality of complex questions for semantic parsing.",Algorithms/ Methods Construction or Optimization
1932,"In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks.",Algorithms/ Methods Construction or Optimization
1933,We demonstrate that the automatically curated corpus allows a bidirectional LSTM sentence encoder to yield high quality sentence embeddings and can serve as a supervised fine-tuning dataset for larger models such as BERT,Dataset Creation or Resources
1934,"we introduce SParC (cross-domain Semantic Parsing in Context), an expert-labeled dataset which contains 4,298 coherent question sequences (12k+ questions paired with SQL queries) querying 200 complex databases in 138 different domains",Dataset Creation or Resources
1935,We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges: 1) the mismatch between intents expressed in natural language (NL) and the implementation details in SQL; 2) the challenge in predicting columns caused by the large number of outof-domain words,Model Construction or Optimization
1936,"we experiment with spectral methods of signal representation and summarization as mechanisms for constructing such word-sequence embeddings in an unsupervised fashion. In particular, we explore an algorithm rooted in fluid-dynamics, known as higher-order Dynamic Mode Decomposition, which is designed to capture the eigenfrequencies, and hence the fundamental transition dynamics, of periodic and quasi-periodic systems.",Algorithms/ Methods Construction or Optimization
1937,"We propose SEMBLEU, a robust metric that extends BLEU (Papineni et al., 2002) to AMRs",Theory Proposal
1938,"We implement our reranker in a competitive neural semantic parser and test on four semantic parsing (GEO, ATIS) and Python code generation (DJANGO, CONALA) tasks, improving the strong baseline parser by up to 5.7% absolute in BLEU (CONALA) and 2.9% in accuracy (DJANGO), outperforming the best published neural parser results on all four datasets.",Dataset Creation or Resources
1939," In this paper, we present an encoder-decoder semantic parser, where the structure of the DB schema is encoded with a graph neural network, and this representation is later used at both encoding and decoding time.",Theory Proposal
1940,This paper presents a conservative estimate of human performance to serve as a target for the GLUE sentence understanding benchmark.,Model Construction or Optimization
1941,"In this paper, we present a single semantic parser that does very well across all of DM, PAS, PSD, EDS and AMR (2015 and 2017).",Algorithms/ Methods Construction or Optimization
1942,"In this paper, we show that combination of different methods makes a positive impact",Algorithms/ Methods Construction or Optimization
1943,"we present two novel contributions. First, we present an analysis that spans the common components of a traditional NLP pipeline. We show that the order in which specific abstractions are encoded reflects the traditional hierarchy of these tasks. Second, we qualitatively analyze how individual sentences are processed by the BERT network, layer-by-layer. We show that while the pipeline order holds in aggregate, the model can allow individual decisions to depend on each other in arbitrary ways, deferring ambiguous decisions or revising incorrect ones based on higher-level information",Algorithms/ Methods Construction or Optimization
1944,"We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the timeconsuming intermediate step of creating paraphrase corpora",Algorithms/ Methods Construction or Optimization
1945,"In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of edges",Theory Proposal
1946,"we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD1 ), compiled from popular TV shows.",Theory Proposal
1947,"In this paper, we tackle these tasks in the context of complex arguments on a diverse set of topics.",Dataset Creation or Resources
1948,", we investigate two formalisms with deep sentiment representations that capture sentiment subtype expressions by latent variables and Gaussian mixture vectors, respectively",Performance Evaluation
1949,In this work we focus on Japanese and show the potential use of transfer learning techniques in text classification.,Theory Proposal
1950,We analyze the nature of these cues and demonstrate that a range of models all exploit them,Performance Evaluation
1951,We propose a reason comparing network (RCN) to leverage reason information for stance comparison.,Theory Proposal
1952,"we conduct a task of human motive detection. We manually annotate 1,600 review texts in restaurant and laptop domains from existing ABSA datasets with the six motives. The annotation results reveal that people are driven by different motives in different domains. Finally, we report the performance of baseline methods on this new dataset.",Algorithms/ Methods Construction or Optimization
1953,we propose a novel method to refine the embeddings of targets and aspects. Such pivotal embedding refinement utilizes a sparse coefficient vector to adjust the embeddings of target and aspect from the context.,Performance Evaluation
1954,"We address this task in an empirical manner by annotating 39 political debates from the last 50 years of US presidential campaigns, creating a new corpus of 29k argument components, labeled as premises and claims. We then propose two tasks: (1) identifying the argumentative components in such debates, and (2) classifying them as premises and claims.",Theory Proposal
1955,This study investigates (i) span representation originally developed for other NLP tasks and (ii) a simple task-dependent extension for ASP. Our extensive experiments and analysis show that these representations yield high performance for ASP and provide some challenging types of instances to be parsed,Algorithms/ Methods Construction or Optimization
1956,"In this paper, we present a fast and strong neural approach for general purpose text matching applications.",Model Construction or Optimization
1957,"We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are illsuited for these longer alignments",Model Construction or Optimization
1958,"In this paper, we show that these two problems are actually complementary",Theory Proposal
1959,We present a latent variable model for predicting the relationship between a pair of text sequences,Model Construction or Optimization
1960,"We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017).",Model Construction or Optimization
1961,We present a supervised model for automatically identifying when one event is a subevent of another.,Model Construction or Optimization
1962,"In this paper, we show that commonsense inference still proves dicult for even stateof-the-art models, by presenting HellaSwag, a new challenge dataset.",Dataset Creation or Resources
1963,we propose a novel framework to build a unified multi-domain enabled semantic parser trained only with weak supervision (denotations).,Theory Proposal
1964,We introduce the use of Poincare embeddings Вґ to improve existing state-of-the-art approaches to domain-specific taxonomy induction from text as a signal for both relocating wrong hyponym terms within a (pre-induced) taxonomy as well as for attaching disconnected terms in a taxonomy.,Algorithms/ Methods Construction or Optimization
1965,"In this paper, we recast MNLI and JOCI as COPA-style plausibility tasks by sampling and constructing (p, h, h 0 ) triples from these two datasets. Each premise-hypothesis pair (p, h) is labeled with different levels of plausibility yp,h.",Dataset Creation or Resources
1966,we propose a simple and effective method for fine-tuning distributional word vectors for LE. Our Generalized Lexical ENtailment model (GLEN) is decoupled from the word embedding model and applicable to any distributional vector space,Algorithms/ Methods Construction or Optimization
1967,"In this paper, we describe a simple re-implementation of BERT for commonsense reasoning.",Theory Proposal
1968,". In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when finetuned on a similar pronoun disambiguation problem dataset (denoted WSCR).",Dataset Creation or Resources
1969,"In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph.",Model Construction or Optimization
1970,We propose an end-to-end neural model with coreference alignment and conversation flow modeling.,Model Construction or Optimization
1971,We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages.,Model Construction or Optimization
1972,"we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a lowlevel agent that alters the sentence",Algorithms/ Methods Construction or Optimization
1973,"We propose a new metric, PARENT, which aligns n-grams from the reference and generated texts to the semi-structured data before computing their precision and recall.",Theory Proposal
1974,"In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA.",Theory Proposal
1975,", we propose MULTIQA, a BERTbased model, trained on multiple RC datasets, which leads to state-of-the-art performance on five RC datasets",Model Construction or Optimization
1976,"We propose a curriculum learning (CL) based Pointer-Generator framework for reading/sampling over large documents, enabling diverse training of the neural model based on the notion of alternating contextual difficulty",Model Construction or Optimization
1977,We propose Commonsense Auto-Generated Explanations (CAGE) as a framework for generating explanations for CQA.,Theory Proposal
1978,"In this work, we address the interpretability of ML based question answering (QA) models on a combination of knowledge bases (KB) and text documents",Model Construction or Optimization
1979,"We measure this characteristic using modularity, a network measurement that measures the strength of clusters in a graph",Theory Proposal
1980,"In this paper, we present the first work on cross-lingual generalisation of GR-LE relation",Theory Proposal
1981,"In this paper, we extend these earlier experiments to cover 69 languages from 13 language families using a multilingual Bible corpus",Theory Proposal
1982,The goal of this paper is to shed light on this matter so as to better understand the nature and extension of these limitations.,Theory Proposal
1983,"We provide implication for other domainrelated works where better representation of
domain terms is important, especially when
the data set is highly imbalanced.",Theory Proposal
1984,"we propose a novel methodology to automatically
verify the presence of therapeutic factors in
social networking websites by using Natural
Language Processing (NLP) techniques",Algorithms/ Methods Construction or Optimization
1985,"To achieve this task, natural language processing techniques were used to predict whether
each Tweet from a given set of Tweets contains a
mention of an ADR and extract any mentions of
ADRs",Theory Proposal
1986,"we describe the development of
TCL, a lexicon for Turkish discourse connectives,
which follows the format of DiMLex",Theory Proposal
1987,"This paper proposes a novel representation of
event structure by separating verbal semantics and the meaning of argument structure
constructions that verbs occur in.",Algorithms/ Methods Construction or Optimization
1988,"we propose that natural language generation
systems describing emotions should take into account how emotions are expressed non-verbally",Algorithms/ Methods Construction or Optimization
1989,"we show that some emotions are more
likely to be expressed via a certain channel, and
this channel is also influenced by the presence or
non-presence of a communication partner",Theory Proposal
1990,"Using the Recursive feature elimination with
cross-validation (RFECV) algorithm, we perform feature selection experiments on an exhaustive set of nineteen features (belonging
to all the classes mentioned above) extracted
from Brown corpus text",Algorithms/ Methods Construction or Optimization
1991,"we take advantage of
these characteristics to identify the highlights
of pre-scheduled events from tweet streams
and we demonstrate a method to summarize
these highlights",Theory Proposal
1992,"To incorporate sentiment score in predicting
a movieвЂ™s success",Performance Evaluation
1993,"we explore the viability
of models for the preemptive toxic detection task.",Performance Evaluation
1994,"we adapt a CRF layer as a a top module over the
outputs of the BERT-based model and demonstrate
that it improves performance even further.",Model Construction or Optimization
1995,we increase precision by filtering these name candidates with automatically learnt inflection patterns derived from name occurrences in large news article collections.,Algorithms/ Methods Construction or Optimization
1996,we discuss possible methods for improving sentiment classification for Slovak language by using state-of-the-art methods.,Algorithms/ Methods Construction or Optimization
1997,"Examines bias in ELMo and BERT, taking advantage of their context-sensitivity to give better visualizations",Theory Proposal
1998,"We propose a multi-head natural
language inference (NLI) encoder which resolves
co-reference though heuristic interaction and efficiently addresses the redundancy in BERT by applying dropout to inputs directly",Algorithms/ Methods Construction or Optimization
1999,we propose an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset.,Theory Proposal
2000,"we aim to support the annotation of argument schemes by combining a recently developed annotation method for one of
the leading typologies of argument schemes (Section 4) and a popular online software tool for
annotating argumentative discourse, OVA",Algorithms/ Methods Construction or Optimization
2001,we present a robust English corpus and annotation schema that allows us to explore the less straightforward examples of term-definition structures in free and semi-structured text,Dataset Creation or Resources
2002,"it is essential to include a
justification method in similar annotation tasks as
a suitable way of checking the guidelines and improving the training and evaluation processes of
automatic systems towards explainable AI",Algorithms/ Methods Construction or Optimization
2003,"We introduce two novel automated metrics:
Semantic Similarity and Response Echo Index and we show that they correlate well with
human judgment",Algorithms/ Methods Construction or Optimization
2004,we propose a novel method to select an appropriate response from response candidates generated by NCMs.,Algorithms/ Methods Construction or Optimization
2005,"we outline the approach and key components through which our conversational agent, Ruuh is able to accommodate a wide range of social needs",Theory Proposal
2006,"We present de-lexical segmentation, a linguistically motivated alternative to greedy or other unsupervised methods, requiring language specific knowledge, but no direct supervision.",Algorithms/ Methods Construction or Optimization
2007,We explore the use of data mining and NLP techniques for understanding the variability of tones in a large corpus of Mandarin newscast speech,Theory Proposal
2008,k we investigate using a subtle yet robust signal to resolve such ambiguity: linguistic alignment.,Performance Evaluation
2009,we conduct a detailed study with human annotators to confirm that our selection of semantic roles is effective in determining the underlying rhetorical structure of existing biomedical articles in an extensive dataset.,Theory Proposal
2010,we show that filtering for transitivity within pairwise annotations is more effective than filtering based on annotation confidence measures for individual examples.,Algorithms/ Methods Construction or Optimization
2011,"we take the novel approach of applying, for aggregation, a gradual argumentation semantics to bipolar argumentation frameworks mined using stance detection",Algorithms/ Methods Construction or Optimization
2012,we describe the the DipInfo-UniTo realizer (hencefort UniTO realizer) participating to the shallow track of the Surface Realization Shared Task 2018,Theory Proposal
2013,we show that the internal representations of RNNs trained on a variety of NLP tasks encode these syntactic features without explicit supervision,Theory Proposal
2014,We propose an efficient gradient-based optimization method to manipulate discrete text structure at its one-hot representation,Algorithms/ Methods Construction or Optimization
2015,we propose a method for obtaining high quality word embeddings that capture domain specific semantics and are suitable for tasks on the specific domain,Algorithms/ Methods Construction or Optimization
2016,"addresses the linguistic phenomenon of null-instantiated frame elements, i.e., implicit semantic roles, and their
representation in FrameNet (FN)",Theory Proposal
2017,We develop an unsupervised pipeline to extract schemas and apply our method to Reddit posts to detect schematic structures that are characteristic of different subreddits.,Algorithms/ Methods Construction or Optimization
2018,"We developed a machine-learning-based
method to detect video game players that
harass teammates or opponents in chat earlier
in the conversation",Algorithms/ Methods Construction or Optimization
2019,"The
aim of these models is to identify abusive language that directly targets certain individuals or
groups, particularly people belonging to protected
categories",Theory Proposal
2020,"focuses on using exclusively text-based input in the detection, in an optimised architecture combining Convolutional Neural Networks and Long ShortTerm Memory-networks.",Algorithms/ Methods Construction or Optimization
2021,"I
show how gender should be explored in
multiplicity in computational research
through clustering techniques, and layout
how this is being achieved in a study in
progress on gender hostility on Stack
Overflow.",Theory Proposal
2022,"aims to fill this gap by applying
the WEAT bias detection method to four sets
of word embeddings trained on corpora from
four different domains: news, social networking, biomedical and a gender-balanced corpus extracted from Wikipedia (GAP).",Performance Evaluation
2023,Demonstrates the effectiveness of the debiasing conceptor on both traditional and contextualized word embeddings.,Theory Proposal
2024,"we propose to make use of the
recent popular BERT tool (Devlin et al., 2018).
BERT is a model trained for masked language
modeling (LM) word prediction and sentence prediction using the transformer network",Model Construction or Optimization
2025,"Our work is the
first successful attempt of using R-GCN to boost
the performance of BERT contextual embeddings
without the need to fine tune BERT",Model Construction or Optimization
2026,"we apply a variant of the Structured Prediction Energy Network (SPEN) (Belanger and McCallum, 2016) to the Dialogue State Tracking Challenge (DSTC) 2 datase",Applications
2027,"We leverage the pretrained multilingual
BERT cased model to encode input sentences and apply additional word-level and
character-level LSTM layers before jointly
decoding lemmas and morphology tags using
simple sequence tagging layers",Model Construction or Optimization
2028,We apply convolutional neural networks to the task of shallow morpheme segmentation using low-resource datasets for 5 different languages,Algorithms/ Methods Construction or Optimization
2029,"we apply modern language modeling techniques to a large-vocabulary icon set commonly used in AAC applications, but for which we have no in-domain training data.",Applications
2030,"we define a meaning representation label set by adapting the English
schema and taking into account the specific
characteristics of Vietnamese.",Theory Proposal
2031,"we propose the addition of a set of speech acts, tense and aspect information, and parameters that help specify spatial location",Theory Proposal
2032,"We
propose using a neural encoder-decoder model to
extract story events and present empirical results
with significant improvements over the baseline.",Model Construction or Optimization
2033,"we present the results of a full end-to-end
story generation pipeline as originally proposed by
Martin et al. (2018) (Figure 1), showing how all of
the sub-systems can be integrated.",Theory Proposal
2034,"We define the task of scenario detection
and introduce a benchmark dataset of
annotated narrative texts, with segments
labeled according to the scripts they in-stantiate.",Dataset Creation or Resources
2035,To prepare a data set to define a movieвЂ™s success,Dataset Creation or Resources
2036,"we introduce the first
publicly-available Levantine Hate Speech and
Abusive (L-HSAB) Twitter dataset with the
objective to be a benchmark dataset for automatic detection of online Levantine toxic contents",Dataset Creation or Resources
2037,"using a large data set of conversations among
Wikipedia contributors, we compile and make publicly available a new dataset with complete discussion threads and with semi-automatically generated
toxicity labels",Dataset Creation or Resources
2038,"We train a neural network
with an objective to label sentences as grammatical or ungrammatical, using a вЂњsimulated
learner corpusвЂќ: a dataset with correct text
and with artificial errors, generated automatically",Algorithms/ Methods Construction or Optimization
2039,"We present the first gold-standard dataset for
Russian annotated with compositionality information of noun compounds.",Dataset Creation or Resources
2040,"We release
a new gender-balanced dataset1 of 800 sentences pertaining to specific professions and
propose a methodology for using it as a test
bench to evaluate sentiment analysis models",Dataset Creation or Resources
2041,we use Strictly k-Piecewise languages to generate datasets with various propertiesto compute the characteristics of the LDDs in these datasets using mutual information and analyze the impact of factors,Dataset Creation or Resources
2042,we introduce a dataset of 230 synthesis procedures annotated by domain experts with labeled graphs that express the semantics of the synthesis sentences.,Dataset Creation or Resources
2043,"create and organize a collection of
lemmas that would serve as a вЂњhubвЂќ point for different resources",Dataset Creation or Resources
2044,"presents the annotation
of formulaic sequences in the reference corpus of
spoken Slovenian in terms of syntactic structure,
pragmatic function and semantic relevance",Algorithms/ Methods Construction or Optimization
2045,"we present a data set of HindiEnglish code-mixed tweets labelled with semantic
roles. These labels provide us with information of the role played by an argument with respect to a
verb in a given sentence",Dataset Creation or Resources
2046,"We developed detailed
and explicit guidelines for human annotators, and
tested these on corpus data",Algorithms/ Methods Construction or Optimization
2047,"a recorded dataset of 400 speeches discussing 200 controversial topics, along with mined claims for each topic",Dataset Creation or Resources
2048,"We release CompSent-19, a new corpus consisting of 7,199 sentences containing item pairs (27% of the sentences are tagged as comparative and annotated with a preference);",Dataset Creation or Resources
2049,"we propose the Restricted RNTN (r-RNTN) which uses only K < |V | recurrence matrices. Given that |V | words must be assigned K matrices, we map the most frequent K в€’ 1 words to the first K в€’ 1 matrices, and share the K-th matrix among the remaining words.",Theory Proposal
2050,"We enhance tweet representation with a language model and distinguish the importance of different words with
Multi-Head Self-Attention",Model Construction or Optimization
2051,"We propose that a lattice-like architecture of the annotation categories can adequately handle all four issues, and at the same
time remain both intuitive for annotators and
faithful to typological insights",Algorithms/ Methods Construction or Optimization
2052,"presents an annotation scheme for modality that employs a dependency structure. Events and sources (here, conceivers) are represented as nodes and epistemic strength relations characterize the edges.",Algorithms/ Methods Construction or Optimization
2053,"We propose a novel way to combine a neural
story generation model with an explicit, symbolic text planning component; furthermore,
we show that the design reduces the demand
on training data",Algorithms/ Methods Construction or Optimization
2054,"We present an ensemble-based system for eventto-sentence that allows for guided language generation and demonstrate that this outperforms a
baseline sequence-to-sequence approach.",Algorithms/ Methods Construction or Optimization
2055,We propose a hybrid system combining a rule-based approach and light ML techniques. We use multilingual lexical resources such as JRC-NAMES and BABELNET together with a named entity guesser to recognise names.,Algorithms/ Methods Construction or Optimization
2056,I present a novel neural network model based on the pre-trained BERT for the gendered pronoun resolution task,Model Construction or Optimization
2057,"The model presented here draws upon
the strengths of state-of-the-art language and
coreference resolution models, and introduces
a novel evidence-based deep learning architecture.",Model Construction or Optimization
2058,"we started experimenting with machine
learning approaches for automating part of the annotation process",Model Construction or Optimization
2059,"we achieve
these features in a simple architecture integrating
existing methods on top of SEQ2SEQ in order to
make it easily reproducible in existing dialogue
systems",Algorithms/ Methods Construction or Optimization
2060,Our models combine sparse sequence-to-sequence models with a two-headed attention mechanism that learns separate attention distributions for the lemma and inflectional tags,Model Construction or Optimization
2061,We propose a merging strategy inspired by Byte-Pair-Encoding that reduces the space of valid operations by merging frequent adjacent operations,Algorithms/ Methods Construction or Optimization
2062,We present various models to tackle each task and evaluate performance.,Model Construction or Optimization
2063,We explore the potential of a transfer learning approach to improve the performance of an argument mining model trained with a small volume of data annotated with the proposed scheme.,Algorithms/ Methods Construction or Optimization
2064,we propose a neural network to evaluate the probability of there being a relation between ACs and to rank ACs using TextRank on the basis of probability,Performance Evaluation
2065,"we first introduce a variant of GloVe, in which there is an explicit connection between word vectors and PMI weighted co-occurrence vectors. We then show how relation vectors can be naturally embedded into the resulting vector space.",Algorithms/ Methods Construction or Optimization
2066,"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes",Algorithms/ Methods Construction or Optimization
2067,"Our approach relied on a text processing pipeline for tweets, and training traditional machine learning and deep learning models",Theory Proposal
2068,aims to detect tweets with Adverse Drug Reaction (ADR) mentions we used ELMo embeddings which is a deep contextualized word representation able to capture both syntactic and semantic characteristics,Algorithms/ Methods Construction or Optimization
2069,"We train ULMFit and BERT models for Tasks 1 and 4, and show that these models are agnostic to the effects of undersampling and oversampling, given a highly imbalanced dataset",Performance Evaluation
2070,"We propose
an end-to-end framework to automatically generate a sequence of pictures that represent major
2
events in a story text.",Algorithms/ Methods Construction or Optimization
2071,"We develop a story generation model that
generates globally coherent stories about
daily activities.",Algorithms/ Methods Construction or Optimization
2072,"we present a system to monitor cyberbullying phenomena by
combining message classification and social
network analysis.",Algorithms/ Methods Construction or Optimization
2073,"We propose
a structured annotation scheme that labels claim
verifiability, stance, and sentiment on news outlets.",Algorithms/ Methods Construction or Optimization
2074,"The goal is to develop a resource and
methods for distinguishing compositional compounds, which meaning could be split into parts,
from non-compositional ones that have a solid
meaning, and for which we would like to have a
dedicated embedding",Dataset Creation or Resources
2075,"we build a neural (NMT) machine system on the publicly available clean out-of-domain news corpus, and a phrase-based (PBMT) system trained on the same data in order to compare the two approaches in this specific scenario.",Algorithms/ Methods Construction or Optimization
2076,The paper presents a generic approach to the supervised sentiment analysis of social media content in foreign languages,Algorithms/ Methods Construction or Optimization
2077,"presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health.",Algorithms/ Methods Construction or Optimization
2078,"Introduces debiasing conceptors along with
a formal definition and mathematical relation
to the Word Embedding Association Test",Theory Proposal
2079,"we
describe our BERT-based approach to solving
the problem of gender-balanced pronoun resolution. We are able to reach 92% F1 score and
a much lower gender bias on the benchmark
dataset shared by Google AI Language team.",Algorithms/ Methods Construction or Optimization
2080,we propose an approach to extend biased single-output genderblind NLP systems with gender-specific alternative reinflections.,Algorithms/ Methods Construction or Optimization
2081,"we present the currently available
language processing systems similar to emtsv for
the sake of comparison.",Theory Proposal
2082,"we show that representing the concept of word complexity in a continuous manner
results in higher inter-annotator agreement than
using binary labels.",Algorithms/ Methods Construction or Optimization
2083,"our
aim is to create a system that is actually capable
of formulating relevant questions about the text it
processes.",Algorithms/ Methods Construction or Optimization
2084,"we focus on goal-oriented dialog systems that have a
clear message they need to convey, such as a price
or available times, and the role of computational
creativity in encapsulating their message in a creative form",Algorithms/ Methods Construction or Optimization
2085,"We propose an adversarial learning approach
for generating multi-turn dialogue responses.
Our proposed framework, hredGAN, is based
on conditional generative adversarial networks",Algorithms/ Methods Construction or Optimization
2086,"we propose a response
generation model that outputs diverse words while
preserving relevance in response to the input utterance",Model Construction or Optimization
2087,We present a hierarchical neural model for contextual morphological analysis with a shared encoder and independent decoders for each coarse-grained feature.,Model Construction or Optimization
2088,", we present our approach of treating contextual morphological analysis as the generation of the correct sequence of MSD tag dimensions.",Algorithms/ Methods Construction or Optimization
2089,We propose a model to perform morphosyntactic annotation for any language with a translation of the Bible.,Model Construction or Optimization
2090,we present artificial phonology experiments that show that phone embeddings learn paradigmatic relationships such as phonemic and allophonic distribution quite well,Model Construction or Optimization
2091,"This paper demonstrates that there are regular functions that are not weakly deterministic, and, because all attested processes so far studied are weakly deterministic, supports the subregular hypothesis.",Performance Evaluation
2092,We propose and test an annotation scheme that we use to conduct a pilot annotation experiment in which we enrich a subset of the SciDTB corpus with an additional layer of argumentative structures.,Algorithms/ Methods Construction or Optimization
2093,We present an experimental study of supervised classifiers and a strong rule-based baseline from prior work.,Theory Proposal
2094,"we present a large-scale and indepth computational readability study for Arabic. Arabic, being a relatively low-resource and morphologically complex language, presents numerous challenges to the task of automatic readability assessment.",Theory Proposal
2095,"we propose a new method to study social media
content by characterizing disease-related correlations of language, by leveraging available demographic and disease information on the community level.",Algorithms/ Methods Construction or Optimization
2096,we describe our methods to automatically classify Twitter posts conveying events of adverse drug reaction (ADR). B,Algorithms/ Methods Construction or Optimization
2097,The best-performed model on the test sets were trained on a merged corpus consisting of the datasets released by SMM4H 2017 and 2019,Algorithms/ Methods Construction or Optimization
2098,We also show the use of combining pretrained BERT embeddings with Glove embeddings fed to a BLSTM text classifier for sub-task-1 and sub-task-4.,Performance Evaluation
2099,"we propose an extension to
Abstract Meaning Representations (AMRs) to
encode scope information of quantifiers and
negation, in a way that overcomes the semantic gaps of the schema while maintaining its
cognitive simplicity.",Algorithms/ Methods Construction or Optimization
2100,"We propose two extensions of GKR that
clearly show this division and empirically test
one of the proposals on an NLI dataset with
hard compositional pairs.",Algorithms/ Methods Construction or Optimization
2101,"We present a method of generating inferences
from ULFs from a small set of interpretable inference rules by first defining general semantic predicates over ULF clauses and tree transformations
that correspond to natural semantic operations in
ULF.",Algorithms/ Methods Construction or Optimization
2102,"We describe
how ULF can be used to generate natural language inferences that are grounded in the semantic and syntactic structure through a small
set of rules defined over interpretable predicates and transformations on ULFs",Theory Proposal
2103,"This paper presents a new task-oriented meaning representation called meta-semantics, that
is designed to detect patients with early symptoms of AlzheimerвЂ™s disease by analyzing their
language beyond a syntactic or semantic level",Algorithms/ Methods Construction or Optimization
2104,"This paper proposes using a Bidirectional
LSTM-CRF model in order to identify the
tense and aspect of verbs",Model Construction or Optimization
2105,"we describe new semantic representations for the lexical resource VerbNet that
provide this sort of information for thousands of verb senses and introduce a means for automatically translating text to these representations.",Theory Proposal
2106,"we describe an approach to overcome this
by getting labelled persona data from a different task and leveraging those annotations to
perform persona based story generation.",Theory Proposal
2107,"We propose a novel take on understanding
narratives in social media, focusing on learning вЂњfunctional story schemasвЂќ, which consist
of sets of stereotypical functional structures.",Algorithms/ Methods Construction or Optimization
2108,"We introduce a novel
partitioning approach for characterizing user
polarization based on their distribution of participation across interest subreddits",Algorithms/ Methods Construction or Optimization
2109,"we describe a workflow for the
data-driven acquisition and semantic scaling
of a lexicon that covers lexical items from the
lower end of the German language registerвЂ”
terms typically considered as rough, vulgar or
obscene.",Algorithms/ Methods Construction or Optimization
2110,"we propose an approach
for semi-automatically creating a data-to-text
(D2T) corpus for Russian that can be used
to learn a D2T natural language generation
model.",Algorithms/ Methods Construction or Optimization
2111,"we propose a new method to quantify bias in BERT embeddings (В§2). Since BERT embeddings use a masked language modelling objective, we directly query the model to measure the bias for a particular token",Algorithms/ Methods Construction or Optimization
2112,Construction of a corpus with template sentences that can check the preservation of gender-neutrality in KR-EN translation,Dataset Creation or Resources
2113,"we have developed a method of acquiring hedge annotations through crowdsourcing, by
framing the hedge identification task as a simple
word sense disambiguation problem.",Algorithms/ Methods Construction or Optimization
2114,"a demonstration that the generalized method
is comparable in reliability of annotations to
the original more restricted crowd-sourcing
method proposed by (Scholman and Demberg, 2017a);",Model Construction or Optimization
2115,"we present a discourse annotation
study of Italian data, which uses the annotation
scheme and discourse-analytic method, the QUDtree framework",Algorithms/ Methods Construction or Optimization
2116,"Does controlling for the homogeneity of the
group of annotators with respect to their
age, education level and native language contribute to higher agreement",Algorithms/ Methods Construction or Optimization
2117,"We propose a novel method for CMC based
on fine-tuning BERT by regarding the sequences of the questions and the answers as
independent inputs.",Algorithms/ Methods Construction or Optimization
2118,we contribute to the under-explored area of generating natural language explanations for general phenomena,Theory Proposal
2119,"We introduce the use of multiple attention
mechanisms that selectively focus character and
word sequences in the sentence context.",Algorithms/ Methods Construction or Optimization
2120,We propose the input tier-based input strictly local (I-TISL) functions as a functional analogue of the generalized tierprojection mechanism of the IO-TSL languages,Algorithms/ Methods Construction or Optimization
2121,we adapt a graph-based approach to characterize the clusters (fuzzy types) of tone contour shapes observed in each tone n-gram category.,Algorithms/ Methods Construction or Optimization
2122,we will apply a hybrid approach for finding the correct splits of words and augmenting a morphological database,Algorithms/ Methods Construction or Optimization
2123,We propose an unsupervised approach for morphological segmentation of polysynthetic languages based on Adaptor Grammars,Algorithms/ Methods Construction or Optimization
2124,"We show that TSSL functions naturally describe rhythmic syncope while TIOSL functions cannot, and we argue that TSSL functions provide a more restricted characterization of rhythmic syncope than existing treatments within Optimality Theory.",Theory Proposal
2125,"we have created a semantic graph that, together with named entity recognition and resolution (NER), should make it easier to establish connections between arguments in a given debate",Algorithms/ Methods Construction or Optimization
2126,We propose an attention mechanism to leverage lexicon information.,Algorithms/ Methods Construction or Optimization
2127,"We introduce a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings.",Model Construction or Optimization
2128,"We introduce a the DM NLP teamвЂ™s system for NLPTEA 2018 shared task of Chinese Grammatical Error Diagnosis (CGED), which can be used to detect and correct grammatical errors in texts written by Chinese as a Foreign Language (CFL) learners.",Algorithms/ Methods Construction or Optimization
2129,"We describe an overview of the Dialogue Emotion Recognition Challenge, EmotionX, at the Sixth SocialNLP Workshop, which recognizes the emotion of each utterance in dialogues. This challenge offers the EmotionLines dataset as the experimental materials.",Theory Proposal
2130,we propose a method to combine the breadth of generic embeddings with the specificity of domain specific embeddings,Algorithms/ Methods Construction or Optimization
2131,we propose a simple hyperparameter selection technique for active learning applied to semantic parsing,Algorithms/ Methods Construction or Optimization
2132,"we investigate whether SNACS
(Schneider et al., 2018b), an approach to semantic
disambiguation of adpositions and possessives, can
be adapted to cover syntactically core grammatical
relations (subjects and objects).",Theory Proposal
2133,"we examine how narrative coherence is attained in the submissions
of NaNoGenMo 2018, an online text generation event where participants are challenged to
generate a 50,000 word novel.",Theory Proposal
2134,"This study explores the relation between lexical concreteness and narrative text quality. We
present a methodology to quantitatively measure lexical concreteness of a text.",Theory Proposal
2135,"we deploy a logistic regression
classifier to ascertain whether a given document belongs to the fiction or non-fiction
genre",Theory Proposal
2136,"we will focus on the analysis of speech utterances in theatre scripts. Dialogues in theatre plays
are quite easy to collect (i.e. the characters are explicitly stated in the scripts) without the need of
lengthy and costly manual annotation.",Theory Proposal
2137,"We evaluate our algorithm on
tweets collected around 2 episodes of a popular TV show, Game of Thrones, Season 7",Performance Evaluation
2138,"we
delineate and clarify the main challenges
and frontiers in the field, critically evaluate
their implications and discuss solutions",Theory Proposal
2139,"We compare the effectiveness of end-to-end
character based models, with word + character embedding models, byte pair encoding and
subword models, to show which of the techniques perform better than pure word based
models.",Model Construction or Optimization
2140,"We also examine how preprocessing documents with byte pair encoding model pretrained on a large corpus, boost the performance of several word embedding based models massively.",Model Construction or Optimization
2141,"an investigation on the role
of populist themes and rhetoric in an Italian
Twitter corpus of hate speech against immigrants.",Theory Proposal
2142,"contribution
of transfer learning technique to pronoun resolution systems is investigated and the gender
bias contained in classification models is evaluated.",Performance Evaluation
2143,Our work improves the snippetcontext baseline F1 score on Gendered Ambiguous Pronouns dataset from 66.9% to 80.3%.,Algorithms/ Methods Construction or Optimization
2144,"the development of a system-independent gender-awareness wrapper, and the building of a corpus for training and evaluating first-person-singular gender identification and reinflection in Arabic",Algorithms/ Methods Construction or Optimization
2145,A measure to evaluate and compare the performance of translation systems regarding the preservation of gender neutrality of pronouns,Performance Evaluation
2146,"we investigate RNN learning from the formal language
perspective using the WFA models, and we show
that adding more layers may not be sufficient if the
model has to deal with long-term dependencies.",Model Construction or Optimization
2147,"presents the annotation and evaluation of the Litkey Corpus, a longitudinal corpus of written texts in German from children in primary school between grades 2 to 4",Dataset Creation or Resources
2148,"we explore corpus data of five Oceanic languages of Melanesia which are known to be mood-prominent (in the sense of Bhat, 1999). In order to find out more about tense, aspect, modality, and polarity, we tagged these categories in a subset of our corpora",Dataset Creation or Resources
2149,we discover which linguistic phenomena are hard for humans to annotate and show that these do not always coincide with what is assumed to be difficult for automatic systems.,Theory Proposal
2150,"we discuss whether the different distribution of discourse relations in each
setting reflects different strategies used to pursue a
communicative purpose (В§6), and how these might
relate to audience design",Theory Proposal
2151,"We found that the gold answer history contributed to the model performance most by
analyzing the effects of dialogue history",Model Construction or Optimization
2152,"We present the analysis of the application of
deep neural work for contextual resolution in dialogue, including both step-by-step and end-to-end
approaches",Applications
2153,We provide a detailed analysis of the proposed models both on an internal benchmark and public dataset,Model Construction or Optimization
2154,"we propose and test the idea of performing cognate projection
to leverage high-resource training data for lowresource inflection generation.",Algorithms/ Methods Construction or Optimization
2155,We evaluate the effect of a variety of types of external embeddings for lemmatization and morphological tagging.,Performance Evaluation
2156,We evaluate the effect of combining annotated datasets from related languages for both tasks,Performance Evaluation
2157,"We analyze the dependencies among different morphological features to inform model choices, and find that adding POS information to the encoder significantly improves prediction accuracy by reducing errors across features, particularly Gender errors.",Model Construction or Optimization
2158,"We evaluate our proposed approach on 107 treebanks and achieve +14.76 (accuracy) average improvement over the shared task baseline (McCarthy et al., 2019) for morphological analysis.",Performance Evaluation
2159,"we examine whether a вЂњCRFinspiredвЂќ neural model without the hand-crafted features, can be applied to the task of argumentative unit segmentation at the clause level, and whether its performance is comparable to approaches exploiting such features",Model Construction or Optimization
2160,. We analyze challenges facing our computational methods and suggest future directions.,Theory Proposal
2161,we investigate similarities between discourse and argumentation structures by aligning subtrees in a corpus containing both annotations,Theory Proposal
2162,"In the face of the scarcity of argument lexicon, we explore several different types of lexicons to verify whether outside resources are useful for AM tasks.",Performance Evaluation
2163,we present and evaluate new attention-based architectures for the task of argumentative text segmentation.,Algorithms/ Methods Construction or Optimization
2164,we review the effectiveness of recently proposed contextualized word embedding approaches in regard to AM,Performance Evaluation
2165,"we run various discourse parsers (RST, PDTB) on the corpus, compare their results to the gold annotations (for RST) and then assess the contribution of automatically-derived discourse features for argumentation parsing",Performance Evaluation
2166,presents a first attempt at using WaltonвЂ™s argumentation schemes for annotating arguments in Swedish political text and assessing the feasibility of using this particular set of schemes with two linguistically trained annotators.,Algorithms/ Methods Construction or Optimization
2167,"we study the possibility of combining short-term representations, stored in neural activations (hidden state), with medium-term representations encoded in a set of dynamical weights of the language model",Theory Proposal
2168,we evaluate our approach which compares the use of вЂњblack-boxвЂќ features (without ASR decoder information) and вЂњglass-boxвЂќ features which use internal information from the decoder,Performance Evaluation
2169,"We investigate the robustness of a classifier trained with adversarial examples, by studying its resilience to attacks and its accuracy on clean test data",Performance Evaluation
2170,"The solution presented
here features a bidirectional Long Shortterm Memory Network (bi-LSTM) for the
generation of character-level embeddings.",Theory Proposal
2171,"we explore various aspects of sentiment detection
and their correlation to toxicity, and use our
results to implement a toxicity detection tool.",Theory Proposal
2172,"we explore deep multimodal
fusion of text and photo for the task of hate
speech classification on social networks, where
hate speech posts frequently appear with images.",Theory Proposal
2173,"we employ several wellestablished automated text analysis tools and
build on common practices for handling highly
imbalanced datasets and reducing sensitivity
to overfitting.",Dataset Creation or Resources
2174,"The final model submitted is a multisource neural NER system with multilingual
BERT embeddings, trained on the concatenation of training data in various Slavic languages (as well as English)",Model Construction or Optimization
2175,"we use a
mixed model which combines multilingualcontextual and language-specific embeddings.",Model Construction or Optimization
2176,"Shows how heterogeneity in content and size of the вЂќtarget listвЂќ of gendered or racially marked terms interferes with debiasing, and how conceptors on contextual embeddings can be used to address such target list heterogeneity.",Theory Proposal
2177,"For gender reinflection, we use a character-level neural MT (NMT) model in a single step (identify and reinflect, jointly), and as the second part of a twostep (identify then reinflect) system",Model Construction or Optimization
2178,"a вЂњconnective bankвЂќ consisting of 800 entries
including traditional connectives as well as
variations of connectives and alternative lexicalizations;",Dataset Creation or Resources
2179,"we present a corpus annotated with
these relations and the analysis of these results where corpus contains 520 sentence pairs, annotated with these relations",Dataset Creation or Resources
2180,"making
up for the scarcity of NLP resources in Turkish by
annotating a new corpus that has not been introduced to the UD project before, namely the TNC",Dataset Creation or Resources
2181,"we describe three platforms that
constitute our annotation ecosystem, as background for a demonstration of their ability to work
in concert to provide easily usable means to adapt
NLP processes to specific domains",Algorithms/ Methods Construction or Optimization
2182,"we present
a repository of conversational datasets consisting of hundreds of millions of examples,
and a standardised evaluation procedure for
conversational response selection models using 1-of-100 accuracy.",Dataset Creation or Resources
2183,"our model utilizes fine-tuning
to compensate for the training data scarcity, which
is essential because there is a limited amount of
domain-dependent and sentiment-rich dialogues",Model Construction or Optimization
2184,"We have developed a system based on LSTM neural networks inspired
by the excellent results obtained by deep learning classifiers",Algorithms/ Methods Construction or Optimization
2185,We study approaches based on machine learning and deep learning to extract adverse drug reaction mentions from highly informal texts in Twitter.,Theory Proposal
2186,This paper describes the system developed by team ASU-NLP for the Social Media Mining for Health Applications(SMM4H) shared task,Model Construction or Optimization
2187,"This paper describes the system that team MYTOMORROWS-TU DELFT developed for the 2019 Social Media Mining for Health Applications (SMM4H) Shared Task 3, for the end-to-end normalization of ADR tweet mentions to their corresponding MEDDRA codes.",Algorithms/ Methods Construction or Optimization
2188,We make an initial attempt in studying the effectiveness of transfer learning using ULMFit and BERT for the problems in the domain of health care pertaining to the shared tasks.,Algorithms/ Methods Construction or Optimization
2189,"We employed a combination of three types of word representations as input to a LSTM model for detecting reportage of adverse drug reaction in tweets as part of the 2019 social media
mining for healthcare applications shared task.",Performance Evaluation
2190,"AMR concepts show a higher level of abstraction from surface forms, meaning that
AMR concepts bear less resemblance to the
word tokens in the original sentence.",Theory Proposal
2191,"we consider neural network solution for multilingual named entity
recognition for Bulgarian, Czech, Polish and Russian languages for the BSNLP 2019 Shared Task
(Piskorski et al., 2019)",Algorithms/ Methods Construction or Optimization
2192,"Present an approach to find one of the subtypes of gender bias, Gender Generalization",Theory Proposal
2193,Provide a high-level definition of gender bias in text,Theory Proposal
2194,"The main idea of our augmentation is to replace each name in the name-pronoun pair by a set of common placeholder names, in order to (1) diversify the idiosyncratic information embedded in individual names and leave only the contextual information",Theory Proposal
2195,"The main contribution of this study is providing progress on the recent detected problem which
is gender bias in MT",Theory Proposal
2196,aims to address such issues of interpretability by relating sequential neural networks to forms of computation that are more well understood.,Theory Proposal
2197,"We address the nontrivial problem of evaluating the extractions
produced by systems against the reference tuples, and share our evaluation script",Theory Proposal
2198,"we discuss how we tackle the challenges raised by harmonizing different lemmatization criteria in the LiLa: Linking Latin project,
which aims to make resources for Latin interoperable.1",Theory Proposal
2199,"we first look at the use of discourse
connectives along two dimensions of variation and
show that there are systematic differences regarding the frequency of different forms of discourse
connectives",Theory Proposal
2200,"While there is relevant
ongoing research on Semantic Role Labelling
(SRL) and on building tools for code-mixed
social media data, this is the first attempt at labelling semantic roles in Hindi-English codemixed data, to the best of our knowledge.",Dataset Creation or Resources
2201,"We alleviated these problems
by developing WAT-SL 2.0, an open-source
web-based annotation tool for long-segment
labeling, hierarchically structured label sets
and built-ins for quality control.",Theory Proposal
2202,"aims to 
create an annotated corpus where the annotation
contains all the features needed to generate questions concerning the text.",Dataset Creation or Resources
2203,"we describe our system for
morphological analysis and lemmatization
in context, using a transformer-based
sequence to sequence model and a biaffine
attention based BiLSTM model",Algorithms/ Methods Construction or Optimization
2204,We use sequence-to-sequence networks trained on sequential phonetic encoding tasks to construct compositional phonological representations of words,Algorithms/ Methods Construction or Optimization
2205,we propose a three-way feature grouping: (i) features which access only the EAU span; (ii) features which access only the context of an EAU; (iii) features which access both EAU span and its context.,Algorithms/ Methods Construction or Optimization
2206,"to deploy a novel methodology for classifying different argumentative support (supporting evidences) in arguments, without considering the context",Algorithms/ Methods Construction or Optimization
2207,) the identification of the schemes for which available tools are readily available for use;,Theory Proposal
2208,"This paper uses a novel framework to restore the elided elements in the sentence,
which is named Abstract Meaning Representation (AMR)(Banarescu et al., 2013). AMR represents the whole sentence meaning with concepts,
which are mainly abstracted from its corresponding words occurring in the sentence.",Algorithms/ Methods Construction or Optimization
2209,"Building a dataset for abusive language and
hate speech detection including detecting the
target, category, and level of hate speech in
Indonesian Twitter. We provide this research
dataset for public4
so that it can be used by
other researchers who are interested in doing
future work of this paper.",Dataset Creation or Resources
2210,"Investigate what type of attention mechanism in deep learning architectures (contextual attention vs. self-attention) is better for
abusive language detection. We show that
contextual attention models outperform selfattention models on most cases (datasets and
architectures), and present a thorough error
analysis showing how contextual attention
works better than self-attention particularly
when it comes to modeling implicit abusive
content.",Algorithms/ Methods Construction or Optimization
2211,"Investigate whether stacked architectures are
better than simple architectures for abusive
language detection when using Biderectional
Long Short Term Memory (Bi-LSTM) networks. We show that stacked architectures are better than simple architectures
on all datasets. In addition, we discuss
the importance of pre-trained word embeddings for deep learning models.",Algorithms/ Methods Construction or Optimization
2212,"introduction of a novel
fine-grained hate speech typology that improves
on the common state-of-the-art used typologies,
which tend to disregard the existence of subtypes
of hate speech and either consider hate speech
recognition as a binary classification task, or take
into account only a few classes, such as вЂ�racismвЂ™
95
and вЂ�sexismвЂ™ (Waseem and Hovy, 2016) вЂ“ despite
the fact that such broad distinctions unduly overgeneralize.",Algorithms/ Methods Construction or Optimization
2213,"This paper investigates the extent of the new
lexicon problem for different types of Ukrainian
corpora and further proposes and evaluates a
knowledge-light approach to extending lexical
coverage of morphological resources to neologisms (new words, meanings or usages) and new
single-word Named Entities (proper names) which
follow regular inflectional patterns",Algorithms/ Methods Construction or Optimization
2214,we pay special attention to the gapping resolution methods that were introduced within the shared task as well as an alternative test set that illustrates that our corpus is a diverse and representative subset of Russian language gapping sufficient for effective utilization of machine learning techniques.,Algorithms/ Methods Construction or Optimization
2215,"We provide an experimental evaluation of
models and methods for predicting compositionality of noun compounds. We show that
the methods from the previous work trained
on the proposed Russian-language resource
achieve the performance comparable with results on English corpora.",Performance Evaluation
2216,"describes the Second Shared Task on
multilingual NE recognition (NER), which aims
at addressing these problems in a systematic way.
The shared task was organized in the context of
the 7th Balto-Slavic Natural Language Processing
Workshop co-located with the ACL 2019 conference",Theory Proposal
2217,"We propose a black-box approach for injecting the missing information to a pre-trained neural machine translation system, allowing to control the morphological variations in the generated translations without changing the underlying model or training data.",Algorithms/ Methods Construction or Optimization
2218,"we present an open-source, lightweight, easy-to-use graphical annotation tool that employs a statistical parser to create initial CCG derivations for sentences, and allows annotators to correct these annotations via lexical category constraints and span constraints",Dataset Creation or Resources
2219,"we propose a corpus
generation strategy that only requires a machine translation system between English and
the target language in both directions, where
we filter the best translations by computing automatic translation metrics and the task performance score",Algorithms/ Methods Construction or Optimization
2220,"we present a new annotation
scheme for the Sejong part-of-speech tagged
corpus based on Universal Dependencies
style annotation. By using a new annotation
scheme, we can produce Sejong-style morphological analysis and part-of-speech tagging results which have been the de facto standard for
Korean language processing",Model Construction or Optimization
2221,"We formulate the problem
definition of context reconstruction in dialogue
into one detection problem and one ranking problem and present the difference between it and
traditional tasks such as pronoun and zero pronoun detection and mention candidate selection;",Theory Proposal
2222,We improve upon the slot carryover model architecture in Naik et al. (2018) by introducing approaches for modeling slot interdependencies. We propose two neural network models based on pointer networks and transformer networks that can make joint predictions over slots.,Model Construction or Optimization
2223,"we computationally simulate two directions of verbal inflection in Japanese, Present 7в†’ Past and Past 7в†’ Present, with the rule-based computational model called Minimal Generalization Learner (MGL; Albright and Hayes, 2003) and experimentally evaluate the model with the bidirectional вЂњwugвЂќ test where humans inflect novel verbs in two opposite directions.",Performance Evaluation
2224,"we propose Probabilistic FastText (PFT), which provides probabilistic characterlevel representations of words. The resulting word embeddings are highly expressive, yet straightforward and interpretable, with simple, efficient, and intuitive training procedures.",Algorithms/ Methods Construction or Optimization
2225,we transform external lexico-semantic relations into training examples which we use to learn an explicit retrofitting model (ER). The ER model allows us to learn a global specialization function and specialize the vectors of words unobserved in the training data as well.,Algorithms/ Methods Construction or Optimization
2226,"we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high-level representations of the input sentences.Besides, two different generative adversarial
networks (GANs), namely the local GAN
and global GAN, are proposed to enhance
the cross-language translation. With this
new approach, we achieve significant improvements on English-German, EnglishFrench and Chinese-to-English translation
tasks.",Model Construction or Optimization
2227,"We propose a novel triangular training architecture (TA-NMT) to effectively tackle the
data sparsity problem for rare languages in
NMT with an EM framework.Our method can exploit two additional bilingual datasets at both the model and data levels by introducing another rich language.Our method is a unified bidirectional EM algorithm, in which four translation models on
two low-resource pairs are trained jointly and
boost each other.",Algorithms/ Methods Construction or Optimization
2228,"We propose a unified model combining sentence-level and word-level attentions to
take advantage of both extractive and abstractive summarization approaches. We propose a novel inconsistency loss function to ensure our unified model to be mutually beneficial to both extractive and abstractive summarization. The unified model with
inconsistency loss achieves the best ROUGE
scores on CNN/Daily Mail dataset and outperforms recent state-of-the-art methods in
informativity and readability on human evaluation.",Model Construction or Optimization
2229,"We propose to introduce soft templates as additional input to improve the readability and stability of seq2seq summarization systems. Code and results can be found at http://www4.comp.polyu. edu.hk/Лњcszqcao/. We extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously. We fuse the popular IR-based and seq2seqbased summarization systems, which fully utilize the supervisions from both sides.",Algorithms/ Methods Construction or Optimization
2230,"We first to combine structural semantics and neural methods for TS, we propose an intermediate way for performing sentence splitting, presenting Direct Semantic Splitting (DSS), a simple and efficient algorithm based on a semantic parser which supports the direct decomposition of the sentence into its main semantic constituents.",Algorithms/ Methods Construction or Optimization
2231,We propose a method of combining Conditional Random Fields (CRFs) model with a post-processing layer using Google n-grams statistical information tailored to detect word selection and word order errors made by learners of Chinese as Foreign Language (CFL).,Model Construction or Optimization
2232,we report a short answer grading system in Chinese. We build a system based on standard machine learning approaches and test it with translated corpus from two publicly available corpus in English. The experiment results show similar results on two different corpus as in English.,Algorithms/ Methods Construction or Optimization
2233,"we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task. The novelty of the work lies in the fact that instead of considering only the word and sentence representation of a text, we try to augment the different complex linguistic, cognitive and psychological features associated within a text document along with a hierarchical convolution recurrent neural network framework.",Algorithms/ Methods Construction or Optimization
2234,"we propose a new semi-supervised learning method with a feedback loop to leverage vast amounts of unlabeled data and feedback signals. In particular, we train two machine learning models iteratively. The main model, which is represented as M ain, performs the main task at runtime.",Algorithms/ Methods Construction or Optimization
2235,"We outline future directions in summarization to address all of these issues. By resolving the existing problems, we will make it easier for users of review-sites to make more informed decisions.",Model Construction or Optimization
2236,"We hypothesize that by training on higher information and more difficult training sentences, RNN language models can learn the language distribution more accurately and produce lower perplexities than models trained on similar-sized randomly sampled training sets",Theory Proposal
2237,"We propose a learning-based framework to incorporate the scores of a set of lexical and semantic metrics as features, to capture the adequacy and fluency of captions at different linguistic levels. Our experimental results demonstrate that composite metrics draw upon the strengths of standalone measures to yield improved correlation and accuracy",Model Construction or Optimization
2238,"we propose a preordering method with a recursive neural network (RvNN). RvNN calculates reordering in a bottom-up manner (from the leaf nodes to the root) on a source syntax tree. Thus, preordering is performed considering the entire sub-trees.",Algorithms/ Methods Construction or Optimization
2239,"we aim to automatically generate description of medical images, to develop medical visual question answering system and to develop medical dialog agents that interact with patients to answer their queries based on their medical data.",Dataset Creation or Resources
2240,"We review the existing methods which are revised to tackle complex entity mentions and categorize them as tokenlevel and sentence-level approaches. We then identify the research gap, and discuss some directions that we are exploring",Algorithms/ Methods Construction or Optimization
2241,"we attempt to contribute to LBD discipline outside of medical domain by automating crossdisciplinary knowledge discovery process. As a proof of concept, the proposed solution will be applied to different CS-related concepts.",Dataset Creation or Resources
2242,"We compare our method with existing off-theshelf NER tools for social media content, and find that our systems outperforms the best baseline by 33.18 % (F1 score).",Algorithms/ Methods Construction or Optimization
2243,"We present ongoing work on data-driven parsing of German and French with Lexicalized Tree Adjoining Grammars. We use a supertagging approach combined with deep learning. We show the challenges of extracting LTAG supertags from the French Treebank, introduce the use of leftand right-sister-adjunction, present a neural architecture for the supertagger, and report experiments of n-best supertagging for French and German.",Model Construction or Optimization
2244,"we incorporate semantic supersensetags and syntactic supertag features into ENвЂ“FR and ENвЂ“DE factored NMT systems. In experiments on various test sets, we observe that such features (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.",Performance Evaluation
2245,"we develop a novel pipeline for Semantic Abstractive Summarization (SAS). SAS, as introduced by Liu et al. (2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph. Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-ofthe-art co-reference resolution and Meta Nodes. Which we then use in a novel unsupervised algorithm based on how humans summarize a piece of text to extract the summary sub-graph. Our algorithm outperforms the state of the art SAS method by 1.7% F1 score in node prediction.",Dataset Creation or Resources
2246,"we are focusing on biomedical document retrieval from literature for clinical decision support systems. We compare statistical and NLP based approaches of query reformulation for biomedical document retrieval. Also, we have modeled the biomedical document retrieval as a learning to rank problem. We report initial results for statistical and NLP based query reformulation approaches and learning to rank approach with future direction of research.",Model Construction or Optimization
2247,"we do not present direct quotes from any data, nor any identifying information. Anonymised data was collected from microblogging website Twitter - specifically, content containing self-classified suicidal ideation (i.e. text posts tagged with the word вЂ™suicide) over the period of December 3, 2017 to January 31, 2018. The Twitter REST API2 was used for collection of tweets containing any of the following English words or phrases that are consistent with the vernacular of suicidal ideation (OвЂ™Dea et al., 2015",Dataset Creation or Resources
2248,"we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts. We discuss the methodology followed for the polarity annotations and validate the developed resource. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for sentiment predictions. The fundamental aim of this paper is to validate and study the possibility of utilizing machine learning algorithms, word-level sentiment annotations in the task of automated sentiment identification. Furthermore, accuracy is improved by annotating the bi-grams extracted from the target corpus.",Algorithms/ Methods Construction or Optimization
2249,"We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level",Theory Proposal
2250,"we capture using the HITS algorithm. We apply our proposed method to two tasks: machine translation and grammatical error correction. For Japanese-to-English translation, this method achieves a BLEU score that is 0.56 points more than that of a baseline. Furthermore, it outperforms the baseline method for English grammatical error correction, with an F0.5-measure that is 1.48 points higher",Algorithms/ Methods Construction or Optimization
2251,"we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain. We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence. To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints.",Performance Evaluation
2252,"we develop an adversarial writing setting, where humans interact with trained models and try to break them. This annotation process yields a challenge set, which despite being easy for trivia players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing robust and generalizable question answering systems",Dataset Creation or Resources
2253,"we could predict a possible cognate from the given input. Our study shows that when language modelling smoothing methods are applied as the retrieval functions and used in conjunction with positional segmentation and error modelling gives better results than competing baselines, in both classification and prediction of cognates",Applications
2254,we can demystify affect generation by reviewing psychological models which build on neuro-biological findings in regards to human emotion,Model Construction or Optimization
2255,"we show how to build an automatic spelling corrector for resourcescarce languages. We propose a sequenceto-sequence deep learning model which trains end-to-end. We perform experiments on synthetic datasets created for Indic languages, Hindi and Telugu, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our model is competitive with the existing spell checking and correction techniques for Indic languages.",Model Construction or Optimization
2256,We reformulate the problem of encoding a multi-scale representation of a sequence in a language model by casting it in a continuous learning framework. We propose a hierarchical multi-scale language model in which short time-scale dependencies are encoded in the hidden state of a lower-level recurrent neural network while longer time-scale dependencies are encoded in the dynamic of the lower-level network by having a meta-learner update the weights of the lower-level neural network in an online meta-learning fashion. We use elastic weights consolidation as a higher-level to prevent catastrophic forgetting in our continuous learning framework,Model Construction or Optimization
2257,"we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations show that for fixed hidden layer sizes, r-RNTNs improve language model performance over RNNs using only a small fraction of the parameters of unrestricted RNTNs. These results hold for r-RNTNs using Gated Recurrent Units and Long Short-Term Memory.",Algorithms/ Methods Construction or Optimization
2258,"We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision",Model Construction or Optimization
2259,"we propose a novel approach to estimate WER, or e-WER, which does not require a gold-standard transcription of the test set. Our e-WER framework uses a comprehensive set of features: ASR recognised text, character recognition results to complement recognition output, and internal decoder features. We report results for the two features; black-box and glass-box using unseen 24 Arabic broadcast programs. Our system achieves 16.9% WER root mean squared error (RMSE) across 1,400 sentences. The estimated overall WER eWER was 25.3% for the three hours test set, while the actual WER was 28.5%",Theory Proposal
2260,"we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes. Evaluating on two tasks, we show that this leads to increased privacy in the learned representations, as well as more robust models to varying evaluation conditions, including out-of-domain corpor",Theory Proposal
2261,"We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the onehot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier.",Algorithms/ Methods Construction or Optimization
2262,We apply active learning to both traditional and вЂњovernightвЂќ data collection approaches. We show that it is possible to obtain good training hyperparameters from seed data which is only a small fraction of the full dataset. We show that uncertainty sampling based on least confidence score is competitive in traditional data collection but not applicable for overnight collection. We evaluate several active learning strategies for overnight data collection and show that different example selected.,Dataset Creation or Resources
2263,"we suggest to leverage the partition of articles into sections, in order to learn thematic similarity metric between sentences. We assume that a sentence is thematically closer to sentences within its section than to sentences from other sections. Based on this assumption, we use Wikipedia articles to automatically create a large dataset of weakly labeled sentence triplets, composed of a pivot sentence, one sentence from the same section and one from another section. We train a triplet network to embed sentences from the same section closer. To test the performance of the learned embeddings, we create and release a sentence clustering benchmark. We show that the triplet network learns useful thematic metrics, that significantly outperform state-of-theart semantic similarity methods and multipurpose embeddings on the task of thematic clustering of sentences. We also show that the learned embeddings perform well on the task of sentence semantic similarity prediction",Theory Proposal
2264,"We use dependency triples automatically extracted from a Web-scale corpus to perform unsupervised semantic frame induction. We cast the frame induction problem as a triclustering problem that is a generalization of clustering for triadic data. Our replicable benchmarks demonstrate that the proposed graph-based approach, Triframes, shows state-of-the art results on this task on a FrameNet-derived dataset and performing on par with competitive methods on a verb class clustering task",Dataset Creation or Resources
2265,We present a new architecture for named entity recognition. Our model employs multiple independent bidirectional LSTM units across the same input and promotes diversity among them by employing an inter-model regularization term. By distributing computation across multiple smaller LSTMs we find a reduction in the total number of parameters. We find our architecture achieves state-of-the-art performance on the CoNLL 2003 NER dataset.,Model Construction or Optimization
2266,"We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entityrelation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings learned by baseline models",Performance Evaluation
2267,"We present a novel graph-based neural network model for relation extraction. Our model treats multiple pairs in a sentence simultaneously and considers interactions among them. All the entities in a sentence are placed as nodes in a fully-connected graph structure. The edges are represented with position-aware contexts around the entity pairs. In order to consider different relation paths between two entities, we construct up to l-length walks between each pair. The resulting walks are merged and iteratively used to update the edge representations into longer walks representations. We show that the model achieves performance comparable to the state-ofthe-art systems on the ACE 2005 dataset without using any external tools.",Model Construction or Optimization
2268,"We first point out that these tasks are related. Then, inspired by ranking relation instances and patterns computed by the HITS algorithm, and selecting cluster centroids using the K-means, LSA, or NMF method, we propose methods for selecting the initial seeds from an existing resource, or reducing the level of noise in the distantly labeled data. Experiments show that our proposed methods achieve a better performance than the baseline systems in both tasks",Algorithms/ Methods Construction or Optimization
2269,"we propose to improve the end-toend coreference resolution system by (1) using a biaffine attention model to get antecedent scores for each possible mention, and (2) jointly optimizing the mention detection accuracy and the mention clustering log-likelihood given the mention cluster labels. Our model achieves the stateof-the-art performance on the CoNLL2012 Shared Task English test set.",Dataset Creation or Resources
2270,"We show that this update mechanism can be learned jointly with the semantic decoding and context modelling parts of the NBT model, eliminating the last rule-based module from this DST framework. We propose two different statistical update mechanisms and show that dialogue dynamics can be modelled with a very small number of additional model parameters. In our DST evaluation over three languages, we show that this model achieves competitive performance and provides a robust framework for building resource-light DST models.",Model Construction or Optimization
2271,"We study the role of linguistic context in predicting quantifiers (вЂ�fewвЂ™, вЂ�allвЂ™). We collect crowdsourced data from human participants and test various models in a local (single-sentence) and a global context (multi-sentence) condition. Models significantly out-perform humans in the former setting and are only slightly better in the latter. While human performance improves with more linguistic context (especially on proportional quantifiers), model performance suffers. Models are very effective in exploiting lexical and morpho-syntactic patterns; humans are better at genuinely understand",Model Construction or Optimization
2272,"We ask how to practically build a model for German named entity recognition (NER) that performs at the state of the art for both contemporary and historical texts, i.e., a big-data and a small-data scenario. The two best-performing model families are pitted against each other (linear-chain CRFs and BiLSTM) to observe the trade-off between expressiveness and data requirements. BiLSTM outperforms the CRF when large datasets are available and performs inferior for the smallest dataset.",Model Construction or Optimization
2273,"we analyze a novel dataset of more than one million code reviews for the Google Chromium project, from which we extract linguistic features of feedback that elicited responsive actions from coworkers. Using a manually-labeled subset of reviewer comments, we trained a highly accurate classifier to identify вЂњacted-uponвЂќ comments (AUC = 0.85). Our results demonstrate the utility of our dataset, the feasibility of using NLP for this new task, and the potential of NLP to improve our understanding of how communications between colleagues can be authored to elicit positive, proactive responses",Dataset Creation or Resources
2274,we describe a new multimodal dataset that consists of gaze measurements and spoken descriptions collected in parallel during an image inspection task. The task was performed by multiple participants on 100 general-domain images showing everyday objects and activities. We demonstrate the usefulness of the dataset by applying an existing visual-linguistic data fusion framework in order to label important image regions with appropriate linguistic labels,Dataset Creation or Resources
2275,"we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.",Dataset Creation or Resources
2276,"We therefore construct a significant new corpus on metaphor, with 5,605 manually annotated sentences in Chinese. We present an annotation scheme that contains annotations of linguistic metaphors, emotional categories (joy, anger, sadness, fear, love, disgust and surprise), and intensity. The annotation agreement analyses for multiple annotators are described. We also use the corpus to explore and analyze the emotionality of metaphors. To the best of our knowledge, this is the first relatively large metaphor corpus with an annotation of emotions in Chinese",Performance Evaluation
2277,we further develop automatic metrics that generalize a broad set of popular reference-based metrics and exhibit greatly improved correlations with human evaluations,Dataset Creation or Resources
2278,"we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. It consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. Evaluations on the LCSTS and the English Gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of generating summary of higher quality and reducing repetition",Model Construction or Optimization
2279,"We herein present a language-modelbased evaluator for deletion-based sentence compression, and viewed this task as a series of deletion-and-evaluation operations using the evaluator. More specifically, the evaluator is a syntactic neural language model that is first built by learning the syntactic and structural collocation among words. Subsequently, a series of trial-and-error deletion operations are conducted on the source sentences via a reinforcement learning framework to obtain the best target compression. An empirical study shows that the proposed model can effectively generate more readable compression, comparable or superior to several strong baselines. Furthermore, we introduce a 200-sentence test set for a largescale dataset, setting a new baseline for the future research",Performance Evaluation
2280,"we seek to better understand how users react to trusted and deceptive news sources across two popular, and very different, social media platforms. To that end, (1) we develop a model to classify user reactions into one of nine types, such as answer, elaboration, and question, etc, and (2) we measure the speed and the type of reaction for trusted and deceptive news sources for 10.8M Twitter posts and 6.2M Reddit comments. We show that there are significant differences in the speed and the type of reactions between trusted and deceptive news sources on Twitter, but far smaller differences on Reddit",Model Construction or Optimization
2281,we model this task using CNN regression with an auxiliary ordinal regression objective. We demonstrate the effectiveness of our proposed approach using UK and US government petition datasets.1,Model Construction or Optimization
2282,"We introduce a new approach to tackle the problem of offensive language in online social media. Our approach uses unsupervised text style transfer to translate offensive sentences into non-offensive ones. We propose a new method for training encoderdecoders using non-parallel data that combines a collaborative classifier, attention and the cycle consistency loss. Experimental results on data from Twitter and Reddit show that our method outperforms a state-of-the-art text style transfer system in two out of three quantitative metrics and produces reliable non-offensive transferred sentences",Algorithms/ Methods Construction or Optimization
2283,"we address a research gap by exploring finer temporal granularity and using a more accessible language corpus. TwitterвЂ™s1 discourse is rather different from traditional English writing. So far, word embeddings trained on Twitter (Kulkarni et al., 2015; Mikolov et al., 2013) have considered it a static corpus, and have not used it to study short term changes in word connotations. It contributes with the following observations",Performance Evaluation
2284,"we make a move to build a dialogue system for automatic diagnosis. We first build a dataset collected from an online medical forum by extracting symptoms from both patientsвЂ™ self-reports and conversational data between patients and doctors. Then we propose a taskoriented dialogue system framework to make the diagnosis for patients automatically, which can converse with patients to collect additional symptoms beyond their self-reports. Experimental results on our dataset show that additional symptoms extracted from conversation can greatly improve the accuracy for disease identification and our dialogue system is able to collect these symptoms automatically and make a better diagnosis",Theory Proposal
2285,"we study transfer learning for multi-turn information seeking conversations in this paper. We first propose an efficient and effective multiturn conversation model based on convolutional neural networks. After that, we extend our model to adapt the knowledge learned from a resource-rich domain to enhance the performance. Finally, we deployed our model in an industrial chatbot called AliMe Assist 1 and observed a significant improvement over the existing online model.",Dataset Creation or Resources
2286,"We present a novel multi-task modeling approach to learning multilingual distributed representations of text. Our system learns word and sentence embeddings jointly by training a multilingual skipgram model together with a cross-lingual sentence similarity model. Our architecture can transparently use both monolingual and sentence aligned bilingual corpora to learn multilingual embeddings, thus covering a vocabulary significantly larger than the vocabulary of the bilingual corpora alone. Our model shows competitive performance in a standard crosslingual document classification task. We also show the effectiveness of our method in a limited resource scenario",Model Construction or Optimization
2287,"We investigate the behavior of maps learned by machine translation methods. The maps translate words by projecting between word embedding spaces of different languages. We locally approximate these maps using linear maps, and find that they vary across the word embedding space. This demonstrates that the underlying maps are non-linear. Importantly, we show that the locally linear maps vary by an amount that is tightly correlated with the distance between the neighborhoods on which they are trained. Our results can be used to test non-linear methods, and to drive the design of more accurate maps for word translation",Theory Proposal
2288,"We learn a joint multilingual sentence embedding and use the distance between sentences in different languages to filter noisy parallel data and to mine for parallel data in large news collections. We are able to improve a competitive baseline on the WMTвЂ™14 English to German task by 0.3 BLEU by filtering out 25% of the training data. The same approach is used to mine additional bitexts for the WMTвЂ™14 system and to obtain competitive results on the BUCC shared task to identify parallel sentences in comparable corpora. The approach is generic, it can be applied to many language pairs and it is independent of the architecture of the machine translation system",Dataset Creation or Resources
2289,"we improve the existing SCRF methods by employing word-level and segment-level information simultaneously. First, word-level labels are utilized to derive the segment scores in SCRFs. Second, a CRF output layer and an SCRF output layer are integrated into an unified neural network and trained jointly. Experimental results on CoNLL 2003 named entity recognition (NER) shared task show that our model achieves state-of-the-art performance when no external knowledge is used",Algorithms/ Methods Construction or Optimization
2290,"we discuss the importance of external knowledge for performing Named Entity Recognition (NER). We present a novel modular framework that divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources, such as a knowledgebase, a list of names, or document-specific semantic annotations. Further, we show the effects on performance when incrementally adding deeper knowledge and discuss effectiveness/efficiency trade-of",Model Construction or Optimization
2291,"We consider the task of detecting contractual obligations and prohibitions. We show that a self-attention mechanism improves the performance of a BILSTM classifier, the previous state of the art for this task, by allowing it to focus on indicative tokens. We also introduce a hierarchical BILSTM, which converts each sentence to an embedding, and processes the sentence embeddings to classify each sentence. Apart from being faster to train, the hierarchical BILSTM outperforms the flat one, even when the latter considers surrounding sentences, because the hierarchical model has a broader discourse view.",Performance Evaluation
2292,"We present a paper abstract writing system based on an attentive neural sequenceto-sequence model that can take a title as input and automatically generate an abstract. We design a novel Writing-editing Network that can attend to both the title and the previously generated abstract drafts and then iteratively revise and polish the abstract. With two series of Turing tests, where the human judges are asked to distinguish the system-generated abstracts from human-written ones, our system passes Turing tests by junior domain experts at a rate up to 30% and by nonexpert at a rate up to 80%.",Model Construction or Optimization
2293,"We explore recently introduced definition modeling technique that provided the tool for evaluation of different distributed vector representations of words through modeling dictionary definitions of words. In this work, we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms. Our quantitative and qualitative evaluation and analysis of the model shows that taking into account words ambiguity and polysemy leads to performance improveme",Model Construction or Optimization
2294,"we propose a Convolutional Neural Network (CNN) model for textbased multiple choice question answering where questions are based on a particular article. Given an article and a multiple choice question, our model assigns a score to each question-option tuple and chooses the final option accordingly. We test our model on Textbook Question Answering (TQA) and SciQ dataset. Our model outperforms several LSTM-based baseline models on the two datasets.",Dataset Creation or Resources
2295,"we propose a novel method, tracking various semantic aspects with external neural memory chains while encouraging each to focus on a particular semantic aspect. Evaluated on the task of story ending prediction, our model demonstrates superior performance to a collection of competitive baselines, setting a new state of the art. 1",Algorithms/ Methods Construction or Optimization
2296,"we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) predicting labels on a very large corpus of question pairs, and (iii) pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on GS",Algorithms/ Methods Construction or Optimization
2297,"We offer a simple and effective method to seek a better balance between model confidence and length preference for Neural Machine Translation (NMT). Unlike the popular length normalization and coverage models, our model does not require training nor reranking the limited n-best outputs. Moreover, it is robust to large beam sizes, which is not well studied in previous work. On the Chinese-English and English-German translation tasks, our approach yields +0.4 в€ј 1.5 BLEU improvements over the state-of-the-art baselines.",Model Construction or Optimization
2298,"we propose an efficient method to dynamically sample the sentences in order to accelerate the NMT training. In this approach, a weight is assigned to each sentence based on the measured difference between the training costs of two iterations. Further, in each epoch, a certain percentage of sentences are dynamically sampled according to their weights. Empirical results based on the NIST Chinese-to-English and the WMT English-to-German tasks show that the proposed method can significantly accelerate the NMT training and improve the NMT performance.",Algorithms/ Methods Construction or Optimization
2299,"we propose to overcome this problem by replacing the source-language embedding layer of NMT with a bi-directional recurrent neural network that generates compositional representations of the input at any desired level of granularity. We test our approach in a low-resource setting with five languages from different morphological typologies, and under different composition assumptions. By training NMT to compose word representations from character trigrams, our approach consistently outperforms (from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically generated sub-word units.",Theory Proposal
2300,"We explore strategies for incorporating target syntax into Neural Machine Translation. We specifically focus on syntax in ensembles containing multiple sentence representations. We formulate beam search over such ensembles using WFSTs, and describe a delayed SGD update training procedure that is especially effective for long representations like linearized syntax. Our approach gives state-of-the-art performance on a difficult Japanese-English task",Performance Evaluation
2301,"We empirically investigate learning from partial feedback in neural machine translation (NMT), when partial feedback is collected by asking users to highlight a correct chunk of a translation. We propose a simple and effective way of utilizing such feedback in NMT training. We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method. Our results show that chunk-level feedback outperforms sentence based feedback by up to 2.61% BLEU absolute.",Theory Proposal
2302,"We found such monotonicity forces the algorithm to sacrifice some decoding paths to explore new paths. As a result, the overall quality of the hypotheses selected by the algorithm is lower than expected. To mitigate this problem, we relax the monotonic constraint of the beam search by maintaining all found hypotheses in a single priority queue and using a universal score function for hypothesis selection. The proposed algorithm allows discarded hypotheses to be recovered in a later step. Despite its simplicity, we show that the proposed decoding algorithm enhances the quality of selected hypotheses and improve the translations even for highperformance models in English-Japanese translation task.",Theory Proposal
2303,"we propose and evaluate models for classifying VNC usages as idiomatic or literal, based on a variety of approaches to forming distributed representations. Our results show that a model based on averaging word embeddings performs on par with, or better than, a previously-proposed approach based on skip-thoughts. Idiomatic usages of VNCs are known to exhibit lexico-syntactic fixedness. We further incorporate this information into our models, demonstrating that this rich linguistic knowledge is complementary to the information carried by distributed representations.",Model Construction or Optimization
2304,"we propose Pseudofit, a new method for specializing word embeddings according to semantic similarity without any external knowledge. Pseudofit exploits the notion of pseudo-sense for building several representations for each word and uses these representations for making the initial embeddings more generic. We illustrate the interest of Pseudofit for acquiring synonyms and study several variants of Pseudofit according to this perspective",Algorithms/ Methods Construction or Optimization
2305,we study the performance of both approaches on several hypernymy tasks and find that simple pattern-based methods consistently outperform distributional methods on common benchmark datasets. Our results show that pattern-based models provide important contextual constraints which are not yet captured in distributional methods.,Algorithms/ Methods Construction or Optimization
2306,"We explore novel strategies to address the coverage problem that change only the attention transformation. Our approach allocates fertilities to source words, used to bound the attention each word can receive. We experiment with various sparse and constrained attention transformations and propose a new one, constrained sparsemax, shown to be differentiable and sparse. Empirical evaluation is provided in three languages pairs.",Performance Evaluation
2307,"We show that the divergence in the tag distributions of the common named entities between the primary and assisting languages can reduce the effectiveness of multilingual learning. To alleviate this problem, we propose a metric based on symmetric KL divergence to filter out the highly divergent training instances in the assisting language. We empirically show that our data selection strategy improves NER performance in many languages, including those with very limited training data.",Theory Proposal
2308,"we propose a neural Open IE approach with an encoder-decoder framework. Distinct from existing methods, the neural Open IE approach learns highly confident arguments and relation tuples bootstrapped from a state-of-the-art Open IE system. An empirical study on a large benchmark dataset shows that the neural Open IE system significantly outperforms several baselines, while maintaining comparable computational efficiency.",Algorithms/ Methods Construction or Optimization
2309,"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, to detect events in sentences. This model first learns event detection oriented embeddings of documents through a hierarchical and supervised attention based RNN, which pays word-level attention to event triggers and sentence-level attention to those sentences containing events. It then uses the learned document embedding to enhance another bidirectional RNN model to identify event triggers and their types in sentences. Through experiments on the ACE-2005 dataset, we demonstrate the effectiveness and merits of the proposed DEEB-RNN model via comparison with state-of-the-art methods",Model Construction or Optimization
2310,"We propose a method that can leverage unlabeled data to learn a matching model for response selection in retrieval-based chatbots. The method employs a sequence-tosequence architecture (Seq2Seq) model as a weak annotator to judge the matching degree of unlabeled pairs, and then performs learning with both the weak signals and the unlabeled data. Experimental results on two public data sets indicate that matching models get significant improvements when they are learned with the proposed method.",Algorithms/ Methods Construction or Optimization
2311,"We present a generative neural network model for slot filling based on a sequenceto-sequence (Seq2Seq) model together with a pointer network, in the situation where only sentence-level slot annotations are available in the spoken dialogue data. This model predicts slot values by jointly learning to copy a word which may be out-of-vocabulary (OOV) from an input utterance through a pointer network, or generate a word within the vocabulary through an attentional Seq2Seq model. Experimental results show the effectiveness of our slot filling model, especially at addressing the OOV problem. Additionally, we integrate the proposed model into a spoken language understanding system and achieve the state-of-the-art performance on the benchmark data.",Model Construction or Optimization
2312,"we propose a new transition-based discourse parser that makes use of memory networks to take discourse cohesion into account. The automatically captured discourse cohesion benefits discourse parsing, especially for long span scenarios. Experiments on the RST discourse treebank show that our method outperforms traditional featured based methods, and the memory based discourse cohesion can improve the overall parsing performance significantly 1 .",Theory Proposal
2313,"we present SciDTB, a domainspecific discourse treebank annotated on scientific articles. Different from widelyused RST-DT and PDTB, SciDTB uses dependency trees to represent discourse structure, which is flexible and simplified to some extent but do not sacrifice structural integrity. We discuss the labeling framework, annotation workflow and some statistics about SciDTB. Furthermore, our treebank is made as a benchmark for evaluating discourse dependency parsers, on which we provide several baselines as fundamental work.",Model Construction or Optimization
2314,"we develop methods for predicting how much data is required to achieve a desired test accuracy by extrapolating results from systems trained on a small pilot training dataset. We model how accuracy varies as a function of training size on subsets of the pilot data, and use that model to predict how much training data would be required to achieve the desired accuracy. We introduce a new performance extrapolation task to evaluate how well different extrapolations predict system accuracy on larger training sets. We show that details of hyperparameter optimisation and the extrapolation models can have dramatic effects in a document classification task. We believe this is an important first step in developing methods for estimating the resources required to meet specific engineering performance targets.",Dataset Creation or Resources
2315,"We investigate the influence that document context exerts on human acceptability judgements for English sentences, via two sets of experiments. The first compares ratings for sentences presented on their own with ratings for the same set of sentences given in their document contexts. The second assesses the accuracy with which two types of neural models вЂ” one that incorporates context during training and one that does not вЂ” predict these judgements. Our results indicate that: (1) context improves acceptability ratings for ill-formed sentences, but also reduces them for well-formed sentences; and (2) context helps unsupervised systems to model acceptability",Theory Proposal
2316,"we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and visionto-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.",Theory Proposal
2317,"We explore using a policy gradient method as a parser-agnostic alternative. In addition to directly optimizing for a tree-level metric such as F1, policy gradient has the potential to reduce exposure bias by allowing exploration during training; moreover, it does not require a dynamic oracle for supervision. On four constituency parsers in three languages, the method substantially outperforms static oracle likelihood training in almost all settings. For parsers where a dynamic oracle is available (including a novel oracle which we define for the transition system of Dyer et al. (2016)), policy gradient typically recaptures a substantial fraction of the performance gain afforded by the dynamic oracle.",Performance Evaluation
2318,"We propose a linear-time constituency parser with RNNs and dynamic programming using graph-structured stack and beam search, which runs in time O(nb2 ) where b is the beam size. We further speed this up to O(nb log b) by integrating cube pruning. Compared with chart parsing baselines, this linear-time parser is substantially faster for long sentences on the Penn Treebank and orders of magnitude faster for discourse parsing, and achieves the highest F1 accuracy on the Penn Treebank among single model end-to-end systems.",Model Construction or Optimization
2319,"We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures. The resulting system on its own achieves stateof-the-art performance, beating the previous, substantially more complex stateof-the-art system by 0.6% labeled F1. Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9% labele",Performance Evaluation
2320,"We investigate the feasibility of recovering the original text written in an abugida after omitting subordinate diacritics and merging consonant letters with similar phonetic values. This is crucial for developing more efficient input methods by reducing the complexity in abugidas. Four abugidas in the southern Brahmic family, i.e., Thai, Burmese, Khmer, and Lao, were studied using a newswire 20, 000-sentence dataset",Theory Proposal
2321,"we propose a novel task: automatic academic paper rating (AAPR), which automatically determine whether to accept academic papers. We build a new dataset for this task and propose a novel modularized hierarchical convolutional neural network to achieve automatic academic paper rating. Evaluation results show that the proposed model outperforms the baselines by a large margin",Algorithms/ Methods Construction or Optimization
2322,"we present an approach based on combining string kernels and word embeddings for automatic essay scoring. String kernels capture the similarity among strings based on counting common character ngrams, which are a low-level yet powerful type of feature, demonstrating state-of-theart results in various text classification tasks such as Arabic dialect identification or native language identification",Model Construction or Optimization
2323,"we aim to analyze structured time-series documents such as a collection of news articles and a series of scientific papers, wherein topics evolve along time depending on multiple topics in the past, and are also related to each other at each time.",Performance Evaluation
2324," we propose a novel topic model PhraseCTM and a twostage method to find out the correlated topics at phrase level. In the first stage, we train PhraseCTM, which models the generation of words and phrases simultaneously by linking the phrases and component words within Markov Random Fields when they are semantically coheren",Algorithms/ Methods Construction or Optimization
2325,"we address the problem of finding a novel document descriptor based on the covariance matrix of the word vectors of a document. Our descriptor has a fixed length, which makes it easy to use in many supervised and unsupervised applications",Performance Evaluation
2326,"We report an empirical study on the task of negation scope extraction given the negation cue. Our key observation is that certain useful information such as features related to negation cue, long distance dependencies as well as some latent structural information can be exploited for such a task",Performance Evaluation
2327,We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for this entailment task,Model Construction or Optimization
2328,"we focus on the task of pun location, which aims to identify the pun word in a given short text. We propose a sense-aware neural model to address this challenging task. Our model first obtains several WSD results for the text, and then leverages a bidirectional LSTM network to model each sequence of word senses.",Performance Evaluation
2329,"we report experiments with a rank-based metric for WE, which performs comparably to vector cosine in similarity estimation and outperforms it in the recently-introduced and challenging task of outlier detection, thus suggesting that rank-based measures can improve clustering quality",Performance Evaluation
2330,"We make three contributions to address this noise. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence",Dataset Creation or Resources
2331,"We hypothesize that taking into account global, corpuslevel information and generating a different noise distribution for each target word better satisfies the requirements of negative examples for each training word than the original frequency-based distribution",Theory Proposal
2332,"We propose extending the continuous bag of words (CBOW) model (Mikolov et al., 2013a) to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent",Dataset Creation or Resources
2333,"we explore two approaches that transfer knowledge from documentlevel data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification.",Performance Evaluation
2334,"We found that discourse relation, sentiment conflict and sentiment transition are effective indicators for humor recognition. On the perspective of using sentiment related features, sentiment association in discourse is more useful than counting the number of emotional words.",Theory Proposal
2335,"we propose a double embeddings mechanism that is shown crucial for aspect extraction. The embedding layer is the very first layer, where all the information about each word is encoded.",Model Construction or Optimization
2336,"We propose a methodology to blend high quality but scarce labeled data with noisy but abundant weak labeled data during the training of neural networks. Experiments in the context of topic-dependent evidence detection with two forms of weak labeled data show the advantages of the blending scheme. In addition, we provide a manually annotated data set for the task of topicdependent evidence detection",Algorithms/ Methods Construction or Optimization
2337,"We propose a tri-modal architecture to predict Big Five personality trait scores from video clips with different channels for audio, text, and video data.",Model Construction or Optimization
2338,"We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning.",Theory Proposal
2339,We generalize chart constraints to more expressive grammar formalisms and describe a neural tagger which predicts chart constraints at very high precision,Dataset Creation or Resources
2340,we assess to what extent prominent sentence embedding methods exhibit select semantic properties,Dataset Creation or Resources
2341,"We present the Supervised Directional Similarity Network (SDSN), a novel neural architecture for learning task-specific transformation functions on top of generalpurpose word embeddings",Model Construction or Optimization
2342,"We propose and assess methods for extracting one type of commonsense knowledge, object-property comparisons, from pretrained embeddings",Dataset Creation or Resources
2343,We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge.,Theory Proposal
2344,We propose the task of predicting simultaneous interpreter performance by building on existing methodology for quality estimation (QE) of machine translation output,Algorithms/ Methods Construction or Optimization
2345,"We experiment with a new approach where we combine resources from a pair of languages in the CoNLL 2009 shared task (Hajic et al. Л‡ , 2009) to build a polyglot semantic role labeler. Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a monolingual baseline",Theory Proposal
2346,we present a study to show how learning distributed representations of the logical forms from data annotated in different languages can be used for improving the performance of a monolingual semantic parser.,Model Construction or Optimization
2347,We propose a novel neural method to extract drug-drug interactions (DDIs) from texts using external drug molecular structure information,Algorithms/ Methods Construction or Optimization
2348,"we devise with these features can robustly cope with inputs 687 from diachronic corpora. We propose a new evaluation benchmark, based on the New York Times Archive, spanning more than 20 years, and the history collection historynet.com, spanning several centuries. Our experiments demonstrate that timeaware NED substantially outperforms some of the best standard NED tools",Theory Proposal
2349,"We show experimentally that classification performance varies over time, and that performance can be improved by using a standard domain adaptation approach to adjust for changes in time.",Performance Evaluation
2350,We show how an adaptable language model can be used to generate personalized completions and how the model can use online updating to make predictions for users not seen during training. The personalized predictions are significantly better than a baseline that uses no user information,Dataset Creation or Resources
2351,we focus on the problem of building assistive systems that can help users to write reviews.,Theory Proposal
2352,We explore these two features of TS to build models tailored for specific grade levels. Our approach uses a standard sequenceto-sequence architecture where the original sequence is annotated with information about the target audience and/or the (predicted) type of simplification operation,Model Construction or Optimization
2353,"We show that while vanilla seq2seq models can reach high scores on the proposed benchmark (Narayan et al., 2017), they suffer from memorization of the training set which contains more than 89% of the unique simple sentences from the validation and test sets.",Performance Evaluation
2354,we supervise the learning of the representation of the source content with that of the summary,Theory Proposal
2355,We present an alternative view to explain the success of LSTMs: the gates themselves are versatile recurrent models that provide more representational power than previously appreciated,Model Construction or Optimization
2356,"We consider the case of RNNs with finite precision whose computation time is linear in the input length. Under these limitations, we show that different RNN variants have different computational power.",Dataset Creation or Resources
2357,we propose a new model to match a question-answer pair to a given passage. Our comatching approach explicitly treats the question and the candidate answer as two sequences and jointly matches them to the given passage,Model Construction or Optimization
2358,"we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have aggregated, we have designed a new crowdsourcing scheme that creates a new SCT dataset, which overcomes some of the biases.",Model Construction or Optimization
2359,"we propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the problem by integrating three kinds of sentiment linguistic knowledge (e.g., sentiment lexicon, negation words, intensity words) into the deep neural network via attention mechanisms",Model Construction or Optimization
2360,we address a sentiment classification task for a tweet analysis service as a case study and propose a pretraining strategy with unlabeled dialog data (tweet-reply pairs) via an encoder-decoder model.,Performance Evaluation
2361,"We analyze the ambiguity of hashtag usages and propose a novel neural networkbased model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection",Performance Evaluation
2362,"we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target",Theory Proposal
2363,"we present SQUADRUN, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones",Dataset Creation or Resources
2364,We propose a novel paradigm of grounding comparative adjectives within the realm of color descriptions.,Algorithms/ Methods Construction or Optimization
2365,"We introduce in this paper a novel method, that
we call Multi-Task Supervised Pre-training and Adaptation (MuTSPad)",Algorithms/ Methods Construction or Optimization
2366,"we pro-pose to build multi-task datasets for the News and
Tweets domains, by unifying the aforementioned
task-independent datasets.",Dataset Creation or Resources
2367,"Hence our model can grasp
useful word-level semantic information and al-leviate the interference of segmentation error
cascading.",Model Construction or Optimization
2368,"The above operations provide a
wealth of resources to allow the model to in-
fer word-level deep characteristics, rather than
bluntly impose segmentation information.",Dataset Creation or Resources
2369,"For document
level, we reused last yearвЂ™s English-French data
for training and validation, but introduced a new
test set from the same corpus",Performance Evaluation
2370,"For QE as a metric we ran the evaluation jointly with the WMT19 metrics task, which meant applying the QE systems to news translation submissions and evaluating them against the human judgments collected this year",Performance Evaluation
2371,fair assessment of the progress in APE technology and for tests in more challenging conditions,Performance Evaluation
2372,"reusing the same test English-German set used last year, the evaluation framework allows us for a direct comparison with the last yearвЂ™s outcomes at least on one language",Performance Evaluation
2373,"construction of training data and the official test sets, including statistics and an evalua- 31 tion of the quality of the test sets",Dataset Creation or Resources
2374,a description of the three baselines that we developed for comparison,Theory Proposal
2375,"an overview of the task, presents the results for the participating systems and provides analysis on additional subset sizes and the average sentence length of sub-selected data.",Performance Evaluation
2376,We obtain new results using referential translation machines with increased number of learning models in the set of results that are stacked to obtain a better mixture of experts prediction,Theory Proposal
2377,We extend OpenKiwi with a Transformer predictor-estimator model,Model Construction or Optimization
2378,"We propose new ensembling techniques for combining word-level and sentence-level predictions, which outperform previously used stacking approaches",Model Construction or Optimization
2379,"We apply transfer learning techniques, finetuning BERT (Devlin et al., 2018) and XLM (Lample and Conneau, 2019) models in a predictor-estimator architecture",Applications
2380,We build upon our BERT-based predictorestimator model to obtain document-level annotation and MQM predictions via a simple wordto-annotation conversion scheme,Model Construction or Optimization
2381,we propose a вЂњbilingualвЂќ BERT using multi-task learning for translation quality estimation (called the QE BERT).,Algorithms/ Methods Construction or Optimization
2382,"we introduce our base model, which is a modified version of phrase-level Shef-bRNN (Ive et al., 2018), and further develop it by using different methods of extracting features from the input alongside the bi-RNN features",Model Construction or Optimization
2383,"we present two different approaches for the sentence-level QE task, which employ bi-directional translation knowledge and large-scale monolingual knowledge to the QE task, respectively",Theory Proposal
2384,a simple ensemble of them can help to achieve better quality estimation performance in the sentence-level QE task,Performance Evaluation
2385,"we introduce a light-weight neural method with pre-trained embeddings, that means it does not require any pre-training",Algorithms/ Methods Construction or Optimization
2386,"to predict the required post-editing cost, measured in HTER",Performance Evaluation
2387,to rank all sentence pairs in descending translation quality,Performance Evaluation
2388,we propose a multisource APE model by extending Transformer to contain a joint multi-source encoder and a decoder that involves a multi-source attention layer to combine the outputs of the encoder.,Algorithms/ Methods Construction or Optimization
2389,"We also introduce the conservativeness penalty, a simple yet effective mechanism that controls the freedom of our APE in modifying the given MT output",Algorithms/ Methods Construction or Optimization
2390,we present a multi-source neural APE architecture model called transference,Algorithms/ Methods Construction or Optimization
2391,we explore the effect of adding tokens that identify partitions in the training data which may be relevant to guide the behaviour of the NPE system,Applications
2392,"In order to tackle the over-correction problem and to induce a post-editing strategy that resembles the work of a human post-editor, we add a special token to the beginning of both the source text and the MT output indicating the amount of required post-editing",Performance Evaluation
2393,we re-implement a multi-source transformer model for the task,Model Construction or Optimization
2394,we designed a data preparation strategy for domainspecific translation systems to enrich data with terminology information without affecting the model architecture,Model Construction or Optimization
2395,we present an approach which aims at increasing the training corpus by mining similar in domain (Bio Med) sentences from out of domain data,Theory Proposal
2396,"We have developed NMT system for English-French language pair, for translation in both directions",Theory Proposal
2397,we present HuaweiвЂ™s practices on adapting our NMT systems from general-domain to in-domain,Model Construction or Optimization
2398,"We apply transfer learning iteratively on datasets from different domains, obtaining strong models that cover two domains for both directions of the English-German language pair, and three domains for both directions of EnglishSpanish.",Applications
2399,We therefore investigate applying Bayesian Interpolation for language-model based multi-domain ensemble weighting,Applications
2400,"For that matter, we developed a machine translation (MT) system based on neural machine translation (NMT), using OpenNMT-py",Algorithms/ Methods Construction or Optimization
2401,This paper introduces a novel approach to translation modeling that is currently being developed,Model Construction or Optimization
2402,in this article we aimed to determine whether the neural or the statistical approach is a better one to solve the given problem.,Theory Proposal
2403,We first briefly introduce the phenomenon of intercomprehension between Slavic languages and our idea how to take advantage of it for machine translation purposes,Theory Proposal
2404,The next section spreads out our plans on Czech-Polish translation by exploring the similarities and differences between the two languages,Theory Proposal
2405,"The task focuses on improving machine translation results for three language pairs Czech-Polish
(Slavic languages), Hindi-Nepali (Indo-Aryan languages) and Spanish-Portuguese (Romance languages).",Model Construction or Optimization
2406,"To examine the efficiency of our NMT systems, the predicted translations exposed to automatic evaluation using the BLEU score",Performance Evaluation
2407,"For both translation directions, we trained supervised neural MT (NMT) and statistical MT (SMT) systems, and combined them through n-best list reranking using different informative features as proposed by Marie and Fujita (2018a)",Model Construction or Optimization
2408,"Keeping in view the recent results obtained in MT developments, we experimented with both PBSMT as well as NMT models and evaluated how different models perform in comparison to each other",Performance Evaluation
2409,we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task.,Theory Proposal
2410,we assume that proper subword segmentation will be beneficial for neural machine translation (NMT) performance but we aim at consistent segmentation across both related languages,Performance Evaluation
2411,"We participated only in the Sinhala-English track, basing our system on that of JunczysDowmunt (2018) but extensively modified for the 2019 low-resource scenario",Dataset Creation or Resources
2412,"we describe the 4 systems we submitted, which have three main components: pre-filtering rules, sentence pair scoring, and reranking to improve vocabulary coverage",Theory Proposal
2413,"In our submission for this shared task, we use of multilingual sentence embeddings obtained from LASER2 which uses an encoder-decoder architecture to train a multilingual sentence representation model using a relatively small parallel corpus.",Dataset Creation or Resources
2414,"we include a text quality metric in the subcorpus-building process, rather than combining it afterward.",Dataset Creation or Resources
2415,describes the participation of Webinterpret in the shared task on parallel corpus filtering at the Fourth Conference on Machine Translation,Theory Proposal
2416,"We present a method based on projecting word embeddings learned from a monolingual corpus in a highresource language, to the target low-resource language through whatever parallel text is available",Algorithms/ Methods Construction or Optimization
2417,we introduce a filtering method for noisy parallel corpora based mainly on generating hypotheses for each sentence pair from noisy data and scoring based on hypothesis and target sentence similarity,Algorithms/ Methods Construction or Optimization
2418,The aim of this shared task is to extract two smaller sets of high-quality parallel sentences from a very noisy parallel corpus,Dataset Creation or Resources
2419,This methodology allowed us to build a simple and reliable system that is easily adaptable to other language pairs.,Model Construction or Optimization
2420,"In order to gain further insight into the performance of individual MT systems, we organized a call for dedicated вЂњtest suitesвЂќ, each focussing on some particular aspect of translation quality",Performance Evaluation
2421,"QE developers were invited to perform the same scoring as standard metrics participants, with the exception that they refrain from using a reference translation in production of their scores. We then evaluate the QE submissions in exactly the same way as regular metrics are evaluated",Performance Evaluation
2422,"The goal of this shared task is to provide a testbed for improving MT modelsвЂ™ robustness to orthographic variations, grammatical errors, and other linguistic phenomena common in usergenerated content, via better modelling, training, adaptation techniques, or leveraging monolingual training data",Model Construction or Optimization
2423,we investigated character-based tokenisation vs. sub-word segmentation of Chinese text,Algorithms/ Methods Construction or Optimization
2424,"introduce the method of data filtering, mainly in the application of language model and describe the techniques on transformer architecture and show the conducted experiments in detail of all directions, including data preprocessing,
model architecture, back-translation and knowledge distillation",Algorithms/ Methods Construction or Optimization
2425,upperbounds on the translation performance using lowercased coverage to identify which models used data in addition to the parallel corpus,Model Construction or Optimization
2426,"we introduced two new translation directions involving two European languages, namely French and German",Algorithms/ Methods Construction or Optimization
2427,examine transfer learning for the KazakhвЂ“English language pair using additional parallel data from TurkishвЂ“English.,Performance Evaluation
2428,We choose news translation task and focus on KazakhEnglish (and vice versa) language pair,Dataset Creation or Resources
2429,Lingua CustodiaвЂ™s submission to the WMTвЂ™19 news shared task for German-to-French on the topic of the EU elections,Dataset Creation or Resources
2430,a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudoparallel corpora,Model Construction or Optimization
2431,"We focused on the new Germanto-French language direction, and mostly used current standard approaches to develop a Neural Machine Translation system",Theory Proposal
2432,"we describe all the systems for Kazakhв†”English, Gujaratiв†”English, Chineseв†”English, and Englishв†’Finnish, that we developed and submitted for WMT 2019 under the team name вЂњNICT.",Theory Proposal
2433,we propose a novel augmentation method Cycle Translation and a data mixture strategy Big/Small parallel construction to entirely exploit the synthetic corpus,Algorithms/ Methods Construction or Optimization
2434,"Our system is based on the self-attentional Transformer networks, into which we integrated the most recent effective strategies from academic research (e.g., BPE, back translation, multi-features data selection, data augmentation, greedy model ensemble, reranking, ConMBR system combination, and postprocessing)",Model Construction or Optimization
2435,"describes the systems and experiments conducted to participate in the news translation tasks of WMT 2019 for GujaratiвЂ“ English (guвЂ“en, low-resourced language pair) and GermanвЂ“English (deвЂ“en, document-level evaluation).",Theory Proposal
2436,"Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English",Performance Evaluation
2437,We also proposed our own model architectures and applied them in the tasks.,Applications
2438,"we refine our approach to training popular neural machine translation toolkits, experiment with a new domain adaptation technique and again measure improvements in performance on the RussianвЂ“English language pair",Model Construction or Optimization
2439,"We conduct an in-depth evaluation of the translation performance of different models, highlighting the trade-offs between methods of sharing decoder parameters",Performance Evaluation
2440,"In this edition, we have submitted systems for the German в†” English and German в†” French language pairs, participating in both directions of each pair",Theory Proposal
2441,Our main focus is document-level neural machine translation with deep transformer models.,Model Construction or Optimization
2442,we describe our approach to low-resource NMT,Theory Proposal
2443,This paper describes our submitted systems with embeddings pre-trained on monolingual corpora,Model Construction or Optimization
2444,"We proposed four novel Deep-Transformer architectures based on (Wang et al., 2019) as our baseline, which outperformed the standard Transformer-Big significantly in terms of both translation quality and convergence speed.",Model Construction or Optimization
2445,Our submission is a multi-source NMT system taking both the original Kazakh sentence and its Russian translation as input for translating into English,Model Construction or Optimization
2446,"the systems we implement for the German-Czech language pair are built based on the previously proposed unsupervised MT systems, with some adaptations made to accommodate the morphologically rich characteristics of German and Czech",Algorithms/ Methods Construction or Optimization
2447,We created a News transalated Shared task system to to translate news text from Lithuanian to English.,Theory Proposal
2448,We submitted systems for both directions of the EnglishGerman language pair,Theory Proposal
2449,This paper describes the unsupervised neural (NMT) and statistical machine translation (SMT) systems built for the participation of the National Institute of Information and Communications Technology (NICT) to the WMT19 shared News Translation Task,Model Construction or Optimization
2450,"we participate with neural MT systems for two language pairs and in three directions: English-Russian, EnglishGerman and German-English",Model Construction or Optimization
2451,we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for EnglishвЂ“Gujarati language pair within the translation task subtrack,Theory Proposal
2452,"We participate with the methods for shared news translation task in four language
directions, English в†” German and English
в†” Russian in both directions",Dataset Creation or Resources
2453,"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Model Construction or Optimization
2454,"The systems have been developed with the aim of identifying and following rather than establishing best practices, under the constraints imposed by a low resource training and decoding environment normally used for our production system",Algorithms/ Methods Construction or Optimization
2455,"I describe a rule-based, bidirectional machine translation system for the FinnishвЂ”English language pair.",Theory Proposal
2456,We describe our NMT systems submitted to the WMT19 shared task in Englishв†’Czech news translation.,Theory Proposal
2457,"describes the neural machine translation systems developed at the RWTH Aachen University for the Deв†’En, Zhв†’En and Kkв†’En news translation tasks",Theory Proposal
2458,"Our two new news translation tasks address the low-resource
English-to-Kazakh language pair, for which only
a few thousand in-domain parallel sentences are
available",Theory Proposal
2459,"Elastic weight consolidation (Kirkpatrick et al., 2017, EWC) is a domain adaptation technique that aims to avoid degradation in performance on the original domain",Model Construction or Optimization
2460,"To incorporate document-level context in a light-weight fashion, we propose a modification to the Transformer (Vaswani et al., 2017) that has separate attention layers for inter- and intra-sentential context.",Model Construction or Optimization
2461,"Even though the performance gap between NMT and traditional statistical machine translation (SMT) is growing rapidly on the task at hand, SMT can still improve very strong NMT ensembles",Performance Evaluation
2462,"we focus on the improvement of single system, and propose three novel Transformer variants",Algorithms/ Methods Construction or Optimization
2463,we trained a single multilingual translation system using the constrained parallel and monolingual data for several language pairs.,Model Construction or Optimization
2464,"neural machine translation (NMT) systems for Englishв†”Kazakh
(henceforth referred to as ENв†”KK) constrained
tasks.",Theory Proposal
2465,we describe the system we developed at the LMU Munich Center for Information and Language Processing,Model Construction or Optimization
2466,"We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data.",Dataset Creation or Resources
2467,"we present the University of Helsinki submissions to the WMT 2019 shared task on news translation in three language pairs: EnglishвЂ“German, EnglishвЂ“Finnish and FinnishвЂ“English",Dataset Creation or Resources
2468,"Neural architecture optimization (NAO), our newly proposed method (Luo et al., 2018), leverages the power of a gradient-based method to conduct optimization and guide the creation of better neural architecture in a continuous and more compact space given the historically observed architectures and their performances",Algorithms/ Methods Construction or Optimization
2469,"This paper is based on Transformer, a neural machine translation network structure, to develop a two-way evaluation task between Russian and English.",Algorithms/ Methods Construction or Optimization
2470,This paper describes the DFKI-NMT submission to the WMT19 News translation task for both English-to-German and German-toEnglish directions,Model Construction or Optimization
2471,"we use the DFKI test suite for Germanв†’English MT (Burchardt et al., 2017) in order to analyze the performance of the 16 MT Systems that took part at the translation task",Model Construction or Optimization
2472,We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task.,Performance Evaluation
2473,We present a test set for evaluating an MT systemвЂ™s capability to translate ambiguous conjunctions depending on the sentence structure,Algorithms/ Methods Construction or Optimization
2474,we present a languageindependent method for automatically building ContraWSD-style test suites,Algorithms/ Methods Construction or Optimization
2475,"a machine translation test set of documents from the auditing domain and its use as one of the вЂњtest suitesвЂќ in the WMT19 News Translation Task for translation directions involving Czech, English and German.",Performance Evaluation
2476,we propose WMDO (metric) вЂ“ an extension to WMD that incorporates word order,Performance Evaluation
2477,we seek to directly address the problem mentioned before by adopting a syntactic-level language resource into Meteor.,Theory Proposal
2478,"We present YiSi, a unified automatic semantic machine translation quality evaluation and estimation metric for languages with different levels of available resources",Algorithms/ Methods Construction or Optimization
2479," introduces a new MT metric: Extended Edit Distance (EED), based on an extension of the Levenshtein distance",Dataset Creation or Resources
2480,We propose a method to filter pseudo-references by paraphrasing for automatic evaluation of machine translation (MT),Algorithms/ Methods Construction or Optimization
2481,We proposed one single and one ensemble system for each translation direction,Algorithms/ Methods Construction or Optimization
2482,we describe our neural machine translation (NMT) systems for Japaneseв†”English translation which we submitted to the translation robustness task,Theory Proposal
2483,"describes the systems of Fraunhofer FOKUS for the WMT 2019 machine translation robustness task on EN-FR, FR-EN, and JA-EN language pairs",Theory Proposal
2484,We further improved the performance of our model by fine-tuning on the in-domain noisy data without influencing the translation quality on the news domain,Model Construction or Optimization
2485,"Our submission combined techniques including utilization of a synthetic corpus, domain adaptation, and a placeholder mechanism, which significantly improved over the previous baseline",Algorithms/ Methods Construction or Optimization
2486,we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FRвЂ“EN) and a handful of hyperparameters settings (JAв†”EN),Model Construction or Optimization
2487,We illustrated that adding a domain symbol in source sentence improves the robustness of the model,Model Construction or Optimization
2488,We found that вЂњsocial-media-styleвЂќ sentences can be generated by training a translation model with different вЂњstart-of-sentenceвЂќ symbols for sentences in different domains in the decoder side,Model Construction or Optimization
2489,we propose a multitask learning algorithm for transformer-based MT systems that is more resilient to this noise.,Algorithms/ Methods Construction or Optimization
2490,"We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change",Algorithms/ Methods Construction or Optimization
2491,Our work here focuses on the zero-shot translation aspect of universal multilingual NMT,Theory Proposal
2492,This is one of the first attempts at using syntax to improve Transformer-based NMT,Model Construction or Optimization
2493,We introduce two methods for adding syntax to NMT that are straightforward to incorporate in practice,Algorithms/ Methods Construction or Optimization
2494,"We empirically evaluate both methods on translation from English into 21 diverse target languages, finding that the multi-task method improves consistently over a nonsyntactic baseline",Performance Evaluation
2495,We introduce an APE model trained only on synthetic data generated with RTT for fixing typical translation errors from NMT output and investigate its scalability,Model Construction or Optimization
2496,We improve the BLEU of top submissions of the recent WMT evaluation campaigns,Model Construction or Optimization
2497,"We propose separately reporting scores on test sets whose source sentences are translated and whose target sentences are translated, and call for higher-quality test sets",Performance Evaluation
2498,we focus on investigating why sampling creates better training data by re-writing the loss criterion of an NMT model to include a model-based data generator,Dataset Creation or Resources
2499,"We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token.",Algorithms/ Methods Construction or Optimization
2500,We introduce and explore different approaches for using document embeddings in parallel document mining,Algorithms/ Methods Construction or Optimization
2501,We adapt the previous work on hierarchical networks to introduce a simple hierarchical document encoder trained on document pairs for this task.,Dataset Creation or Resources
2502,Empirical results show our best document embedding model leads to state-of-the-art results on the document-level bitext retrieval task on two different datasets,Performance Evaluation
2503,"We study in depth the effect of translationese on test data, using the test sets from the last three editions of WMTвЂ™s news shared task, containing 17 translation directions.",Performance Evaluation
2504,"we present a customized NMT system for subtitling, with focus on the entertainment domain",Algorithms/ Methods Construction or Optimization
2505,"We introduce our work, which to the best of our knowledge is the first of its kind, on integrating synchrony constraints into the machine translation paradigm",Model Construction or Optimization
2506,We propose the use of lexical shortcuts as a simple strategy for alleviating the representation bottleneck in NMT models,Algorithms/ Methods Construction or Optimization
2507,We demonstrate significant improvements in translation quality across multiple language pairs as a result of equipping the transformer with lexical shortcut connections,Performance Evaluation
2508,We report a positive impact of our modification on the modelвЂ™s ability to perform word sense disambiguation,Model Construction or Optimization
2509,This paper presents a high-quality multilingual dataset for the documentation domain to advance research on localization of structured text,Dataset Creation or Resources
2510,"In this talk I will give an overview of advances on the identification and treatment of multiword expressions, in particular concentrating on techniques for identifying their degree of idiomaticity.",Theory Proposal
2511," we present the types of VMWEs existing in each language, as they are reflected in the respective corpora created within PARSEME",Model Construction or Optimization
2512,This paper reports on the Romanian journalistic corpus annotated with verbal multiword expressions following the PARSEME guidelines.,Theory Proposal
2513,"We show how the Multiword Expressions (MWEs) contained in OdeNet can be morphologically specified by the use of the lexical representation and linking features of OntoLex-Lemon, which also support the formulation of restrictions in the usage of such expressions.",Dataset Creation or Resources
2514,introduction of a new task in NLP that sheds light on the basic mechanisms underlying conceptual creativity; an automatic way of evaluating newly generated language; a temporally-aware neural model that learns what are plausible new conceptual combinations by generalising over attested combinations and corrupted instances thereof.,Algorithms/ Methods Construction or Optimization
2515,this unsupervised method to a bilingual vector space so as to model translation as a process of compositional contextualization.,Algorithms/ Methods Construction or Optimization
2516,this paper also contributes with a new freely available dataset of 273 EnglishSpanish compound equivalents,Dataset Creation or Resources
2517,This paper presents a systematic evaluation of twelve AMs вЂ”both symmetric and directionalвЂ” which have been proposed for collocation extraction.,Theory Proposal
2518,we aimed to replicate the MWS frequency effects found for adult native language speakers based on evidence from self-paced reading and sentence recall tasks in an ecologically more valid eye-tracking study,Model Construction or Optimization
2519,we present the distribution and treatment of MultiWord Expressions (MWEs) within BTB-WN вЂ” a data-driven Bulgarian WordNet.,Model Construction or Optimization
2520,We focus on modeling compositionality of MWEs as reflected in their morphosyntactic and semantic properties.,Performance Evaluation
2521,We propose a scenario for coupling MWEI with MWE discovery via syntactic MWE lexicons,Theory Proposal
2522,This paper is a position statement based on an analysis of the state of the art in MWEI,Theory Proposal
2523,"we test the quality of noun compound representations produced by different methods, including distributional representations, composition functions, and paraphrase-based phrase embeddings",Performance Evaluation
2524,"our own proposal of how to deal with semantics of collocations; we argue that the notion of a semantic frame in the sense of FrameNet (Ruppenhofer et al., 2016) provides a suitably general semantic framework that is applicable to a wide range of semantic fields",Applications
2525,We propose to tackle the problem of verbal multiword expression (VMWE) identification using a neural graph parsing-based approach.,Algorithms/ Methods Construction or Optimization
2526,this paper aims to determine whether the sentiment of the component words of an idiom is related to the sentiment of that idiom.,Theory Proposal
2527,"We report on the ongoing development of IDION, a web resource of richly documented multiword expressions (MWEs) of Modern Greek addressed to the human user and to NLP",Algorithms/ Methods Construction or Optimization
2528,describe how we created a dataset for noun-adjective neologisms and in particular how we constructed a weak negative set for evaluation,Dataset Creation or Resources
2529,describe our baseline methodologies and how we used pretrained language models in order to identify adjective-noun neologism with increased accuracy,Applications
2530,"we propose a deep encoderdecoder architecture generating for every MWE word its corresponding part in the lemma, based on the internal context of the MWE",Model Construction or Optimization
2531,we aim to close this gap and present an evaluation study that considers both corpus- and documentlevel ATE.,Performance Evaluation
2532,we propose a neural model that improves MWE identification by jointly learning MWE and dependency parse labels,Model Construction or Optimization
2533,"we propose, to the best of our knowledge for the first time, a cross-lingual transfer learning method for processing MWEs",Algorithms/ Methods Construction or Optimization
2534,"We show that MWE identification models, when multitasked with dependency parsing, outperform the models which naively add dependency parse information as additional features",Dataset Creation or Resources
2535,"Our work aims to compile a comprehensive lexicon of Irish MWEs (Ilfhocail) for the purposes of NLP, by leveraging both existing monolingual and bilingual lexical resources and generating new MWE entries through methods of semiautomatic discovery",Algorithms/ Methods Construction or Optimization
2536,"Our goal is to study the impact of word representations on verbal MWE (VMWE) identification, comparing lemmas, surface forms, traditional word embeddings and subword representations.",Performance Evaluation
2537,We explore a variety of methods for the novel task of classifying four types of assertions about activity performance,Model Construction or Optimization
2538,"We propose a neural network model, which is a combination of a convolutional neural network (CNN) (LeCun et al., 1989), a recurrent neural network (RNN) (Elman, 1990), and a residual network (He et al., 2016) inspired by their recent successes in multiple tasks",Model Construction or Optimization
2539,Application of VAE in context to clinical paraphrasing task,Applications
2540,"In this work, we build a unifying framework for RE, applying this on three highly used datasets (from the general, biomedical and clinical domains) with the ability to be extendable to new datasets",Model Construction or Optimization
2541,we develop a simple measure of sentence importance and demonstrate its effectiveness in interpreting a complex LSTM modelвЂ™s decision making process,Algorithms/ Methods Construction or Optimization
2542,we discover clusters in the high-dimensional space of the sentence embedding model and test their correlation with feature importance scores for a given diagnosis class,Performance Evaluation
2543,We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results,Performance Evaluation
2544,"We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes: Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a Convolutional Neural Network",Algorithms/ Methods Construction or Optimization
2545,to present the construction of a biomedical gold standard corpus annotated both with part-of-speech tags and named entities,Algorithms/ Methods Construction or Optimization
2546,"Two different approaches for domain adaptation of SRL for biological processes, with our code and models publicly available",Model Construction or Optimization
2547,Analysis of the model performance when the target corpus is annotated with event-event relationships to the SRL corpus,Performance Evaluation
2548,We present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model,Model Construction or Optimization
2549,we will tackle the word categorization task and compare the performance of classification model on different feature sets: standard linguistic and non-linguistic features,Performance Evaluation
2550,we propose to apply deep learning techniques to improve identification of readability and understandability of medical words by nonexpert users,Algorithms/ Methods Construction or Optimization
2551,"Construct a dataset for training machine learning models to identify and extract data from full-text articles on diagnostic test accuracy. We focus on the target condition, index test, and reference standard.",Dataset Creation or Resources
2552,"a discriminative model for automatically constructing high-coverage and domain-specific corpora for information extraction,",Model Construction or Optimization
2553,"an approach for automatically selecting queries using index terms as candidates,",Algorithms/ Methods Construction or Optimization
2554,an automated method to evaluate queries based on a sample corpus,Model Construction or Optimization
2555,We present a simple and computationally efficient approach using a widely-available вЂњoff-theshelfвЂќ retrofitting algorithm to align pretrained embeddings according to semantic verb clusters,Model Construction or Optimization
2556,"we show that by using semantic clusters for verbs, a large lexicon of verb classes derived from biomedical literature, we are able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes",Model Construction or Optimization
2557,We compare wordbased and context-based representations for the three classification problems.,Performance Evaluation
2558,We propose a number of methods for extracting patterns from a sentence in which two eligible entities co-occur; different types of patterns have different trade-offs between expressive power and coverage,Algorithms/ Methods Construction or Optimization
2559,we propose a method which utilises these seed pairs to rank newly discovered patterns in terms of their compatibility with the existing data.,Algorithms/ Methods Construction or Optimization
2560,"We provide a resource to be distributed for research purposes in the BioNLP community. MedLexSp includes inflected forms (singular/plural, masculine/feminine) and conjugated verb forms of term lemmas, which are mapped to UMLS Concept Unique Identifiers",Dataset Creation or Resources
2561,We present a novel multichannel TextCNN model for MeSH term indexing.,Model Construction or Optimization
2562,Experimental results show that incorporating figure and table information improves the performance of automatic MeSH indexing,Performance Evaluation
2563,We make available a labeled full text biomedical document dataset,Dataset Creation or Resources
2564,We publish a dataset of 2010 sentences with complete annotations of biological entities and binding interactions between the entities,Dataset Creation or Resources
2565,"We propose a benchmark task with a welldefined evaluation system, which follows the best practices of machine learning research",Theory Proposal
2566,We perform extensive evaluation of several competing methods on the dataset and report the results.,Performance Evaluation
2567,The first NLP method to focus specifically on drug information for nursing mothers.,Model Construction or Optimization
2568,"Application of a deep learning-based system on two separate lactation information sources, drug labels and LactMed.",Applications
2569,Evaluation of cross-corpus similarity in terms of important lactation information,Performance Evaluation
2570,"we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on TimeML",Model Construction or Optimization
2571,we propose a novel annotation schema that could be useful for timeline reconstruction: CALendar EXpression (CALEX).,Algorithms/ Methods Construction or Optimization
2572,We present a method for the semantic categorization of clinical terms based on their surface form.,Algorithms/ Methods Construction or Optimization
2573,"we build a dataset of PIO elements by improving the methodology found in (Jin and Szolovits, 2018)",Dataset Creation or Resources
2574,"we built a multi-label PIO classifier, along with a boosting framework, based on the state of the art text embedding, BERT",Model Construction or Optimization
2575,A collection of Portuguese clinical texts with manuallylabelled named entities,Dataset Creation or Resources
2576,"A model of word embeddings learned from a larger collection of Portuguese clinical text (i.e., Neurology clinical case descriptions)",Model Construction or Optimization
2577,"An analysis of the performance of state-of-the-art models in Portuguese clinical NER, namely BiLSTM-CRF neural networks (Lample et al., 2016), tested on the labelled collection, either using the previous word embeddings or general-language word embeddings",Performance Evaluation
2578,We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narrative,Model Construction or Optimization
2579,a single methodology to generate medical text for a series of downstream NLP tasks,Algorithms/ Methods Construction or Optimization
2580,an assessment of the utility of the generated data as complementary training data in two important biomedical NLP tasks: text classification (phenotype classification) and temporal relation evaluation,Performance Evaluation
2581,"we introduce our work on building a Chinese medical QA corpus named ChiMed
by crawling data from a big Chinese medical forum",Applications
2582,Our goal in this paper is to maximize the predictive power of clinical notes by bridging the gap between information extraction and deep learning models,Theory Proposal
2583,we present the semantic annotations we made on a corpus of clinical cases written in French by domain experts,Theory Proposal
2584,"We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task",Model Construction or Optimization
2585,"focus on causal sentence detection as a binary classification task and  to consider causal sentence detection in
both generic and biomedical texts",Model Construction or Optimization
2586,We propose a new NE method that leverages the strengths of both structure and content-oriented approaches.,Algorithms/ Methods Construction or Optimization
2587,Our objective is to propose methods and material for the creation of transformation rules from a small set of parallel sentences differentiated by their technicity,Algorithms/ Methods Construction or Optimization
2588,We also propose a typology of transformations and quantify them,Theory Proposal
2589,We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets,Performance Evaluation
2590,this paper will focus on presenting the best NER performance achieved to date on full chemical patent corpus,Dataset Creation or Resources
2591,"Our main research contribution is a new neural model that detects ADRs by firstly learning to classify sentiment, using a publicly available corpus of Tweets that is annotated with sentiment information and then using transfer learning to adapt this classifier to the detection of ADRs in social media postings",Theory Proposal
2592,This work instead examines the evolution in biomedical knowledge over time using scientific literature in terms of diachronic change.,Performance Evaluation
2593,"we present our approach towards extracting outcomes, significance levels and relations between them, that can be incorporated into a spin detection pipeline",Algorithms/ Methods Construction or Optimization
2594,"In this paper, we describe the tasks, the datasets, and the participantsвЂ™ approaches and results of shared task.",Theory Proposal
2595,"we demonstrate that we can achieve significant performance gains over traditional deep learning models like ESIM by adapting pre-trained language
models into the medical domain",Model Construction or Optimization
2596,"we introduce an end-to-end system, trained in a multi-task setting, to filter
and re-rank answers in medical domain",Theory Proposal
2597,we investigate different methods to combine and transfer the knowledge from the two different sources and illustrate our results on the MEDIQA shared task,Performance Evaluation
2598,We apply the transfer learning method with two general domain NLI datasets and show that a source task in a domain can benefit learning a target task in a different domain,Model Construction or Optimization
2599,We show the independent strengths of the proposed approaches in quantitative and qualitative manners,Performance Evaluation
2600,"we propose a hybrid approach to biomedical NLI, which includes three main components",Theory Proposal
2601,"To enhance our model, we also use model ensemble and conflict resolution strategies",Model Construction or Optimization
2602,we specialize our model on the MedNLI dataset.,Model Construction or Optimization
2603,"In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks.",Model Construction or Optimization
2604,"Our approach for both task 1 and task 2 is based on the state-of-the-art natural language understanding model MT-DNN (Liu et al., 2019), which combines the strength of multi-task learning (MTL) and language model pre-training. MTL in deep networks has shown performance gains when related tasks are trained together resulting in better generalization to new domains",Theory Proposal
2605,This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain,Theory Proposal
2606,we present our novel approach to detect question entailment by determining the type of question asked rather than focusing on the type of the ailment given,Model Construction or Optimization
2607,"we detail our approach in MEDIQA which addresses some of the problems with biomedical text such as utilising deep contextual relationships between words within a sentence for semantic understanding and ambiguity associated with esoteric terminology, abbreviations, and patient colloquialism",Model Construction or Optimization
2608,we present Biomedical MultiTask Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge,Applications
2609,we describe our proposed model and the implementation details for both tasks,Model Construction or Optimization
2610,"This paper describes our approach to the Natural Language Inference (NLI) subtask of the MEDIQA 2019 shared task (Ben Abacha et al., 2019)",Theory Proposal
2611,This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT) for solving MedNLI,Algorithms/ Methods Construction or Optimization
2612," Our proposed systems produce
encouraging results",Performance Evaluation
2613,Our approach explored a common Transformer-based architecture that could be applied to each task.,Performance Evaluation
2614,"Our solution explores a BERT-based model, in which the BiLSTM network with attention mechanism is integrated for textual inference",Performance Evaluation
2615,"We discuss the Proposed Architecture for NLI, RQE and QA and  the results,
performance of the various models for each task,
followed by error analysis, conclusion and references",Performance Evaluation
2616,"we propose a new component
that aims to address this particular weakness of
seq2seq models",Algorithms/ Methods Construction or Optimization
2617,"we propose a new testing paradigm based on overgeneralization, that can be used to gain more insights in the biases of a model which cannot be inferred from task success alone",Algorithms/ Methods Construction or Optimization
2618,the creation of a challenging sentiment dataset from previously available data,Dataset Creation or Resources
2619,finally presenting a practical use-case demonstrating how the dataset can be used to probe the particular types of errors made by a new model.,Applications
2620,We create an artificial data set with target words displaying context overlap in different orders of co-occurrence and show that SGNS behaves similarly to SVD in capturing second-order co-occurrence information,Dataset Creation or Resources
2621,we present a new evaluation dataset1 that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications,Dataset Creation or Resources
2622,we study what the meaningful units to highlight are  so that all highlighted symptoms can be directly used for explaining the model.,Algorithms/ Methods Construction or Optimization
2623,Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions,Model Construction or Optimization
2624,we compare the explanations from the two models through human evaluation on Mechanical Turk and find that the model trained with human rationales is judged to generate explanations that better support its decisions,Performance Evaluation
2625,visualizing attention in the Transformer at three levels of granularity,Model Construction or Optimization
2626,"The proposal of a neural network architecture, the Headline Attention Network that is designed to capture the important parts of news article causing political bias by paying headline attention",Algorithms/ Methods Construction or Optimization
2627,"we show that, contrary to our expectations, most models fail to generalize across the different datasets.",Performance Evaluation
2628,we examine the behavior of POS taggers across languages from the perspective of individual hidden units within the character LSTM,Performance Evaluation
2629,"One approach to explainable VQA is to generate visual explanations, which highlight image regions that most contributed to the systemвЂ™s answer, as determined by attention mechanisms or gradient analysis",Theory Proposal
2630,"we evaluate and compare the aforementioned methods, using two different experimental setups, thereby we assess basic properties and differences between the explanation methods",Algorithms/ Methods Construction or Optimization
2631,"we explore how word relevances can be used to build sentence-level representations, and demonstrate how the relevance visualization can help to understand the (mis-)classification of selected samples w.r.t. semantic composition.",Algorithms/ Methods Construction or Optimization
2632,We present a detailed comparison of two types of sequence to sequence models trained to conduct a compositional task,Performance Evaluation
2633,"we show that a seq2seq model with attention mechanism not only solves the tagging task, but also generalizes well over unseen depths",Performance Evaluation
2634,"we propose a new KBC model, the Context Path Model (CPM), which provides a path-based explanation for newly proposed facts.",Model Construction or Optimization
2635,we extend previous work on longdistance dependencies to tease apart the potential grounds for the different outcomes by making previous work more comparable,Dataset Creation or Resources
2636,"we examine whether the word embeddings (trained on the whole words, not using any subword units or individual characters) capture derivational relations",Performance Evaluation
2637,we present a suite of experiments probing whether neural language models trained on linguistic data induce these stack-like data structures and deploy them while incrementally predicting words,Performance Evaluation
2638,"we define and apply representational stability analysis (ReStA), an intuitive way of analyzing neural language models.",Algorithms/ Methods Construction or Optimization
2639,"We propose a novel approach to the study of how artificial neural network perceive the distinction between grammatical and ungrammatical sentences, a crucial task in the growing field of synthetic linguistics",Algorithms/ Methods Construction or Optimization
2640,"We propose a method for robustness evaluation without goldstandard translation references, and perform experiments and extensive analysis on all available English Grammar Error Correction (GEC) corpora",Algorithms/ Methods Construction or Optimization
2641,we introduce a visualization technique for performing further analysis,Algorithms/ Methods Construction or Optimization
2642,we attempt to detect the presence of latent representations of hierarchical structure through an exploration of the unsupervised learning of constituency structure,Algorithms/ Methods Construction or Optimization
2643,we propose a white-box attack algorithm called вЂњGlobal SearchвЂќ method and compare it with a simple misspelling noise and a more sophisticated and common white-box attack approach called вЂњGreedy Search,Algorithms/ Methods Construction or Optimization
2644,We propose a simple attention-based metric called the confusion score that captures BERTвЂ™s response to syntactic distortions in an input sentence,Algorithms/ Methods Construction or Optimization
2645,"This paper presents a simple but general and effective method to debug the output of machine learning (ML) supervised models, including neural networks",Theory Proposal
2646,"We propose a transparent deterministic method of quantifying the amount of syntactic information present in the self-attentions, based on automatically building and evaluating phrasestructure trees from the phrase-like sequences.",Algorithms/ Methods Construction or Optimization
2647,we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERTвЂ™s attention,Model Construction or Optimization
2648,"We introduce novel computational models for modeling semantic bleaching, a widespread category of change in which words become more abstract or lose elements of meaning, like the development of arrive from its earlier meaning вЂ�become at shore.вЂ™",Model Construction or Optimization
2649,"This paper is an attempt to understand what has changed in poetry over the last 150 years within the age of mechanical reproduction of art, named so by Benjamin and Underwood",Theory Proposal
2650,"The present study employs Word2Vec models (Mikolov et al., 2013) to investigate two questions about the FOOD>MEAT>FLESH chain.",Performance Evaluation
2651,The paper focuses on diachronic evaluation of semantic changes of harm-related concepts in psychology.,Performance Evaluation
2652,"We propose a novel, attentional, diachronic word embedding model that derives inductive biases from several contextualized, sociodemographic, features to fit the data accurately",Model Construction or Optimization
2653,"our work is also the first to estimate the usefulness of the diachronic word embeddings
for downstream task like tweet classification.",Theory Proposal
2654,I discuss how evolutionary approaches to language change allow the modeling of cognate evolution,Theory Proposal
2655,This paper introduces a novel method to track collocational variations in diachronic corpora that can identify several changes undergone by these phraseological combinations and to propose alternative solutions found in later periods.,Algorithms/ Methods Construction or Optimization
2656,We propose an accurate and interpretable model for identifying the era of authorship of old Thai prose,Model Construction or Optimization
2657,"We are the first to provide statistical evidence that Traiphumikatha and Pumratchatham might be both written in the Sukhothai era, contrary to previous hypotheses",Applications
2658,we conclude that grammaticalized words and polyfunctionalized words are the strongest distinguishing indicators of prose from the Sukhothai era,Theory Proposal
2659,we propose a data-driven methodology for identifying temporal trends in a corpus of medieval charters,Algorithms/ Methods Construction or Optimization
2660,This paper examines gender bias in historical newspapers,Dataset Creation or Resources
2661,The paper at hand presents a computational method based on deep neural networks to predict phonetic features of historical sounds where the exact quality is unknown and to test the overall coherence of reconstructed historical phonetic features,Model Construction or Optimization
2662,"we introduce ParHistVis: a novel, free, easy-to-use, interactive visualization tool for parallel, multilingual, diachronic and synchronic linguistic data.",Theory Proposal
2663,"We collected a large corpus for this purpose, composed of thousands of books and newspapers published in France between 1789 and 1914",Dataset Creation or Resources
2664,"we present DiaHClust, a new approach which can be used to identify stages in diachronic change based on quantitative corpusderived data",Algorithms/ Methods Construction or Optimization
2665,"we propose an approach that fits additional, theoretically informative parameters to configure a mixture of embeddings",Algorithms/ Methods Construction or Optimization
2666,We propose a novel method to investigate the pace of language change based on the entire embedding matrix,Algorithms/ Methods Construction or Optimization
2667,"I propose that as words immigrate to new syntactic environments over time, they tend to push out words that populated these environments prior to immigration",Algorithms/ Methods Construction or Optimization
2668,we investigate semantic change across languages by measuring the semantic distance of cognate words in multiple languages,Performance Evaluation
2669,Verify that the represented temporal change reflects syntax rather than simply word frequency.,Theory Proposal
2670,"The paper showcases the application of word embeddings to change in language use in the domain of science, focusing on the Late Modern English period",Theory Proposal
2671,we model the contact possibility based on two of the most important factors in sociolinguistics to be affecting language change: age and distance,Model Construction or Optimization
2672,We reformulate the well-known word analogy task such that multiple correct answers or no correct answer at all become possible,Theory Proposal
2673,We process historical armed conflicts data and present it as a ready-to-use evaluation set,Dataset Creation or Resources
2674,we show that our learned cosine threshold approach can significantly improve the temporal one-to-X analogies performance by filtering out false positives.,Model Construction or Optimization
2675,"we investigate on is there a general trend in human languages which makes evaluative adjectives change
more intensely over time",Performance Evaluation
2676,we investigate to what extent diachronic semantic change occurs in the Hansard record by examining the contexts in which words appear during two different periods in the corpus,Performance Evaluation
2677,"we illustrate this importance and propose methods that take these risks into account
when investigating conceptual change using word
embeddings.",Algorithms/ Methods Construction or Optimization
2678,we present the first study on the compositionality of compounds over time.,Theory Proposal
2679,we introduce a linguistic classification that allows to better characterize the variants than edit operations,Model Construction or Optimization
2680,we propose to focus on a specific conceptвЂ”that of Circular Economy (CE).,Theory Proposal
2681,This paper proposes a Gaussian Process model of sound change targeted toward questions in Indo-Aryan dialectology,Model Construction or Optimization
2682,"we apply computational methods, to the extent that it is possible, to gain insight into the nature of language change that occurred in historical West-Frisian, a lesser-used language spoken in the Dutch province of Fryslan",Algorithms/ Methods Construction or Optimization
2683,"This paper presents a significant extension of HistoBankVis, a multilayer visualization system which allows a fast and interactive exploration of complex linguistic data",Model Construction or Optimization
2684,we implement a new query strategy for selecting вЂњunlabeledвЂќ instances from a target domain and investigate its effect on fine-tuning a generic NMT model,Dataset Creation or Resources
2685,This paper compares morphologyaware DA word segmentation to other word segmentation approaches like Byte Pair Encoding (BPE) and Sub-word Regularization (SR).,Theory Proposal
2686,we investigate the possibility of using POS tagging to improve word-level language identification for diglossic Arabic in a deep-learning system,Performance Evaluation
2687,we present syntax-ignorant n-gram embeddings to be used in sentiment analysis of several Arabic dialects,Algorithms/ Methods Construction or Optimization
2688,we propose six Arabic-English cross-lingual word embedding models,Model Construction or Optimization
2689,We introduce automatic selective diacritization as a viable step in lexical disambiguation and provide an encouraging baseline for future developments towards optimal diacritization,Algorithms/ Methods Construction or Optimization
2690,We propose several unsupervised data-driven methods for the automatic identification of ambiguous words,Algorithms/ Methods Construction or Optimization
2691,We evaluate and analyze the impact of partial sense disambiguation (i.e. selective diacritic restoration of identified homographs) in downstream applications for MSA.,Algorithms/ Methods Construction or Optimization
2692," The proposed model
integrates various tailored techniques together,
including representation learning, feature engineering, sequence labeling, and ensemble
learning.",Model Construction or Optimization
2693,we aim at advancing performance and generalization capabilities of Arabic NLP tasks by developing new ULMs for Arabic,Dataset Creation or Resources
2694,"We develop the first Arabic specific ULM model, called hULMonA",Dataset Creation or Resources
2695,We introduce a newly built (small) ALG dataset for STS.,Model Construction or Optimization
2696,"We compare the performance of different DNN configurations on this dataset, namely: various combinations of Recurrent Neural NetworksConvolutional Neural Networks (CNNs),
pre-training of embeddings, including a replication of two new state-of-the art attention models.",Performance Evaluation
2697,we propose to leverage this sequential substructure to improve the root extraction process and morphological decomposition,Model Construction or Optimization
2698,"we investigate the effect of different Arabic segmentation schemes, sentence length and embedding sizes on learning Arabic-English (Ar-En) Bilingual word embeddings",Model Construction or Optimization
2699,"Crowdsourced Arabic Reading Comprehension Dataset (ARCD) of 1,395 questions, and translated Arabic-SQuAD: 48k translated questions",Dataset Creation or Resources
2700,"End-toend system for open domain Arabic questions using a hierarchical TF-IDF retriever, BERT and linear answer ranking",Dataset Creation or Resources
2701,"we show how NLP applications
can scale up their performance on dialectal data by
integrating a basic and simple preprocessing step,
i.e. segmentation",Performance Evaluation
2702,"we propose a semi-supervised deep learning approach, which we refer to as deep co-learning.",Algorithms/ Methods Construction or Optimization
2703,"We present a collection of morphologically annotated corpora for seven Arabic
dialects",Theory Proposal
2704,This paper reports on the construction and annotation of a comprehensive 100-million-word corpus of contemporary Arabic,Algorithms/ Methods Construction or Optimization
2705,our goal is building an ArabicTurkish machine translation on the news domain,Theory Proposal
2706,we propose the use of domain adaptation to address this challenge while considering the task of sentiment analysis (SA) also referred to as Opinion Mining (OM).,Algorithms/ Methods Construction or Optimization
2707,This paper presents the first version of the Open Source International Arabic News (OSIAN) corpus.,Theory Proposal
2708,we proposed speech act classification for asynchronous conversations on Twitter using multiple machine learning methods including SVM and deep neural networks,Algorithms/ Methods Construction or Optimization
2709,"we present Mazajak , an Online Arabic sentiment analysis system that utilises deep learning and massive Arabic word embeddings",Dataset Creation or Resources
2710,we present the results and findings of the MADAR Shared Task on Arabic Fine Grained Dialect Identification,Applications
2711,We propose a simple classification approach that only utilizes word and character n-grams using NaВЁД±ve Bayes learning model.,Model Construction or Optimization
2712,the relationships between entities in an image by utilizing only image captions and object locations as the source of supervision,Algorithms/ Methods Construction or Optimization
2713,"we study multimodal summarization with various methods to summarize the intent of open-domain instructional videos stating the exclusive and unique features of the video, irrespective of modality",Model Construction or Optimization
2714,"we (i) collect human edits for machine-generated stories from two different state-of-the-art models, (ii) analyze what people edited, and (iii) advance the task of visual story post-editing",Performance Evaluation
2715,This technique can greatly reduce the workload of radiologists for interpreting CXR images and writing corresponding reports.,Algorithms/ Methods Construction or Optimization
2716,"an end-to-end model that extends the standard Transformer network (Vaswani et al., 2017) to learn representations directly from unaligned multimodal streams",Model Construction or Optimization
2717,"we introduce a high-level object-based visual representation to ground language into visual context in a more generalizable way, using the symbolic output of a pretrained object detection system",Algorithms/ Methods Construction or Optimization
2718,"This is done by building on the Word MoverвЂ™s Distance (WMD) metric, which measures the distance between two texts in a word embeddings space. Another contribution is the extension of WMD to allow for multiple references to be used to model object importance",Performance Evaluation
2719,: (i) a novel approach to MMT based on deliberation networks and structured visual information which gives state of the art results (Sections 3.2 and 5.1); (ii) a frequency bias-free investigation on the need for visual context in MMT (Sections 4.2 and 5.2); and (iii) a thorough investigation on different visual sual representations for transformer-based architectures,Algorithms/ Methods Construction or Optimization
2720,we propose to construct an imagegrounded vocabulary as a way to leverage the image semantics for image captioning,Algorithms/ Methods Construction or Optimization
2721,"the Collaborative Drawing (CoDraw) task, which combines grounded language understanding and learning effective goal-driven communication into a single, unified testbed",Algorithms/ Methods Construction or Optimization
2722,"leveraging upstream models that are capable of producing fine-grained entity names, and integrating them in a controlled manner to produce captions that are both fluent and highly informative",Model Construction or Optimization
2723,"a novel attention mechanism that consumes a word lattice and the probability scores from the ASR system. ii) The proposed approach is naturally applied to both the encoder self-attention and encoder-decoder attention. iii) Another appealing feature is that the lattice transformer can be reduced to standard latticeto-sequence model without probability scores, fitting the text translation task. iv) Extensive experiments on speech translation datasets demonstrate that our method outperforms the previous transformer and Lattice-LSTMs",Algorithms/ Methods Construction or Optimization
2724,(i) We propose a ReDAN framework that supports multi-step reasoning for visual dialog. (ii) We introduce a simple rank aggregation method to combine the ranking results of discriminative and generative models to further boost the performance. (iii) Comprehensive evaluation and visualization analysis demonstrate the effectiveness of our model in inferring answers progressively through iterative reasoning steps,Algorithms/ Methods Construction or Optimization
2725,"to encourage the model to learn speech representations which are correlated with the encoding of spoken language as a sequence of characters. Additionally, and for completeness, we also consider a second auxiliary task matching text to images.",Model Construction or Optimization
2726,вЂў An end-to-end architecture for goal-oriented visual dialogue combining Information Gain with Reinforcement Learning. вЂў A novel reward function for goal-oriented visual question generation to model long-term dependencies in dialogue. вЂў Both versions of our model outperform the current baselines on the GuessWhat?! dataset for the task of identifying an undisclosed object in an image by asking a series of questions.,Model Construction or Optimization
2727,"generating text as a sequence of segments, where each segment is generated either character-by-character from a sequence model or as a single draw from a lexical memory of multi-character units. The segmentation decisions and decisions about how to generate words are not observed in the training data and marginalized during learning using a dynamic programming algorithm",Model Construction or Optimization
2728,"(1) a procedure for collecting visually rich images paired with semantically-diverse language descriptions; (2) NLVR2, which contains 107,292 examples of captions and image pairs, including 29,680 unique sentences and 127,502 images",Algorithms/ Methods Construction or Optimization
2729,we use an implicit data gathering approach to label human activities in videos.,Algorithms/ Methods Construction or Optimization
2730,"our latent variable MMT formulation improves considerably over strong baselines, and compares favourably to the state-of-the-art. вЂў we exploit correlations between both modalities at training time through a joint generative approach and do not require images at prediction time.",Theory Proposal
2731,"1. We propose a model fusing transcript of narrated instructional video during procedure extraction and captioning. 2. We employ the pre-trained BERT(Devlin et al., 2018) and self-attention(Vaswani et al., 2017) layer to embed transcript, and then integrate them to visual encoding during procedure extraction. 3. We adopt the sequence-to-sequence model to generate captions by merging tokens of the transcript with the aligned video frames.",Model Construction or Optimization
2732,"We introduce a uniqueness measure to evaluate topic quality more wholistically. вЂў W-LDA produces significantly better quality topics than existing topic models in terms of topic coherence and uniqueness. вЂў We experiment with both the WAE-GAN and WAE-MMD variants (Tolstikhin et al., 2017) for distribution matching and demonstrate key performance advantage of the latter with a carefully chosen kernel, especially in high dimensional settings. вЂў We discover a novel technique of adding noise to W-LDA to significantly boost topic coherence. This technique can potentially be applied to WAE in general and is of independent interest.",Performance Evaluation
2733,". Using a qualitative analysis, we further show that RAT works as a regularizer and prohibits NMT to overfit to TC vocabulary",Performance Evaluation
2734,We explore possible explanations for the finding that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks and provide a set of adaptation guidelines for the NLP practitioner.,Theory Proposal
2735,"We propose a novel approach to handle the discrete nature of text, during training, using word embeddings.",Algorithms/ Methods Construction or Optimization
2736,"In this paper, we explore a multilingual translation model with a cross-lingually shared layer that can be used as fixed-size sentence representation in different downstream tasks.",Model Construction or Optimization
2737,we present a multilingual translation system that efficiently tackles the task of learning language-agnostic sentence representations,Algorithms/ Methods Construction or Optimization
2738,In this article we propose an adaptation of Doubly Stochastic Variational Inference for Automatic Relevance Determination (DSVIARD) for neural networks compression.,Performance Evaluation
2739,"We introduce a simple yet effective, self-supervised post-processing method that constructs task-specialized word representations by picking from a menu of reconstructing transformations to yield improved end-task performance (MORTY)",Algorithms/ Methods Construction or Optimization
2740,"we compile several key pitfalls of evaluation of sentence embeddings, a currently very popular NLP paradigm",Performance Evaluation
2741,We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data,Algorithms/ Methods Construction or Optimization
2742,"In this work, we present POSTLE, an all-words post-specialization model for the asymmetric LE relation",Model Construction or Optimization
2743,we propose two novel constraints for composing linguistically informed and intuitively explainable noun phrase representations and show how these approaches could benefit future composition methods.,Model Construction or Optimization
2744,We apply pre-trained language models to low-resource named entity recognition for Historic German.,Algorithms/ Methods Construction or Optimization
2745,"We propose a simple entity-pair ranking (PR) protocol (PR), which is more suitable to assess model performance for KBC.",Algorithms/ Methods Construction or Optimization
2746,"We propose a novel supertagger based on the Transformer architecture (Vaswani et al., 2017) that is capable of constructing categories inductively, bypassing the aforementioned limitations.",Algorithms/ Methods Construction or Optimization
2747,"In this work, we introduce a deep generative model that generates source and target sentences jointly from a shared latent representation",Model Construction or Optimization
2748,"In this paper, we propose BilLex (Bilingual Word Embeddings Based on Lexical Definitions) to learn bilingual word embeddings.",Algorithms/ Methods Construction or Optimization
2749,We empirically study how pre-trained embeddings and language models perform when used to analyze text from social media.,Model Construction or Optimization
2750,This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain.,Dataset Creation or Resources
2751,We develop a fine-grained entity typing model that embeds both entity types and entity mentions in hyperbolic space.,Model Construction or Optimization
2752,We propose to generate multilingual metarepresentations from pre-trained monolingual word embeddings. The model can learn how to construct the best word representation by mixing multiple sources without explicit language identification.,Model Construction or Optimization
2753,"we explore and evaluate several sub-word unit based embedding strategies вЂ“ character n-grams, lemmatization provided by an NLP-pipeline, and segments obtained in unsupervised learning (morfessor) вЂ“ to boost semantic consistency in Hungarian word vectors.",Performance Evaluation
2754,"The method we propose, learns discriminative features from both an autoencoder and a sentence embedding, then uses assignments from a clustering algorithm as supervision to update weights of the encoder network",Model Construction or Optimization
2755,"In this paper, we introduce a new approach to warm-start embedding models with morphological information, in order to reduce training time and enhance their performance.",Algorithms/ Methods Construction or Optimization
2756,"In this paper, we aim to gain a better insight into the inner workings of recurrent models with respect to incrementality while taking inspiration from and drawing parallels to this psycholinguistic perspective.",Model Construction or Optimization
2757,In this paper we investigate how representing adversarial training models as committees can be used to effectively improve the performance of QuestionAnswer (QA) Ranking.,Performance Evaluation
2758,"We propose to consider lifelong relation extraction as a metalearning challenge, to which the machinery of current optimization-based meta-learning algorithms can be applied",Theory Proposal
2759,"In this paper, we investigate the best practices for constructing the seed dictionary for a specific domain.",Theory Proposal
2760,"we present a novel technique that efficiently combines PCA based dimensionality reduction with a recently proposed post-processing algorithm (Mu and Viswanath, 2018), to construct effective word embeddings of lower dimensions",Algorithms/ Methods Construction or Optimization
2761,We present a modified skip-gram negative sampling algorithm that produces related word and context vectors.,Algorithms/ Methods Construction or Optimization
2762,"We present a novel approach for cross-lingual representation learning that combines methods for multi-task learning of monolingual sentence representations (Cer et al., 2018; Subramanian et al., 2018) with recent work on dual encoder methods for obtaining multilingual sentence representations for bi-text retrieval (Guo et al., 2018; Yang et al., 2019).",Algorithms/ Methods Construction or Optimization
2763,"We propose a novel method, Modality-based Redundancy Reduction Fusion (MRRF), for understanding and modulating the relative contribution of each modality in multimodal inference tasks",Algorithms/ Methods Construction or Optimization
2764,we present the results of our experiments on learning a simple multi-task neural network model for partof-speech and semantic tagging for Welsh using a pre-trained embedding model from FastText.,Model Construction or Optimization
2765,In this paper we discuss different definitions of fairness and possible ways to apply them to educational applications.,Applications
2766,"we propose a method for estimating the difficulty of MCQs from a high-stakes medical exam, where all questions were deliberately written to a common reading level.",Algorithms/ Methods Construction or Optimization
2767,we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT) in vocabulary assessment for Chinese L2 learners.,Performance Evaluation
2768,"we  explore the use of computational linguistic methods to investigate how taskappropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers.",Performance Evaluation
2769,In this paper we present a model for automatic scoring of summaries based on analysing a rhetorical structure of a studentвЂ™s summary compared to that of reference summaries.,Model Construction or Optimization
2770,This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC).,Dataset Creation or Resources
2771,This paper addresses automatic correction of spelling errors where the misspelled string is not a valid word in the language.,Dataset Creation or Resources
2772,The present study explores how fluency filtering can affect the quality of artificial errors.,Theory Proposal
2773,In this paper we present first results for automated essay scoring of Norwegian learner language.,Theory Proposal
2774,"In this paper, we perform a systematic comparison of ELMo, BERT and Flair embeddings on a range of public GED datasets, and propose an approach to effectively integrate such representations in current methods, achieving a new state of the art on GED.",Performance Evaluation
2775,We formulate precise hypotheses about the possible effects of adding character representations to word-based models and test these hypotheses on large-scale real-world content scoring datasets.,Model Construction or Optimization
2776,"In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses.",Model Construction or Optimization
2777,We introduce unsupervised techniques based on phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation.,Algorithms/ Methods Construction or Optimization
2778,"We propose a new method for combining systems (В§4) that can combine many systems and relies solely on their output, i.e., it uses systems as a black-box.",Algorithms/ Methods Construction or Optimization
2779,"In this work, we investigate a similar approach by systematically generating parallel data for pretraining.",Dataset Creation or Resources
2780,This paper describes our two systems for the three tracks in the BEA-2019 GEC Shared Task,Algorithms/ Methods Construction or Optimization
2781,This paper presents the contributions from the Cambridge University Engineering Department to the latest GEC competition at the BEA 2019 workshop.,Dataset Creation or Resources
2782,We introduce the AIP-Tohoku grammatical error correction (GEC) system for the BEA2019 shared task in Track 1 (Restricted Track) and Track 2 (Unrestricted Track) using the same system architecture,Algorithms/ Methods Construction or Optimization
2783,"In this paper, we present our models and their results in the restricted, unrestricted, and lowresource tracks.",Model Construction or Optimization
2784,"In the following, we present our low-resource approach to GEC, which ranked as the 6th best performing system in the low-resource 192 track of the BEA 2019 shared task.",Model Construction or Optimization
2785,"In this paper, we describe the submissions from the group of Beijing Language and Culture University (BLCU) in the first two tracks.",Applications
2786,we propose to finetune BERT on learner corpora with grammatical errors for re-ranking.,Algorithms/ Methods Construction or Optimization
2787,"In this paper, we introduce a neural GEC system that combines the power of pre-training and transfer learning.",Model Construction or Optimization
2788,We present a system pipeline that utilises both error detection and correction models.,Algorithms/ Methods Construction or Optimization
2789,we explore two approaches of generating error-focused phrases and examine whether these phrases can lead to better performance in grammatical error correction for the restricted track of BEA 2019 Shared Task on GEC.,Algorithms/ Methods Construction or Optimization
2790,we suggest an alternative approach for GEC with вЂњMulti-headedвЂќ architecture that uses BERT as Encoder and specialized вЂњHeadsвЂќ networks enabling additional text processing based on particular error types.,Algorithms/ Methods Construction or Optimization
2791,we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data,Algorithms/ Methods Construction or Optimization
2792,"This paper compares three end-to-end resources for collocation learning, all of which used the same corpus but different methods",Dataset Creation or Resources
2793,The experiments presented in this paper aim to analyze how much each of these phenomena reveal about the L2 speakerвЂ™s native language,Theory Proposal
2794,we present a novel method based on deep learning applied to the task of automatic prerequisite relations identification between concepts to automatically create pedagogically motivated sequences of LOs.,Algorithms/ Methods Construction or Optimization
2795,our study develops an example sentence retrieval system with grammatical error detection using the large-scale Lang-8 dataset for JSL by focusing on the usability of automatic incorrect example retrieval.,Model Construction or Optimization
2796,we propose an automated algorithm which provides feedback about the specific content of non-native English speakersвЂ™ spoken responses.,Algorithms/ Methods Construction or Optimization
2797,This paper provides an analytical assessment of student short answer responses with a view to potential benefits in pedagogical contexts.,Performance Evaluation
2798,we discuss leveraging this observation in our efforts to build audio-visual content for young learnersвЂ™ vocabulary learning.,Algorithms/ Methods Construction or Optimization
2799,"we discuss our system, Curio SmartChat for self-paced K-12 learning through Question Answering as a mode",Theory Proposal
2800,This paper proposes a support tool for evaluating student summaries in terms of their contents by suggesting the links between the ideas of a source text and its summary.,Algorithms/ Methods Construction or Optimization
2801,"we take first steps towards understanding the relation between expert annotations, reader proficiency and comprehension for automatic readability assessment research by conducting a web-based reading study with over 100 participants in a natural reading environment.",Performance Evaluation
2802,we assess the effectiveness of an automatic classification tool for the evaluation of text complexity in Italian,Performance Evaluation
2803,"Our goal is to create a machine teacher that can detect and exploit situations where incidental learning can occur in narrative text (stories, articles etc.).",Theory Proposal
2804,We track the development of writing complexity and accuracy in German studentsвЂ™ early academic language development from first to eighth grade.,Applications
2805,We developed an automated oral proficiency scoring system for non-native English speakersвЂ™ spontaneous speech,Algorithms/ Methods Construction or Optimization
2806,"we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task.",Algorithms/ Methods Construction or Optimization
2807,"we study several simplistic machine understanding systems, described in В§ 2.4 and empirically examine the correlation between their performance and the actual complexity of texts, measured by humans (see В§ 3).",Algorithms/ Methods Construction or Optimization
2808,In this paper we investigate metaphors in the context of news texts simplification.,Model Construction or Optimization
2809,"This paper presents a roadmap for now incorporating equity into the design, evaluation, and implementation of those systems",Performance Evaluation
2810," In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation.",Theory Proposal
2811,"we propose a tool, Dexter, that extracts a subjectspecific corpus from a heterogeneous corpus, such as Wikipedia, by relying on a small seed corpus and distributed document representations.",Dataset Creation or Resources
2812,"we investigate how effective are different model architectures in generating artificial, parallel data to improve a GEC model.",Model Construction or Optimization
2813,"This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays",Dataset Creation or Resources
2814,"we present a simple and effective method for assessing the proficiency of language learners, as well as the difficulty of linguistic concepts, by utilizing the Elo formula, (Elo, 1978)вЂ” in an unsupervised fashion.",Algorithms/ Methods Construction or Optimization
2815,"We present a unique dataset of student sourcebased argument essays to facilitate research on the relations between content, argumentation skills, and assessment",Dataset Creation or Resources
2816,"we designed a principled framework of boosting response generation,
based on the recently developed theory of boosting generative models",Algorithms/ Methods Construction or Optimization
2817,"we propose an adversarial training algorithm to learn two sets
of better word weights which contribute to
two emotion dimensions in two attention layers.",Algorithms/ Methods Construction or Optimization
2818,"Two auxiliary tasks are designed to enhance
the labeling of ATE and ASC, and an extra
RNN cell ReGU is proposed to improve the
capability of feature extraction.",Algorithms/ Methods Construction or Optimization
2819,"we propose an approach that provides an
entity-level representation in a simple and intuitive
manner, and also facilitates end-to-end optimization.",Algorithms/ Methods Construction or Optimization
2820,"We analyze the discriminative features that
help the best performing method, string kernels, in (i) distinguishing the Moldavian and
the Romanian dialects and in (ii) categorizing the text samples by topic.",Algorithms/ Methods Construction or Optimization
2821,we focus on the transferability of our methods from biased datasets to ones having different or no biases.,Algorithms/ Methods Construction or Optimization
2822,We propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own.,Algorithms/ Methods Construction or Optimization
2823,"We propose a new task: emotion-cause pair extraction (ECPE). It solves the shortcomings of the traditional ECE task that depends on the annotation of emotion before extracting cause, and allows emotion cause analysis to be applied to real-world scenarios.",Algorithms/ Methods Construction or Optimization
2824,"we introduce a new word replacement order determined by both the word saliency and the classification probability, and propose a greedy algorithm called probability weighted word saliency (PWWS) for text adversarial attack.",Algorithms/ Methods Construction or Optimization
2825,we propose a strong unsupervised system for parallel sentence mining and show that the mined data improves the performance of unsupervised MT systems.,Algorithms/ Methods Construction or Optimization
2826,"We propose a simple algorithm on top of these parses that allows us to control the average chunk size, which in turn limits the number of autoregressive decoding steps we have to perform.",Algorithms/ Methods Construction or Optimization
2827,"We introduce a вЂњCo-curricular learningвЂќ, for transfer learning across data quality. It extends the single curriculum learning work in NMT and makes
the existing domain-data selection method
work better with noisy data.",Theory Proposal
2828,"we propose an imitation learning framework for nonautoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart.",Algorithms/ Methods Construction or Optimization
2829,"We extend the recently-proposed Average Lagging latency metric, making it differentiable and calculable in expectation, which allows it to be used as a training objective.",Algorithms/ Methods Construction or Optimization
2830,"Our ARNOR framework achieves significant improvement over state-of-the-art noise reduction methods, in terms of both RC performance and noise reduction effect.",Algorithms/ Methods Construction or Optimization
2831,"We evaluate our method even with contextual embeddings. The relative performance of
the adaptation alternatives remain fairly stable whether the adapted embeddings are used
on their own, or concatenated with contextsensitive embeddings",Performance Evaluation
2832,Our aim in this paper is to integrate the advantages of TMs into NMT systems in order to improve MT quality by utilizing existing translations for highly similar source sentences in a given TM,Applications
2833,"we attempt to obtain diverse translations by using sentence codes to condition the sentence generation. We describe two methods to extract the codes, either with or without the help of syntax information.",Algorithms/ Methods Construction or Optimization
2834,"we propose a method to distill the important domain signal as part of a multi-domain learning system, using a latent variable model in which parts of a neural model are stochastically gated based on the inferred domain.",Algorithms/ Methods Construction or Optimization
2835,"we propose a new head-modifier templatebased method to improve the readability and data fidelity of generating type descriptions, which is also the first attempt of integrating head-modifier rule into neural generative models",Algorithms/ Methods Construction or Optimization
2836,"We propose a syntax-infused VAE that integrates syntactic trees with sentences, to grammatically improve the generated sentences. i",Algorithms/ Methods Construction or Optimization
2837,"We propose a simple domain embedding approach to merge the sourceand target-domain training data, which is shown to be more effective than both direct corpus concatenation and multi-task learning.",Theory Proposal
2838,We propose a domain adaptive dialog generation method based on meta-learning (DAML). DAML is an end-to-end trainable dialog system model that learns from multiple rich-resource tasks and then adapts to new domains with minimal training samples.,Algorithms/ Methods Construction or Optimization
2839,Our goal is to design a counter-argument generation system to address the above challenges and produce paragraph-level arguments with rich-yetcoherent content.,Theory Proposal
2840,we propose a sequence-level training method based on a novel reinforcement algorithm for NAT to reduce the variance and stabilize the training procedure,Algorithms/ Methods Construction or Optimization
2841,"We propose SynGCN, a Graph Convolution based method for learning word embeddings. Unlike previous methods, SynGCN utilizes syntactic context for learning word representations without increasing vocabulary size.",Algorithms/ Methods Construction or Optimization
2842,"we demonstrate that our proposed methods obtain substantial improvement over state-of-the-art approaches, and also yield an advantage when used in conjunction with
methods",Algorithms/ Methods Construction or Optimization
2843,"Based on BERT, we introduce target word embedding dropout for helping substitute candidate proposal, and a substitute candidate validation method based on the substitutionвЂ™s influence on the global contexts.",Algorithms/ Methods Construction or Optimization
2844,a method for assessing the credibility of claims derived from medical usergenerated content.,Algorithms/ Methods Construction or Optimization
2845,we propose a noise-added strategy to add noise samples into the training set in the form of pseudo data,Theory Proposal
2846,"we investigate the potential of using MT methods to normalize non-canonical texts in Turkish, a morphologically-rich, agglutinative language, allowing for a very large number of common word forms.",Performance Evaluation
2847,", we present an improved and effective methodology to classify domain-specific freeform speech commands while utilizing this direct classification and transfer learning approaches.",Algorithms/ Methods Construction or Optimization
2848,We introduce a hybrid Convolutional Neural Network (CNN) and Long Short Term Memory Network (LSTM) approach to dementia detection that takes advantage of both targeted and implicitly learned features to perform classification.,Algorithms/ Methods Construction or Optimization
2849,propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations,Algorithms/ Methods Construction or Optimization
2850,"we introduce a demo system of
our in-house OL framework, in which we integrated our translation servers with the translators
user-friendly interface SDL Trados Studio",Algorithms/ Methods Construction or Optimization
2851,"we address these limitations
by introducing a tool that provides a flexible
and efficient way to query the Semantic Scholar
knowledge base, a semi-automatically constructed
knowledge base of scientific literature",Algorithms/ Methods Construction or Optimization
2852,"We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus",Algorithms/ Methods Construction or Optimization
2853,we have described a method to merge multiple medical terminologies into a single network preserving both terminology-specific and cross-terminology relations.,Algorithms/ Methods Construction or Optimization
2854,"developed two systems based on bidirectional encoder representations from transformers (BERT) (Devlin, Chang, Lee, & Toutanova, 2018) for the two subtasks respectively",Algorithms/ Methods Construction or Optimization
2855,We propose an iterative algorithm to form a single representation for up-to l-length walks between the entities of a pair,Algorithms/ Methods Construction or Optimization
2856,we propose to improve the end-toend coreference resolution system by using a biaffine attention model to get antecedent scores for each possible mention,Algorithms/ Methods Construction or Optimization
2857,we propose the HSCRF architecture which employs both word-level and segment-level labels for segment score calculation,Algorithms/ Methods Construction or Optimization
2858,we propose a joint CRF-HSCRF training framework and a naive joint decoding algorithm for neural sequence labeling,Algorithms/ Methods Construction or Optimization
2859,"We have devised a simple but effective strategy to deal with questions having options like none of the above, two of the above, all of the above, both (a) and (b) etc",Theory Proposal
2860,we propose a method of dynamic sentence sampling (DSS) to improve the NMT training efficiency,Algorithms/ Methods Construction or Optimization
2861,we design a memory network method to capture discourse cohesion implicitly in order to improve discourse parsing,Algorithms/ Methods Construction or Optimization
2862,we apply a simple policy gradient method to train four different state-of-theart transition-based constituency parsers to maximize expected F1,Applications
2863,"We investigated the impact of a specific
set of grammatical roles on coherence, we instead investigate a large set
of GR types, and train the model to predict the
type of role dependents participate in.",Performance Evaluation
2864,"We perform an extensive analysis of ways to represent the conversational-context in terms of the number of utterance history, and sampling strategy considering to use the generated sentences or the true preceding utterance.",Theory Proposal
2865,"We present a universal representor to replace encoder and decoder, leading to a compact translation model, which fully explores the commonality between languages.",Model Construction or Optimization
2866,"we propose a new solution that can complete the multiple entityrelations extraction task with only one-pass encoding on the input corpus, and achieve a new state-of-the-art accuracy performance, as demonstrated in the ACE 2005 benchmark.",Algorithms/ Methods Construction or Optimization
2867,"We propose an entmax sparse output layer, together with a natural loss function. In largevocabulary settings, sparse outputs avoid wasting probability mass on unlikely outputs, substantially improving accuracy.",Algorithms/ Methods Construction or Optimization
2868,"we use adversarial training across tasks, to вЂњsoftcodeвЂќ shared and private spaces, to avoid the shared space gets too sparse.",Theory Proposal
2869,"We note that our approach differs from other applications in the NLP literature in using the mean reward as our baseline, and in comparing different reward functions",Theory Proposal
2870,"we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way.",Theory Proposal
2871,"It application of a well-studied graphical model to a
novel domain, outperforming previous approaches
on word and sentence-level translation retrieval tasks.",Applications
2872,The proposed reordering mechanism can be easily integrated into the Transformer to learn reordering-aware sentence representation for machine translation.,Applications
2873,we extend the architecture search approach to an important paradigm of transfer learning across multiple data sources: continual learning. The major problem in continual learning is catastrophic forgetting,Algorithms/ Methods Construction or Optimization
2874,"In order to adapt to non-parallel data, we design a cycle reinforcement learning algorithm CycleRL to guide the model training in an unsupervised way.",Algorithms/ Methods Construction or Optimization
2875,"We propose a new and effective framework for CQG, which is equipped with a dynamic reasoning component to generate a conversational question and is further fine-tuned via a reinforcement learning mechanism.",Algorithms/ Methods Construction or Optimization
2876,"We show the effectiveness of our method using the recent CoQA dataset. Moreover, we
show its wide applicability by using it to create multi-turn QA conversations for passages
in SQuAD",Performance Evaluation
2877,we propose to train the decoder in a sequence of steps that encourages the source and target embedding spaces to remain aligned during adaptation,Theory Proposal
2878,"We introduce and experiment with various self-supervised approaches for extractive summarization, one of which achieves the new state-ofthe-art results with a basic hierarchical model.",Theory Proposal
2879,Token-level cross-passage information interaction is implemented through the application of the proposed DynSA at relatively less computational costs.,Algorithms/ Methods Construction or Optimization
2880,QFE adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question.,Algorithms/ Methods Construction or Optimization
2881,"we show that policy gradient fine-tuning learns an easy-first strategy, which reduces error propagation",Performance Evaluation
2882,We present the first ever application of this formalism to the task of realistic wide-coverage parsing.,Theory Proposal
2883,"we survey the state of the art in constructing author profiling corpora for the first time, compiling a taxonomy of construction strategies applied.",Theory Proposal
2884,"we show that in the multihop HotpotQA dataset, the examples often contain reasoning shortcuts through which models can directly locate the answer by word-matching the question with a sentence in the context.",Performance Evaluation
2885,"we perform a replication and a series of reproductions. These techniques were until recently quite rare in this field, despite the inherently repeatable nature of most natural language processing experiments.",Theory Proposal
2886,We propose alternative evaluation metrics based on example difficulty and provide a reference implementation.,Algorithms/ Methods Construction or Optimization
2887,we apply a different analysis based on intermediate representation erasure to assess whether attention weights can instead be relied upon to explain the relative importance of the inputs to the attention layer itself.,Algorithms/ Methods Construction or Optimization
2888,"we propose to apply RSA to neural representations of strings from a language on one side, and to structured symbolic representations of these strings on the other side.",Theory Proposal
2889,"we empirically show that our approach is competitive with previous work and that HardKuma has further applications,",Algorithms/ Methods Construction or Optimization
2890,We show how pre-trained BERT models can also be used and fine-tuned as the decoder in a language generation task.,Theory Proposal
2891,we focus on the multilingual transfer setting where training data in multiple source languages is leveraged to further boost target language performance.,Algorithms/ Methods Construction or Optimization
2892,we investigate the problem of biomedical name embedding and its applications. We pay attention to the similarity between semantically related names as well as the names of the same concept.,Theory Proposal
2893,we have manually annotated 100 sentences from the Turkish translation of the novel вЂњThe Little PrinceвЂќ with AMRs to describe the differences between these annotations and their English counterparts,Theory Proposal
2894,Our goal is to develop robust ASR systems for pathological speech and incorporate the ASR technology to detect their speech intelligibility problems.,Algorithms/ Methods Construction or Optimization
2895,The first is to provide a formal definition of the notion of informativeness applied to both sentential context (as a whole) and context words (taken individually).,Theory Proposal
2896,"we show that ELMo models can be successfully fine-tuned on a small in-domain corpus, bringing significant improvements to strategies involving contextual embeddings.",Model Construction or Optimization
2897,"we apply and compare simple shallow capsule networks for hierarchical multi-label text classification and show that they can perform superior to other neural networks, such as CNNs and LSTMs, and non-neural network architectures such as SVMs.",Theory Proposal
2898,"we characterize the available datasets as capturing various phenomena related to abusive language, and investigate this characterization in cross-domain classification.",Algorithms/ Methods Construction or Optimization
2899,This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow.,Algorithms/ Methods Construction or Optimization
2900,"The entire operable SARAL system itself, an end-to-end CLIR and summarization system that combines SEARCHER and traditional IR techniques and applies them to text and speech documents in low-resource languages",Algorithms/ Methods Construction or Optimization
2901,We demonstrate the practical utility of our approach by applying it on a set of 67 novel event types.,Performance Evaluation
2902,", the system is designed to
make it easy to port to other application domains (e.g., the dialogue component factors
out domain-specific execution from domaingeneral actions such as requesting and updating slot values).",Algorithms/ Methods Construction or Optimization
2903,"we show that crossturn dependencies can be learned automatically, this eliminates the rule-based NBT component and effectively yields a fully statistical dialogue state tracker",Algorithms/ Methods Construction or Optimization
2904,we demonstrate the feasibility of using NLP for this task in the form of a highaccuracy classifier of actionable feedback,Model Construction or Optimization
2905,we apply our model to label 10.8M Twitter posts and 6.2M Reddit comments in order to evaluate the speed and type of user reactions to various news sources,Model Construction or Optimization
2906,we aim to give transparency and user-comprehensible explainability,Theory Proposal
2907,we investigate the empirical hypothesis that NMT is able to learn from the good chunks of a noisy sentence and describe a simple way of utilizing such chunk-level feedback in NMT training,Theory Proposal
2908,"We provide a detailed empirical comparison of various attention transformations, including softmax, sparsemax",Performance Evaluation
2909,We demonstrate the benefits of multilingual Neural NER on low-resource languages,Theory Proposal
2910,"we provide a large number of highquality training examples which can be bootstrapped from state-of-the-art Open IE systems, which is released for future research",Dataset Creation or Resources
2911,we conduct comprehensive experiments on a large benchmark dataset to compare different Open IE systems to show the neural approachвЂ™s promising potential,Performance Evaluation
2912,"We devise a new formulation of graphstructured stack (Tomita, 1991) which requires no extra bookkeeping, proving a new theorem that gives deep insight into GSS",Algorithms/ Methods Construction or Optimization
2913,"our parser is substantially faster for long sentences on the Penn Treebank, and orders of magnitude faster for end-to-end discourse parsing",Algorithms/ Methods Construction or Optimization
2914,"We evaluate the proposed model over two
real-world datasets. We adapt distant supervision with co-reference resolution and paraphrase detection to obtain high-quality training
data.",Model Construction or Optimization
2915,"We introduce the task of email subject line generation
(SLG) and build a benchmark dataset AESLC",Algorithms/ Methods Construction or Optimization
2916,"We propose the Multimodal EmotionLines Dataset (MELD), which includes not only
textual dialogues, but also their corresponding visual and audio counterparts.",Dataset Creation or Resources
2917,"we extend, improve, and further develop the EmotionLines dataset for the multimodal
scenario.",Dataset Creation or Resources
2918,"introduce a
new color-grid reference task and data set consisting of higher dimensional objects and more complex speaker language",Dataset Creation or Resources
2919,"We propose a set of cross-domain coherence
datasets with increasingly difficult evaluation
protocols.",Dataset Creation or Resources
2920,"We introduce a novel large corpus containing
33564 text samples written in the Moldavian
and the Romanian dialects",Dataset Creation or Resources
2921,"We propose OneSeC (One Sense per Category), a novel fully-automatic method
that produces multilingual sense-annotated
datasets on a large scale by mapping
Wikipedia categories to word senses.",Algorithms/ Methods Construction or Optimization
2922,"we present SP-10K, which is unprecedented in both size and the number of SP
relations. It contains 10,000 selectional triplets
consisting of 2,500 frequent verbs, nouns, and
adjectives in American English.",Dataset Creation or Resources
2923,"We propose a new dataset, ChID, for clozestyle reading comprehension in Chinese language. ChID contains 581K passages and
729K blanks from three domains",Dataset Creation or Resources
2924,we explore the use of noisy counseling data obtained from public sources for the analysis of counseling quality,Performance Evaluation
2925,we obtain substantial improvement over prior models for both entities and negations on the 2010 i2b2/VA challenge task as well as a proprietary de-identified clinical note dataset for medical conditions,Model Construction or Optimization
2926,"we present a new data set, IBMEviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives.",Dataset Creation or Resources
2927,"Based on a benchmark ECE corpus, we construct a corpus suitable for the ECPE task. The experimental results prove the feasibility of the ECPE task as well as the effectiveness of our approach.",Dataset Creation or Resources
2928,We introduce the first large-scale multi-document summarization datasets in the news domain.,Dataset Creation or Resources
2929,"To learn such an embedding, we create the largest distant supervision dataset by linking the entire English ClueWeb09 corpus to Freebase. The dataset is publicly available",Dataset Creation or Resources
2930,"We extend the GPT to handle bag-level, multi-instance training and prediction for distantly supervised datasets, by aggregating sentence-level information with selective attention to produce bag-level predictions",Algorithms/ Methods Construction or Optimization
2931,"We perform extensive experiments on five publicly available datasets for entity alignment tasks, and achieve significant improvements of 5% Hits@1 on average. Further ablation study demonstrates the effectiveness of our key components.",Dataset Creation or Resources
2932,"We propose new formulations for training topicspecific embeddings on a limited target corpus DT by adapting generic pre-trained word embeddings E, and/or selecting from any available broad-coverage corpus DS",Algorithms/ Methods Construction or Optimization
2933,We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set,Performance Evaluation
2934,We create a novel human language guided image editing dataset to boost the study in describing visual relationships,Algorithms/ Methods Construction or Optimization
2935,"We contribute a new dataset, named as VID-sentence, to serve as a benchmark for the novel WSSTG task",Dataset Creation or Resources
2936,we propose a data-collection task formulated as a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions.,Dataset Creation or Resources
2937,"we propose a new dataset with two new automatic metrics for this task, and experiments show that our method achieves stateof-the-art performance on both datasets.",Dataset Creation or Resources
2938,"We propose a method to construct a pseudo parallel dataset for the surface realization model, without the need of labeled data.",Algorithms/ Methods Construction or Optimization
2939,"we create a new dataset, that contains 1716 summaries for papers from several computer science conferences, that can be used as training data",Dataset Creation or Resources
2940,the new state-of-the-art performance on five real-world datasets in a setting where a model is able to determine the number of keyphrases to generate.,Algorithms/ Methods Construction or Optimization
2941,"we present a novel dataset, BIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries.",Dataset Creation or Resources
2942,a large-scale multi-sentence compression corpus is introduced along with a manually created test set for future research. We release source code and data here,Dataset Creation or Resources
2943,"we introduce a cross-lingual OpenQA dataset called XQA. It consists of a training set in English, and development and test sets in English, French, German, Portuguese, Polish,Chinese, Russian, Ukrainian, and Tamil.",Dataset Creation or Resources
2944,We create a new dataset for multi-modal Twitter sarcasm detection and release it,Dataset Creation or Resources
2945,we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities.,Dataset Creation or Resources
2946,"We propose a silver dataset containing user-generated reviews labelled with a approximation of the socio-economic status of their author, based on the price range of restaurants",Dataset Creation or Resources
2947,"To address real-world, large-scale application scenarios and to facilitate the possibility of adopting modern вЂdata-hungryвЂ™ language models in this domain, we collect a new largescale book review dataset from goodreads.com.",Dataset Creation or Resources
2948,"we report on the construction of the first large-scale corpus of celebrity profiles, describing our acquisition approach based on a reliable matching of Twitter accounts to Wikidata items.",Theory Proposal
2949,"We create a dataset for ranking constructive comments including 100K+ Japanese comments with constructiveness scores, in collaboration with Yahoo! News. Our dataset will be publicly available.",Dataset Creation or Resources
2950,We propose the task of cross-modal automatic commenting (CMAC) and construct a large-scale dataset.,Dataset Creation or Resources
2951,We introduce a novel data set of tweets posted by U.S. politicians who self-reported their tweets using a signature.,Dataset Creation or Resources
2952,We use a back-translation procedure that generates pseudo source sentences paired with the true summaries to build a training corpus for the cross-lingual ASSUM.,Algorithms/ Methods Construction or Optimization
2953,A massive collection of parallel texts for over 300 diverse languages is our main contribution to facilitate multilingual NLP,Dataset Creation or Resources
2954,We propose the creation of a dataset to learn the QAR strategy with weak supervision.,Dataset Creation or Resources
2955,we build a corpus of New Zealand English tweets containing Maori loan- ВЇ words,Theory Proposal
2956,We present a Telugu-English code-mixed corpus with the corresponding named entity tags.,Theory Proposal
2957,", we introduce the French
CASS dataset, composed of judgments from
the French Court of cassation and their corresponding summaries.",Dataset Creation or Resources
2958,"we introduce manually verified corpus of compelling fake and questionable news articles on the USA politics, containing around 700 articles from Aug-Nov, 2016",Theory Proposal
2959,we visualize probably the first job posting data set with labels from domain experts showing the intensity of PhD-level research skills,Dataset Creation or Resources
2960,"we present a ranking-based model that has been successfully applied to predicting PhD skills intensity from job postings, with empirical performance evaluation.",Model Construction or Optimization
2961,we use a generic and simple frame-slots data-structure with pre-defined dialogue policies that allows for fast design and implementation at the price of some flexibility reduction.,Algorithms/ Methods Construction or Optimization
2962,"We benchmark OpenKiwi on two datasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art performance on the word-level tasks and near state-of-the-art in the sentencelevel tasks",Performance Evaluation
2963,"we provide an annotated dataset of 5,727 partwhole relations , which contains 8 subtypes for the bootstrapping RE system",Dataset Creation or Resources
2964,we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus,Theory Proposal
2965,we propose a large structured dataset of automatically linguistically annotated software developer conversations for feature exploration,Dataset Creation or Resources
2966,we propose a smaller manually-labeled subset of that dataset for hypothesis testing,Dataset Creation or Resources
2967,We demonstrate the usefulness of this general-domain dataset by applying an existing visual-linguistic annotation framework that successfully annotates image regions by combining gaze and language data,Theory Proposal
2968,"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary)",Performance Evaluation
2969,we design a large scale news dataset with 1.02 million sentence compression pairs are compiled for this task in addition to 200 manually created sentences.,Dataset Creation or Resources
2970,"We annotate the first medical dataset for dialogue system that consists of two parts, one is self-reports from patients and the other is conversational data between patients and doctors",Dataset Creation or Resources
2971,we incorporate knowledge of the lexico-syntactic fixedness of VNCs вЂ” automatically acquired from corpora using the method of Fazly et al. (2009) вЂ” into our various embedding-based approaches,Theory Proposal
2972,we verified the effectiveness of the method on public data sets,Performance Evaluation
2973,"we construct the discourse dependency corpus SciDTB1 . based on scientific abstracts, with the reference to the discourse dependency representation in Li et al. (2014)",Dataset Creation or Resources
2974,"we show that metadata is crucial for modeling voting outcomes in new contexts, as changes between sessions lead to changes in the underlying data generation process",Model Construction or Optimization
2975,"We introduce pivot translation into unsupervised NMT to improve the accuracy of distant
languages.",Model Construction or Optimization
2976,"We propose an n-gram based attention model
to effectively map the multi-word mentions of
entities and their relationships into uniquely
identified entities and predicates.",Model Construction or Optimization
2977,"we empirically show that multimodal learning with audio and text can indeed reduce prediction error, compared to previous work that relies
on text only.",Performance Evaluation
2978,"we try to model the multidimensional learning task as a multi-task learning
task through adversarial learning.",Model Construction or Optimization
2979,"We propose global fusion to obtain an overall view of multimodal embeddings via a specifically designed ABS-LSTM, in which we integrate two levels of attention mechanism: Regional Interdependence Attention and Global Interaction Attention.",Algorithms/ Methods Construction or Optimization
2980,"We propose the factored tensor network FTN
to model the complex semantic interactions,
and it has the advantage of significantly reducing the complexity of the original model",Model Construction or Optimization
2981,"This paper codifies model and task agnostic principles for
informative error analysis, and presents Errudite, an interactive tool for better supporting this process.",Model Construction or Optimization
2982,"we propose a new fully-trainable, language-independent mention detectors that outperform the Stanford CORE mention detector in a variety of genres.",Algorithms/ Methods Construction or Optimization
2983,introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness,Algorithms/ Methods Construction or Optimization
2984,"We show that the proposed approaches outperform baselines in both indomain and cross-domain evaluation, demonstrating that the model learns domain-agnostic walking
patterns that are generalizable for unseen domains.",Model Construction or Optimization
2985,we propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multievidence information.,Algorithms/ Methods Construction or Optimization
2986,our goal is to induce semantic information from the proposed multimodal model into an acoustic model. We study a more challenging scenario where we establish that lexical information is available during,Model Construction or Optimization
2987,"We introduce a multi-task learning framework based on the neural network model, transformer",Algorithms/ Methods Construction or Optimization
2988,"we present a novel approach to CWI based on sequence modelling. Our system is capable of performing CWI in context, does not require extensive feature engineering and outperforms state-of-the-art systems on this task",Algorithms/ Methods Construction or Optimization
2989,we incorporate the global lattice structure into the model through reachability masks that mimic the pairwise conditioning structure of previous recurrent approaches.,Model Construction or Optimization
2990,"we introduce a model suitable for this scenario, and demonstrate that it is effective on our new benchmarks without sacrificing performance as measured with BLEU.",Model Construction or Optimization
2991,"We extend a novel graph neural network model with generated parameters, to enable relational message-passing with rich text information, which could be applied to process relational reasoning on unstructured inputs such as natural language.",Model Construction or Optimization
2992,"We incorporate the embeddings of characterwise/word-wise BIO tag from NER task to enrich the input representation, which proves to be very effective not only for our model but for other models as well.",Model Construction or Optimization
2993,"We propose a novel neural framework named MGNER for Multi-Grained Named Entity Recognition, aiming to detect both nested and non-overlapping named entities effectively in a single model",Algorithms/ Methods Construction or Optimization
2994,"MGNER is highly modularized. Each module
in MGNER can adopt a wide range of neural network designs. Moreover, MGNER can
be easily extended to many other related information extraction tasks.",Applications
2995,we show experimental results show that our model significantly outperforms previous methods of using gazetteers and the state-of-the-art Chinese NER models,Model Construction or Optimization
2996,"we propose an alternative approach to address this limitation, and in particular, to train models by marginalizing over the set of segmentations",Model Construction or Optimization
2997,We propose a phrase prediction model that improves the performance of state-of-the-art word-level language models,Model Construction or Optimization
2998,We introduce an adaptive optimizer to selfadjust the number of iterations for each example in order to improve instance-level convergence and enhance the reliability of routing processes.,Algorithms/ Methods Construction or Optimization
2999,we propose a neural P2C conversion model augmented by an online updated vocabulary with a sampling mechanism to support open vocabulary learning during IME working.,Model Construction or Optimization
3000,we propose a method to simultaneously learn tokenization and text classification to address these problems. Our model incorporates a language model for unsupervised tokenization into a text classifier and then trains both models simultaneously,Algorithms/ Methods Construction or Optimization
3001,"we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others.",Performance Evaluation
3002,"We introduce LSTMEmbed, an RNN model based on a bidirectional LSTM for learning word and sense embeddings in the same semantic space, which вЂ“ in contrast to the most popular approaches to the task вЂ“ takes word ordering into account.",Model Construction or Optimization
3003,The proposed translation models outperform the state-of-the-art NMT baselines systems with a similar number of parameters and achieve comparable results compared to NMT systems with much more parameters.,Applications
3004,"we analyze the performance of different models on different types of constituents, and find that our model shows substantial improvement on noun phrases and prepositional phrases which are common in captions",Performance Evaluation
3005,"We design novel relationalspeaker models, including a dynamic relational
attention module, to handle the problem of twoimage captioning by focusing on all their visual
relationships",Model Construction or Optimization
3006,We conduct extensive experiments showing that our model outperforms the state-of-theart both in automated and human evaluations.,Performance Evaluation
3007,"We propose a sentiment intensity controlled generative model Seq2SentiSeq, in which a sentiment intensity value is introduced via a Gaussian kernel layer to achieve fine-grained sentiment control of the generated sentence.",Model Construction or Optimization
3008,"We propose to break up the table-to-text generation into two stages with two separate models, so that the model can be trained with fewer annotated data.",Model Construction or Optimization
3009,"We redesign the ELBO of the joint log likelihood, to accommodate two separate latent spaces in one VAE framework, for two SIVAE model variants based on different intuitions, which can be further used for other applications.",Algorithms/ Methods Construction or Optimization
3010,"we utilize a multi-level decoder structure to capture the coherent long-term structure inherent in long-form texts, by generating intermediate sentence representations as highlevel plan vectors.",Algorithms/ Methods Construction or Optimization
3011,"we extend supervised DIM to semi-supervision setup (SEMIDIM), where unsupervised learning objectives based on unlabeled data are also optimized",Algorithms/ Methods Construction or Optimization
3012,"we propose that the rich multi-modal data from recording the meeting environment, especially cameras facing each participant, can provide speaker interaction and participant feedback to discover salient utterances.",Theory Proposal
3013,We introduce multi-style learning that enables our model to control answer styles and improves RC for all styles involved.,Algorithms/ Methods Construction or Optimization
3014,We use a co-attention mechanism to model sentence coherence and integrate the coherenceand entailment-based attentions into our proposed hierarchical attention framework for better evidence embedding,Algorithms/ Methods Construction or Optimization
3015,we analyze the usefulness of a userвЂ™s network information over the userвЂ™s tweets for predicting its occupational group. We extend the existing dataset for occupation classification by introducing the network information about a user,Theory Proposal
3016,we propose the WMM2Seq for dialog generation which separates the storage of dialog history and KB information by using the episodic and semantic memories and then leverages the working memory to interact with them,Theory Proposal
3017,"we consider an extension to the FC scenario, where a practitioner has the computational capacity to fit multiple models in parallel.",Algorithms/ Methods Construction or Optimization
3018,It seamlessly integrates implicit anticipation and translation in a single model that directly predicts target words without explictly hallucinating source ones.,Model Construction or Optimization
3019,Our prefix-to-prefix framework is tailored to simultaneous translation and trained from scratch without using full-sentence models.,Algorithms/ Methods Construction or Optimization
3020,"We combine the ability of BERT to handle sentence pair inputs together with its pre-trained multilingual model, to use both the src and mt in a cross-lingual encoder, that takes a multilingual sentence pair as input",Algorithms/ Methods Construction or Optimization
3021,"we propose a framework, which
we call LANGRANK, to empirically answer the
question posed above: given a particular task lowresource language and NLP task, how can we determine which languages we should be performing
transfer",Algorithms/ Methods Construction or Optimization
3022,"We propose a morphology-aware alignment model for unsupervised bilingual lexicon induction, which aims to alleviate the adverse effect of morphological variation by introducing grammatical information learned from pre-trained language model.",Model Construction or Optimization
3023,"We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings",Algorithms/ Methods Construction or Optimization
3024,"we design an NPI-based model that simulates the editing process by a programmer and an interpreter, which outperforms the state-of-the-art neural MT-based TS models by large margins in terms of SARI and is judged by humans as simpler and overall better",Model Construction or Optimization
3025,"It proposes the use of a unique combination of lexical, sentiment, durational and further derivative features of adjacency pairs to train traditional classification models",Dataset Creation or Resources
3026,"r aims to improve existing document
embedding models (Le and Mikolov, 2014; Li
et al., 2016a) by training document embeddings
using cosine similarity instead of dot product",Model Construction or Optimization
3027,r presents an alternative to the current morpheme-based scheme for Japanese word segmentation,Theory Proposal
3028,"we propose a joint neural model to simultaneously extract names and kinships from obituaries, which combines a two-layer bidirectional Long Short-Term Memory (bi-LSTM) (Hochreiter and Schmidhuber, 1997) and a unique tagging scheme",Model Construction or Optimization
3029,"we exploited ensembles based on a pretrained language representation with a neural transformer architecture (BERT) (Tasks 1
and 4) and a CNN-BiLSTM(-CRF) network
within a multi-task learning scenario",Algorithms/ Methods Construction or Optimization
3030,"We propose a novel architecture that encodes
locally stored domain information into sentence representation.",Algorithms/ Methods Construction or Optimization
3031,"we propose a new approach for learning thematic relatedness between sentences, formulating the related TDC task and creating a thematic clustering benchmark",Algorithms/ Methods Construction or Optimization
3032,"we propose a new approach to triclustering, achieving state-of-the-art performance on the frame induction task",Algorithms/ Methods Construction or Optimization
3033,"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword",Algorithms/ Methods Construction or Optimization
3034,we propose a new parallel recurrent neural network model for entity recognition,Model Construction or Optimization
3035,we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation,Model Construction or Optimization
3036,we study the problem of word ambiguities in definition modeling and propose a possible solution by employing latent variable modeling and soft attention mechanisms,Theory Proposal
3037,The proposed CNN model performs comparatively or better than LSTM-based baselines on two different datasets,Model Construction or Optimization
3038,we extend the beam search to introduce more flexibility,Algorithms/ Methods Construction or Optimization
3039,"we analized the the encoder-decoder framework learns the sequence-to-sequence task directly, bypassing other hand-crafted patterns and alleviating error propagation",Performance Evaluation
3040,"we model the response
selection problem as a multi-class classification
problem with sequences as input, where the label of the true response is set to one and the
other candidates are set to zero.",Model Construction or Optimization
3041,"we introduce a different way to
handle reentrancy, and propose an attention-based model that treats AMR parsing as sequence-tograph transduction.",Model Construction or Optimization
3042,"we propose a novel
reliability-aware name tagging model to tackle
this issue. We design a set of word frequencybased reliability signals to indicate the quality
of each word embedding.",Model Construction or Optimization
3043,"We propose an end-to-end model for extract-
ing and canonicalizing triples to enrich a KB.
The model reduces error propagation between
relation extraction and NED, which existing
approaches are prone to.",Model Construction or Optimization
3044,"We propose the novel AGGCNs that learn a
вЂњsoft pruningвЂќ strategy in an end-to-end fashion, which learns how to select and discard
information. Combining with dense connections, our AGGCN model is able to learn a
better graph representation",Model Construction or Optimization
3045,"we proposed DihEdral to model
the relation in KG with the representation of dihedral group. The elements in a dihedral group are
constructed by rotation and reflection operations
over a 2D symmetric polygon.",Model Construction or Optimization
3046,we propose a novel recursive neural network architecture consisting of a decomposable attention framework in every branch,Algorithms/ Methods Construction or Optimization
3047,"It proposes a probabilistic model,
JELTA, which jointly estimates the credibility of
claims and the trustworthiness of sources, when
claims are made by sources directly, indirectly, or
both",Model Construction or Optimization
3048,"Our framework incorporates a TE model
as part of the global inference framework as a way
to link evidence (and thus, sources) to claims.",Model Construction or Optimization
3049,"We propose
a novel model to generate email subjects. Our automatic and human evaluations demonstrate that
our model outperforms competitive baselines and
approaches human-level quality.",Model Construction or Optimization
3050,"We propose a generic hierarchical fusion strategy, termed вЂ�divide, conquer and combineвЂ™, to explore both local and global interactions in multiple stages each focusing on
different dynamics.",Algorithms/ Methods Construction or Optimization
3051,"we propose an interactive multitask learning network (IMN), which solves both
tasks simultaneously, enabling the interactions between both tasks to be better exploited.",Model Construction or Optimization
3052,"we propose a novel Transfer
Capsule Network (TransCap) model to transfer
sentence-level semantic knowledge from DSC to
ASC.",Model Construction or Optimization
3053,"we
propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training
corpus to refine attention mechanisms.",Model Construction or Optimization
3054,"A novel framework DOER is proposed to address the aspect term-polarity co-extraction
problem in an end-to-end fashion. A crossshared unit (CSU) is designed to leverage the
interaction of the two tasks",Model Construction or Optimization
3055,"We propose a MTL approach to coherence assessment
and compare it against a number of baselines",Algorithms/ Methods Construction or Optimization
3056,"we
designed a novel discourse relation identification pipeline specifically tuned for opendomain dialogue systems.",Algorithms/ Methods Construction or Optimization
3057,"we introduce Word Injection to LSC, a modeling idea drawn from term extraction, that overcomes the problem of vector space alignment.",Model Construction or Optimization
3058,"We introduce unified models for multi-task learning that learn three sets of features: task, task group, and task universe features;",Model Construction or Optimization
3059,"We propose a knowledge attention module,
which helps to select the most related and helpful knowledge from different KGs",Theory Proposal
3060,we propose An end-to-end hierarchical neural model consisting of a shared encoder and different decoding schemes to jointly extract entities and negations.,Model Construction or Optimization
3061,"we present a novel method inspired by the determinantal point process for multi-document summarization. The method includes a diversity measure assessing the redundancy between sentences, and a quality measure that indicates the importance of sentences",Algorithms/ Methods Construction or Optimization
3062,we propose to learn topic-aware news representations by jointly training the news encoder with an auxiliary topic classification task,Algorithms/ Methods Construction or Optimization
3063,Proposing a novel end-toend sequence labeling architecture utilizing LDL to model the emphasis words in a given text.,Algorithms/ Methods Construction or Optimization
3064,"We propose a classifier by integrating multiple text feature sets, including the publicly available pre-trained textual language model Bi-directional Encoder Representation from transformers (BERT)",Algorithms/ Methods Construction or Optimization
3065,we propose the use of lattice positional embeddings to model positioning and ordering of lattice nodes.,Model Construction or Optimization
3066,"We propose the novel task of learning general-purpose embedding of textual relations, which has the potential to facilitate a wide range of relational understanding tasks",Algorithms/ Methods Construction or Optimization
3067,We present a novel and concise joint model to handle the joint type inference problem based on graph convolutional network,Model Construction or Optimization
3068,"We introduce a binary relation classification
task to explore the structure of entity-relation bipartite graph in a more efficient and interpretable way",Algorithms/ Methods Construction or Optimization
3069,"we propose GraphRel, a neural end-to-end joint model for entity recognition and relation extraction that is the first to handle all three key aspects in relation extraction",Model Construction or Optimization
3070,"we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine highquality relational patterns from noise data with human experts in the loop.",Algorithms/ Methods Construction or Optimization
3071,"We propose a novel Multi-channel GNN model MuGNN that learns alignmentoriented embeddings by encoding graphs from different perspectives: completion and pruning, so as to be robust to structural differences.",Model Construction or Optimization
3072,"we propose a lightweight recurrent network (LRN), which combines the strengths of ATR and SRU. The structure of LRN is simple: an input gate and a forget gate are applied to weight the current input and previous hidden state, respectively",Model Construction or Optimization
3073,we focus on perfectly decodable encoding of sentences which will be very useful in designing good generative models that can generate longer sentences.,Theory Proposal
3074,"we present a new approach to counterfactual data augmentation 
for mitigating gender stereotypes associated with
animate nouns for morphologically rich languages.",Algorithms/ Methods Construction or Optimization
3075,"we introduce a generative latent-variable model that jointly represents adjective choice, with its sentiment, given the natural gender of a head noun.",Model Construction or Optimization
3076,we first propose a relation-aware semantic projection model to estimate probabilistic distributions of lexical relations over unlabeled data.,Model Construction or Optimization
3077,"we introduce a novel вЂ�continual architecture searchвЂ™ (CAS) approach, where the model parameters evolves and adapts when trained sequentially on a new task while maintaining the performance on the previously learned tasks.",Algorithms/ Methods Construction or Optimization
3078,we propose a novel aspect-aware coarse-tofine decoder for generating product reviews. We first utilize unsupervised topic models to extract aspects and tag review sentences with aspect labels.,Algorithms/ Methods Construction or Optimization
3079,We propose a novel metaphor and personification generation model with a rhetorically controlled encoder-decoder.,Algorithms/ Methods Construction or Optimization
3080,We propose a memory-augmented neural model with adversarial training to integrate external commonsense knowledge into topicto-essay generation.,Model Construction or Optimization
3081,"we propose various multi-level network structures for the VAE model (ml-VAE), to address coherency and repetitiveness challenges associated with long-form text generation.",Theory Proposal
3082,"we propose a novel data-totext generation model with two modules, one for saliency tracking and another for text generation.",Model Construction or Optimization
3083,"we propose the Extended Transformer model for Abstractive Document Summarization (ETADS) to tackle the above issues. Specifically, we design a novel focusattention mechanism and saliency-selection network equipped in the encoder and decoder",Model Construction or Optimization
3084,We propose a novel unsupervised end-to-end model to generate an abstractive summary of a single product review while inducing a latent discourse tree,Model Construction or Optimization
3085,We propose an RL approach with a novel adaptive reward function that explicitly encourages the model to generate both sufficient and accurate keyphrases,Algorithms/ Methods Construction or Optimization
3086,a new evaluation method that considers name variations of the keyphrase labels,Performance Evaluation
3087,"we propose a multi-modal hierarchical attention mechanism across topic segments, utterances, and words. We learn topic segmentation as an auxiliary task and limit the attention within each segment.",Algorithms/ Methods Construction or Optimization
3088,"we propose an end-to-end MRC model named as Knowledge Aided Reader (KAR), which explicitly uses the above extracted general knowledge to assist its attention mechanisms.",Model Construction or Optimization
3089,"we propose RE3QA, a neural question answering model that conducts the full retrieve-read-rerank process for multi-document RC tasks.",Model Construction or Optimization
3090,We propose QFE for explainable multi-hop QA. We use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.,Algorithms/ Methods Construction or Optimization
3091,"We devise a new approach KTNET to MRC. It outperforms competitive baselines, ranks the 1st place on the ReCoRD leaderboard, and is also the best single model on the SQuAD",Model Construction or Optimization
3092,We propose two novel methods to handle the simplified HPSG parsing.,Algorithms/ Methods Construction or Optimization
3093,"We are the first to introduce the deep transition architecture for sequence labeling, and further enhance it with the global contextual representation at the sentence level, named GCDT",Theory Proposal
3094,"We conduct elaborate investigations of global contextual representation, model complexity and effects of various components in GCDT.",Performance Evaluation
3095,We propose a novel claim verification framework based on hierarchical attention neural networks to learn sentence-level evidence embeddings to obtain claim-specific representation,Algorithms/ Methods Construction or Optimization
3096,"we propose a simple, automatic recipe towards reducing hallucination for neural surface realisers by enhancing the semantic equivalence between pairs of MRs and utterances.",Theory Proposal
3097,"We present a novel co-attention model, which aims at capturing intrinsic interactions between multiple modal contents.",Model Construction or Optimization
3098,We Propose a novel path-based reasoning approach for multi-hop QA over text that produces explanations in the form of explicit paths,Algorithms/ Methods Construction or Optimization
3099,"We design A model, PathNet, which aims to extract implicit relations from text and compose them",Model Construction or Optimization
3100,We define author context as the embedded representation of their historical posts on Twitter and suggest neural models that extract these representations.,Theory Proposal
3101,we develop a novel framework for temporal relation representation that puts event duration front and center.,Algorithms/ Methods Construction or Optimization
3102,We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence.,Algorithms/ Methods Construction or Optimization
3103,we propose a novel model namely Reference Network that incorporates the referring process into translation decoding of NMT.,Model Construction or Optimization
3104,we propose a hard-attention based NMT model which selects a subset of source tokens for each target token to effectively handle long sequence translation.,Model Construction or Optimization
3105,we propose a sentencelevel agreement module to directly minimize the difference between the representation of source and target sentence.,Algorithms/ Methods Construction or Optimization
3106,"we introduce the topic entity graph, a local sub-graph of an entity, to represent entities with their contextual information in KG.",Theory Proposal
3107,we focus on methods for cross-lingual transfer to distant languages and propose to learn a generative model with a structured prior that utilizes labeled source data and unlabeled target data jointly,Theory Proposal
3108,"we propose to encode relational knowledge in a separate word embedding, which is aimed to be complementary to a given standard word embedding.",Algorithms/ Methods Construction or Optimization
3109,we propose a word embedding model which explicitly aims to learn context vectors that are organised in clusters.,Model Construction or Optimization
3110,"We propose a BERT-based end-to-end lexical substitution approach without relying on
any annotated data and external linguistic resources.",Algorithms/ Methods Construction or Optimization
3111,We propose a novel Seq2Seq model that decomposes the paraphrase generation into learning paraphrase patterns at different granularity levels separately,Model Construction or Optimization
3112,a methodology for testing existing models and proposed extensions.,Algorithms/ Methods Construction or Optimization
3113,proposing the use of Inverted Softmax and Cross-modal Local Scaling to replace naive nearest neighbor search (for inference).,Theory Proposal
3114,"we present a recurrent neural model to detect ad hominem attack in a paragraph, and we experiment with various other models to compare them",Model Construction or Optimization
3115,We put forward a shared Bi-LSTM-CRF model for efficiently integrating multiple embeddings and sharing useful linguistic features;,Model Construction or Optimization
3116,"we propose a
new training schedule that allows the system
to scale to more languages without modification of the previous components based on
joint training and language-independent encoder/decoder modules allowing for zero-shot
translation.",Algorithms/ Methods Construction or Optimization
3117,we develop a neural model based on a CNN-LSTM architecture that learns to detect AD and related dementias using targeted and implicitly-learned features from conversational transcripts,Model Construction or Optimization
3118,we build the NMT systems for both EN-ID and ID-EN directions using the Transformer model,Algorithms/ Methods Construction or Optimization
3119,"We propose a new strategy for using scheduled sampling in Transformer models by
making two passes through the decoder in
training time.",Algorithms/ Methods Construction or Optimization
3120,"we propose an approach
of using semantic similarity between the output
sequence and the ground-truth sequence to train
the generation model.",Theory Proposal
3121,"We present a modular framework for the rapidprototyping of linguistic, web-based, visual
analytics applications.",Algorithms/ Methods Construction or Optimization
3122,We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks,Theory Proposal
3123,provides pretrained conversational models that can be either used directly or loaded for fine-tuning or bootstrapping other models; these models power an online demo of our framework.,Model Construction or Optimization
3124,"we present PERSPECTROSCOPE, a web-based system which lets users query a discussion-worthy natural language claim, and extract and visualize various perspectives in support or against the claim, along with evidence supporting each perspective",Algorithms/ Methods Construction or Optimization
3125,"We demonstrate HEIDL, a prototype HITLML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text",Algorithms/ Methods Construction or Optimization
3126,"We describe My Turn
To Read, an app that uses interleaved reading
to help developing and struggling readers improve reading skills while reading for meaning
and pleasure.",Algorithms/ Methods Construction or Optimization
3127,"we present ClaimPortal, a webbased platform for monitoring, searching, checking, and analytics of factual claims on Twitter. ClaimPortal is available at https://idir.
uta.edu/claimportal",Algorithms/ Methods Construction or Optimization
3128,We propose a graph walk based neural model that considers multiple entity pairs in relation extraction from a sentence,Model Construction or Optimization
3129,we develop a linguistically-infused neural network model to classify reactions in social media posts,Model Construction or Optimization
3130,we model this task using CNN regression with an auxiliary ordinal regression objective,Model Construction or Optimization
3131,we propose an unified approach to filter noisy bitexts and to mine bitexts in huge monolingual texts,Algorithms/ Methods Construction or Optimization
3132,Our model takes question-option tuple to generate a score for the concerned option,Model Construction or Optimization
3133,"we gauge human ability to perform cross-lingual gender detection, an angle of analysis which has not been studied thus far",Theory Proposal
3134,we propose an entity-centric neural crosslingual coreference model,Model Construction or Optimization
3135,"we propose a novel Document Embedding Enhanced Bi-RNN model, called DEEB-RNN, for ED at sentence level",Model Construction or Optimization
3136,we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain,Model Construction or Optimization
3137,We propose the task of automatically rating academic papers and build a new dataset for this task,Algorithms/ Methods Construction or Optimization
3138,"proposal of a novel interaction-over-interaction
network which enables deep-level matching with
carefully designed interaction block chains",Algorithms/ Methods Construction or Optimization
3139,"we propose a novel method for
zero-shot multilingual transfer, inspired by research in truth inference in crowd-sourcing, a related problem, in which the вЂ�ground truthвЂ™ must be
inferred from the outputs of several unreliable annotators",Algorithms/ Methods Construction or Optimization
3140,"We propose the learning to route
(LTR) method to automatically select the good
translation path",Algorithms/ Methods Construction or Optimization
3141,"We propose a machine learning algorithm that
uses self-regulation in order to balance the cost
and effect of learning from different types of feedback.",Algorithms/ Methods Construction or Optimization
3142,"We propose a systematic
and principled method of injecting semantic
change in a controlled fashion.",Algorithms/ Methods Construction or Optimization
3143,"We introduce a novel corpus on aspect-based
argument similarity and demonstrate how contextualized word embeddings help to improve clustering similar arguments in a supervised fashion with
little training data.",Dataset Creation or Resources
3144,"We introduce the simplified topic model STM
to infer the latent topic-level representations
and employ such topic-level relevance to recognize Chinese implicit discourse relations.",Model Construction or Optimization
3145,we design a computational methodology to quantitatively track systematic changes along the two dimensions of within- and between-counselor linguistic diversification.,Algorithms/ Methods Construction or Optimization
3146,We present algorithms for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically.,Algorithms/ Methods Construction or Optimization
3147,"We propose a multimodal method that is inspired by the way humans process emotions in a conversation. That is, lexical and acoustic information is simultaneously perceived at every word step.",Algorithms/ Methods Construction or Optimization
3148,"We propose a two-step framework to address the ECPE task, which first performs individual emotion extraction and cause extraction and then conduct emotion-cause pairing and filtering.",Algorithms/ Methods Construction or Optimization
3149,We propose an end-to-end method to incorporate MMR into pointer-generator networks.,Algorithms/ Methods Construction or Optimization
3150,We propose a method for text categorization that complements implicit representation by leveraging a predominant sense of a word.,Algorithms/ Methods Construction or Optimization
3151,we propose a new multi-task learning approach for rumor detection and stance classification tasks.,Algorithms/ Methods Construction or Optimization
3152,It systematically studies word alignment from NMT and proposes two approaches to induce word alignment which are agnostic to specific NMT models,Model Construction or Optimization
3153,"We present MILk attention, which allows us to build the first simultaneous MT system to learn an adaptive schedule jointly with an NMT model that attends over all source tokens read thus far",Algorithms/ Methods Construction or Optimization
3154,"We propose a novel attention regularization method for reducing the noise in DS. Our method forces the model to clearly explain the relation patterns in terms of attention, and selects trustable instances if they can be explained by the model.",Algorithms/ Methods Construction or Optimization
3155,We propose novel algorithms to generate more natural adversarial examples that both preserve the semantics and mislead the classifiers.,Algorithms/ Methods Construction or Optimization
3156,"we present our method for learning representations from imperfect human language across the language, visual, and acoustic modalities.",Algorithms/ Methods Construction or Optimization
3157,we propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations.,Algorithms/ Methods Construction or Optimization
3158,"We propose a debiasing method that preserves the genderrelated information in feminine and masculine
words",Algorithms/ Methods Construction or Optimization
3159,We propose a simple method for TM-NMT integration that is based on augmenting the source data with retrieved fuzzy TM targets by means of concatenation.,Algorithms/ Methods Construction or Optimization
3160,we propose an approach based on dynamic linear combination of layers (DLCL) to memorizing the features extracted from all preceding layers.,Theory Proposal
3161,"we propose a new and simpler method without a priori parallel corpora. Our premise is that NMT systems вЂ”either sequence to sequence models with RNNs, transformers, or any architecture based on encoderвЂ“decoder models",Algorithms/ Methods Construction or Optimization
3162,we introduce a novel constraint-driven approach to learning a document-level (вЂ�globalвЂ™) co-reference model without using any document-level annotation;,Model Construction or Optimization
3163,we propose a reinforcement learning (RL) framework that synchronously searches for training instances relevant to the target domain and learns better representations for them.,Algorithms/ Methods Construction or Optimization
3164,"We introduce a new task of Conversational Question Generation (CQG), which is crucial for developing intelligent agents to drive question-answering style conversations and can potentially provide valuable datasets for future relevant research.",Algorithms/ Methods Construction or Optimization
3165,We propose a novel bi-directional selective mechanism with two gates to mutually select important information from both article and template to assist with summary generation,Algorithms/ Methods Construction or Optimization
3166,We develop a Fast Rerank method to automatically select high-quality templates from training corpus.,Dataset Creation or Resources
3167,"we propose a method to learn to select sentence singletons and pairs, which then serve as the basis for an abstractive summarizer to compose a summary sentence-by-sentence, where singletons are shortened and pairs are merged",Algorithms/ Methods Construction or Optimization
3168,We design a new network that can answer inferential question by recursively deducing the evidence chain from the text,Algorithms/ Methods Construction or Optimization
3169,We propose an effective termination mechanism which can dynamically determine the uncertain reasoning depth,Algorithms/ Methods Construction or Optimization
3170,"we propose a data enrichment method, which uses WordNet to extract inter-word semantic connections as general knowledge from each given passage-question pair",Algorithms/ Methods Construction or Optimization
3171,"We propose A novel text generation task (SQUASH), which converts documents into specificity-based hierarchies of QA pairs.",Theory Proposal
3172,We proposed a novel PU learning algorithm to perform the NER task using only unlabeled data and named entity dictionaries.,Algorithms/ Methods Construction or Optimization
3173,"To make the above assumption hold as far as possible, we propose an adapted method, motivated by the AdaSampling algorithm, to enrich the dictionary.",Algorithms/ Methods Construction or Optimization
3174,we propose a new parsing algorithm for semantic dependency parsing (SDP) that combines transition-based and graph-based approaches,Algorithms/ Methods Construction or Optimization
3175,"we consider using cross-domain LM as a bridge cross-domains for NER domain adaptation, performing crossdomain and cross-task knowledge transfer by designing a novel parameter generation network.",Theory Proposal
3176,"we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created",Algorithms/ Methods Construction or Optimization
3177,A multi-task learning method that uses different sets of features to handle different types of hashtags,Algorithms/ Methods Construction or Optimization
3178,We propose a novel method for analyzing entities in a narrative that is both interpretable and generalizable,Algorithms/ Methods Construction or Optimization
3179,We propose the novel CogQA framework for multi-hop reading comprehension QA at scale according to human cognition,Algorithms/ Methods Construction or Optimization
3180,we propose a new method to solve the multi-hop RC problem across multiple documents.,Algorithms/ Methods Construction or Optimization
3181,We introduce methods based on sentence moverвЂ™s similarity; our automatic metrics evaluate text in a continuous space using word and sentence embeddings.,Algorithms/ Methods Construction or Optimization
3182,To propose a multi-level matching and aggregation network is proposed to encode query instances and class prototypes in an interactive fashion,Algorithms/ Methods Construction or Optimization
3183,"we introduce an adaptive and general framework for measuring similarity of the pairs of relations these distributions are
parameterized by a very simple neural network",Algorithms/ Methods Construction or Optimization
3184,we propose an unsupervised adaptation method which finetunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus.,Algorithms/ Methods Construction or Optimization
3185,we propose a two step pipeline for building a rapid neural MT system for many languages. The pipeline does not require parallel data or parameter fine-tuning when adapting to new source languages.,Algorithms/ Methods Construction or Optimization
3186,"We propose a general method to detect cognates from multilingual lexical resources, with precision and recall parametrable according to usage needs",Algorithms/ Methods Construction or Optimization
3187,we introduce a neural decipherment algorithm that delivers strong performances across several languages with distinct linguistic characteristics.,Algorithms/ Methods Construction or Optimization
3188,we propose a new method for this task based on multilingual sentence embeddings,Algorithms/ Methods Construction or Optimization
3189,"we propose to generate, without supervision, synthetic parallel sentences that can be directly exploited to jointly train BWE with existing algorithms",Applications
3190,we define and distinguish three aspects constituting to quality of biomedical name representations. We propose a novel encoding framework that considers all these aspects in the representation learning.,Algorithms/ Methods Construction or Optimization
3191,"We also present SemGCN, a framework for incorporating diverse semantic knowledge in learned word embeddings, without requiring relation-specific special handling as in previous methods.",Algorithms/ Methods Construction or Optimization
3192,"we propose delta embedding learning, a novel method that aims to address the above problems together: using regularization to find the optimal fine-tuning of word embeddings.",Algorithms/ Methods Construction or Optimization
3193,"We investigate how an LSTM language model deals with lexical ambiguity in English, designing a method to probe its hidden representations for lexical and contextual information about words.",Algorithms/ Methods Construction or Optimization
3194,We propose a Method for mapping entities from a graphical representation to the space in which a pretrained embedding lies,Algorithms/ Methods Construction or Optimization
3195,"Based on the proposed model, we develop a simple yet effective method for unsupervised domain adaptation.",Applications
3196,Our goal is to present a patient biomedical QA system that can address the gaps in biomedical research and allows a patient to query their symptoms,Theory Proposal
3197,methods for extracting of aggregated knowledge from patient experiences on online fora,Algorithms/ Methods Construction or Optimization
3198,"a method for cross-linking curated knowledge and complementary patient knowledge, and",Algorithms/ Methods Construction or Optimization
3199,"we propose a general approach for permuting the words in an input sentence based on the notion of simplification,",Algorithms/ Methods Construction or Optimization
3200,we present an unsupervised pretraining method for NMT models using Elastic Weight Consolidation,Algorithms/ Methods Construction or Optimization
3201,we propose a method for neural grammar error correction (GEC) that can control the degree of correction,Algorithms/ Methods Construction or Optimization
3202,we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs.,Algorithms/ Methods Construction or Optimization
3203,", we propose a novel task, automatically generating personalized comment based on
user profile.",Algorithms/ Methods Construction or Optimization
3204,", we propose an inexpensive, scalable, CPUtrainable and efficient method of extractive text
summarization based on the use of sentence embeddings.",Algorithms/ Methods Construction or Optimization
3205,"we propose a method for add weights to a training loss according to levels of words on top of (Scarton and Specia, 2018), and thus output only words under the desired level.",Algorithms/ Methods Construction or Optimization
3206,we present a hybrid architecture for the task of Sentiment Analysis of EnglishHindi code-mixed data,Algorithms/ Methods Construction or Optimization
3207,"we propose an unsupervised
method to capture discourse structure in terms
of cohesion and coherence for document embedding.",Algorithms/ Methods Construction or Optimization
3208,". SEARCHER, a novel CLIR approach designed
for low-resource conditions that relies on the
construction of a shared semantic space learned
from bitext and monolingual corpora",Algorithms/ Methods Construction or Optimization
3209,"We present an approach to rapidly gather event trigger examples for new event types, with minimal human effort.",Algorithms/ Methods Construction or Optimization
3210,We develop a User Interface (UI) to further expedite and improve the time efficiency of our approach,Algorithms/ Methods Construction or Optimization
3211,", we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism",Algorithms/ Methods Construction or Optimization
3212,"We introduce an open-source web-based data
annotation framework (AlpacaTag) for sequence tagging tasks such as named-entity
recognition (NER)",Algorithms/ Methods Construction or Optimization
3213,"we introduce a Knowledge-Constraint Typing Annotation Tool (KCAT1 ), which is efficient for fine-grained entity typing annotation",Algorithms/ Methods Construction or Optimization
3214,"We develop GLTR, a tool to support humans in detecting whether a text was generated by a model",Algorithms/ Methods Construction or Optimization
3215,"we develop and evaluate a multilabel, multidimensional deep neural network designed to predict PHQ-4 scores based on individuals written text",Algorithms/ Methods Construction or Optimization
3216,we propose a new method for the evaluation of frame induction enabling straightforward comparison of approaches,Algorithms/ Methods Construction or Optimization
3217,we propose methods for automatic seed selection for bootstrapping RE and noise reduction for distant supervised RE,Algorithms/ Methods Construction or Optimization
3218,"we propose the new task of automatic article commenting, and introduces a large-scale Chinese dataset1 with millions of real comments and a humanannotated subset characterizing the commentsвЂ™ varying quality",Algorithms/ Methods Construction or Optimization
3219,"we design an effective syntaxbased evaluator is built as a post-hoc checker, yielding compression with better quality based upon the evaluation metrics",Algorithms/ Methods Construction or Optimization
3220,we learn word and sentence embeddings jointly by training a multilingual skip-gram model together with a cross-lingual sentence similarity model,Model Construction or Optimization
3221,"we propose an approach that aims at injecting syntactic information in NNs, still keeping them simple",Algorithms/ Methods Construction or Optimization
3222,we present a simple and effective approach by introducing a coverage-based feature into NMT,Algorithms/ Methods Construction or Optimization
3223,"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training se",Algorithms/ Methods Construction or Optimization
3224,"we propose Pseudofit, a method that improves word embeddings without external knowledge and focuses on semantic similarity and synonym extraction",Algorithms/ Methods Construction or Optimization
3225,"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them",Algorithms/ Methods Construction or Optimization
3226,We formulate constrained sparsemax and derive efficient linear and sublinear-time algorithms for running forward and backward propagation,Algorithms/ Methods Construction or Optimization
3227,We present a simple approach to select assisting language sentences based on symmetric KLDivergence of overlapping entities,Algorithms/ Methods Construction or Optimization
3228,"We devise a novel loss function which penalizes wrong spans that cross gold-tree spans, and employ max-violation update (Huang et al., 2012) to train this parser with structured SVM and beam search",Algorithms/ Methods Construction or Optimization
3229,we propose a new method that can leverage unlabeled data to learn matching models for retrieval-based chatbots,Algorithms/ Methods Construction or Optimization
3230,"we show that there are relations
between sentences and semantic representations
which can be described by compositional mechanisms which are bounded and non-projective, but
not by ones which are bounded and projective.",Theory Proposal
3231,"more importantly, we demonstrate, on several sentence-matching datasets, that simply evaluating the Hamming distance over binary representations performs on par or even better than calculating the cosine similarity between their continuous counterparts",Performance Evaluation
3232,"We propose a
technique to quantitatively estimate this assumption of the isometry between two embedding spaces and empirically show that this assumption weakens as the languages in question become increasingly etymologically distant.",Performance Evaluation
3233,We present a large-scale evaluation of multilingual subword representations on two sequence tagging tasks,Performance Evaluation
3234,"We evaluate our approach on three different
NLP tasks: machine comprehension, textual
entailment, and text chunking. We show that
augmented models lead to large performance
gains in the low training data regimes",Performance Evaluation
3235,"We frame the problem of open-domain argument search as a combination of topic-dependent
argument classification and clustering and discuss how contextualized word embeddings can
help to improve these tasks across four different
datasets.",Model Construction or Optimization
3236,"After
training a supervised deep learning algorithm to
predict attachments on the STAC corpus1
, we then
constructed a weakly supervised learning system
in which we used 10% of the corpus as a development set.",Algorithms/ Methods Construction or Optimization
3237,"we frame zero-shot learning as
a challenge for pragmatic modeling and explore
zero-shot reference games, where a speaker needs
to describe a novel-category object in an image to
an addressee who may or may not know the category",Theory Proposal
3238,"Our new method outperforms previous methods by a significant margin on both the previous closed domain WSJ dataset as well as on
all open-domain ones, setting the new stateof-the-art for coherence modelling.",Algorithms/ Methods Construction or Optimization
3239,"Even with the simplest sentence encoder, averaged GloVe, our method frequently outperforms previous methods, while it can gain
further accuracy by using stronger encoders.",Algorithms/ Methods Construction or Optimization
3240,"We provide a comprehensive
comparative evaluation of a wide range of stateof-the-artвЂ”both supervised and unsupervisedвЂ”
projection-based CLE models.",Performance Evaluation
3241,"We unify
evaluation protocols for all models and conduct experiments over 28 language pairs spanning diverse
language types.",Performance Evaluation
3242,"provides a benchmark to evaluate the ability of understanding idioms, a unique yet common language phenomenon in Chinese.",Theory Proposal
3243,"We conduct extensive experiments on the design of candidate idioms and the idiom representation methods, and compare state-ofthe-art models.",Performance Evaluation
3244,evaluates token-level topic assignment quality to understand which topic models produce meaningful local topics for individual documents and proposes metrics that correlate with human judgment of the quality of these assignments.,Performance Evaluation
3245,"we evaluate the proposed models to perform
multi-domain joint learning of slot filling and
intent classification on both public datasets
and a real-world dataset from the Alexa virtual assistant;+99:116",Performance Evaluation
3246,"We explore how to resolve pronoun coreferences with KGs, which outperforms all existing models by a large margin on datasets from two different domains.",Model Construction or Optimization
3247,We evaluate the performance of different pronoun coreference models in a cross-domain setting and show that our model has better generalization ability than state-of-the-art baselines.,Model Construction or Optimization
3248,We evaluate a large number of baselines on SherLIiC. The best-performing baseline makes use of typing,Performance Evaluation
3249,analysis of the performance of the models that provides meaningful insights for further improvements,Performance Evaluation
3250,"We test models for open-domain and multi-choice QA, showing the complexity of the dataset and its utility to encourage progress in QA",Performance Evaluation
3251,"We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers.",Performance Evaluation
3252,"We perform two tasks, a classification and a regression one.
The evaluation shows that our proposed model
successfully outperforms the earlier reported results in PeerRead",Model Construction or Optimization
3253,Defining evaluation metrics and providing comparisons with several baselines to assess the model performance.,Performance Evaluation
3254,we consider a novel and realistic set-up where a much larger amount of sentencelevel data is available compared to that aligned at the document level,Theory Proposal
3255,"We verify our GP-GNNs on the task of relation extraction from text, which demonstrates its ability on multi-hop relational reasoning as compared to those models which extract relationships separately.",Performance Evaluation
3256,"We evaluate our fine-tuned language model
on the NYT10 dataset and show that it achieves a state-of-the-art AUC compared
to RESIDE 2018 and
PCNN+ATT in held-out
evaluation",Performance Evaluation
3257,"We publish a better manually labeled sentence-level test set1 for evaluating the performance of RC models. This test set contains 1,024 sentences and 4,543 entity pairs, and is carefully annotated to ensure accuracy.",Dataset Creation or Resources
3258,"We evaluate our Quaternion NLP models on
a wide range of diverse NLP tasks such as
pairwise text classification, neural
machine translation (NMT), sentiment analysis, mathematical language understanding
(MLU), and subject-verb agreement",Performance Evaluation
3259,"We formulate routing processes as a proxy problem minimizing a total negative agreement score in order to evaluate how routing processes perform at instance level, which will be discussed more in depth later",Algorithms/ Methods Construction or Optimization
3260,We show that training with delayed rewards achieves better performance than maximum likelihood training across six different historical text normalization benchmarks,Theory Proposal
3261,we present a transparent framework and metric for evaluating discrimination across protected groups with respect to their word embedding bias,Algorithms/ Methods Construction or Optimization
3262,"we aim to combine the power of neural networks with the dataefficiency of logical forms by pre-learning abstractions in a semi-supervised way, satiating part of the networkвЂ™s data hunger on cheaper unlabeled data from the environment.",Theory Proposal
3263,We develop a series of automatic evaluation metrics to comprehensively assess the quality of the generated essay.,Performance Evaluation
3264,"We evaluate our models on data with humanconstituted trees or parsed trees, and yield promising results in generating sentences with better reconstruction loss and less grammatical errors, compared to other baseline methods.",Performance Evaluation
3265,We propose DIM to capture the duality and adopt variational approximation to maximize the dual information,Algorithms/ Methods Construction or Optimization
3266,"The experimental results demonstrate that our model is competitive with or outperforms other unsupervised models. In particular, for long reviews, it achieves a competitive or better performance than the supervised models.",Performance Evaluation
3267,We propose Empirical evaluations on the benchmark dataset show our model has achieved a new state of the art.,Performance Evaluation
3268,"we show that our model improves performance over ADA and an expanded vocabulary alone and further, that a limited amount of labeled target data can achieve performance close to training on all labeled target data.",Performance Evaluation
3269,we compare different NLI models regarding their ability to rank more correct summaries above incorrect alternatives.,Performance Evaluation
3270,"we present a neural rewriter for multi-sentence compression without any parallel data. This rewriter significantly improves the grammaticality and novel word rate, while maintaining the information coverage according to automatic evaluation",Algorithms/ Methods Construction or Optimization
3271,"Our Dynamic Self-attention Network (DynSAN) achieves new state-of-the-art performance compared with previously published results on SearchQA, Quasar-T and WikiHop benchmarks.",Performance Evaluation
3272,"We show the effectiveness of our approach, which achieves state-of-the-art results in both single- and multi-hop open-domain QA benchmarks.",Performance Evaluation
3273,We correlate several linguistically- and psycholinguisticallymotivated predictors to parsing accuracy on a large multilingual grammar induction evaluation data set.,Performance Evaluation
3274,"Framing the problem as pairwise ranking using novel neural approaches, in contrast to previous work which ignored the relative order of candidate segmentations",Theory Proposal
3275,"We experimentally confirm that our method is much more effective than several state-of-theart claim verification models using three public benchmark datasets collected from snopes.com, politifact.com and Wikipedia.",Performance Evaluation
3276,We explore a neural model of stylistic variation that can predict socioeconomic status with good performance,Model Construction or Optimization
3277,We investigate how to label comments for ranking and clarify that the performance of pairwise ranking models tends to be more enhanced by the variation in comments than that in articles,Performance Evaluation
3278,"The experiments show that our approach can achieve better performance than competitive baselines. With multiple modal information and co-attention, the generated comments are more diverse and informative.",Algorithms/ Methods Construction or Optimization
3279,"To evaluate model performance, we collect and annotate a large-scale dataset from Google Business News1 with diverse event types and explainable event schemas.",Performance Evaluation
3280,"we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words.",Theory Proposal
3281,"We propose to improve the robustness of NMT to homophone noises by jointly embedding both textual and phonetic information of source sentences,",Algorithms/ Methods Construction or Optimization
3282,"We make a thorough empirical evaluation of different ways of coupling BERT models in an APE system, comparing different options of parameter sharing, initialization, and fine-tuning.",Theory Proposal
3283,we propose to boost lowresource cross-lingual document retrieval performance with deep bilingual query-document representations.,Algorithms/ Methods Construction or Optimization
3284,"Extensive experimental results show that our approach achieves better performance than several state-of-the-art unsupervised systems, and even achieves competitive performance compared to supervised methods",Algorithms/ Methods Construction or Optimization
3285,"we evaluate the proposed encoder in biomedical synonym retrieval, name normalization, and semantic similarity and relatedness benchmarks.",Performance Evaluation
3286,"We evaluate our corpus by using it to train supervised classifiers to automatically assign aspectual categories to verbs in context, permitting favourable comparisons to previous work.",Algorithms/ Methods Construction or Optimization
3287,"we propose a novel approach for manual evaluation, HIGHlight-based Referenceless Evaluation of document Summarization",Algorithms/ Methods Construction or Optimization
3288,We demonstrate that the model achieves more interpretable and controllable generation of paraphrases.,Performance Evaluation
3289,"adding paraphrases with additional multilingual data yields mixed performance; its performance is better than training on language families alone, but is worse than training on both the source and target paraphrases without language families.",Theory Proposal
3290,"A system that jointly performs NER and EL, with competitive results in both tasks.",Theory Proposal
3291,A empirical qualitative analysis of the advantage of doing joint learning vs using separate models and of the influence of the different components to the result obtained.,Theory Proposal
3292,we do an in-depth analysis of how adding community features may enhance the performance of classification models that detect religious hate speech in Arabic.,Theory Proposal
3293,we define two ways of combining contextual and static embeddings and conclude that the naive concatenation of vectors is consistently outperformed by the addition of the static representation directly into the internal linear combination of ELMo;,Theory Proposal
3294,"we perform an analytic comparison of these methods, and introduce our own results. By fine-tuning GoogleвЂ™s
recently published transformer-based architecture, BERT, on the fake review detection task",Theory Proposal
3295,". A configuration format that natively enables
searching over hyperparameters and running
remote multistage experiments at scale.",Theory Proposal
3296,"critical examinations of different training conditions and requirements under which unsupervised
algorithms can and cannot work effectively",Performance Evaluation
3297,the first corpus for evaluating mistake detection and correction in a medical patient forum,Algorithms/ Methods Construction or Optimization
3298,"We investigate the use of a
language representation model BERT trained
to obtain semantic representations of social
media texts",Performance Evaluation
3299,"we evaluate the linguistic differences between temporal cohorts, e.g. 20-year-olds in 2011 vs. 20-year-olds in 2015",Performance Evaluation
3300,we achieve state-of-the-art performance in CoNLL 2003 NER shared task,Algorithms/ Methods Construction or Optimization
3301,"We adopt the pointer network to handle the OOV problem in slot value prediction, which achieves good performance without any manually-designed rules or features",Algorithms/ Methods Construction or Optimization
3302,"we investigate how to simplify and recover abugidas, with the aim of developing a more efficient method of encoding abugidas for input",Algorithms/ Methods Construction or Optimization
3303,"we propose a conceptually simpler
approach to the issue, which is agnostic on any
parser architecture, namely, automatic generation
of CCGbanks (i.e., CCG treebanks)1
for new domains, by exploiting cheaper resources of dependency trees.",Algorithms/ Methods Construction or Optimization
3304,we present the first study exploiting capsule networks for determining sentence similarity for summarization purpose. It is important to recognize that summarization places particular emphasis on measuring redundancy between sentences,Theory Proposal
3305,we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities.,Theory Proposal
3306,"We introduce a contextual gating mechanism to incorporate multiple types of embeddings, word, speech, and conversationalcontext embeddings.",Algorithms/ Methods Construction or Optimization
3307,we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences,Theory Proposal
3308,"We demonstrate favorable trade-offs to those of wait-k strategies at many latency values, and provide evidence that MILkвЂ™s advantage extends from its ability to adapt based on source content",Theory Proposal
3309,"We write and enabling the quick generalization to new relation types by only requiring a small number
of human annotations",Theory Proposal
3310,"We propose to perform KG inference and alignment jointly, so that the heterogeneity of KGs are explicitly reconciled through completion by rule inference and transfer, and pruning via cross-KG attention.",Dataset Creation or Resources
3311,"We construct entmax sparse attention, improving interpretability at no cost in accuracy.
We show that the entmax gradient has a simple
form revealing an insightful
missing link between softmax and sparsemax.",Algorithms/ Methods Construction or Optimization
3312,"We conduct comprehensive experiments to examine the robustness of RNN, Transformer, and BERT. Our results show that both
self-attentive models, whether pre-trained or
not, are more robust than recurrent models.",Performance Evaluation
3313,"We critically discuss issues with current debiasing methods with the purpose of identifying optimizations, knowledge gaps, and directions for future research.",Theory Proposal
3314,"we first empirically characterize the racial bias present in several widely used Twitter corpora annotated for toxic content, and quantify the propagation of this bias through models trained on them",Applications
3315,We present an innovative idea for taking advantage of pretrained embeddings by using them as an objective during training.,Theory Proposal
3316,we offer a holistic quantification of the systematicity of the sign using mutual information and recurrent neural networks.,Theory Proposal
3317,we explore the use of multitask learning and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging.,Theory Proposal
3318,we show how Wikipedia and unlabeled data can be used to construct an accurate linker which rivals linkers constructed using expensive human supervision,Algorithms/ Methods Construction or Optimization
3319,"We Propose a novel entity-aware model for data-to-text generation which is linguistically motivated, yet resource lean (no preprocessing is required",Model Construction or Optimization
3320,"we note some writer-specific patterns and characteristics: how data records are selected to be mentioned; and how data records are expressed as text, e.g., the order of data records and the word usages.",Algorithms/ Methods Construction or Optimization
3321,we propose a new approach to automatically generate summaries for scientific papers based on video talks,Algorithms/ Methods Construction or Optimization
3322,we investigate the factors involved in representing sentence singletons and pairs. We perform extensive experiments and report findings on sentence selection and abstraction.,Theory Proposal
3323,we propose the use of artificial titles for unlabeled target documents to train a decoder to learn the grammatical style of titles in the new domain,Theory Proposal
3324,we present a detailed error analysis and discuss potential areas of improvements for consumer health question summarization.,Algorithms/ Methods Construction or Optimization
3325,"We also propose using sentence-level representations for retrieval, and show the possible benefits of this approach over paragraph-level representations.",Theory Proposal
3326,"We investigate and demonstrate the feasibility of enhancing pre-trained LMs with rich knowledge for MRC. To our knowledge, this is the first study of its kind, indicating a potential direction for future research.",Theory Proposal
3327,investigating new configurations of GNNs for handling direct edges and nodes with multiple representations.,Theory Proposal
3328,"We quantitatively show the significance of each modality in Twitter sarcasm detection. We further show that to fully unleash the potential of images, we would need to consider image attributes",Theory Proposal
3329,Our study aims to help this body of research grow by automating the process of collection of tweets containing recollections of sexual harassment.,Theory Proposal
3330,"we highlight the importance of contextualizing social information, capturing how this information is disseminated in social networks",Theory Proposal
3331,we investigate novel decompositions of the story generation process that break down the problem into a series of easier coarse-tofine generation problems.,Theory Proposal
3332,We show that the cognitive graph structure in our framework offers ordered and entitylevel explainability and suits for relational reasoning.,Performance Evaluation
3333,We learn incremental suggestion models for little data scenarios through continuous adjustments of the suggestion model and discuss suitable setups.,Model Construction or Optimization
3334,We propose a criterion to distinguish between obvious and non-obvious examples in text pair similarity datasets,Theory Proposal
3335,We define the types of relationships between the text and the image of a social media post,Theory Proposal
3336,"we build on extensions of HarrisвЂ™ distributional hypothesis to relations, as well as recent advances in learning text representations to build task agnostic relation representations solely from entity-linked text.",Algorithms/ Methods Construction or Optimization
3337,we present a differentiable approach to extractive rationales including an objective that allows for specifying how much text is to be extracted,Algorithms/ Methods Construction or Optimization
3338,The pipeline only requires a comprehensive source to target dictionary. We show that this dictionary can be easily obtained using offthe shelf tools within a few hours.,Performance Evaluation
3339,we empirically show that jointly training multiple languages improves separately trained bilingual models,Performance Evaluation
3340,We also show how simple techniques over our data yield competitive results in building crosslingual word embeddings and annotation projection for part-of-speech tagger induction.,Theory Proposal
3341,we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing.,Theory Proposal
3342,we study the benefits of hybrid strategies of hypernymy via a hybrid of extremely simple models of pattern-based and distributional hypernym discovery.,Theory Proposal
3343,we describe the commonly used approaches in a subarea of interest and specify their features which could improve or deteriorate the performance of these models,Theory Proposal
3344,We focus on the NLG approaches based on semantic representations and discuss their advantages and limitations.,Theory Proposal
3345,"analyzing the shortcomings of sum and maxmargin loss, proposing a kNN-margin loss as a trade-off (for training);",Theory Proposal
3346,we define a hop as a computational step which could be performed for an output symbol many times,Theory Proposal
3347,"we propose a fullyautomated, context-aware machine translation approach with fewer stages of processing.",Algorithms/ Methods Construction or Optimization
3348,"We compare several approaches for conditioning on the model predictions when they
are used instead of the gold target.",Theory Proposal
3349,"we report on our shared framework and infrastructure that drives a multitude
of linguistic visualization projects,",Performance Evaluation
3350,"ConvLab provides a rich set of tools and recipes to develop dialog systems of different types, enabling researchers to compare widely different approaches under the same condition.",Algorithms/ Methods Construction or Optimization
3351,"an unsupervised datadriven spelling correction method that works well
on specialized domains with many OOV terms
without the need for a specialized dictionary",Algorithms/ Methods Construction or Optimization
3352,"we analyze the role of linguistic context in both humans and the models, with implications for cognitive plausibility and future modeling work",Theory Proposal
3353,"we use petitions from the official UK and US government websites, whereby citizens can directly appeal to the government for action on an issue",Dataset Creation or Resources
3354,"we allow for an underlying mapping function that is non-linear, but assume that it can be approximated by linear maps at least in small enough neighborhoods",Applications
3355,"we extend the research to investigate the impact of context on human acceptability judgements, where context is defined as the full document environment surrounding a sentence",Algorithms/ Methods Construction or Optimization
3356,"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes.",Model Construction or Optimization
3357,"we take a step in that direction and
confirm some of these speculations, showing that
models do not make use of a lot of the information available to it, by subjecting the dialog history to a variety of synthetic perturbations.",Model Construction or Optimization
3358,"We perform systematic analyses on nine languages using two different architectures (transition-based and graph-based) across
two dimensions: with and without BiLSTM representations, and with and without features drawn
from structural context.",Performance Evaluation
3359,"we investigate
words classified by L&M as negative, litigious and
uncertain that our embedding classifier classifies
otherwise",Theory Proposal
3360,"we examine analystsвЂ™ decision making behavior as it pertains to the
language content of earnings calls.",Performance Evaluation
3361,"We provide a general
modular framework for sequence learning tasks.
While we focus on sentiment analysis task, the
framework is broadly applicable to many other
tagging tasks",Algorithms/ Methods Construction or Optimization
3362,"several principled model changes
to produce better structures but that still do not resemble the structure of discourse.",Model Construction or Optimization
3363,comprehensive performance results on existing and additional tasks and datasets showing document-level structured attention is largely unhelpful,Performance Evaluation
3364,"We eliminate the dependency on the structure of a semantic network by relying only on
the association between Wikipedia pages and
categories and on a sparse vector representation of concepts",Theory Proposal
3365,"we provide the first large-scale
evaluation of an extensive number of approaches.",Performance Evaluation
3366,approach to mention detection for large-scale coreference annotation projects in which the output of mention detectors is corrected using a Gamewith-a-Purpose,Algorithms/ Methods Construction or Optimization
3367,"To overcome the multi-turn mapping problem,
TRADE leverages its context-enhanced slot
gate and copy mechanism to properly track slot values mentioned anywhere in dialogue history",Algorithms/ Methods Construction or Optimization
3368,we demonstrate experimentally the superiority of introducing group-level features and learning features in both parallel and serial ways.,Theory Proposal
3369,"we define the task, including the annotation scheme for labeling the clinical conversations and the evaluation metrics to measure model performance",Algorithms/ Methods Construction or Optimization
3370,"we address this knowledge gap by examining how individuals change their conversational language in a domain with profound societal importance, where conversations play a primary role: mental health counseling.",Theory Proposal
3371,"we describe the process of acquiring, anonymizing and filtering the dataset, deduplicating the answer set, and our first attempts towards automating the answering of questions.",Dataset Creation or Resources
3372,"We present HEAD-QA, a multichoice testbed of graduate-level questions about medicine, nursing, biology, chemistry, psychology, and pharmacology",Dataset Creation or Resources
3373,"we take a step towards closing this gap, by introducing the task of Debate Topic Expansion вЂ“ finding related topics that can enrich our arguments and strengthen our case when debating a given topic.",Theory Proposal
3374,"we aim to explicitly define a taxonomy of such principled recurring arguments, and, given a controversial topic, to automatically identify which of these arguments are relevant to the topic",Theory Proposal
3375,"we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and learning schemas",Theory Proposal
3376,we find an effective way to improve current frameworks and achieve the state-ofthe-art result on CNN/DailyMail by a large margin based on our observations and analyses.,Algorithms/ Methods Construction or Optimization
3377,"We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them",Theory Proposal
3378,"we focus on the problem of generating valid adversarial examples for text classification, which could inspire more works for NLP attack and defense.",Theory Proposal
3379,We introduce an approach that models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts,Algorithms/ Methods Construction or Optimization
3380,we use neural sequence generation models for automatic conversion of poetry to prose. Lack of sufficient poetry-prose parallel data is an impediment in framing the problem as a seq2seq task,Model Construction or Optimization
3381,"We introduce language-sensitive embedding, attention, and discriminator which augment the ability of Multi-NMT model in distinguishing different languages.",Model Construction or Optimization
3382,"We understand NMT from the viewpoint of
word alignment and investigates the effect
of alignment errors on translation errors via
quantitative analysis over many testing examples.",Theory Proposal
3383,"we utilize both large-scale textual corpora and KGs to train an enhanced language
representation model, which can
take full advantage of lexical, syntactic, and
knowledge information simultaneously.",Model Construction or Optimization
3384,we firstly recognize named entity mentions in text and then align these mentions to their corresponding entities in KGs,Algorithms/ Methods Construction or Optimization
3385,we hypothesize that the underperformance of monotonic models stems from the lack of joint training of the alignments with the transduction.,Performance Evaluation
3386,"We 
summarize recent studies of algorithmic bias in
NLP under a unified framework for the ease of future discussion.",Dataset Creation or Resources
3387,We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights.,Performance Evaluation
3388,We show that the proper use of layer normalization is the key to learning deep encoders. The deep network of the encoder can be optimized smoothly by relocating the layer normalization unit.,Applications
3389,"we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation.",Algorithms/ Methods Construction or Optimization
3390,"We tackle a novel task, namely weakly-supervised spatio-temporally video grounding (WSSTG), which localizes a spatiotemporal tube in a given video that semantically corresponds to a given natural sentence, in a weakly-supervised manner",Algorithms/ Methods Construction or Optimization
3391,we provide evidence that fully-annotated documents may not be as beneficial as previously believed.,Performance Evaluation
3392,"We present the first work to generate modern Chinese poetry while controlling for the use of metaphor and personification, which play an essential role in enhancing the aesthetics of poetry",Algorithms/ Methods Construction or Optimization
3393,"we report correctness estimates for summaries generated by three recent abstractive summarization systems, showing that even recent state-of-the-art
models have errors in 25% of their summaries",Performance Evaluation
3394,"To the best of our knowledge, we are the first to consider using the whole document to learn contextualized sentence representations with selfsupervision and without any human annotations.",Theory Proposal
3395,"we explore data augmentation techniques, including semantic selection from open-domain datasets, and study the behavior of state-of-the-art neural abstractive models on the original and augmented datasets",Performance Evaluation
3396,We propose Dynamic Self-attention (DynSA) for information interaction in a long sequence.,Algorithms/ Methods Construction or Optimization
3397,"We introduce the pointer-generator mechanism for generating an abstractive answer from the question and multiple passages, which covers various answer styles",Algorithms/ Methods Construction or Optimization
3398,"Our model achieves state-of-the-art results on
PTB and CTB for both constituent and dependency parsing",Model Construction or Optimization
3399,"We proved that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data, under the assumption that the entities found out by the dictionary can reveal the distribution of entities.",Performance Evaluation
3400,we show that multitask learning of state representations for this parsing algorithm is superior to single-task training,Performance Evaluation
3401,"introducing graph neural networks to dependency parsing, which aims to efficiently encode high order information in dependency tree node representations.",Theory Proposal
3402,We show an assessment of how well contextualized word embeddings capture affect information,Performance Evaluation
3403,We show empirical evidence that constructiveness scores are not always related to positive user feedback such as вЂњLikeвЂќ-button clicks,Theory Proposal
3404,we propose to exploit social media and natural language processing techniques to enhance air quality prediction.,Theory Proposal
3405,We study the effects of automatically suggesting annotations to expert annotators across two domains for a hard discourse-level sequence labelling task.,Performance Evaluation
3406,"We propose a solution that meets our three criteria. Particularly, we adapt to our problem the recently presented concept of Almost Stochastic Order (ASO) between two distributions",Theory Proposal
3407,"we would like to focus on the joint effects of conversation context and user history, ignoring other information.",Theory Proposal
3408,To analyse into the authorвЂ™s demographic traits that are related to usage preference of textimage relationship types,Theory Proposal
3409,To analyze manually annotated corpus of claims from debates about migration found in German newspaper reports,Theory Proposal
3410,"we introduce HardKuma, which gives support to binary outcomes and allows for reparameterized gradient estimates",Algorithms/ Methods Construction or Optimization
3411,we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. C,Algorithms/ Methods Construction or Optimization
3412,we propose a strategy to train multilingual unsupervised NMT for one source to many targets and many targets to one source translations,Theory Proposal
3413,"we also show that without training the network for many-to-many translations, the network can translate between all the languages participating in the training",Theory Proposal
3414,We propose teaching both summary word generation distribution and attention weights in the cross-lingual ASSUM networks by using the monolingual ASSUM networks.,Theory Proposal
3415,We demonstrate consistent and significant improvements on benchmark datasets in unsupervised and supervised settings.,Algorithms/ Methods Construction or Optimization
3416,We devise a straightforward and efficient approach for combining distributional and hypernymy information for the task of noun phrase compositionality prediction.,Algorithms/ Methods Construction or Optimization
3417,"we claim that vector space models, despite giving close representations for synonyms and antonyms, contain subtle differences that allow to discriminate antonymy.",Theory Proposal
3418,We propose An approach to constructing graphical representations of entities in a knowledge base in an unsupervised manner.,Algorithms/ Methods Construction or Optimization
3419,"we
show that existing embedding models are inadequate at constructing representations that
capture salient aspects of mathematical meaning for numbers, which is important for language understanding.",Theory Proposal
3420,How is personal recovery discussed online by individuals meeting criteria for BD?,Theory Proposal
3421,What new insights do we get about personal recovery and factors that facilitate or hinder it?,Theory Proposal
3422,"This research proposal consequently explores this question in the context of a neural morphological analyzer for a polysynthetic language, St",Model Construction or Optimization
3423,"we find that over the past few decades, gender stereotypes in writings by males have decreased.",Theory Proposal
3424,"Our paraphrase-exploiting NMT uses only two languages, the source and the target languages, and achieves higher BLEUs than the multi-source and multi-target NMT that incorporates more languages",Algorithms/ Methods Construction or Optimization
3425,a system for ranking explicit and implicit questions by their appropriateness in a dialogue is presented,Algorithms/ Methods Construction or Optimization
3426,we investigate the effect of the textual information of the tweets that target users liked/retweeted.,Theory Proposal
3427,"we present a machine learning approach for information extraction, which has a recall of 80% for a social media data source.",Algorithms/ Methods Construction or Optimization
3428,", we investigate the efficacy
of bias reduction during training by introducing a
new loss function which encourages the language
model to equalize the probabilities of predicting
gendered word pairs like he and she.",Algorithms/ Methods Construction or Optimization
3429,"Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts currently surpasses the benchmark results on the same dataset.",Algorithms/ Methods Construction or Optimization
3430,we propose an artificial neural network (ANN) solution which does not use a lexicon or any other manually labeled source.,Theory Proposal
3431,"we explored the use of a domain-independent, multilingual lexicon of abusive words called HurtLex (Bassignana et al., 2018) in both cross-domain and cross-lingual settings",Theory Proposal
3432,"we use logic-based representations as
unified meaning representations for texts and
images and present an unsupervised multimodal logical inference system that can effectively prove entailment relations between
them",Algorithms/ Methods Construction or Optimization
3433,"we focus on
extraction information of adverse drug reactions from various sources of biomedical textbased information, including biomedical literature and social media",Theory Proposal
3434,"Our system shows the incorrect sentences and
the corresponding sentence as corrected by
a native speaker. Thus, learners can rectify
their mistakes during composition.",Dataset Creation or Resources
3435,". An intuitive snippet extraction and presentation design which has been shown in human studies to provide readers with sufficient evidence to filter out erroneous query matches and preserve good ones, even in low-resource conditions",Theory Proposal
3436,to provide a highly flexible research framework not only for technique oriented developers but also for non-technical oriented developers such as linguists,Algorithms/ Methods Construction or Optimization
3437,"Modular machine learning components to develop replicable, state of the art research
results. This includes: neural network
components (pretrained or not), benchmark
datasets, and standardized training and evaluation modules.",Theory Proposal
3438,"an overview of linguistic structures and corresponding discourse analysis tasks that discourse researchers are generally interested in,
as well as key applications on which these discourse structures have an impact",Theory Proposal
3439,"We aim to provide a gentle, all-round
introduction to methods and tasks related to computational analysis of political texts",Theory Proposal
3440,"addresses the fundamentals
of statistical models and neural networks, and focus on a series of advanced Bayesian models and
deep models",Theory Proposal
3441,we present a new task and results for training models to learn semantically-rich function words,Model Construction or Optimization
3442,we introduce a new way to deal with the problem of offensive language on social media,Theory Proposal
3443,"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation",Algorithms/ Methods Construction or Optimization
3444,"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models",Performance Evaluation
3445,We design the first neural parser that is both linear time and capable of searching over exponentially large space,Algorithms/ Methods Construction or Optimization
3446,We propose a modularized hierarchical convolutional neural network model that considers the overall information of the source paper,Model Construction or Optimization
3447,we propose to combine string kernels (low-level character n-gram features) and word embeddings (high-level semantic features) to obtain state-of-the-art AES results,Model Construction or Optimization
3448,"we develop a more principled approach to unsupervised SMT, addressing several
deficiencies of previous systems by incorporating subword information, applying a theoretically
well founded unsupervised tuning method, and developing a joint refinement procedure.",Algorithms/ Methods Construction or Optimization
3449,"Our model achieves new state-of-the-art results without additional computational over
Implementation is based on Pytorch (Paszke et al., 2017).
head when compared with previous GCNs.
Unlike tree-structured models (e.g., TreeLSTM (Tai et al., 2015)), it can be efficiently
applied over dependency trees in parallel.",Model Construction or Optimization
3450,"We find that different methods have different strengths: Monolingual BPEmb works
best in medium- and high-resource settings,
multilingual non-contextual subword embeddings are best in low-resource languages,
while multilingual BERT gives good or best
results across languages.",Performance Evaluation
3451,"we propose a span-based
extract-then-classify framework, where multiple opinion targets are directly extracted from
the sentence under the supervision of target
span boundaries, and corresponding polarities
are then classified using their span representations.",Algorithms/ Methods Construction or Optimization
3452,"We create SherLIiC, a new resource for LIiC, consisting of 3985 manually annotated InfCands. Additionally, we provide ~960k unlabeled InfCands (SherLIiC-InfCands), and the typed event graph SherLIiC-TEG, containing ~190k typed textual binary relations between Freebase entities.",Dataset Creation or Resources
3453,"we conduct extensive analyses on conversational aspects such as turn-by-turn interaction, the sentiment expressed during the interaction, linguistic alignment, and salient topics during the conversation to obtain insights into what are the patterns of high-quality counseling.",Performance Evaluation
3454,"we propose a new paradigm to handle the task of entity-relation extraction. We formalize the task as a multi-turn question answering task: each entity type and relation type is characterized by a question answering template, and entities and relations are extracted by answering template questions",Algorithms/ Methods Construction or Optimization
3455,"We propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification task with ranking loss, which can successfully mitigate the negative effect of having too many negative instances.",Algorithms/ Methods Construction or Optimization
3456,"We propose two RelDist losses: a skewness
loss, which encourages the classifier to predict a class with confidence for a single sentence, and a distribution distance loss, which
encourages the classifier to scatter a set of
sentences into different classes",Theory Proposal
3457,"we propose a novel multi-digraph model to learn how to combine the gazetteer information and to resolve conflicting matches in learning with contexts. To the best of our knowledge, we are the first neural approach to NER that models the gazetteer information with a graph structure",Model Construction or Optimization
3458,"we propose a regularization technique that exploits a symmetry in language models. A unique aspect of language modeling using
LSTMs (or any RNN) is that at each time step t,
the model takes as input a particular token xt from
a vocabulary W and using the hidden state of the
LSTM predicts a probability distribution on the next
token over the same vocabulary as output",Model Construction or Optimization
3459,"We propose Quaternion neural models for NLP. More concretely, we propose a novel Quaternion attention model and Quaternion Transformer for a wide range of NLP tasks. To the best of our knowledge, this is the first formulation of hypercomplex Attention and Quaternion models for NLP.",Model Construction or Optimization
3460,"we add morphology supervision to character language modeling and show that, across two benchmark datasets, multitasking morphology with CLMs improves bits-per-character (BPC) performance on twentyfour languages, even when the annotated morphology features and language modeling data do not
overlap",Model Construction or Optimization
3461,"we conduct the first large-scale multilingual evaluation of gender-bias in machine translation (MT), following recent small-scale qualitative studies which observed that online MT services, such as Google Translate or Microsoft Translator, also exhibit biases",Performance Evaluation
3462,"we answer several of these open questions. We begin by proving that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc via subspace projection is, under certain conditions, equivalent to training on an unbiased corpus without reconstruction error.",Theory Proposal
3463,"we address both issues simultaneously: leveraging the high accuracy of English taggers and parsers, we project morphological information onto translations of the Bible in 26 varied test languages. Using an iterative discovery, constraint, and training process, we build inflectional lexica in the target languages.",Theory Proposal
3464,"We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system.",Model Construction or Optimization
3465,We propose a novel attentive interactor to exploit fine-grained relationships between instances and the sentence to characterize their matching behaviors. A diversity loss is proposed to strengthen the matching behaviors between reliable instance-sentence pairs and penalize the unreliable ones during training,Theory Proposal
3466,"We propose a new dataset for data-to-text generation which we hope will encourage further work in this area a comprehensive evaluation and
comparison study which highlights the merits and
shortcomings of various recently proposed datato-text generation models on two datasets.",Dataset Creation or Resources
3467,"we show both automatic and human evaluations for our approach. We make our dataset and related code publicly available . To our knowledge, this is the first approach to automatically create extractive summaries for scientific papers by utilizing the videos of conference talks",Theory Proposal
3468,"we define Question Summarization as generating a condensed question expressing the minimum information required to find correct answers to the original question, and we create a new corpus1 of 1K consumer health questions and their summaries based on this definition",Theory Proposal
3469,"We propose a novel hierarchical fusion model
to address the challenging multi-modal sarcasm detection task in Twitter. To the best
of our knowledge, we are the first to deeply
fuse the three modalities of image, attribute
and text, rather than naВЁД±ve concatenation, for
Twitter sarcasm detection",Model Construction or Optimization
3470,"We aim to improve over existing MT evaluation methods, through developing a series of new metrics based on contextual word embeddings a technique which captures rich and portable representations of words in context, which have been shown to provide important signal to many other NLP tasks.",Algorithms/ Methods Construction or Optimization
3471,"we describe the creation of the first large-scale, multilingual, expert-based dataset of hate speech/counternarrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task",Dataset Creation or Resources
3472,"we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions.",Algorithms/ Methods Construction or Optimization
3473,We propose a new unsupervised multilingual word embedding method that overcomes the limitations of the existing methods. Our approach can successfully obtain multilingual word embeddings under the challenging conditions when only small monolingual corpora are available,Algorithms/ Methods Construction or Optimization
3474,"Extensive experimental results on two benchmark datasets show that our proposed method is able to perform better than several baselines and related works, and significantly reduce the performance gap between the crosslingual ASSUM and the monolingual ASSUM.",Algorithms/ Methods Construction or Optimization
3475,"we propose to model the edit operations explicitly for sentence simplification in an end-to-end fashion, rather than relying on MT-based models to learn the simplification mappings implicitly, which often generates outputs by blindly repeating the source sentences",Model Construction or Optimization
3476,"our research aims to develop a distributed knowledge-based clinical autocoding system that would leverage on NLP and ML techniques, where a human coders will give their queries to the coding system and in revert the system will suggest a set of clinical codes",Theory Proposal
3477,"we describe a simple yet effective approach to merge lexicon information with
an attention LSTM model for ABSA in order to
leverage both the power of deep neural networks
and existing linguistic resources, so that the framework becomes more flexible and robust without
requiring additional labeled data",Model Construction or Optimization
3478,a better way is to utilize the system to assist human creation. The human-machine collaboration mechanism in Jiuge system can not only improve the emotions and semantics of generated poems but also guide and teach beginners to understand the poetic creation process.,Performance Evaluation
3479,"we design and construct a real-world online platform that offers PhD graduates a dedicated job search functionality, as well as helps governments, universities, and employers in increasing the understanding of different industriesвЂ™ absorption of PhD graduates.",Algorithms/ Methods Construction or Optimization
3480,"We introduce Texar, a general-purpose text generation toolkit aiming to support popular and
emerging applications in the field, by providing researchers and practitioners a unified and flexible framework for building their models.
Texar has two versions, building upon TensorFlow
(tensorflow.org) and PyTorch (pytorch.
org), respectively, with the same uniform design",Algorithms/ Methods Construction or Optimization
3481,"we present an open source modular tool dedicated to automatic summarization. Written in Java, it is designed to first answer the lack of such a tool and so provide the community with an easy-to-use summarization tool, to allow a straightforward maintenance of existing modules and development of new modules, and to allow methods comparison in a unified framework.",Algorithms/ Methods Construction or Optimization
3482,"We present a prototype vocabulary
learning system, Linggle Booster, that applies
the method to corpora and web pages. Evaluation on a set of target words shows that the
method has reasonably good performance in
terms of generating useful and correct information for vocabulary learning.",Algorithms/ Methods Construction or Optimization
3483,"We will introduce researchers to state-of-theart methods for constructing resource-light crosslingual word representations and discuss their applicability in a broad range of downstream NLP
applications, covering bilingual lexicon induction,
machine translation (both neural and phrase-based),
dialogue, and information retrieval tasks",Model Construction or Optimization
3484,"Classification models that can generalize to different health contexts would be greatly beneficial to researchers in these fields (e.g., (Payam and Eugene, 2018)), as this would allow researchers to more easily apply existing tools and resources to new problems",Algorithms/ Methods Construction or Optimization
3485,"we present a MedNorm corpus consisting of 27,979 textual descriptions (phrases) simultaneously mapped to both MedDRA and SNOMED-CT, that have been sourced from five publicly available datasets across biomedical and social media domains. To combine them, we designed a data harmonisation pipeline that can be re-used in the future to integrate new datasets into the corpus or applied in relevant annotation and data processing tasks.",Dataset Creation or Resources
3486,"We provide the language and vision communities with a unique multimodal dataset comprised of co-captured gaze and audio data, and transcriptions. This dataset was collected via an image-inspection task with 100 general-domain images and American English speakers",Dataset Creation or Resources
3487,"we propose to improve the quality of input (source language) representations of rare words in NMT by augmenting its embedding layer with a bi-directional recurrent neural network (biRNN), which can learn compositional input representations at different levels of granularity",Model Construction or Optimization
3488,"We choose bidirectional long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) with an attention mechanism to represent EDUs directly from embeddings, and use simple position features to capture shallow discourse structures, without relying on off-the-shelf tools or resources",Dataset Creation or Resources
3489,"we propose an approach based on linguistic knowledge for identification of aliases mentioned using proper nouns, pronouns or noun phrases with common noun headword. We use Markov Logic Network (MLN) to encode the linguistic knowledge for identification of aliases. We evaluate on four diverse history narratives of varying complexity as well as newswire subset of ACE 2005 dataset. Our approach performs better than the state-of-the-art.",Theory Proposal
3490,"we study how to automatically extract such relationship through a sentence-level relation classifier and aggregating the scores of entity pairs from a large corpus. Also, we release two benchmark datasets for evaluation and future research.",Dataset Creation or Resources
3491,"we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary). We reveal its fallibility under certain conditions and propose an evaluation framework with normalization of inner terms, which is resilient to the dataset imbalance. We conclude with the experimental justification of the proposed measure. The implementation of the new framework is made publicly available as a Github repository",Dataset Creation or Resources
3492,"we use named entities as domain-specific terms for newscentric content and present a new weighting model for Latent Dirichlet Allocation. Our experimental results indicate that involving more named entities in topic descriptors positively influences the overall quality of topics, improving their interpretability, specificity and diversity.",Dataset Creation or Resources
3493,"we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation. Experiments on TED talks in three languages demonstrate improvements in translation accuracy, and better reflection of speaker traits in the target text.",Theory Proposal
3494,"we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training set. We evaluate our model on a Chinese-English translation dataset, and experiments show our model outperforms the strong baselines by the BLEU score of 4.55.1",Model Construction or Optimization
3495,"We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1",Dataset Creation or Resources
3496,"we aim to compare the performance of attention-based models to another baseline, namely, neural hidden Markov models. The neural HMM has been successfully applied in the literature on top of conventional phrasebased systems (Wang et al., 2017). In this work, our purpose is to explore its application in standalone decoding, i.e. the model is used to generate and score candidates without assistance from a phrase-based system. Because translation is done standalone using only neural models, we still refer to this as NMT. In addition, while Wang et al. (2017) applied feedforward networks to model alignment and translation, the recurrent structures proposed in this work surpass the feedforward variants by up to 1.3% in BLEU.",Performance Evaluation
3497,"we propose a model that jointly identifies the domain and tracks the belief states corresponding to that domain. It uses semantic similarity between ontology terms and turn utterances to allow for parameter sharing between different slots across domains and within a single domain. In addition, the model parameters are independent of the ontology/belief states, thus the dimensionality of the parameters does not increase with the size of the ontology, making the model practically feasible to deploy in multidomain environments without any modifications. Finally, we introduce a new, large-scale corpora of natural, human-human conversations providing new possibilities to train complex, neural-based models",Model Construction or Optimization
3498,Crowdsourcing a large paraphrasing corpus of questions which are answerable using the data from EHR,Applications
3499,The creation and annotation of a newspaper dataset for political bias detection,Dataset Creation or Resources
3500,this paper puts forward a new thinking direction of enriching training dataset for the CGED task.,Algorithms/ Methods Construction or Optimization
3501,"We conduct a comparison and evaluation of our findings with other URE techniques, to ascertain the important features in URE. We conclude that entity types provide a strong inductive bias for URE",Performance Evaluation
3502,"we address the task of machine reading the time of historical events, compile datasets for the task, and develop a model for tackling it.",Theory Proposal
3503,"we explore the implicit event argument detection task, which studies event arguments beyond sentence boundaries",Algorithms/ Methods Construction or Optimization
3504,We demonstrate the effectiveness of our approach with state-of-the-art accuracy on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks,Algorithms/ Methods Construction or Optimization
3505,"In this paper we explore the use of synthetic data for the English shallow task. We analyse the effects of synthetic data, and
we argue that its use should be encouraged
rather than prohibited so that future research
efforts continue to explore systems that can
take advantage of such data.",Applications
3506,"In this paper, we present a novel image captioning architecture to better explore semantics available in captions and leverage that to enhance both image representation and caption generation",Algorithms/ Methods Construction or Optimization
3507,"In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges.",Theory Proposal
3508,"we outline several lessons that transfer to QA research: removing ambiguity, identifying better QA agents, and adjudicating disputes.",Performance Evaluation
3509,"In this paper, we will attempt to uncover potential reasons for this.",Theory Proposal
3510,"Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs",Theory Proposal
3511,we compare the structural probe to a more traditional parser with an identical lightweight parameterisation,Performance Evaluation
3512,"We review motivations, definition, approaches, and methodology for unsupervised crosslingual learning and call for a more rigorous position in each of them.",Algorithms/ Methods Construction or Optimization
3513,"We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection",Algorithms/ Methods Construction or Optimization
3514,"This paper provides the first study of how these explanations can be generated automatically based on available claim context, and how this task can be modelled jointly with veracity prediction",Theory Proposal
3515,"This paper presents Kernel Graph Attention Network (KGAT), which conducts more finegrained fact verification with kernel-based attentions",Model Construction or Optimization
3516,we propose a multi-source meta transfer (MMT) for low-resource MCQA.,Model Construction or Optimization
3517,We evaluate stateof-the-art cross-lingual models and machinetranslation-based baselines on MLQA.,Performance Evaluation
3518,"In this paper we present DoQA, a task and associated dataset for accessing domain-specific FAQs via conversational QA",Algorithms/ Methods Construction or Optimization
3519,we devise a novel bootstrapping framework based on self-supervision to obtain a dataset of clarification questions from various domains of stackexchange,Model Construction or Optimization
3520,"In this paper, we develop simple approaches to semi-supervised contextualized text normalization",Algorithms/ Methods Construction or Optimization
3521,We create a ten-year Reddit corpus as a benchmark for MFEP and evaluate a number of baselines on this benchmark,Algorithms/ Methods Construction or Optimization
3522,we propose a model that can disambiguate between mappings and convert between the two scripts.,Model Construction or Optimization
3523,"Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space",Algorithms/ Methods Construction or Optimization
3524,"This paper contributes a sober view of the problem, a survey of techniques to address it, novel techniques, and extensions to the model. To establish a ranking of techniques, we perform a systematic comparison using Bayesian optimisation and find that many techniques perform reasonably similar, given enough resources",Theory Proposal
3525,"In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks",Performance Evaluation
3526,"We propose a novel large-scale referring expression recognition dataset, Refer360В°, consisting of 17,137 instruction sequences and ground-truth actions for completing these instructions in 360В° scenes.",Dataset Creation or Resources
3527,"This paper proposes a new neural network architecture for VQA based on the recent Graph Network (GN) (Battaglia et al., 2018).",Algorithms/ Methods Construction or Optimization
3528,we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages.,Model Construction or Optimization
3529,we propose to explicitly segment target text into fragment units and align them with their data correspondences,Algorithms/ Methods Construction or Optimization
3530,"In this paper, we propose the Heterogeneous Graph Transformer to independently model the different relations in the individual subgraphs of the original graph, including direct relations, indirect relations and multiple possible relations between nodes.",Algorithms/ Methods Construction or Optimization
3531,"In this paper, we propose a novel attentional sequence-to-sequence(Seq2seq) model that dynamically exploits the relevance of each output word to the target stylefor unsupervised style transfer.",Model Construction or Optimization
3532,we propose a neural co-generation model that generates dialogue acts and responses concurrently,Model Construction or Optimization
3533,we propose a multi-task learning model with a simple yet effective utterance tagging technique and a bidirectional language model as an auxiliary task for task-oriented dialogue state generation.,Model Construction or Optimization
3534,"In this paper, we propose a Meta-Reinforced MultiDomain State Generator (MERET). Our first contribution is to improve the DST accuracy. We enhance a neural model based DST generator with a reward manager, which is built on policy gradient reinforcement learning (RL) to fine-tune the generator",Algorithms/ Methods Construction or Optimization
3535,"In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs",Dataset Creation or Resources
3536,"In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text",Algorithms/ Methods Construction or Optimization
3537,"we aim to identify, from among a set of speeches on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community.",Performance Evaluation
3538,"In this paper, we model debatersвЂ™ prior beliefs, interests, and personality traits based on their previous activity, without dependence on explicit user profiles or questionnaires. Using a dataset of over 60,000 argumentative discussions, comprising more than three million individual posts collected from the subreddit r/ChangeMyView, we demonstrate that our modeling of debaterвЂ™s characteristics enhances the prediction of argument persuasiveness as well as of debatersвЂ™ resistance to persuasion.",Model Construction or Optimization
3539,"In this paper, we formulate the data augmentation as a conditional generation task: generating a new sentence while preserving the original opinion targets and labels. We propose a masked sequence-to-sequence method for conditional augmentation of aspect term extraction.",Model Construction or Optimization
3540,"In order to further test the capabilities of these powerful neural networks on a harder NLP problem, we propose a transition system that, thanks to Pointer Networks, can straightforwardly produce labelled directed acyclic graphs and perform semantic dependency parsing.",Algorithms/ Methods Construction or Optimization
3541,"We apply, extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level, including dimensionality reduction (Yin and Schutze ВЁ , 2016), generalized Canonical Correlation Analysis (Rastogi et al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018).",Applications
3542,"In this paper, we present an improved crowdsourcing protocol for complex semantic annotation, involving worker selection and training, and a data consolidation phase.",Dataset Creation or Resources
3543,"In this paper, we propose N 3 (Neural Networks from Natural Language) - a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model.",Algorithms/ Methods Construction or Optimization
3544,"We therefore present a novel domain-agnostic Human-In-The-Loop annotation approach: we use recommenders that suggest potential concepts and adaptive candidate ranking, thereby speeding up the overall annotation process and making it less tedious for users. We evaluate our ranking approach in a simulation on difficult texts and show that it greatly outperforms a strong baseline in ranking accuracy.",Model Construction or Optimization
3545,"We present a method for incorporating model and data uncertainty estimates into natural language processing models for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous, so that these difficult instances can be prioritised by a human fact-checker. We propose two methods for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret model performance as a rumour unfolds.",Algorithms/ Methods Construction or Optimization
3546,"In this paper, we present CorefQA, an accurate and extensible approach for the coreference resolution task. We formulate the problem as a span prediction task",Algorithms/ Methods Construction or Optimization
3547,"In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction.",Performance Evaluation
3548,"We propose uncertainty-aware curriculum learning, which is motivated by the intuition that: 1) the higher the uncertainty in a translation pair, the more complex and rarer the information it contains; and 2) the end of the decline in model uncertainty indicates the completeness of current training stage. Specifically, we serve cross-entropy of an example as its data difficulty and exploit the variance of distributions over the weights of the network to present the model uncertainty",Model Construction or Optimization
3549,"We present the first thorough investigation of gender bias in speech translation, contributing with: i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian/French).",Performance Evaluation
3550,"In this work, we present CLASSYMAP, a classification-based approach to self-learning, yielding a more robust and a more effective induction of projection-based CLWEs. Unlike prior self-learning methods, our approach allows for integration of diverse features into the iterative process. We show the benefits of CLASSYMAP for bilingual lexicon induction: we report consistent improvements in a weakly supervised setup (500 seed translation pairs) on a benchmark with 28 language pairs.",Algorithms/ Methods Construction or Optimization
3551,"In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns.",Algorithms/ Methods Construction or Optimization
3552,we introduce a gated component self-dependency units (SDU) that incorporates LSTM-styled gating units to replenish internal semantic importance within the multi-dimensional latent space of individual representations.,Algorithms/ Methods Construction or Optimization
3553,"We introduce a parametric family of entropy regularizers, which includes label smoothing as a special case, and use it to gain a better understanding of the relationship between the entropy of a trained model and its performance on language generation tasks.",Algorithms/ Methods Construction or Optimization
3554,"In this paper, we develop a deep, endto-end model that learns to effectively classify mismatches and to generate hard mismatched examples to improve the classifier. We train the model end-to-end by introducing a latent variable into the cross-entropy loss that alternates between using the real and generated samples.",Algorithms/ Methods Construction or Optimization
3555,"In this paper, we compare the performance of both QT and DT using the traditional SMT and state-of-the-art NMT methods trained on the same data to make the comparison as fair as possible. We present a novel approach for NMT model selection that is optimized towards CLIR performance and investigate the effect of morphological pre- and post-processing on the performance on CLIR.",Performance Evaluation
3556,"In this paper, we propose a method FGS2EE to inject fine-grained semantic information into entity embeddings to reduce the distinctiveness and facilitate the learning of contextual commonality.",Algorithms/ Methods Construction or Optimization
3557,"In this paper, we propose FLAT: Flat-LAttice Transformer for Chinese NER, which converts the lattice structure into a flat structure consisting of spans.",Algorithms/ Methods Construction or Optimization
3558,"We present an effective TSE method which is based on querying large, pre-trained masked language models (MLMs).",Algorithms/ Methods Construction or Optimization
3559,"In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling.",Model Construction or Optimization
3560,"we propose a two-stage semantic parsing framework, where the first stage utilizes an unsupervised paraphrase model to convert an unlabeled natural language utterance into the canonical utterance.",Model Construction or Optimization
3561,We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework.,Algorithms/ Methods Construction or Optimization
3562," we formulate the task based on the divergence between literal and intended meanings. We combine the complementary strengths of English Resource Grammar, a linguistically-precise hand-crafted deep grammar, and TLE, an existing manually annotated ESL UD-TreeBank with a novel reranking model.",Algorithms/ Methods Construction or Optimization
3563,We demonstrate the effectiveness of this new perspective by developing a new state-of-the-art semantic parser for Minimal Recursion Semantics.,Algorithms/ Methods Construction or Optimization
3564,"In this paper, we introduce a new model, called RikiNet, which reads Wikipedia pages for natural question answering.",Model Construction or Optimization
3565,"In this paper, we study machine reading comprehension (MRC) on long texts, where a model takes as inputs a lengthy document and a question and then extracts a text span from the document as an answer",Theory Proposal
3566,"We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R4C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations).",Dataset Creation or Resources
3567,we propose to learn the model with the help of a large scale of unlabeled data that is much easier to obtain.,Theory Proposal
3568,"In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA)",Algorithms/ Methods Construction or Optimization
3569,"we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously",Model Construction or Optimization
3570,"We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas",Algorithms/ Methods Construction or Optimization
3571,"Here, we investigate the strength of those clues. More specifically, we operationalize вЂњstrengthвЂќ as measuring how much information, in bits, we can glean about declension class from knowing the form and meaning of nouns",Performance Evaluation
3572,"In this paper, we propose a new framework that incorporates typological awareness by explicitly modeling different morphological patterns including suffixation, prefixation, infixation, and reduplication.",Model Construction or Optimization
3573,we develop a sentence-level training procedure to perform noise reduction and maximum utilization of the source domain information.,Algorithms/ Methods Construction or Optimization
3574,"We generate data from a finite state transducer to train an encoderdecoder model. We improve the model by вЂњhallucinatingвЂќ missing linguistic structure into the training data, and by resampling from a Zipf distribution to simulate a more natural distribution of morphemes.",Dataset Creation or Resources
3575,"we propose a modification to contextual representation fine-tuning which, during inference, allows for an early (and fast) вЂњexitвЂќ from neural network calculations for simple instances, and late (and accurate) exit for hard instances.",Algorithms/ Methods Construction or Optimization
3576,we present a general approach to learn both intra-cell and inter-cell architectures (call it ESS).,Theory Proposal
3577,"In this paper, we make use of a multi-task objective, i.e., the models simultaneously predict words as well as ground truth parse trees in a form called вЂњsyntactic distancesвЂќ, where information between these two separate objectives shares the same intermediate representation",Model Construction or Optimization
3578,"we show that adversarial examples also exist in dependency parsing: we propose two approaches to study where and how parsers make mistakes by searching over perturbations to existing texts at sentence and phrase levels, and design algorithms to construct such examples in both of the black-box and white-box settings",Performance Evaluation
3579,"We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including machine translation, sentiment analysis, subject-verb agreement and language modeling. Our experimental results demonstrate consistent and sizable improvements across all tasks.",Algorithms/ Methods Construction or Optimization
3580,we propose a dependency graph enhanced dual-transformer network (named DGEDT) by jointly considering the flat representations learnt from Transformer and graphbased representations learnt from the corresponding dependency graph in an iterative interaction manner.,Algorithms/ Methods Construction or Optimization
3581,we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters,Performance Evaluation
3582,"We critically examine RefCOCOg, a standard benchmark for this task, using a human study and show that 83.7% of test instances do not require reasoning on linguistic structure, i.e., words are enough to identify the target object, the word order doesnвЂ™t matter",Algorithms/ Methods Construction or Optimization
3583,"We propose a video span localizing network (VSLNet), on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple and yet effective query-guided highlighting (QGH) strategy",Performance Evaluation
3584,We present a simple experiment on language grounding that highlights the great potential of top-down processing even for very common words with a lot of visual instances: we learn to ground colour terms in visual representations of real-world objects and show that model predictions improve strongly when incorporating prior knowledge and assumptions about the object itself.,Model Construction or Optimization
3585,"In this paper, we propose to tackle this issue of large-scale image-caption consistency using a coherence-aware approach inspired by the framework of discourse coherence theory (Hobbs, 1978; Phillips, 1977).",Dataset Creation or Resources
3586,"In this paper, we explore AspectOpinion Pair Extraction (AOPE) task, which aims at extracting aspects and opinion expressions in pairs",Algorithms/ Methods Construction or Optimization
3587,"In this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language",Algorithms/ Methods Construction or Optimization
3588,"In this paper, we present a novel approach to the task of extracting structured information from formlike documents using a learned representation of an extraction candidate.",Algorithms/ Methods Construction or Optimization
3589,In this work we annotate a test set with ground-truth sentence-level explanations to evaluate the quality of explanations afforded by the relation extraction models. We demonstrate that replacing the entity mentions in the sentences with their fine-grained entity types not only enhances extraction accuracy but also improves explanation. We also propose to automatically generate вЂњdistractorвЂќ sentences to augment the bags and train the model to ignore the distractors.,Performance Evaluation
3590,"We present Neighborhood Matching Network (NMN), a novel sampling-based entity alignment framework. NMN aims to capture the most informative neighbors and accurately estimate the similarities of neighborhoods between entities in different KGs",Model Construction or Optimization
3591,"In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017).",Model Construction or Optimization
3592,We then propose a Medical Information Extractor (MIE) towards medical dialogues.,Algorithms/ Methods Construction or Optimization
3593,"In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans.",Model Construction or Optimization
3594,"In this paper, we refer this phenomenon particularly to rare entity problem. It is different from other types of data sparsity problems such as the lack of training data for lowresource language (Lin et al., 2018), as this rare entity problem is more related to a mismatch of entity distributions between training and test, rather than the size of training data. We present an example of the problem in Table",Theory Proposal
3595,we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning in this paper,Theory Proposal
3596,"In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs.",Algorithms/ Methods Construction or Optimization
3597,"In this paper, we propose a novel bipartite flatgraph network (BiFlaG) for nested named entity recognition (NER), which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers.",Algorithms/ Methods Construction or Optimization
3598,"In this paper, we argue that incorporation of multimodal cues can improve the automatic identification of PPI",Theory Proposal
3599,"In this paper, we justify from both computational and perceptive points-of-view that the top-down architecture is more suitable for textlevel DRS parsing. On the basis, we propose a top-down neural architecture toward text-level DRS parsing.",Performance Evaluation
3600,"In this paper, we propose an automatic evaluation model based on that idea and learn the model parameters from an unlabeled conversation corpus.",Model Construction or Optimization
3601,We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant informationвЂ™s interference and improve long dialogue context tracking.,Model Construction or Optimization
3602,"In this paper, we present that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping.",Algorithms/ Methods Construction or Optimization
3603,"we propose a novel Dynamic Fusion Network (DFNet) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature",Model Construction or Optimization
3604,"In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously",Algorithms/ Methods Construction or Optimization
3605,"In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations",Algorithms/ Methods Construction or Optimization
3606,"In this paper we intend to give a thorough chronology of the major interplay between corpus progression and query tool evolution, with a strong focus on the latter",Theory Proposal
3607,"In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures.",Theory Proposal
3608,"In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time.",Theory Proposal
3609,"This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, natural language is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction",Theory Proposal
3610,"In this paper, we analyze three different instances of sample bias that are prevalent in QE datasets, which affect the generalization that models trained on them can achieve.",Performance Evaluation
3611,"we propose an algorithm that reduces parsing to tagging, where all tags are predicted in parallel using a standard model architecture such as BERT (Devlin et al., 2019).",Algorithms/ Methods Construction or Optimization
3612,"In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents.",Algorithms/ Methods Construction or Optimization
3613,"In this paper, we develop a neural abstractive multidocument summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries.",Model Construction or Optimization
3614,"In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages.",Algorithms/ Methods Construction or Optimization
3615,"In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences.",Model Construction or Optimization
3616,"In this paper, we focus on extractive summarization since it usually generates semantically and grammatically correct sentences (Dong et al., 2018; Nallapati et al., 2017) and computes faster.",Theory Proposal
3617,"In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization",Algorithms/ Methods Construction or Optimization
3618,"In this paper, we study the challenging problem of automatic generation of citation texts in scholarly papers",Algorithms/ Methods Construction or Optimization
3619,we present a method suitable for reasoning about the semantic-level structure of evidence.,Algorithms/ Methods Construction or Optimization
3620,"In this paper, we propose two efficient neural mixed counting models, i.e., the Negative BinomialNeural Topic Model (NB-NTM) and the Gamma Negative Binomial-Neural Topic Model (GNB-NTM) for dispersed topic discovery.",Model Construction or Optimization
3621,"we propose neural graph matching networks, a novel sentence matching framework capable of dealing with multi-granular input information",Algorithms/ Methods Construction or Optimization
3622,"we propose a neural network model, called NeuInfer, to conduct both simple and flexible knowledge inference on n-ary facts",Model Construction or Optimization
3623,"we propose to incorporate paraphrase knowledge into question generation(QG) to generate human-like questions. Specifically, we present a two-hand hybrid model leveraging a self-built paraphrase resource, which is automatically conducted by a simple back-translation method.",Applications
3624," we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts",Algorithms/ Methods Construction or Optimization
3625,"In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition",Algorithms/ Methods Construction or Optimization
3626,"In this paper, we draw inspiration from similar ideas, and propose our approach 6096 for arranging a curriculum when learning NLU tasks",Theory Proposal
3627,we propose a novel decoding algorithm that integrates constrained decoding using positive/negative examples during inference: this demonstrates the potential of our dataset to enable work at the intersection of NLP and program synthesis.,Algorithms/ Methods Construction or Optimization
3628,"In this paper, we propose a novel attack model, which incorporates the sememebased word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately.",Model Construction or Optimization
3629,"we propose LogicalFactChecker, a neural network approach capable of leveraging logical operations for fact checking",Algorithms/ Methods Construction or Optimization
3630,we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation: automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation.,Performance Evaluation
3631,we propose a novel speed-tunable FastBERT with adaptive inference time.,Algorithms/ Methods Construction or Optimization
3632,"In this paper, we present the first detailed empirical study of the effects of different masked lan- guage modeling (MLM) pretraining regimes on cross-lingual transfer. Our first set of experiments is a detailed ablation study on a range of zero-shot cross-lingual transfer tasks",Algorithms/ Methods Construction or Optimization
3633,"In this paper, we present an effective retrievalbased approach to paraphrase generation by proposing a novel editor module.",Algorithms/ Methods Construction or Optimization
3634,"In this paper, we use both frequency changes and word semantic shifts to measure document influence by developing a neural network based framework",Algorithms/ Methods Construction or Optimization
3635,"In this paper, we apply pre-trained word embedding as the intermediate level in the multitask ST model. We propose to constrain the hidden states of the decoder of the recognition part to be close to the pre-trained word embedding",Model Construction or Optimization
3636,"In this paper, we show that neural machine translation (NMT) systems trained on large back-translated data overfit some of the characteristics of machine-translated texts",Theory Proposal
3637,we propose to use extracted templates from tree structures as soft target templates to guide the translation procedure.,Theory Proposal
3638,"In this work, we investigate the effect of future sentences as context by comparing the performance of a contextual NMT model trained with the future context to the one trained with the past context.",Performance Evaluation
3639,"In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT).",Algorithms/ Methods Construction or Optimization
3640,"In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations.",Algorithms/ Methods Construction or Optimization
3641,"In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation",Algorithms/ Methods Construction or Optimization
3642,"In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE). Specifically, we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings",Model Construction or Optimization
3643,"In this paper, we propose a novel layered model called Pyramid for nested NER. The model consists of a stack of inter-connected layers. Each layer l predicts whether a text region of certain length l, i.e. an l-gram, is a complete entity mention",Model Construction or Optimization
3644,We investigate a multi-cell compositional LSTM structure to deal with the above challenges by separately and simultaneously considering the possibilities of all entity types for each word when processing a sentence.,Performance Evaluation
3645,"In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. We present a joint
model that supports multi-class classification
and introduce a simple variant of self-attention
that allows the model to learn scaling factors.",Model Construction or Optimization
3646,"In the paper, we empower the model with external knowledge called Open-Domain Trigger Knowledge to provides extra semantic support on unseen/sparsely labeled trigger words and improve trigger identification",Model Construction or Optimization
3647,"We present IMOJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. we design the first neural OpenIE
system that uses sequential decoding of tuples conditioned on previous tuples.",Dataset Creation or Resources
3648,"We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER.We propose an end-to-end
transition-based model with generic neural
encoding that allows us to leverage specialized
actions and attention mechanism to determine
whether a span is the component of a discontinuous
mention or not.",Model Construction or Optimization
3649,"In this paper, we propose a unified framework that is capable of handling both flat and nested NER tasks",Algorithms/ Methods Construction or Optimization
3650,"In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating videogrounded dialogue tasks as a sequence-tosequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network.",Algorithms/ Methods Construction or Optimization
3651,"In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting",Algorithms/ Methods Construction or Optimization
3652,"In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance",Model Construction or Optimization
3653,"this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI",Performance Evaluation
3654,"We investigate the following research questions: (i) what is the effect of integrating preprocessing techniques earlier into word embedding models, instead of later on in a downstream classification models? (ii) which preprocessing techniques yield the most benefit in affective tasks? (iii) does preprocessing of word embeddings provide any improvement over stateof-the-art pretrained word embeddings? and if yes, how much?",Performance Evaluation
3655,"We present OPINIONDIGEST, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training",Theory Proposal
3656,we propose a novel Entity-aware Dependencybased Deep Graph Attention Network (ED-GAT) for comparative preference classification. We represent a sentence by its dependency graph,Model Construction or Optimization
3657,"We present an efficient annotation framework for argument quality, a feature difficult to be measured reliably as per previous work.",Model Construction or Optimization
3658,"In this paper, we investigate an extreme scenario of cross-lingual sentiment classification, in which the low-resource language does not have any labels or parallel corpus. We propose an unsupervised cross-lingual sentiment classification model named multi-view encoder-classifier (MVEC) that leverages an unsupervised machine translation (UMT) system and a language discriminator",Performance Evaluation
3659,"in this paper, we introduce a new research problem, stance polarity and intensity prediction in a responsive relationship between posts, which aims to predict a textвЂ™s stance polarity and intensity which we combine into a single continuous agreement value",Performance Evaluation
3660,"In this paper, we present the first comprehensive categorization of essential commonsense knowledge for answering the Winograd Schema Challenge (WSC).",Algorithms/ Methods Construction or Optimization
3661,. In this paper we demonstrate that the combination of a consistent answer structure with span annotations opens the door for new approaches to automatic verification of annotations and enables new types of analyses for reading comprehension.,Theory Proposal
3662,"we provide best practices and guidelines tailored towards NLP research, as well as an easy-to-use package called HyBayes for Bayesian assessment of hypotheses,1 complementing existing tools.",Theory Proposal
3663,We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue.,Algorithms/ Methods Construction or Optimization
3664,"In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers.",Algorithms/ Methods Construction or Optimization
3665,"we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy",Performance Evaluation
3666,"In this paper, we present SCDE, a dataset of sentence-level cloze questions sourced from public school examinations.",Model Construction or Optimization
3667,"In this paper, we demonstrated that the choice of probability space and interpretation of the distant supervision signal for document-level QA have a large impact, and that they interact.",Performance Evaluation
3668,"we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as beam search. We also show that standard QG evaluation metrics such as BLEU, ROUGE and METEOR are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on QA.",Performance Evaluation
3669,"In this paper, we address the task of producing globally consistent and accurate predictions for comparison questions leveraging logical and symbolic knowledge for data augmentation and training regularization",Model Construction or Optimization
3670,"In this work, we propose to cross variational auto-encoders by generating questions with aligned answers and generating answers with aligned questions.",Algorithms/ Methods Construction or Optimization
3671,"In this work, we study the benefits of collecting intermediate reasoning supervision along with the answer during data collection.",Theory Proposal
3672,"In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction",Algorithms/ Methods Construction or Optimization
3673,"we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2 and DROP, two datasets which require composing multiple reasoning steps.",Algorithms/ Methods Construction or Optimization
3674,we build hierarchical explanations by detecting feature interactions.,Algorithms/ Methods Construction or Optimization
3675,"we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy.",Algorithms/ Methods Construction or Optimization
3676,we develop a new quantitative measure based on influence functions that can reveal artifacts in training data,Theory Proposal
3677,"In this paper, we evaluated five explanation methods through simulation tests with text and tabular data.",Performance Evaluation
3678,"In this paper, we introduce the Cross-Linguistic Assessment of Models on Syntax (CLAMS) data set, which extends the subject-verb agreement component of the Marvin and Linzen (2018) challenge set to French, German, Hebrew and Russian",Dataset Creation or Resources
3679,"In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem.",Theory Proposal
3680,"In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, SENTDEBIAS, to reduce these biases",Algorithms/ Methods Construction or Optimization
3681,"In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis",Model Construction or Optimization
3682,"We introduce SOCIAL BIAS FRAMES, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others",Algorithms/ Methods Construction or Optimization
3683,"We survey 146 papers analyzing вЂњbiasвЂќ in NLP systems, fnding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing",Theory Proposal
3684,"We propose a simple but effective technique, Double-Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace.",Algorithms/ Methods Construction or Optimization
3685,we propose a novel regularization technique based on these explanations that encourages models to learn from the context of group identifiers in addition to the identifiers themselves.,Algorithms/ Methods Construction or Optimization
3686,"We propose to better explore their interaction by solving both tasks together, while the previous work treats them separately",Model Construction or Optimization
3687,"We propose PeTra, a memory-augmented neural network designed to track entities in its memory slots. PeTra is trained using sparse annotation from the GAP pronoun resolution dataset and outperforms a prior memory model on the task while using a simpler architecture",Algorithms/ Methods Construction or Optimization
3688,"In this paper, we revisit prior work to explicate the inconsistencies and propose an improved evaluation protocol to promote experimental rigor in future work.",Model Construction or Optimization
3689,we explore to what extent neural network sentence encoders can learn to predict the strength of scalar inferences,Theory Proposal
3690,"we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources, we propose several documentlevel neural-network models to automatically construct news content structures",Applications
3691,we present a new task and corpus for learning alignments between machine and human preferences,Algorithms/ Methods Construction or Optimization
3692,"In this paper, we take the first step towards a better understanding of these processes and the underlying dynamics that shape them, using data-driven methods. We build a new large-scale dataset, from multiple data sources, connecting state bills and legislator information, geographical information about their districts, and donations and donorsвЂ™ information",Performance Evaluation
3693,"In this paper, we introduce the text-based ideal point model (tbip), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the tbip with two types of politicized text data: U.S. Senate speeches and senator tweets.",Model Construction or Optimization
3694,"we collect and categorize applications with text as a causal confounder (Table 1 and В§2), and we provide a flowchart of analystsвЂ™ decisions for this problem setting,we highlight recent work in representation learning in NLP (В§4) and caution that this is still an open research area with questions of the sensitivity of effects to choices in representation,we summarize some of the most-used causal estimators that condition on confounders:matching, propensity score weighting, regression adjustment, doubly-robust methods, and causally-driven representation learning .",Algorithms/ Methods Construction or Optimization
3695,In this paper we explore connections between the language people use to describe their predictions and their forecasting skill.,Algorithms/ Methods Construction or Optimization
3696,"In this paper, we present a novel model that uses message-level attention to learn the relative weight of usersвЂ™ social media posts for assessing their five factor personality traits. We demonstrate that models with message-level attention outperform those with word-level attention, and ultimately yield stateof-the-art accuracies for all five traits by using both word and message attention in combination with past approaches (an average increase in Pearson r of 2.5%).",Model Construction or Optimization
3697,"In this paper, we introduce HURRICANEEMO, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarsegrained emotion groups.",Dataset Creation or Resources
3698,we develop an unsupervised methodology to quantify how counselors manage this balance.,Theory Proposal
3699,we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions.,Algorithms/ Methods Construction or Optimization
3700,"In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias.",Algorithms/ Methods Construction or Optimization
3701,we perform a large-scale study on the pretrained RoBERTa model with 110 intermediateвЂ“target task combinations,Model Construction or Optimization
3702,"In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an indepth analysis of the advantages and disadvantages of existing works to explore possible future directions.",Theory Proposal
3703,We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.,Model Construction or Optimization
3704,"In this paper, we describe work on examining the papers and their citations to identify broad trends within NLP researchвЂ”overall, across paper types, across publication venues, over time, and across research areas within NLP. Notably, we explored questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, etc.)? how well cited are papers published in different time spans? how well cited are papers from different areas of research within NLP? etc",Theory Proposal
3705,"In this position paper, we argue that a system trained only on form has a priori no way to learn meaning,We argue in this paper that genuine progress in our field вЂ” climbing the right hill,
not just the hill on whose slope we currently sitвЂ”
depends on maintaining clarity around big picture
notions such as meaning and understanding in task
design and reporting of experimental results.",Theory Proposal
3706,"In this paper, we engage with an idea largely absent from discussions of meaning in natural language understandingвЂ”namely, that the way something is expressed reflects different ways of conceptualizing or construing the information being conveyed",Algorithms/ Methods Construction or Optimization
3707,"We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the вЂњamount of noveltyвЂќ going into the new review or, equivalently, vary the extent to which it deviates from the input.",Model Construction or Optimization
3708,"This paper presents a novel unsupervised abstractive summarization method that generates summaries directly from source documents, without the aid of example summaries.",Algorithms/ Methods Construction or Optimization
3709,"This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an openended role-playing game.",Dataset Creation or Resources
3710,we develop a general framework where we evaluate the factual correctness of a generated summary by factchecking it automatically against its reference using an information extraction module,Performance Evaluation
3711,"We propose the use of dual encodersвЂ”a sequential document encoder and a graphstructured encoderвЂ”to maintain the global context and local characteristics of entities, complementing each other.",Algorithms/ Methods Construction or Optimization
3712,We present Deep Generalized Canonical Correlation Analysis (DGCCA).,Algorithms/ Methods Construction or Optimization
3713,we investigate a variety of features for automatically detecting plagiarized spoken responses in the context of a standardized assessment of English speaking proficiency.,Model Construction or Optimization
3714,"we recorded 2 hours of Chinese voice data from a female speaker, and Xiaomingbot learnt to speak in English and Japanese with the same voice.",Dataset Creation or Resources
3715,"We propose an end-to-end, data-driven model for predicting depression from interview transcripts that leverages the contextual information provided by interviewer prompts",Model Construction or Optimization
3716,We conduct robust experiments to show that our model outperforms competitive baselines,Dataset Creation or Resources
3717,"Our proposal rests on A light-weight query language that does not require in-depth familiarity with the underlying syntactic representation scheme, and instead lets the user specify their intent via a natural language example and lightweight markup.",Theory Proposal
3718,"Our proposal rests on A fast, near-real-time response time due to efficient indexing, allowing for rapid experimentation",Performance Evaluation
3719,We describe how the cards were generated where each card corresponds to a Wikipedia page,Theory Proposal
3720,"we adapted MRS techniques to create a conversational search portal that enable users to ask natural language questions to find precise answers and extract insights from the last 3 year papers published in top-tier NLP conferences, including ACL, NAACL, EMNLP and etc.",Applications
3721,We developed a collaborative annotation toolkit that enable any researcher to contribute to this dataset so that more potential answers from these papers can be annotated.,Dataset Creation or Resources
3722,we provided further evidence that the nature of LKBs impacts on system performance: the injection of syntagmatic relations вЂ“ in the form of disambiguated pairs of co-occurring words вЂ“ into an existing LKB biased towards paradigmatic knowledge enables knowledge-based systems to rival their supervised counterparts,Model Construction or Optimization
3723,"we introduce a Web interface and a RESTful API for SyntagRank, our multilingual WSD system, which applies the Personalized PageRank (PPR) algorithm (Haveliwala, 2002) to an LKB made up of WordNet, the Princeton WordNet Gloss Corpus (PWNG) and the lexical-semantic syntagmatic combinations available in the SyntagNet resource",Algorithms/ Methods Construction or Optimization
3724,"We introduce a broad-coverage, datadriven and linguistically sound set of transformations, that makes event-structure and many lexical relations explicit",Dataset Creation or Resources
3725,"We present pyBART, an easy-to-use open-source Python library for converting English UD trees either to Enhanced UD graphs or to our representation",Algorithms/ Methods Construction or Optimization
3726,"We build EVIDENCEMINER, a web-based system for textual evidence discovery for life sciences. EVIDENCEMINER is supported by novel methods for distantly supervised named entity recognition and pattern-based open information extraction.",Algorithms/ Methods Construction or Optimization
3727,"we describe a prototype system that facilitates interactive exploration and mapping of the evidence base, with an emphasis on answering the above questions",Theory Proposal
3728,we introduce SyntaxGym: an online platform and open-source framework that makes targeted syntactic evaluations more accessible to experts in NLP and linguistics,Model Construction or Optimization
3729,"Our system, GAIA enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos.",Theory Proposal
3730,"We present easy-to-use retrieval focused multilingual sentence embedding models, made available on TensorFlow Hub",Model Construction or Optimization
3731,"we developed a user-friendly workflow management platform, 96 BiomEdical Nlp TOolkits (BENTO), to facilitate the process of building and applying of clinical NLP pipelines.",Model Construction or Optimization
3732,"we present BENTO, a workflow management platform with a graphic user interface (GUI) that is built on top of CodaLab, to facilitate the process of building clinical NLP pipelines",Model Construction or Optimization
3733,"We introduce Stanza , a Python natural language processing toolkit supporting many human languages",Algorithms/ Methods Construction or Optimization
3734,"We demonstrate that jiant reproduces published performance on a variety of tasks and models, including BERT and RoBERTa.",Model Construction or Optimization
3735,"We introduce MT-DNN, a comprehensive and easily-configurable open-source toolkit for building robust and transferable natural language understanding models.",Model Construction or Optimization
3736,we developed a web-based system LinggleWrite (f.linggle.com) with many assistive writing functions.,Algorithms/ Methods Construction or Optimization
3737,"We release CLIReval, 1 an open-source toolkit that evaluates the quality of MT outputs in the context of a CLIR system, without the need for any actual CLIR dataset.",Performance Evaluation
3738,"We demonstrate that CLIReval can perform as well as popular intrinsic MT metrics on recent WMT metrics shared task, without supervision from external datasets and domain-basedparameter tuning",Dataset Creation or Resources
3739,we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems.,Algorithms/ Methods Construction or Optimization
3740,"We present a framework for bitext cleaning, OpusFilter, focusing on processing data collected in OPUS (Tiedemann, 2012), the worldвЂ™s largest resource of openly available parallel corpora",Model Construction or Optimization
3741,"We propose the Label Noise in Context system, or LNIC, which uses the neighborhood surrounding a suspicious example in the training set to improve both precision and explainability.",Theory Proposal
3742,We describe LNICвЂ™s nearest-neighbors-based algorithm to improve precision and explainability of automatically detected label noise,Algorithms/ Methods Construction or Optimization
3743,"we developed EXBERT, a tool that combines the advantages of static analyses with a dynamic and intuitive view into both the attentions and internal representations of the underlying model.",Algorithms/ Methods Construction or Optimization
3744,We demonstrate that EXBERT can replicate insights from the analysis by Clark et al. (2019) and easily extend it to other models,Performance Evaluation
3745,"We present a web-based system for diacritization of Hebrew text, which caters to both casual and expert users",Model Construction or Optimization
3746,We provide a web interface for the user to input a text for diacritization and refine the resulting diacritized text,Model Construction or Optimization
3747,"We aim to provide a tool that is useful to casual users and language enthusiasts, but also to experts and professionals who may use it to set scientific editions of historical Hebrew texts.",Model Construction or Optimization
3748,"we present PHOTON, a modular, cross-domain NLIDB that adopts deep learning in its core components",Model Construction or Optimization
3749,we present the prototype of a new task automation agent named SUGILITE,Model Construction or Optimization
3750,"we unified the models of different implementation in a single codebase, implemented demos as top-level managers to access different models, and provide strategies to allow more organic integration across the models, including token probability interpolation, cross-mode scoring, latent interpolation, and unified hypothesis ranking",Model Construction or Optimization
3751,"We describe how we built an interactive visual explorer for this unified data, which we refer to as NLP Scholar",Theory Proposal
3752,"we introduce Funlines1 , an online game for generating funny news headlines for humor research.",Model Construction or Optimization
3753,"We explore and evaluate this fun, competitive way of motivating people to contribute creative text, addressing some of the special challenges of generating humor data mentioned above.",Performance Evaluation
3754,we optimize for efficiency with features that collapse common patterns observed in user testing and components designed for the iterative tuning of the semantic parser exemplars.,Performance Evaluation
3755,"We introduce DIALOGPT, a tunable gigawordscale neural network model for generation of conversational reponses, trained on Reddit data.",Model Construction or Optimization
3756,"we introduce a new version of ADVISER - previously a text-based, multi-domain dialog system toolkit (Ortega et al., 2019) - that supports multi-modal dialogs, including speech, text and vision information processing",Algorithms/ Methods Construction or Optimization
3757,we present Prta вЂ”the PRopaganda persuasion Techniques Analyzer.,Model Construction or Optimization
3758,"we exploit dilated convolution and n-gram matching mechanism to extract implicit semantic features and explicit semantic features, respectively.",Theory Proposal
3759,we develop a system to assist the professional coders in assigning the correct codes.,Algorithms/ Methods Construction or Optimization
3760,"We present ESPnet-ST, a toolkit that implements many of the recent models for E2E-ST, as well as the ASR and MT modules for Cascade-ST.",Algorithms/ Methods Construction or Optimization
3761,", we extend ESPnet to ST tasks, providing code for building translation systems and recipes (i.e., scripts that encapsulate the entire training/inference procedure for reproducibility purposes) for a wide range of ST benchmarks.",Theory Proposal
3762,"We describe and demonstrate Penman, a Python library and command-line utility for working with AMR data at both the tree and graph levels and for encoding and decoding these structures using PENMAN notation",Theory Proposal
3763,"We introduce a web application for writing scientific text with integrated literature discovery, paper reading, and bibliography management capabilities.",Algorithms/ Methods Construction or Optimization
3764,"we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT.",Model Construction or Optimization
3765,"We present MMPE, the first translation environment combining standard mouse & keyboard input with touch, pen, and speech interactions for PE of MT",Model Construction or Optimization
3766,"We introduce Torch-Struct, a library for structured prediction designed to take advantage of and integrate with vectorized, auto-differentiation based frameworks",Algorithms/ Methods Construction or Optimization
3767,we also include a number of general-purpose optimizations to provide cross-algorithm efficiency.,Performance Evaluation
3768,we present a novel approach to building dialog managers (DMs).,Model Construction or Optimization
3769,"we showcase Conversation Learner, a machine teaching tool for building dialog managers",Theory Proposal
3770,"We tackle the challenges involved with consuming vast quantities of news by leveraging modern techniques to semantically cluster stories, as well as innovative summarization methods to extract succinct, informational summaries for each cluster",Algorithms/ Methods Construction or Optimization
3771,"We leverage labeled datasets for DDI identification for supervision, and train a model that transfers to the related task of identifying supplement interactions.",Model Construction or Optimization
3772,we design task specific architectures to incorporate the now captured explanations into training,Model Construction or Optimization
3773,"We designed, built, and evaluated a fully automated news chatbot that bases its content on a stream of news articles from a diverse set of English news sources",Performance Evaluation
3774,We perform interpretability analysis to learn how these approaches can enhance our understanding of attention behavior and adaptive approaches,Applications
3775,We provide experimental results on the recent adaptive approaches for the multi-modal input sequences.,Model Construction or Optimization
3776,we propose methods to transfer text style on the story level.,Algorithms/ Methods Construction or Optimization
3777,we define style as the setting of the story which reveals time background and geographical information,Theory Proposal
3778,"we describe our novel unsupervised method, which can be implemented without the need for labeled paraphasia data",Algorithms/ Methods Construction or Optimization
3779,We demonstrate the utility of our method as an essential first step in developing augmentative and alternative communication (AAC) devices for patients suffering from aphasia in any language.,Algorithms/ Methods Construction or Optimization
3780,"we propose a novel GCN (Kipf and Welling, 2016)-based MeSH term index model, HGCN4MeSH, which learns the co-occurrence representation of tags via a GCN-based mapping function",Model Construction or Optimization
3781,we design a novel data-driven adjacency matrix to guide the information propagation between nodes.,Model Construction or Optimization
3782,We confirm that selecting training data similar to the learnersвЂ™ corpus instead of using randomly selected monolingual data improves the performance of the GEC model.,Applications
3783,We show the effect of realistic pseudo errors by considering the types of errors typically made by language learners for the Russian GEC task.,Theory Proposal
3784,"we study the relations among several popular embedding methods, including GloVe (Pennington et al., 2014), SGNS1 (Mikolov et al., 2013), Singular Value Decomposition (SVD) factorization of PMI matrix, and SVD factorization of log count (LC) matrix.",Algorithms/ Methods Construction or Optimization
3785,"we analyze the influence of training processes, i.e. hyperparameters (negative sampling), random initialization; and the influence of corpora towards word embeddings.",Dataset Creation or Resources
3786,We propose a word attribute transfer method that obtains a vector with an inverted binary attribute without explicit knowledge.,Algorithms/ Methods Construction or Optimization
3787,The proposed method demonstrates more accurate word attribute transfer for words that have target attributes than other baselines without changing the words that do not have the target attributes.,Algorithms/ Methods Construction or Optimization
3788,"we propose a balancing procedure, based on the a priori ratio between topic capacities.",Theory Proposal
3789,"We propose to modify the Transformer architecture (Vaswani et al., 2017) to combine the learned subword representations into word representations in the encoder block.",Theory Proposal
3790,We demonstrate that the North KoreanEnglish translation model can be trained effectively on bilingual South Korean-English data by character-level tokenization and phonemelevel decomposition.,Performance Evaluation
3791,"we propose a method to tokenize South Korean input sentences at the character level and decompose them into phonemes to mitigate the grammatical differences between South Korean and North Korean, and demonstrate that the translation model from North Korean to English can be effectively learned using bilingual South Korean-English data.",Model Construction or Optimization
3792,we present an unsupervised deep learning framework (SCAR) for deletion-based sentence compression,Model Construction or Optimization
3793,We introduce a novel linkage loss that ties together the compressor and the reconstructor.,Model Construction or Optimization
3794,"we propose a model that can identify and focus on abnormal findings more specifically and precisely, similar to the way that physicians would typically read, interpret, and write chest x-ray reports.",Model Construction or Optimization
3795,we investigate a method to exploit the monolingual data of the agglutinative language to enhance the representation ability of the encoder.,Algorithms/ Methods Construction or Optimization
3796,We experimentally compare the relevances produced by our method to those of other black-box and gradient-based explanation approaches.,Algorithms/ Methods Construction or Optimization
3797,We introduce the class zero-sum axiom for explanation methods.,Algorithms/ Methods Construction or Optimization
3798,We introduce NTUs as a novel research object that is capable of advancing our understanding of the interactive and rational aspects of social talk.,Model Construction or Optimization
3799,We propose an annotation strategy for exploring NTUs in naturally occurring dialogues.,Theory Proposal
3800,We propose to replace the rich linguistic feature templates used in the past approaches with a minimal feature function using contextual vector representations,Theory Proposal
3801,We train a BERT model on the Telugu Wikipedia data and use vector representations from this model to train the parser.,Model Construction or Optimization
3802,we understand how models which perform well under pointwise evaluation may fail in practice and find better methods for evaluating paraphrase identification models,Algorithms/ Methods Construction or Optimization
3803,we present our efforts towards building efficient NMT systems between Indian languages (specifically Indo-Aryan languages) and English by exploiting parallel data from related languages,Performance Evaluation
3804,we propose an interpretable approach for event extraction (EE) that mitigates the tension between generalization and interpretability through multitask learning (MTL).,Theory Proposal
3805,"We extend a subset of the BioNLP 2013 GENIA event extraction (Kim et al., 2013) dataset with a
set of rules designed to extract and explain three
of the GENIA biomedical events: protein phosphorylation, localization, and gene expression",Dataset Creation or Resources
3806,We propose a dataset which maintains a broad scope but which addresses subjectivity,Theory Proposal
3807,We propose an effective unsupervised alignment method to tackle the alignment problem.,Algorithms/ Methods Construction or Optimization
3808,we propose a strategy to supplement state-of-theart models with automatically extracted information using basic NLP tools to effectively handle rich morphology.,Model Construction or Optimization
3809,"We describe the first effort at establishing points of correspondence between disparate sentences. Without a clear understanding of points of correspondence, sentence fusion remains a daunting challenge that is only sparsely and sometimes incorrectly performed by abstractive summarizers.",Theory Proposal
3810,We present a sizable dataset for sentence fusion containing human-annotated corresponding regions between pairs of sentences,Dataset Creation or Resources
3811,We developed an uncertainty-aware automatic evaluation method for dialogue systems. Our method automates the human ratings required in в€†BLEU while keeping the performance.,Algorithms/ Methods Construction or Optimization
3812,We showed that integrating П…BLEU into RUBER greatly improves RUBERвЂ™s performance by providing the robustness to evaluate responses with uncertainty,Performance Evaluation
3813,we present a preliminary morphological analyser for verbs in Nen,Model Construction or Optimization
3814,we outline a computational approach for modelling the linguistic phenomenon of distributed exponence.,Model Construction or Optimization
3815,"We propose a novel end-to-end Arabic document classification framework, Arabic document imagebased classifier (AraDIC), inspired by the work on image-based character embeddings. AraDIC consists of an image-based character encoder and a classifier",Theory Proposal
3816,We propose to integrate label component information as embeddings into models. This procedure consists of two steps: (i) label decomposition and (ii) label embedding calculation.,Model Construction or Optimization
3817,we build a Japanese Wikipedia typo dataset (JWTD) from Japanese WikipediaвЂ™s revision history.,Dataset Creation or Resources
3818,We introduce a new task formulation of SAS that matches the actual usage,Algorithms/ Methods Construction or Optimization
3819,we seek to develop models that bridge the gap between biological plausibility and linguistic competence,Theory Proposal
3820,We propose a method to further align representations from such models into the cross-lingual space and use them to derive sentence embeddings.,Algorithms/ Methods Construction or Optimization
3821,we present a compositional semantics that maps various comparative constructions in English to semantic representations via Combinatory Categorial Grammar (CCG) parsers and combine it with an inference system based on automated theorem proving,Model Construction or Optimization
3822,"We introduce a set of new linguistic constraints (i.e. synonyms and antonyms) created with BabelNet for three languages: English, German and Italian.",Dataset Creation or Resources
3823,"We introduce an improved post-specialization method (dubbed WGAN-postspec), which demonstrates improved performance as compared to state-of-the-art DFFN (Vulic et al. Вґ , 2018) and AuxGAN (Ponti et al., 2018) models",Algorithms/ Methods Construction or Optimization
3824,We show that the proposed approach achieves performance improvements on an intrinsic task (word similarity) as well as on a downstream task (dialog state tracking),Theory Proposal
3825,We give a novel study of leveraging monolingual corpora of related and unrelated languages for NMT pre-training.,Model Construction or Optimization
3826,We make a comparison of existing and proposed techniques in a variety of corpora settings to verify our hypotheses,Theory Proposal
3827,We propose a method that selects a better hypothesis giving high importance to distinct words generated from decoder without the usage of any language model or data,Algorithms/ Methods Construction or Optimization
3828,"We aggregate existing datasets into a large disaster dataset using a new annotation scheme. Furthermore, by utilizing a class-mask (elaborated in Section 4.1), we make use of both binary-classification data and multi-class classification data in the same training phase.",Dataset Creation or Resources
3829,"We explore Manifold Mixup (Verma et al., 2019) in the natural language-based disaster domain. Manifold Mixup is a regularization technique originally introduced in computer vision tasks.",Algorithms/ Methods Construction or Optimization
3830,"we evaluate the syntactic difference between the generated trees, randomly generated trees and gold reference trees produced by constituency parsers;",Performance Evaluation
3831,"we introduce a new dataset containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context.",Dataset Creation or Resources
3832,We propose a single step transfer learning based classification method that identifies victim blaming language and labels it.,Algorithms/ Methods Construction or Optimization
3833,"we present various interactive visualization methods such as neuron activations (Karpathy et al., 2015; Dalvi et al., 2019), attention mechanisms (Bahdanau et al., 2014; Strobelt et al., 2018), and saliency measures (Li et al., 2016; Murdoch et al., 2018; Arras et al., 2017), including a walkthrough on how to build a simple attention visualization",Algorithms/ Methods Construction or Optimization
3834,"we learn how to anticipate how a developed technology could be repurposed for harmful or negative results, and designing systems so that they do not inadvertently cause harm.",Algorithms/ Methods Construction or Optimization
3835,"we focus on three main topic areas: 1) grounding in human-human communication; 2) grounding in dialogue systems; and 3) grounding in multi-modal interactive systems, including image-oriented conversations and humanrobot interactions",Theory Proposal
3836,"we propose this tutorial on reviewing natural language processing research, focusing on conference submissions and various review forms used in the NLP community.",Theory Proposal
3837,"we will introduce evaluation methods for style-conditioned text generation. We will present the current practice in the literature, involving both human evaluation and automatic metrics.",Algorithms/ Methods Construction or Optimization
3838,"we present approaches for information extraction (IE) from Web data that can be differentiated along two key dimensions: 1) the diversity in data modality that is leveraged, e.g. text, visual, XML/HTML, and 2) the thrust to develop scalable approaches with zero to limited human supervision",Model Construction or Optimization
3839,"we will (1) outline the various types of commonsense (e.g., physical, social), and (2) discuss techniques to gather and represent commonsense knowledge, while highlighting the challenges specific to this type of knowledge (e.g., reporting bias). We will also (3) discuss the types of commonsense knowledge captured by modern NLP systems (e.g., large pretrained language models), (4) review ways to incorporate commonsense knowledge into downstream task models, and (5) present various benchmarks used to measure systemsвЂ™ commonsense reasoning abilities.",Dataset Creation or Resources
3840,"We discuss two-stage retriever-reader frameworks for open-domain QA, pioneered by Chen et al. (2017): a retriever component finding documents that (might) contain an answer from a large collection of documents, followed by a reader component finding the answer in a given paragraph or a document.",Theory Proposal
3841,"we investigate the effectiveness of extending ImageNet to Arabic using Arabic WordNet (AWN) by searching in AWN for all the synsets used in ImageNet. AWN was originally developed in 2006 (Black et al., 2006).",Model Construction or Optimization
3842,"we propose Entity Synset Alignment(ESA), which is a method to create a general scene graph by aligning various semantic knowledge efficiently to solve this bias problem.",Performance Evaluation
3843,"we introduce VQGR, a VQG system that is able to generate natural language questions when shown radiology images",Model Construction or Optimization
3844,we propose two new metrics that evaluate how each question contributes to the goal,Performance Evaluation
3845,"We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA",Theory Proposal
3846,we propose a novel method for sentence boundary detection that takes it as a multi-class classification task under the endto-end pre-training framework.,Algorithms/ Methods Construction or Optimization
3847,we proposed a new adversarial training method to leverage target monolingual data to relieve the lowresource shortcoming of speech translation.,Algorithms/ Methods Construction or Optimization
3848,we propose a method to handle the two problems so as to generate robust translation to ASR errors.,Algorithms/ Methods Construction or Optimization
3849,"we propose a novel and effective Encoder-NAD-AD framework for NMT, in which the newly added non-autoregressive decoder (NAD) can provide target-side global information when autoregressive decoder (AD) translates, as illustrated in Figure 1. Briefly speaking, the encoder is first used to encode the source sequence into a sequence of vector representations.",Theory Proposal
3850,"We propose a novel and efficient approach to explicitly exploit discourse structure information for documentlevel NMT. Particularly, our approach is applicable for any other context encoder of document-level NMT;",Performance Evaluation
3851,This paper describes our machine translation systems for the streaming Chinese-toEnglish translation task of AutoSimTrans 2020. We present a sentence length based method and a sentence boundary detection model based method for the streaming input segmentation,Algorithms/ Methods Construction or Optimization
3852,we evaluate the joint use of linguistic features and deep learning models. We achieve this fusion by simply taking the output of deep learning models as features themselves.,Performance Evaluation
3853,"we use simulated data to demonstrate that the rate of human-human agreement has a substantial effect on estimates of system performance, making it difficult to compare systems that are evaluated on different datasets",Performance Evaluation
3854,"we are interested in providing feedback specialized to the content of the essay, and specifically for the content areas required by the rubric. A key objective is that the feedback should be localized alongside the relevant essay text.",Dataset Creation or Resources
3855,This paper examines one form of spoken language assessment; whether the response from the candidate is relevant to the prompt provided. This will be referred to as off-topic spoken response detection.,Model Construction or Optimization
3856,We propose a novel method for creating a tutoring dialogue collection that exhibits many of the properties needed for training a conversational tutor.,Algorithms/ Methods Construction or Optimization
3857,we employ a novel approach to advancing our understanding of the development of writing in English and German children across school grades using classification tasks.,Model Construction or Optimization
3858,We introduce an annotation scheme to capture the nature of sentence-level revisions of evidence use and reasoning (the вЂ�RERвЂ™ scheme) and apply it to 5th- and 6th-grade studentsвЂ™ argumentative essays.,Theory Proposal
3859,"we show how a deep-learning based system can outperform feature-based machine learning systems, as well as a string kernel system in scoring essay traits",Applications
3860,we present an NLP-based approach for tracking the evolution of written language competence in L2 Spanish learners using a wide range of linguistic features automatically extracted from studentsвЂ™ written productions.,Model Construction or Optimization
3861,we build two datasets of MCQs for second-language learners with distractor selections annotated manually by human experts.,Dataset Creation or Resources
3862,We develop and train models for automatic distractor selection that combine simple features with representations from pretrained models like BERT and ELMo,Model Construction or Optimization
3863,We annotate a small corpus of methodology sections drawn from Spanish information technology theses for the presence of steps and their logical order.,Algorithms/ Methods Construction or Optimization
3864,"We design a model to detect sentences that represent methodological steps, incorporating language model and verb taxonomy features, achieving 0.939 f-measure.",Algorithms/ Methods Construction or Optimization
3865,we set out methodological considerations of using automated speech recognition to build a corpus of teacher speech in an Indonesian language classroom,Algorithms/ Methods Construction or Optimization
3866,we describe a set of CR formative assessment items that call for students to express and integrate ideas across multiple dimensions of the NGSS.,Theory Proposal
3867,"we present a novel learning-andassessment context where middle school students were asked to criticize an argument presented in the prompt, focusing on identifying and explaining the reasoning flaws.",Model Construction or Optimization
3868,"we investigate whether, in automated essay scoring (AES) research, deep neural models are an appropriate technological choice. We find that fine-tuning BERT produces similar performance to classical models at significant additional cost.",Performance Evaluation
3869,We develop custom g-transformations: token-level edits to perform (g)rammatical error corrections. Predicting g-transformations instead of regular tokens improves the generalization of our GEC sequence tagging system.,Algorithms/ Methods Construction or Optimization
3870,"We decompose the fine-tuning stage into two stages: fine-tuning on errorful-only sentences and further fine-tuning on a small, high-quality dataset containing both errorful and error-free sentences.",Dataset Creation or Resources
3871,"We achieve superior performance by incorporating a pre-trained Transformer encoder in our GEC sequence tagging system. In our experiments, encoders from XLNet and RoBERTa outperform three other cutting-edge Transformer encoders (ALBERT, BERT, and GPT-2)",Applications
3872,we propose a method for interpreting the weights of personalized neural CWI models.,Algorithms/ Methods Construction or Optimization
3873,"we propose an approach for automatically evaluating their appropriateness. Using neural machine translation, we generate correct-incorrect sentence pairs to serve as synthetic data in order to increase the amount and diversity of training data for our scoring model",Model Construction or Optimization
3874,we present work on automatically scoring student responses to constructed-response mathematics items where the response should contain both text and mathematical equations or expressions.,Theory Proposal
3875,we explore whether approaches from the field of transfer learning may be useful for improving item parameter modeling.,Model Construction or Optimization
3876,"we provide a fair comparison of two methods for generating synthetic parallel data for GEC, using two evaluation datasets;",Algorithms/ Methods Construction or Optimization
3877,we look at the temporal change of gender bias in biomedical research.,Theory Proposal
3878,"We answer the question; How has the usage of gender stereotypes changed in the last 60 years of biomedical research? Specifically, we look at the change in well-known gender stereotypes (e.g., Math vs Arts, Career vs Family, Intelligence vs Appearance, and occupations) in biomedical literature from 1960 to 2020.",Theory Proposal
3879,"we are the first to employ a novel, completely unsupervised end-to-end neural attention-based document representation learning approach, using no external labels, in order to achieve the most meaningful term transfer between related documents, i.e. semantic tagging of documents, in a вЂњpseudorelevance feedbackвЂќвЂ“based (Xu and Croft, 2000) setting for unsupervised query expansion.",Model Construction or Optimization
3880,"We present a search system that works in a paradigm which we call Extractive Search, and which allows rapid information seeking queries that are aimed at extracting facts, rather than documents.",Model Construction or Optimization
3881,"we adapt ESP to encode dependency paths, an approach we call Embedding of Structural Dependencies (ESD).",Applications
3882,"We compare two methods for learning biomedical concept embeddings, the skip-gram with negative sampling (SGNS) algorithm (Mikolov et al., 2013a) and Embedding of Semantic Predications (ESP) (Cohen and Widdows, 2017), which adapts SGNS to encode concept-predicate-concept triples.",Algorithms/ Methods Construction or Optimization
3883,"we introduce in more detail the notion of spin, the types of spin that we address, and the information that is required to assess an article for spin",Theory Proposal
3884,"we describe our current algorithms, methods employed and provide their evaluation.",Algorithms/ Methods Construction or Optimization
3885,"we introduce construction of RadVisDial - the first publicly available dataset for visual dialog in radiology, derived from the MIMIC-CXR (Johnson et al., 2019) dataset",Dataset Creation or Resources
3886,we compare several state-of-the-art models for VQA and VisDial applied to these images,Model Construction or Optimization
3887,"our model operates in the relation extraction setting, meaning it must distinguish between relations and nonrelations, as well as classifying by relation type.",Model Construction or Optimization
3888,"We introduce a pooled embedding for relational classification across long distances. Wang et al. (2019) focused on short-distance relations, but clinical CONTAINS relations often span multiple sentences, so a sequence-level embedding is necessary for such long-distance inference.",Algorithms/ Methods Construction or Optimization
3889,we present an experimental evaluation of coding coverage in the MIMIC-III discharge summaries.,Performance Evaluation
3890,"we further propose to combine reinforcement learning (RL) to automatically extract out task-specific noisy text from the long documents, as we observe that many text segments do not contain predictive information such that removing these noise can potentially improve the performance.",Theory Proposal
3891,"We model the noise extraction process as a sequential decision problem, which also aligns with the fact that clinical documents are received in time-sequential order",Model Construction or Optimization
3892,"we study the impact of a number of model design choices. First, following Reimers and Gurevych (2019), we study the impact of various pooling methods on STS, and find that convolution filters coupled with max and mean pooling outperform a number of alternative approaches",Algorithms/ Methods Construction or Optimization
3893,"We establish state-of-the-art benchmarks for EMR QA on a large clinical question answering dataset, emrQA",Dataset Creation or Resources
3894,"We introduce and evaluate new models, achieving SOTA performance for this task.",Performance Evaluation
3895,we show that machine learningbased unsupervised clustering of and anomaly detection with linguistic biomarkers are promising approaches for intuitive visualization and personalized early stage detection of AlzheimerвЂ™s disease.,Theory Proposal
3896,"we introduce BIOMRC, a new dataset for biomedical MRC that can be viewed as an improved version of BIOREAD.",Dataset Creation or Resources
3897,"we propose a simple and intuitive neural model to reinstate migrating words that transpire in letter position dyslexia, a visual analysis deficit to the encoding of character order within a word",Model Construction or Optimization
3898,"We propose a document classification approach to determine the reason for administration of a given drug, with particular focus on domain adaptation from one drug to another, and instance selection to minimize annotation effort.",Theory Proposal
3899,our work explores methods to improve the performance of classifying the indication for an antibiotic administration in veterinary records of dogs and cats.,Algorithms/ Methods Construction or Optimization
3900,"We make the embeddings, code, and other materials publicly available and outline several avenues of future work to facilitate progress in the field.",Performance Evaluation
3901,"We train five recent KGE models on SNOMED-CT and demonstrate their advantages over previous methods, making a case for the importance of leveraging the multirelational nature of knowledge graphs for biomedical knowledge representation.",Algorithms/ Methods Construction or Optimization
3902,"We investigate different types of errors that are penalized by exact F-score and identify a specific error type where there is high degrees of disagreement between the human user experience and what exact F-score measures: namely, errors where the extracted entity is correctly labeled, but the span only overlaps with the annotated entity rather than matching perfectly",Performance Evaluation
3903,"We demonstrate that the simple applications of this model under-perform and require knowledge base order-sensitive markings, ktag, to achieve state-of-the-art performance. This data encoding scheme captures the latent relation direction and provides a simple way to reduce noise in distant supervision.",Model Construction or Optimization
3904,we propose a new neural network model that combines multi-head attention mechanisms with a set of convolutions to provide global locality in biomedical event and relation extraction,Model Construction or Optimization
3905,we investigate the use of MTL with transformer-based models (BERT) on multiple biomedical and clinical NLP tasks,Performance Evaluation
3906,we present the dataset used for our experiments and their respective results,Dataset Creation or Resources
3907,our paper introduces a multi-modal approach for fine-grained opinion mining,Theory Proposal
3908,"Our proposed model, at the time of writing, out-performs the state of the art on a benchmark dataset on a variety of accuracy and regression metrics",Model Construction or Optimization
3909,"we combine ideas from (Tsai et al., 2019) and (Liu et al., 2018) and explore the use of Transformer (Vaswani et al., 2017) based models for both aligned and unaligned signals without extensive over-parameterization of the models by using multiple modality-specific transformers.",Model Construction or Optimization
3910,"a cross-situational learning based grounding framework is proposed that allows grounding of words and phrases through corresponding percepts without human supervision and online, i.e. it does not require any explicit training phase, but instead updates the obtained mappings for every new encountered situation.",Theory Proposal
3911,"We propose a multimodal analytical framework that analyzes the candidate in an interview scenario and provides feedback for predefined labels such as engagement, speaking rate, eye contact, etc.",Theory Proposal
3912,"we discuss the benefits of a multimodal understanding of in-cabin utterances by incorporating verbal/language input together with the non-verbal/acoustic and visual cues, both from inside and outside the vehicle (e.g., passenger gestures and gaze from in-cabin video stream, referred objects outside of the vehicle from the road view camera stream).",Theory Proposal
3913,"we recommend an AI sensing system that can semantically interpret the environmental conditions, objects, relations and activity carried out from the visual feed.",Dataset Creation or Resources
3914,We analyze popular VQA models through the lens of attribution (inputвЂ™s influence on predictions) to gain valuable insights,Dataset Creation or Resources
3915,"We adopt the PU algorithm of Peng et al. (2019) to the domain of consumer electronic product descriptions, and evaluate its effectiveness on four entity types: Product, Component, Brand and Attribute",Performance Evaluation
3916,"we present SessionPath, a novel neural network model that improves facet suggestions on two counts: first, the model is able to leverage session embeddings to provide scalable personalization; second, SessionPath predicts facets by explicitly producing a probability distribution at each node in the taxonomy path.",Model Construction or Optimization
3917,we formulate the recommendation problem into a supervised product embedding learning process,Theory Proposal
3918,"we target and use real-world data - service calls, which poses additional challenges with respect to the artificial datasets that have been typically used in the past in multimodal sentiment researches (Cambria et al., 2017), such as variability and noises.",Dataset Creation or Resources
3919,We demonstrate the success of XLNet on finding product specifications that can help answering product related queries. It beats the baseline Siamese method by 0.14 в€’ 0.31 points in HIT@1.,Algorithms/ Methods Construction or Optimization
3920,we present our work to improve the intent classification in the shopping assistant of Walmart company by using inter-utterance context. Our work also reduces the contextual disambiguation burden from the dialog manager,Model Construction or Optimization
3921,We propose a semi-supervised iterative approach to collect user complaints about a service from social media platforms,Theory Proposal
3922,We evaluate the proposed approach for the problem of complaint detection for transportation services on Twitter.,Performance Evaluation
3923,"we propose a novel approach for item-based collaborative filtering, by leveraging the BERT model (Devlin et al., 2018) to understand item titles and model relevance between different items",Model Construction or Optimization
3924,"We proposed a semisupervised method, and successfully applied it to product reviews from different categories in the ecommerce platform",Algorithms/ Methods Construction or Optimization
3925,"We propose a Deep Hierarchical Classification framework, which incorporates the multi-scale hierarchical information in neural networks and introduces a representation sharing strategy according to the category tree.",Theory Proposal
3926,we introduced SimsterQ - a clustering based system for answering questions that makes use of word vectors. Clustering was performed using cosine similarity scores between sentence vectors of reviews and questions,Model Construction or Optimization
3927,"We propose a novel use of sentiment analysis by examining a key section of the quarterly and annual reports submitted to the SEC in two states: first, the unaltered report as filed with the SEC (X 0 ), and second, the report without selected NGMs (X). We then calculated the change in the tone or sentiment (as we use these terms interchangeable) as (X - X0 ) for each report and used it as an input to our prediction model",Model Construction or Optimization
3928,we study the applicability of Bayesian Parametric and Non-parametric methods for user clustering in an E-commerce search setting.,Algorithms/ Methods Construction or Optimization
3929,We propose a joint training setup in which sentence selection and claim verification are tackled by a single neural sequence matching model.,Model Construction or Optimization
3930,we simplify the training procedure and increase training efficiency for sentence selection and claim verification by merging redundant components and computation that exist when training the two tasks separately.,Performance Evaluation
3931,We describe the methodology for creating the corpus and the annotation process.,Algorithms/ Methods Construction or Optimization
3932,we propose a probabilistic graphical model which formulates fact extraction in a generative process.,Model Construction or Optimization
3933,"we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components",Model Construction or Optimization
3934,We propose two measures for measuring the quality of constructed claims in the FEVER task. Annotating data for this task involves the creation of supporting and refuting claims over a set of evidence,Theory Proposal
3935,"We propose, instead, a model-agnostic framework that consists of two modules: (1) a span extractor, which identifies the crucial information connecting claim and evidence; and (2) a classifier that combines claim, evidence, and the extracted spans to predict the veracity of the claim",Model Construction or Optimization
3936,"we report on the shared task on sarcasm detection that we conducted as part of the2nd Workshop on Figurative Language Processing
(FigLang 2020) at ACL 2020. The task aims to
study the role of conversation context for sarcasm
detection.",Dataset Creation or Resources
3937,"We propose a new data augmentation technique that can successfully leverage the structural patterns of the conversational dataset. Our technique, called CRA(Contextual Response Augmentation), utilizes the conversational context of the unlabeled dataset to generate new training samples.",Theory Proposal
3938,"We propose an architecture where the Transformer Encoder is stacked with BiLSTM (Schuster and Paliwal, 1997) and NeXtVLAD (Lin et al., 2018). We observe that NeXtVLAD, a differentiable pooling layer, proves more effective than simple nonparametric mean/max pooling methods.",Algorithms/ Methods Construction or Optimization
3939,"We present the shared task and provide a brief description of each of the participating systems, a comparative evaluation of the systems, and our observations about trends in designs and performance of the systems that participated in the shared task",Theory Proposal
3940,we propose an end-to-end neural based method named DeepMet for detecting metaphor by transforming the token-level metaphor detection task into the reading comprehension task.,Algorithms/ Methods Construction or Optimization
3941,"We propose a novel approach (as detailed in Figure 1) wherein we first construct a dataset of realworld contextвЂ“satirical headline pairs in which the context is constructed by procedurally retrieving and ranking real-world stories, events and information related to the entities that appear in the original satirical headline.",Theory Proposal
3942,"we introduce a novel approach for modeling satirical news headlines as conditioned on a real-world context, and an information retrieval pipeline for constructing the real-world context for a given real satirical headline",Model Construction or Optimization
3943,"we explore the use of contextualized word embeddings for detecting sarcasm in the responses sampled from Reddit as well as Twitter. We outline the effect of adding contextual information, from previous dialogue turns, to the response, for both the datasets.",Algorithms/ Methods Construction or Optimization
3944,we propose using machine learning techniques with BERT and GloVe embeddings to detect sarcasm in tweets.,Theory Proposal
3945,we present our study on the effectiveness of contextual information to decide if anutterance is sarcastic or not.,Theory Proposal
3946,"we propose to employ bidirectional encoder representations transformers (BERT), and aspect-based sentiment analysis approaches in order to extract the relation between context dialogue sequence and response and determine whether or not the response is sarcastic.",Theory Proposal
3947,"we present traditional Machine learning approaches, Deep learning approach (RNN-LSTM) and BERT (Bidirectional Encoder Representations from Transformers) for identifying sarcasm.",Algorithms/ Methods Construction or Optimization
3948,we present a deep neural architecture for sarcasm detection.,Algorithms/ Methods Construction or Optimization
3949,"We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset1",Model Construction or Optimization
3950,we describe the work we performed for context aware sarcasm detection for both the data sets.,Dataset Creation or Resources
3951,"We present different techniques and models, mostly based on transformer for Sarcasm Detection with Context.",Model Construction or Optimization
3952,we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts in a hierarchical manner.,Theory Proposal
3953,"We perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (Yang et al., 2019) (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.",Applications
3954,"we aim to detect token-level metaphors from plain texts by focusing on content words (Verbs, Nouns, Adjectives and Adverbs) of two corpora: VUA1 and TOFEL2",Theory Proposal
3955,we design an ALBERTBiLSTM structure to recognize metaphorical words in TOEFL dataset,Dataset Creation or Resources
3956,"we use concatenation of GloVe (Pennington et al., 2014) and ELMo (Peters et al., 2018) vectors augmented with character level features using CNN and highway network (Kim et al., 2016; Srivastava et al., 2015)",Theory Proposal
3957,"We propose two models for metaphor detection1 with the input prepared as above - a vanilla BiLSTM model and a vanilla Transformer Encoder (Vaswani et al., 2017) model similar to BERT (Devlin et al., 2019) (but without pre-training).",Model Construction or Optimization
3958,This work explores the differences and similarities between neural image classifiersвЂ™ mis-categorisations and visually grounded metaphors - that we could conceive as intentional mis-categorisations,Theory Proposal
3959,we introduce a gold standard data set of human x-phemism judgments and evaluate our models for this task.,Performance Evaluation
3960,we build our metaphor detection model upon RoBERTa to leverage its strength in capturing contextual information.,Model Construction or Optimization
3961,we are interested in relation-level metaphor identification focusing on the data availability for this level of processing.,Dataset Creation or Resources
3962,we report preliminary results from applying this approach to two distinct scenarios: debates on gun rights and marriage equality,Applications
3963,we describe computational ethnography studies to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence.,Theory Proposal
3964,"we set out a preliminary investigation of oxymorons based on naturally occurring data from Italian, with a view to contributing to the NLP-oriented research on figurative language by supplying an initial list of oxymorons and oxymoronic structures that can be used for further analyses and for evaluation tasks.",Dataset Creation or Resources
3965,"Proposing the first model for humor style transfer, building a transformer model that вЂњtranslatesвЂќ from regular to humorous English1",Model Construction or Optimization
3966,we investigate whether Gao et al. (2018)вЂ™s findings can be replicated when detecting metaphors in TOEFL essays rather than the BNC,Performance Evaluation
3967,we present a novel resourceinexpensive architecture for metaphor detection based on a residual bidirectional long short-term memory and conditional random fields.,Model Construction or Optimization
3968,we investigate the supervised disambiguation of potential occurrences of German VIDs,Performance Evaluation
3969,"we participate in the 2020 Metaphor Detection Shared Task (Leong et al., 2020).",Theory Proposal
3970,we present the first neural metaphor processing architecture that models a broader discourse through the use of attention mechanisms,Model Construction or Optimization
3971,"we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing",Theory Proposal
3972,We propose using both BERT and XLNet language models to create contextualized embeddings and a bidirectional LSTM to identify whether a given word is a metaphor.,Model Construction or Optimization
3973,We present an ensemble approach for the detection of sarcasm in Reddit and Twitter responses in the context of The Second Workshop on Figurative Language Processing held in conjunction with ACL 20201 .,Model Construction or Optimization
3974,we present a transformer-based sarcasm detection model that takes both the target utterance and its context and predicts if the target utterance involves sarcasm.,Model Construction or Optimization
3975,"we explore teacher-student distillation as a means of increasing the efficiency of neural network systems used to undertake a core task in NLP, dependency parsing.",Performance Evaluation
3976,develops a novel approach to the problem based on general graph parsing techniques;,Model Construction or Optimization
3977,proposes and evaluates different ways of integrating вЂ�externalвЂ™ grammatical information;,Performance Evaluation
3978,We propose an end-to-end variational autoencoding parsing (VAP) model for semisupervised graph-based projective dependency parsing,Model Construction or Optimization
3979,we define a neural-network left-corner parser with bounded stack memory for parsing and psycholinguistic prediction.,Theory Proposal
3980,we consider a softer version of homomorphic encryption in the form of obfuscation for natural language,Model Construction or Optimization
3981,"we present a generalization of this concept: latent-variable semiring parsing. With our framework, any semiring weighted logic program can be latentified by transforming weights from scalar values of a semiring to rank-n arrays, or tensors, of semiring values, allowing the modeling of latent variables within the semiring parsing framework",Model Construction or Optimization
3982,we are proposing a new nonterminal naming scheme for hybrid grammars. We hypothesize that these steps are complementary in improving the accuracy of the parsing model.,Model Construction or Optimization
3983,"we lay the theoretical foundations for a supertagging-based LCFRS parser. As LCFRS obtained from corpora such as the PTB are usually not lexical, we employ a lexicalization procedure",Theory Proposal
3984,"we propose SS-PRPN, a semi-supervised extension of the UP architecture PRPN (Shen et al., 2018a), which can be trained jointly on language modeling and supervised parsing.",Model Construction or Optimization
3985,we try to improve both speed and accuracy of chart-based parsers,Theory Proposal
3986,Development of a robust dependency parsing model using the latest transformer encoder.,Model Construction or Optimization
3987,development of a deep parser for Spanish that uses a HPSG grammar and returns trees that contain both syntactic and semantic information.,Model Construction or Optimization
3988,"we introduce the task of parsing into enhanced universal dependencies, describes the datasets used for training and evaluation, and evaluation metrics",Dataset Creation or Resources
3989,We present the approach of the TurkuNLP group to the IWPT 2020 shared task on Multilingual Parsing into Enhanced Universal Dependencies.,Model Construction or Optimization
3990,"we describe our system to predict enhanced dependencies for Universal Dependencies (UD) treebanks, which ranked 2nd in the Shared Task on Enhanced Dependency Parsing with an average ELAS of 82.60%. Our system uses a hybrid two-step approach.",Theory Proposal
3991,we presents our parsing approach to the Shared Task on Enhanced Universal Dependencies at IWPT 202,Model Construction or Optimization
3992,We present the system submission from the FASTPARSE team for the EUD Shared Task at IWPT 2020.,Model Construction or Optimization
3993,"we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.",Algorithms/ Methods Construction or Optimization
3994,This paper presents the system used in our submission to the IWPT 2020 Shared Task. Our system is a graph-based parser with secondorder inference,Model Construction or Optimization
3995,"In this paper, we present the submission of team CLASP to the IWPT 2020 Shared Task on parsing enhanced universal dependencies",Model Construction or Optimization
3996,"We present KГёpsala, the Copenhagen-Uppsala system for the Enhanced Universal Dependencies Shared Task at IWPT 2020.",Model Construction or Optimization
3997,This paper presents our system at the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies,Model Construction or Optimization
3998,"This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2020, offline speech translation and simultaneous speech translation.",Algorithms/ Methods Construction or Optimization
3999,This paper describes KITвЂ™s submissions to the IWSLT2020 Speech Translation evaluation campaign.,Performance Evaluation
4000,we build a simultaneous translation system for text-to-text(t2t) and speech-to-text(s2t) problems based on Transformer wait-k model,Model Construction or Optimization
4001,we describe the system submitted to the IWSLT 2020 Offline Speech Translation Task. We adopt the Transformer architecture coupled with the meta-learning approach to build our end-to-end Speechto-Text Translation (ST) system,Theory Proposal
4002,Our system is an endto-end model based on an adaptation of the Transformer for speech data.,Applications
4003,"This paper describes the submission to IWSLT 2020 End-to-End Speech Translation task by Samsung R&D Institute, Poland",Theory Proposal
4004,We propose a few improvements to our previous system,Algorithms/ Methods Construction or Optimization
4005,"This paper describes the University of Helsinki Language Technology groupвЂ™s participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text",Theory Proposal
4006,"This paper describes the LIT TeamвЂ™s submission to the IWSLT2020 open domain translation task, focusing primarily on Japanese-toChinese translation direction.",Theory Proposal
4007,"we demonstrate our system applied for the IWSLT 2020 open domain text translation task, which aims to translate Chinese from/to Japanese 1",Performance Evaluation
4008,This paper describes the University of EdinburghвЂ™s neural machine translation systems submitted to the IWSLT 2020 open domain Japaneseв†”Chinese translation task.,Theory Proposal
4009,"sambiguation (Tang et al., 2018a,b). In this paper, we describe our Transformer based neural machine translation system submitted to the IWSLT 2020 Chineseв†’Japanese and Japaneseв†’Chinese open domain translation task",Model Construction or Optimization
4010,establishing an efficient data pre-processing pipeline for large web-crawled corpora to train a transformer model for NMT and exploiting large amount of monolingual data with back-translation and language modeling.,Performance Evaluation
4011,we introduce University of TsukubaвЂ™s submission to the IWSLT20 Open Domain Translation Task.,Dataset Creation or Resources
4012,"we describe the XiaomiвЂ™s neural machine translation (NMT) systems evaluated at IWSLT 2020 (Ansari et al., 2020) shared open domain translation task in two directions, Chineseв†’Japanese (Zhв†’Ja) and Japaneseв†’Chinese (Jaв†’Zh)",Performance Evaluation
4013,"This paper describes the neural machine translation (NMT) system of the Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020) (Ebrahim et al., 2020)",Theory Proposal
4014,"we describe the data and training pipeline for building our NMT system. We start with the two datasets provided by the shared task organizersвЂ”the existing parallel (EP) 167 dataset that includes public, parallel sentences, as well as the Web crawled (WC) dataset created by crawling, aligning, and filtering JA-ZH parallel sentences from the Web",Dataset Creation or Resources
4015,we propose a novel domain adaptation method through style transfer of out-of-domain data using unsupervised machine translation.,Algorithms/ Methods Construction or Optimization
4016,we propose a framework for disfluency removal that utilizes a simple noise induction technique for data augmentation using fluent monolingual text in the target language.,Theory Proposal
4017,we present details of our system in the IWSLT Video Speech Translation evaluation.,Theory Proposal
4018,"This paper describes our submission to Non-Native Speech Translation Task in IWSLT 2020 (Ansari et al., 2020).",Theory Proposal
4019,"This paper describes the submission of the EU project ELITR (European Live Translator)1 to the non-native speech translation task at IWSLT 2020 (Ansari et al., 2020).",Theory Proposal
4020,"we propose Speech Translation as an alternative to the template creation process. We experiment with cascade systems, i.e. pipelined ASR+MT architectures, and direct, end-to-end ST systems",Theory Proposal
4021,We evaluate a combination of retranslation techniques that have not previously been studied together,Performance Evaluation
4022,"We provide the first empirical comparison of re-translation and streaming models, demonstrating that re-translation operating in a very low-revision regime can match or beat the quality-latency trade-offs of streaming models",Model Construction or Optimization
4023,"We test a 0-revision configuration of re-translation, and show that it is surprisingly competitive, due to the effectiveness of data augmentation with prefix pairs.",Performance Evaluation
4024,"We therefore propose the use of Adaptive Computation Time (Graves, 2016) for simultaneous machine translation",Theory Proposal
4025,we integrate a source chunk boundary detection component into a bidirectional recurrent NMT model.,Model Construction or Optimization
4026,this work investigates ASR with output compression. We test our approaches on German TV subtitles,Performance Evaluation
4027,we present research work to enhance a STST pipeline in order to comply with the timing and rendering requirements posed by cross-lingual automatic dubbing of TED Talk videos,Algorithms/ Methods Construction or Optimization
4028,we highlight several of such language mixing phenomena related to the task of localization for translation and focus on two distance (miles to kilometers) and temperature (Fahrenheit to Celsius) conversion tasks.,Model Construction or Optimization
4029,we propose a solution for automatic punctuation that is both cost efficient and easy to train,Performance Evaluation
4030,we detail two non-invasive ways of detecting translationese,Theory Proposal
4031,we compare translationese across human and machine translations from text and speech.,Theory Proposal
4032,"we introduced a new shared task, organised by Duolingo, which encouraged models to produce as many correct translations as possible for a given input.",Model Construction or Optimization
4033,we propose a one-to-many text style transfer framework that can be trained using non-parallel text,Theory Proposal
4034,"we have proposed a novel procedure for training encoder-decoder models, where the softmax function is applied to the output of each of the M decoder layers derived using the output of each of the N encoder layers",Model Construction or Optimization
4035,we propose an improved method of scaling the quantization centres,Algorithms/ Methods Construction or Optimization
4036,we propose a new approach that enables NMT systems to effectively adapt to a new domain using few-shots learning,Theory Proposal
4037,"we collect, rank and evaluate a new publicly available headline paraphrase corpus (ParaPhraser Plus), and then perform text generation experiments with manual evaluation on automatically ranked corpora using the Universal Transformer architecture.",Performance Evaluation
4038,we propose to train an end-to-end XLS model to directly generate target language summaries given the source articles by matching the semantics of the predictions with the semantics of the source language summaries,Model Construction or Optimization
4039,"We propose a question type driven framework for AG-QG, which enables the model to generate diverse questions with high quality",Model Construction or Optimization
4040,We develop methods for producing text headings and section-level embeddings through a new task: generation of section titles for Wikipedia articles,Algorithms/ Methods Construction or Optimization
4041,"we explore unexpected and erroneous changes in the output of NMT models. Consider the simple example in Table 1 where the Transformer model (Vaswani et al., 2017) is used to translate very similar sentences.",Model Construction or Optimization
4042,Our approach can be used to mitigate problems commonly associated with language models,Model Construction or Optimization
4043,we perform a large-scale empirical analysis to attempt to discover best practices when using knowledge distillation in combination with domain adaptation,Applications
4044,we introduce a system built for the Duolingo Simultaneous Translation And Paraphrase for Language Education (STAPLE) shared task at the 4th Workshop on Neural Generation and Translation,Algorithms/ Methods Construction or Optimization
4045,"we focus on two approaches, both based on VAE: one that attempts to achieve the diversity by generalizing the sentence representation produced by the encoder; and another which randomly perturbs the encoderвЂ™s output during the sentence generation.",Algorithms/ Methods Construction or Optimization
4046,"we demonstrate that even though we use a simple approach, it is possible to generate varied paraphrased transcriptions which do not simply replace one word with another, contrarily, it utilizes different styles, opposition, word order etc.",Performance Evaluation
4047,we propose a transferlearning-based simultaneous translation model by extending BART,Model Construction or Optimization
4048,"we experiment with various methods to improve the diversity of translations, while preserving their quality",Algorithms/ Methods Construction or Optimization
4049,we propose to address the STAPLE task primarily as a MT task to better understand the strengths and weaknesses of neural MT architectures for generating multiple learner-relevant translations,Model Construction or Optimization
4050,We find that stronger BLEU performance of the beam-search generated translation is not indicative of improvements on the task metricвЂ”weighted macro F1 of a set of hypothesesвЂ”and suggest this should encourage further research on how to train NMT models when n-best lists are needed (В§7.1).,Applications
4051,This paper describes the third place submission to the shared task Mayhew et al. (2020) on simultaneous translation and paraphrasing for language education at the 4th workshop on Neural Generation and Translation (WNGT) for ACL 2020.,Theory Proposal
4052,"We also optimized the Transformer model decoding in engineering, such as caching the decoderвЂ™s attention results and using low precision data type.",Dataset Creation or Resources
4053,"This paper describes the OpenNMT (Klein et al., 2017) submissions to the Workshop on Neural Generation and Translation 2020 efficiency shared task.",Performance Evaluation
4054,This paper describes the University of EdinburghвЂ™s submissions to the Workshop on Neural Generation and Translation (WNGT) 2020 Efficiency Shared Task1 using the Marian machine translation toolki,Performance Evaluation
4055,we aim to demonstrate performance optimization in a particular domain by training document-level models on large out-of domain parallel corpus combined with small in-domain corpus using domain adaptation techniques.,Performance Evaluation
4056,we introduce a new task called Simultaneous Translation and Paraphrasing for Language Education (STAPLE).,Model Construction or Optimization
4057,"We propose a novel KB-QA system, MULTIQUE, that combines information from curated and extracted knowledge bases to answer complex questions.",Theory Proposal
4058,"Dataset for a task of classifying type of logical statement, gathered on MTurk platform and consisting of 851 sentences, belonging to six classes.",Dataset Creation or Resources
4059,We provide novel analysis and selection of interpolation coefficients for combining global models with user-personalized models.,Performance Evaluation
4060,we address the problem of having insufficient data collection methodologies by proposing a novel approach that accelerates the data collection process for use in NL-to-QL models,Model Construction or Optimization
4061,we formulate text normalization and sanitization as a multi-task text generation approach and propose a neural pointer-generator network based on multihead attention,Theory Proposal
4062,we explore the possibility of mitigating the problems related to ASR inconsistency and code-switching in our input data by using two alternate representations of text in our NLU model: ISO-15919 and IndicSOUNDEX. ISO-159191 was developed as a standardized Latin-based representation for Indic languages and scripts,Model Construction or Optimization
4063,we propose some simple alternatives and show that they lead to 13 better performance.,Model Construction or Optimization
4064,We introduce copy mechanism for BERTbased models with a unified encoder-decoder framework for question generation. We further extend this copy mechanism using selfattentions.,Model Construction or Optimization
4065,"we address the problems of training on a domain with effectively limitless possible vocabulary, and aim to create a DST system capable of scaling to unseen vocabulary at inference. We do this by first utilizing a language model (LM) based Transformer that is capable of handling any possible input and output in a textual manner, letting the same exact architecture scale to new intents, slots, and slot values, with no modifications needed",Model Construction or Optimization
4066,"we propose to use efficient dual sentence encoders such as Universal Sentence Encoder (USE) (Cer et al., 2018) and ConveRT (Henderson et al., 2019b) to support intent detection",Performance Evaluation
4067,"we present a vastly simplified, single-layer convolutional model (Kim, 2014; Bai et al., 2018) that is highly compressible but nonetheless achieves competitive results on task-oriented natural language understanding benchmarks",Algorithms/ Methods Construction or Optimization
4068,"we propose DLGNet, a transformer-based model for multi-turn dialogue modeling that addresses some of the highlighted problems above",Model Construction or Optimization
4069,"we propose a simple data augmentation method leveraging a confusionmatrix-based ASR error simulator (Fazel-Zarandi et al., 2019; Schatzmann et al., 2007).",Algorithms/ Methods Construction or Optimization
4070,we explore automating the creation of a template pool for a customer service chat application through clustering historical agent utterances and choosing representative utterances from each cluster,Algorithms/ Methods Construction or Optimization
4071,"We propose a two-stage training strategy. We first coarse-train the state tracking models on reading comprehension datasets, then finetune them on the target state tracking dataset",Model Construction or Optimization
4072,"we propose a multi-task setting to train the model. More specifically, our model is encouraged to explicitly ensure the two aforementioned effects of the contextual information for the task of SF.",Model Construction or Optimization
4073,"we propose the task of few-shot IC/SF, catering to domain adaptation in low resource scenarios, where there are only a handful of annotated examples available per intent and slot in the target domain",Theory Proposal
4074,"We identify the annotation errors, inconsistencies, and ontology issues in MultiWOZ 2.1, and publish its improved version.",Model Construction or Optimization
4075,"We propose Sketch-Fill-A-R, a dialogue agent framework that can learn to generate fluent, consistent and engaging chit-chat responses. Our key motivation is the hypothesis that human-like chit-chat responses often 1) follow common conversational patterns with insertions of agent-specific traits, and 2) condition explicitly on those persona traits.",Theory Proposal
4076,we propose a set of eight probing tasks to measure the conversational understanding of neural dialog models,Model Construction or Optimization
4077,"This paper introduces CODA-19, the COVID19 Research Aspect Dataset and presents the first outcome of our exploration in using non-expert crowds for large-scale scholarly article annotation",Dataset Creation or Resources
4078,"In this paper, we present an information retrieval system on a corpus of scientific articles related to COVID-19.",Theory Proposal
4079,"We present COVID-Q, a dataset of 1,690 questions about COVID from 13 online sources.",Dataset Creation or Resources
4080,we developed a Natural Language Processing (NLP) system to extract potential positive COVID-19 cases from clinical text within the Department of Veterans Affairs (VA).,Algorithms/ Methods Construction or Optimization
4081,"we present and make publicly available a high quality, ground truth text dataset of emotional responses to COVID-19.",Dataset Creation or Resources
4082,We formulate the task of cross-lingual transfer learning for epidemiological outbreak alignment across countries.,Theory Proposal
4083,We create a multi-label classifier based on transfer learning that can detect conspiracyladen comments. We find that misinformation videos contain a significantly higher proportion of conspiratorial comments.,Theory Proposal
4084,"We developed NEMSI (Suendermann-Oeft et al., 2019), or the NEurological and Mental health Screening Instrument, to bridge this gap.",Model Construction or Optimization
4085,"We tested that for long document classification, a simple feature-based approach can work better than state-of-the-art models.",Performance Evaluation
4086,"We propose two novel training signals for FSL. These signals can remarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models",Model Construction or Optimization
4087,"we investigate how an authorвЂ™s and readerвЂ™s identity, as well as overall writing setup, influence how stories are written and rated. We introduce and release STORIESINTHEWILD, 1 containing 1,630 short stories written on a volunteerbased crowdsourcing platform, paired with author demographics and personality information",Theory Proposal
4088,"we extend an existing scheme of annotation of events (Goud et al., 2019); we provide guidelines for annotation of mood of events (realis vs irrealis) and guidelines for annotation of event arguments,",Theory Proposal
4089," we explore how learning to extract
meaning from speech differs when learning from
CDS and ADS.",Theory Proposal
4090,We discuss task performance on the training register as well as generalization across registers,Applications
4091,"emphasize that in order to capture the whole slot entity, it is pivotal for the model to share its parameters for all slot types in the source domains and learn the general pattern of slot entities",Model Construction or Optimization
4092,model can maintain good performances in crossdomain and low-resource settings.,Applications
4093,DST-SC is designed with a slot connecting mechanism to establish the connection between the target slot and its source slot explicitly,Model Construction or Optimization
4094,We demonstrate that DST-SC is more effective for handling the related-slot problem and outperforms state-of-the-art baselines.,Performance Evaluation
4095,"We propose a recurrent knowledge interaction, which chooses knowledge dynamically among decoding steps, integrating multiple knowledge into the response coherently",Theory Proposal
4096,"We use a knowledge-aware pointer network to do knowledge copy, which solves oov problem and keeps knowledge integrity, especially for long-text knowledge",Theory Proposal
4097,"exploring the explicit guidance to help the variational response generator exploit persona information hidden in the nonstructured contents produced by the users, by utilizing intuitive characteristics of personalized conversations for model trainin",Model Construction or Optimization
4098,We introduce a new conversational task and demonstrate added value over traditional conversation modeling through both better control and response generatio,Model Construction or Optimization
4099,"We document the creation of a large, multiturn, multi-actor conversational dataset",Dataset Creation or Resources
4100,"We demonstrate that by increasing model size from 117M to 8.3B parameters, human evaluations measuring preference of model gener- 68 ated samples over held out target distribution increase with respect to realism, style matching, grammar, and conversation coherency",Performance Evaluation
4101,"we propose a new method to tackle the above challenges, aiming to obtain a highquality pre-training model for dialogue generation.",Algorithms/ Methods Construction or Optimization
4102,we propose Iterative Rectification Network (IRN) to improve slot consistency for general NLG systems.,Theory Proposal
4103,we will  focus on dialogues for transactions; other kinds of dialogues such as opinion sharing will have different model,Performance Evaluation
4104," We explore the task of Chinese discourse parsing with a variety of strategies, and our parser achieves the state-of-the-art performance. Our robust dynamic-oracle procedure can be applied to other shift-reduce parsers",Applications
4105,"We release the pre-trained, standalone, readyto-use parser as a resource for the research community.1",Theory Proposal
4106,we propose a novel TransS-driven joint learning neural network framework that leverages the latent geometric structure information of argument-relation instance,Theory Proposal
4107,"we adopt a multi-level encoder to further enrich the argument representations, which could obtain the deeper semantics of discourse",Model Construction or Optimization
4108,"We design a novel model, conditional masked prediction model with mix-attention (CoMMA), to measure the token dependency for sequence generation. вЂў",Model Construction or Optimization
4109,"knowledge distillation and imposing source-target alignment constraint reduce the target-token dependency, and thus reduce the difficulty of training NAR models",Model Construction or Optimization
4110,"we conduct a study aimed at answering the following question: given a large annotated web-scale dataset such as Conceptual Captions (Sharma et al., 2018) in one language, and a baseline machine translation system",Dataset Creation or Resources
4111,"We focus our study on the task of automatic image captioning, as a representative for cross-modal language generation where back-and-forth consistency cannot be leveraged in a straightforward manner",Algorithms/ Methods Construction or Optimization
4112,"we consider a new and specific setting of it, referred to as fact-based text editing, in which a draft text and several fact",Theory Proposal
4113,"We propose the new research problem of fewshot NLG, which has great potential to benefit a wide range of real-world applications.",Theory Proposal
4114,"To study different algorithms for our proposed problem, we create a multi-domain table-totext dataset",Algorithms/ Methods Construction or Optimization
4115,Our proposed algorithm can make use of the external resources as prior knowledge to significantly decrease human annotation effort,Algorithms/ Methods Construction or Optimization
4116,we develop SEQ2SEQ models that generate fluent and informative answer responses to conversational questions,Model Construction or Optimization
4117,we transform the answers from an existing QA dataset into fluent responses via data augmentation,Dataset Creation or Resources
4118,"We propose a novel hierarchical variational framework for generating diverse QA pairs from a single context, which is, to our knowledge, the first probabilistic generative model for questionanswer pair generation",Model Construction or Optimization
4119,"We propose an InfoMax regularizer which effectively enforces the consistency between the generated QA pairs, by maximizing their mutual information. This is a novel approach in resolving consistency between QA pairs for QAG",Theory Proposal
4120,We evaluate our framework on several benchmark datasets,Performance Evaluation
4121,We build a new dataset containing 7.2K passages and 81.9K questions from CoQA. It is the first dataset specially built for SQG,Dataset Creation or Resources
4122,We perform semi-autoregressive SQG under dual-graph interaction,Algorithms/ Methods Construction or Optimization
4123,We use extensive experiments to show that our model outperforms previous work by a substantial margin,Algorithms/ Methods Construction or Optimization
4124,We train and evaluate our approach on the largescale English paraphrase dataset,Performance Evaluation
4125,"we show that position embeddings provide a simple yet effective way to encode reordering information, and that the generated paraphrases exhibit high compliance with the desired reordering input.",Model Construction or Optimization
4126,"We propose a novel framework, PPVAE, for conditional text generation, which allows a separate training for a new condition without retraining the whole network",Theory Proposal
4127,We conduct extensive experiments and analysis to verify the effectiveness of our proposed PPVAE. Our framework achieves state-of-the-art performance on conditionality in both automatic and human evaluations,Theory Proposal
4128,We employ a simple uniform distribution of the masking ratio and name the model as u-PMLM. We prove that u-PMLM actually learns an autoregressive language model on random permutations of training sequences,Model Construction or Optimization
4129,We present a largescale analysis of generated text with a special focus on studying artifacts produced by large generative models.,Theory Proposal
4130,We propose the new task of distinguishing between different fine-grained configurations 276 based on the generated text alone,Theory Proposal
4131,"A new practical task, namely question generation from reviews without annotated instance, is proposed and it has good potential for multiple applications",Theory Proposal
4132,A novel adaptive instance transfer and augmentation framework is proposed for handling the data lacking challenge in the task,Theory Proposal
4133,we propose a Type Auxiliary Guiding (TAG) encoder-decoder framework,Theory Proposal
4134,An adaptive Type-associated encoder which can summarize the information according to the node type,Applications
4135,A Type-restricted decoder with a two-stage process to reduce the search space for the code comment generation,Theory Proposal
4136,We propose the novel UPSA framework that addresses Unsupervised Paraphrasing by Simulated Annealing,Theory Proposal
4137,We design a searching objective function for paraphrasing that not only considers language fluency,Model Construction or Optimization
4138,We propose a copy mechanism as one of our search actions of simulated annealing to address rare words,Theory Proposal
4139,We achieve the state-of-the-art performance on four benchmark datasets,Dataset Creation or Resources
4140,a model that performs segmentation and labeling jointly rather than separately,Algorithms/ Methods Construction or Optimization
4141,we introduce contextualized weak supervision to train a text classifier based on userprovided seed words.,Algorithms/ Methods Construction or Optimization
4142,We propose a novel framework enabling contextualized weak supervision for text classification,Theory Proposal
4143,We develop an unsupervised method to automatically group word occurrences of the same word into an adaptive number of interpretations based on contextualized representations and userprovided seed information,Algorithms/ Methods Construction or Optimization
4144,We design a principled ranking mechanism to identify words that are discriminative and highly label-indicative,Model Construction or Optimization
4145,"We propose a new graph neural network for text classification, where each document is an individual graph and text level word interactions can be learned in i",Theory Proposal
4146,"Our approach can generalise to new words that absent in training, and it is therefore applicable for inductive circumstances.",Theory Proposal
4147,We demonstrate that our approach outperforms state-of-the-art text classification methods experimentally,Algorithms/ Methods Construction or Optimization
4148,"We propose a novel Bidirectional Adversarial Topic (BAT) model, which is, to our best knowledge, the first attempt of using bidirectional adversarial training in neural topic modeling",Model Construction or Optimization
4149,We extend BAT to incorporate the word relatedness information into the modeling process and propose the Bidirectional Adversarial Topic model with Gaussian,Model Construction or Optimization
4150,"Our multi-tasking learning model consistently outperforms the state-of-the-art model in terms of both single and multi-label classifications, sentence and document classifications, and classifications in three languages",Applications
4151,") We encode the content words of the source sentence as a new source representation, and learn an additional content word context vector based on it to improve translation performance;",Model Construction or Optimization
4152,"we thereby make an initial attempt to measure explanation methods for NMT according to the second dimension of interpretability, which covers all target words",Algorithms/ Methods Construction or Optimization
4153,It presents an attempt at evaluating the explanation methods for neural machine translation from a new viewpoint of fidelity.,Algorithms/ Methods Construction or Optimization
4154,"It proposes a principled metric for evaluation, and to put it into practice it derives a simple yet efficient approach to approximately calculate the metric",Performance Evaluation
4155,It quantitatively compares several different explanation methods and evaluates their effects in terms of the proposed metric.,Performance Evaluation
4156,"While previous works only concentrate on manipulating the decoder, we illustrate and emphasize the importance of the encoder in NAT models and propose the encoder masking strategy to improve its training",Model Construction or Optimization
4157,We propose the consecutive masking strategy of the decoder input and the n-gram loss function to alleviate the problem of repetitive translations of NAT models.,Model Construction or Optimization
4158,We integrate the two parts above in the jointly masked sequence-to-sequence model which shows strong performance on benchmark machine translation datasets,Model Construction or Optimization
4159," To address the large phrase table issue, we propose an attentive feature extraction model and generate phrase representation based on token representations.",Model Construction or Optimization
4160,"To the best of our knowledge, our work is the first to model phrase representations and incorporating them into the Transformer",Model Construction or Optimization
4161,"We empirically demonstrate that a simple modification made in the TransformerвЂ™s official implementation (Vaswani et al., 2018) which changes the computation order of residual connection and layer normalization can effectively ease its optimization",Performance Evaluation
4162,we show that recurrent models equipped with this new attention mechanism can extrapolate to longer sequences,Model Construction or Optimization
4163,"The deep MSC nets (with 72-layer encoders) bring great improvements on translation quality from increased depth, producing results that substantially better than existing systems",Theory Proposal
4164,"we propose a novel norm-based criterion for the difficulty of a sentence, which takes advantage of both model-based and linguistically motivated difficulty features",Model Construction or Optimization
4165,"We observe that the norms of the word vectors trained on simple neural networks are expressive enough to model the two features, which are easy to obtain while possessing learning-dependent features",Model Construction or Optimization
4166,"We demonstrate the effectiveness of our proposed technique using fixed (Ma et al., 2019a) and adaptive (Zheng et al., 2019a) policies in both Chineseto-English and English-to-Chinese translation",Theory Proposal
4167,"We compare the expressive power of rational and non-rational RNNs, distinguishing between state expressiveness (what kind and amount of information the RNN states can capture) and language expressiveness (what languages can be recognized when the state is passed to a classifier)",Theory Proposal
4168,"A two-parameter generalization of the ZipfвЂ™s/power law is the Zipf-Mandelbrot law, where f в€ќ (r + ОІ) в€’О± (Mandelbrot, 1965). Li et al. (2010) considered the reversed rank of rmax+1в€’r, where rmax is the maximum of ranking index, and proposed a two-parameter formulation of f в€ќ r в€’О±(rmax + 1 в€’ r) ОІ .",Theory Proposal
4169,we propose to use dice loss in replacement of the standard cross-entropy objective for data-imbalanced NLP tasks,Theory Proposal
4170,"we propose to replace CE or MLE with losses based on the SГёrensenвЂ“Dice coefficient (Sorensen, 1948) or Tversky index (Tversky, 1977).",Performance Evaluation
4171,we argue that syntax can be inferred from a sample of natural language with very minimal supervision,Theory Proposal
4172,We introduce an information theoretical definition of what constitutes syntactic information,Theory Proposal
4173,we specifically focus on the Japanese language due to its complex and flexible word order,Theory Proposal
4174,Discuss and validate the use of LMs as a tool for word order analysis as well as investigate the sensitivity of LMs against different word orders in non-European language,Performance Evaluation
4175,Find encouraging parallels between the results obtained with the LM-based method and those with the previously established method on various hypotheses of canonical word order of Japanese,Algorithms/ Methods Construction or Optimization
4176,Showcase the advantages of an LM-based method through analyzing linguistic phenomena that is difficult to explore with the previous data-driven methods,Algorithms/ Methods Construction or Optimization
4177,We study a novel and more realistic scenario of fake news detection on social media,Model Construction or Optimization
4178,"For accurate detection, we develop a new model, GCAN, to better learn the representations of user interactions, retweet propagation, and their correlation with source short text",Model Construction or Optimization
4179,"deals with fake news detection under a more realistic scenario on social media. We predict whether a source tweet story is fake, given only its short text content and its retweet sequence of users, along with user profiles",Theory Proposal
4180,"We propose two novel GCN-based models, TPC-GCN and DTPC-GCN, for post-level controversy detection",Model Construction or Optimization
4181,"We build a Chinese dataset for controversy detection, consisting of 5,676 posts collected from Chinese Weibo, each of which are manually labeled as controversial or noncontroversial. To the best of our knowledge, this is the first released Chinese dataset for controversy detection",Dataset Creation or Resources
4182,we propose to apply unsupervised stance detection to automatically tag a large number of Twitter users with their positions on specific topics,Theory Proposal
4183,We use unsupervised stance detection to automatically determine the stance of Twitter users with respect to several polarizing topics,Theory Proposal
4184,We then use distant supervision based on these discovered user stances to accurately characterize the political leaning of media outlets,Theory Proposal
4185,We evaluate our approach by comparing its bias predictions for a number of news outlets against gold labels from Media Bias/Fact Check,Performance Evaluation
4186,"We propose a new and simple method for detecting usage change, that does not involve vector space alignment",Algorithms/ Methods Construction or Optimization
4187,"we use it to identify word usage changes in a variety of corpus pairs, reflecting different data division criteria",Dataset Creation or Resources
4188,we propose a new framework for emotion-controllable response generation named Curriculum Dual Learning (CDL),Theory Proposal
4189,"Enabling efficient DST, generating the values of a minimal subset of the slots by utilizing the previous dialogue state at each turn",Performance Evaluation
4190,Achieving state-of-the-art performance on MultiWOZ 2.0 and MultiWOZ 2.1 in an open vocabulary-based DST setting,Applications
4191,Highlighting the potential of improving the state operating prediction accuracy in our proposed framework,Theory Proposal
4192,We propose an effective model framework of five major layers on off-topic response detection task,Model Construction or Optimization
4193,"To explore the essence of our proposed model, we conduct visualization analysis from two perspectives: bi-attention visualization and semantic matching representation visualization to reveal important information on how our model works.",Model Construction or Optimization
4194,"To improve our result on unseen prompts further, we propose a novel negative sampling data augmentation method to enrich training data by shuffling words from the negative sample in off-topic response detection task",Algorithms/ Methods Construction or Optimization
4195," To the best of our knowledge, this is the first study on applying meta-learning to retrieval-based end-to-end goal-oriented dialog systems;",Applications
4196,we leverage the MAML algorithm to optimize a human-machine collaborative dialog system and show very promising results on the lowresource dialog tasks,Algorithms/ Methods Construction or Optimization
4197,we propose a new dataset and hope that can help bring forward the research in this area,Theory Proposal
4198,We investigate and demonstrate the feasibility of applying lexical ontology to facilitate recognizing OOV words in the few-shot scenario,Performance Evaluation
4199,We propose a knowledge integration mechanism and use multi-level graph attention to model explicit lexical relations,Model Construction or Optimization
4200,"we propose Multi-Agent Dialog Policy Learning (MADPL), where the user is regarded as another dialog agent rather than a user simulator",Theory Proposal
4201,We apply actor-critic based multi-agent reinforcement learning to learn the task-oriented dialog policy to facilitate pretraining and avoid explicitly building a user simulator,Applications
4202,We propose Hybrid Value Network for reward decomposition to deal with the asymmetric role issue between the system agent and the user agent in the task-oriented dialog.,Theory Proposal
4203,"We conduct in-depth experiments on the multidomain, multi-intent task-oriented dialog corpus to show the effectiveness, reasonableness and scalability of our algorithm",Algorithms/ Methods Construction or Optimization
4204,we propose to construct dialog paraphrases that consider dialog context in order to improve dialog generation quality,Theory Proposal
4205,we propose a method to construct a response-anticipated memory to contain document information that is potentially more important in generating responses,Algorithms/ Methods Construction or Optimization
4206,"To the best of our knowledge, we are the first to approach semi-supervised dialogue policy learning",Theory Proposal
4207,We propose a novel reward estimation approach to dialogue policy learning which relives the requirements of extensive annotations and promotes a stable learning of dialogue policy,Theory Proposal
4208,We propose an action embedding learning technique to effectively train the reward estimator from either partially labeled or unlabeled dialogues,Theory Proposal
4209,We conduct extensive experiments on the benchmark multi-domain dataset. Results show that our approach consistently outperforms strong baselines coupled with semi-supervised learning technique,Dataset Creation or Resources
4210,"This paper proposes a general learning framework using the duality between NLU and NLG, where supervised and unsupervised learning can be flexibly incorporated for joint training.",Theory Proposal
4211,This work is the first attempt to exploits the dual relationship between NLU and NLG towards unsupervised learning,Theory Proposal
4212,The benchmark experiments demonstrate the effectiveness of the proposed framework,Theory Proposal
4213,"a strongly-correlated, unsupervised and reference free metric is proposed for evaluating open-domain dialog systems",Theory Proposal
4214,a thorough human quality annotation is carried out and is released1 to facilitate future benchmarking of dialog evaluation metrics,Performance Evaluation
4215,We introduce a group of discrete latent variables to model the underlying semantic components,Model Construction or Optimization
4216,"We also show that our model indeed learns meaningful and informative latent codes, and generates more precise and specific definitions",Model Construction or Optimization
4217,", we argue that this phenomenon is not model specific, but is due to the widely-used log loss: we demonstrate that log loss is not robust to noisy and invalid references",Theory Proposal
4218,we show that optimizing for distinguishability is robust in the face of noisy and even invalid data,Dataset Creation or Resources
4219,"We propose a novel graph-to-sequence model, which firstly uses the line graph to model the relationships between AMR edges",Model Construction or Optimization
4220,We integrate higher-order neighborhood information into graph encoders to model the relationships between indirectly connected nodes,Model Construction or Optimization
4221,We demonstrate that both higher-order neighborhood information and edge relations are important to graph-to-sequence modeling.,Performance Evaluation
4222,We propose to tackle a new challenging task: rigid formats controlled text generation. A pre-training and fine-tuning framework named SongNet is designed to address the problem,Theory Proposal
4223,Sets of symbols are tailor-designed to improve the modeling performance. We improve the attention mechanism to impel the model to capture the future information to further enhance the sentence integrity,Algorithms/ Methods Construction or Optimization
4224,"To verify the performance of our framework SongNet, we collect two corpora, SongCi and Sonnet, in Chinese and English respectively. We design several automatic evaluation metrics and human evaluation metrics to conduct the performance evaluation",Dataset Creation or Resources
4225," Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results given arbitrary formats, including the cold-start formats or even the formats newly defined by ourselves",Model Construction or Optimization
4226,"We evaluate our QG framework, Syn-QG against three QG systems on a mixture of Wikipedia and commercial text sentences outperforming existing approaches in grammaticality",Performance Evaluation
4227,"It allows processing each arriving short text in an online way. The online model is not only free of determining the optimal batch size, but also lends itself to handling large-scale data streams efficiently",Performance Evaluation
4228,"To the best of our knowledge, it is the first work to integrate semantic information for model-based online clustering, which is able to handle вЂњterm ambiguity"" problem effectively and finally support high-quality clustering",Model Construction or Optimization
4229," Equipped with Poly Urn Scheme, the number of clusters (topics) are determined automatically in our cluster model",Model Construction or Optimization
4230," to introduce correlations among the bits of hash codes, we propose to employ the distribution of Boltzmann machine as the variational posterior",Theory Proposal
4231,"To obtain similarity-preserving hash codes, extensive efforts have been made to learn hash functions that can preserve the similarity information of original documents in the binary embedding space",Theory Proposal
4232," We formulate the interactive process of a term collection, which brings clarity to the problem to be solved",Theory Proposal
4233,We develop a method that captures an analystвЂ™s intention from a small number of samples with our formulation as the basis,Algorithms/ Methods Construction or Optimization
4234,we propose an automatic evaluation framework that provides a systematic assessment for interactive methods,Algorithms/ Methods Construction or Optimization
4235,"we propose a treestructured neural topic model (TSNTM), which is parameterized by neural networks and is trained using AEVB",Model Construction or Optimization
4236,"we overcome the aforementioned unsupervised gap, by using distant supervision to train neural models",Model Construction or Optimization
4237,"To overcome the lack of training data in the latterвЂ™s case, we further implement a novel weaksupervision approach using automatically generated question paraphrases, coupled with smart filtering to ensure high-quality paraphrases",Model Construction or Optimization
4238,"To the best of our knowledge, PCPR is the first work to jointly model contextualized word embeddings and pronunciation embeddings to recognize puns. Both contexts and phonological properties are beneficial to pun recognition",Model Construction or Optimization
4239,Extensive experiments are conducted on two benchmark datasets. PCPR significantly outperforms existing methods in both pun detection and pun location. In-depth analyses also verify the effectiveness and robustness of PCPR.,Algorithms/ Methods Construction or Optimization
4240,We release our implementations and pre-trained phoneme embeddings at https://github.com/ joey1993/pun-recognition to facilitate future research.,Theory Proposal
4241,"in response to the above question, we propose a novel bidirectional language model named the Transformer-based Text Autoencoder (T-TA), which has a reduced computational complexity of O(n 2 ) when applying the model to unsupervised applications",Model Construction or Optimization
4242,"we propose a Fine-grained Interest Matching network (FIM), which is a new architecture for news recommendation that can tackle the above challenges",Theory Proposal
4243,to the burgeoning body of research on using NLP techniques in key financial applications.,Theory Proposal
4244,"We demonstrate that the user geolocation (especially) for the network-based methods, is largely dominated by the geographical locations of the 1- hop neighboring nodes",Algorithms/ Methods Construction or Optimization
4245,"We propose an attention-based, autoregressive model, bilingual attention language model (BALM), that not only learns the latent alignment from a parallel corpus for cross-lingual word embedding but also captures the word sequential dependency",Model Construction or Optimization
4246,"Adhering to the Matrix Language Frame theory (Myers-Scotton, 1997) and Equivalence Constraint theory (Poplack, 2000; Sankoff, 1998), we implement an objective function by jointly optimizing the cross-entropy loss as the monolingual constraint and the quasitranslation loss as the cross-lingual constraint",Theory Proposal
4247,We show that BALM can learn from bilingual parallel data without the need for CS data,Dataset Creation or Resources
4248,We propose a novel end-to-end trainable SpellGCN to integrate the pronunciation and shape similarities into the semantic space. Its essential components such as the specialized graph convolution and attentive combination operations are carefully investigated,Theory Proposal
4249,We investigate the performance of SpellGCN both quantitatively and qualitatively. Experimental results indicate that our method achieves the best results on three benchmark datasets,Algorithms/ Methods Construction or Optimization
4250,proposal of the novel neural architecture Soft-Masked BERT for the CSC problem,Theory Proposal
4251,empirical verification of the effectiveness of Soft-Masked BERT.,Theory Proposal
4252,"We propose novel attention-based frame representation models, which take full advantage of LUs and F-to-F relations to model frames with attention schema",Model Construction or Optimization
4253,We propose a new Frame-based Sentence Representation (FSR) method that integrates multi-frame semantic information to obtain richer semantic aggregation for better sentence representation,Algorithms/ Methods Construction or Optimization
4254,Our experimental results demonstrate our proposed frame-based sentence representation (FSR) method is very effective on Machine Reading Comprehension (MRC) task,Algorithms/ Methods Construction or Optimization
4255,we propose a new procedure to increase the speed of the annotation process,Theory Proposal
4256,"we propose a new procedure to increase the speed of the annotation process. For this, we first introduce an intermediate representation of the structured queries, which we call Operation Trees",Theory Proposal
4257,It reduces the time needed for an annotation,Theory Proposal
4258,we introduce a method to learn a Contextualized Sparse Representation (SPARC) for each phrase and show its effectiveness in opendomain QA under phrase retrieval setup,Algorithms/ Methods Construction or Optimization
4259,We introduce a dynamic sampling strategy that selects instances from a dataset with probability proportional to the gap between its current performance on some metric (like EM or F1 score) and measured single-task performance of the same model on that dataset,Dataset Creation or Resources
4260,We design two novel auxiliary tasks in multitask fine-tuning to help improve the accuracy of answer span boundary detection for multilingual MRC model.,Model Construction or Optimization
4261,We propose a language-agnostic method to mine language-specific knowledge phrase from search engines. This method is lightweight and easy to scale to any language,Algorithms/ Methods Construction or Optimization
4262,"We conduct extensive experiments to prove the effectiveness of our proposed approach. In addition to an open benchmark dataset, we also create a new multilingual MRC dataset from real-scenario together with fine-grained answer type labels the in-depth impact analysis",Theory Proposal
4263,"we propose a new framework of conversational machine reading with a novel Explicit Memory Tracker (EMT), which explicitly tracks each rule sentence to make decisions and generate follow-up questions",Theory Proposal
4264," A method for injecting skills into pre-trained LMs, given that automatic data generation is possible",Algorithms/ Methods Construction or Optimization
4265,"GENBERT, an architecture for pre-trained LM with generative and extractive abilities",Theory Proposal
4266,A framework for generating numerical and textual synthetic data for numerical reasoning,Dataset Creation or Resources
4267,We propose a new task for follow-up question identification in a conversational reading comprehension setting which supports automatic evaluation,Theory Proposal
4268,"We present a new dataset, namely LIF, which is derived from the recently released conversational QA dataset QuAC",Dataset Creation or Resources
4269,We propose a three-way attentive pooling network which aims to capture topic shift and topic continuity for follow-up question identification. The proposed model significantly outperforms all the baseline systems,Model Construction or Optimization
4270,we handle both constraints and multi-hop relations together for complex KBQA,Theory Proposal
4271,We propose to modify the staged query graph generation method by allowing longer relation path,Algorithms/ Methods Construction or Optimization
4272,"We construct a diverse (in terms of lexicon usage), wide-coverage (in problem type), and publicly available1 MWP corpus, with annotations that can be used to assess the capability of different systems.",Theory Proposal
4273,We propose a lexicon usage diversity metric to measure the diversity of an MWP corpus and use it to evaluate existing corpora,Performance Evaluation
4274,We show that the real performance of state-of-the-art (SOTA) systems is still far behind human performance if evaluated on a corpus that mimics a real human test,Performance Evaluation
4275,we add the concept of mismatch into cosine similarity by a threshold for mismatch detection and proper penalization,Theory Proposal
4276,we attempt to deepen the understanding of cross-lingual word embeddings from the perspective of the choice of the context window through carefully designed experiments,Model Construction or Optimization
4277,We present a jointly optimized bi-encoder model (BEM) for WSD that improves performance on all-words English WSD,Model Construction or Optimization
4278,"We show that our modelвЂ™s improvements come from better performance on LFS and zero-shot examples, without sacrificing accuracy on the most common senses",Algorithms/ Methods Construction or Optimization
4279,"We examine why our model performs well on LFS with a number of experiments, including an evaluation of the BEM in a few-shot learning setting demonstrating that the bi-encoder generalizes well from limited data",Model Construction or Optimization
4280,") humour detection (Khandelwal et al., 2018), (ii) sarcasm detection (Swami et al., 2018) and (iii) hate speech detection (Bohra et al., 2018) for HindiEnglish code-switched data",Dataset Creation or Resources
4281,"We propose a transparent and interpretable scheme that incorporates decision tree model into co-attention networks, which not only discovers evidence for explainable claim verification but also provides interpretation for the discovery process of evidence through the decision conditions",Model Construction or Optimization
4282,"Designed co-attention networks promote the deep semantic interaction between evidence and claims, which can train DTE to obtain more powerful evidence and effectively focus on the false parts of claims",Model Construction or Optimization
4283,"Experiments on two public, widely used fake news datasets demonstrate that our DTCA achieves more excellent performance than previous state-of-the-art methods",Algorithms/ Methods Construction or Optimization
4284,We identify the task of conversational recommendation over multi-type dialogs.,Theory Proposal
4285,"To facilitate the study of this task, we create a novel dialog dataset DuRecDial, with rich variability of dialog types and domains",Dataset Creation or Resources
4286,We propose a conversation generation framework with a novel mixed-goal driven dialog policy mechanism.,Theory Proposal
4287,We propose a semantic-enhanced Gaussian mixture model (SEG) for unknown intent detection by incorporating class semantic information into a Gaussian mixture distribution,Model Construction or Optimization
4288,"We explore to improve existing generalized zero-shot intent classification systems with an unknown intent identifier. To the best of our knowledge, this is the first attempt to apply unknown intent detection in this task",Model Construction or Optimization
4289,We conduct extensive experiments on three real-world datasets to validate the effectiveness of the proposed SEG model for unknown intent detection and its application in generalized zero-shot intent classification,Model Construction or Optimization
4290,"We propose the new task of expertise style transfer, which aims to facilitate communication between experts and laymen",Theory Proposal
4291,We contribute a challenging dataset that requires knowledge-aware and structural modification techniques,Dataset Creation or Resources
4292,"We establish benchmark performance and discuss key challenges of datasets, models and evaluation metrics",Model Construction or Optimization
4293,"we aim to overcome the above problems to automatically generate faithful texts from tables. In other words, we aim to produce the writing that a human without any external knowledge would do given the same table data as input",Performance Evaluation
4294,we propose Dynamic Memory Induction Networks (DMIN) to further tackle the above challenges.,Theory Proposal
4295,"to our best knowledge, we are the first to design a hierarchical decoding process for the keyphrase generation problem",Model Construction or Optimization
4296,) we propose two novel exclusion mechanisms to avoid generating duplicated keyphrases as well as improve the generation accuracy,Theory Proposal
4297,our method consistently outperforms all the SOTA sequential decoding methods on multiple benchmarks under the new setting,Algorithms/ Methods Construction or Optimization
4298,"With the prior hierarchy knowledge, we adopt typical structure encoders for modeling label dependencies in both top-down and bottomup manners, which has not been investigated for hierarchical text classification",Performance Evaluation
4299,We empirically demonstrate that both variants of HiAGM achieve consistent improvements on various datasets when using different structure encoders.,Dataset Creation or Resources
4300,We release our code and experimental splits of Web-of-Science and NYTimes for reproducibility,Theory Proposal
4301,"We report significant improvements for strong retrieval models on a standard benchmark collection, showing that keyphrases produced by state-of-the-art models are consistently helpful for document retrieval, even, to our surprise, when author keywords are provided",Dataset Creation or Resources
4302,We introduce a new extrinsic evaluation framework for keyphrase generation that allows for a deeper understanding of the limitations of current models,Model Construction or Optimization
4303,"We present a derivational graph auto-encoder (DGA) that combines semantic and syntactic information with associative information from the mental lexicon, achieving very good results on MWF prediction and performing on par with a character-based LSTM at a fraction of the number of trainable parameters",Model Construction or Optimization
4304,", we present a new data set of about 1500 sentences randomly sampled from the romanized Algerian dialectal Arabic corpus of Cotterell et al.",Dataset Creation or Resources
4305,") the Webis Gmane Email Crawl 2019, a crawl of more than 153 million emails from a wide range of mailing lists",Theory Proposal
4306,"the Chipmunk email segmenter, a newly developed end-to-end neural model, a",Model Construction or Optimization
4307,"the complete preprocessing of the crawled emails using our model to construct the largest corpus of вЂњready-to-useвЂќ emails to date. Our corpus encompasses more than 20 years worth of discussions on a diverse set of topics, including important political and societal issues.",Model Construction or Optimization
4308,"We propose a language-neutral, fine-grained definition of cross-linguistic morphosyntactic divergences (CLMD) that allows for their extraction using a syntactically annotated, content-wordaligned parallel corpus.",Theory Proposal
4309,data quality. Finding the right trade-off between the two is in fact a key element for an effective automatic CN generation.,Dataset Creation or Resources
4310,To our understanding none of the collection strategies presented so far is able to fulfill this requirement.,Model Construction or Optimization
4311,KLEJ: A set of nine tasks constructed from both existing and newly introduced datasets used for the Polish language understanding evaluation,Dataset Creation or Resources
4312,An online platform1 to evaluate and present the model results in the form of a leaderboard,Performance Evaluation
4313,"HerBERT: Transformer-based model for the Polish language understanding,",Model Construction or Optimization
4314,"Evaluation of several LSTM-based baselines, multilingual Transformer-based models and HerBERT.",Performance Evaluation
4315,We here propose an approach based on crosslingual distant supervision to generate almost arbitrarily large emotion lexicons for any target language and emotional variable,Theory Proposal
4316,We study different ways to generate additional MT hypotheses by exploring uncertainty in NMT models,Model Construction or Optimization
4317,We devise methods to effectively explore multiple MT hypotheses to better evaluate MT output quality with existing evaluation metrics,Performance Evaluation
4318,"we introduce the task of Multimodal QE (MQE) for MT as an attempt to improve QE by using external sources of information, namely images",Algorithms/ Methods Construction or Optimization
4319,we propose several ways of incorporating visual information in neural-based and featurebased QE architectures,Theory Proposal
4320,we achieve the state-of-the-art performance for such architectures in document and sentence-level QE,Applications
4321,"this paper introduces a unique challenge, PuzzLing Machines, made up of в€ј100 Rosetta Stone, a.k.a translation puzzles covering 81 languages from 39 different language families based on the Linguistic Olympiads",Algorithms/ Methods Construction or Optimization
4322,We develop an annotation scheme for marking information on materials-science experiments on scientific publications,Algorithms/ Methods Construction or Optimization
4323,"We provide a new corpus of 45 materialsscience publications in the research area of SOFCs, manually annotated by domain experts for information on experimental settings and results",Model Construction or Optimization
4324,We identify three sub-tasks of extracting experiment information and provide competitive baselines with state-of-the-art neural network approaches for them,Model Construction or Optimization
4325,We show the applicability of our findings to modeling the annotations of another materialsscience corpus,Performance Evaluation
4326,we present the iSarcasm dataset of tweets labelled for sarcasm by their authors,Dataset Creation or Resources
4327,"We introduce a new approach tackling AMR parsing, following the incremental sequence-tograph transduction paradigm",Algorithms/ Methods Construction or Optimization
4328," We present a new large-scale dataset for MDS, that is better aligned with several real-world industrial use cases",Dataset Creation or Resources
4329,We provide an extensive analysis of the properties of this dataset,Dataset Creation or Resources
4330,We provide empirical results for several baselines and state-of-the-art MDS methods aiming to facilitate future work on this datase,Algorithms/ Methods Construction or Optimization
4331,"We introduce a novel and efficient method which integrates the operation of attending, translating, and summarizing",Performance Evaluation
4332,We present three effective strategies to acquire the translation probability. It has shown that all these strategies can significantly improve the performance over the baseline,Model Construction or Optimization
4333,Experimental results demonstrate that our method can achieve remarkable improvements over baselines and achieve comparable performance with the state-of-the-art on both English-to-Chinese and Chinese-to-English cross-lingual summarization tasks,Algorithms/ Methods Construction or Optimization
4334,we examine existing strategies for the full TLS task and how well they actually work,Theory Proposal
4335,We compare different TLS strategies side-byside using suitable evaluation metrics to provide a better picture for how well the full TLS task for news is solved so far,Performance Evaluation
4336," We propose a simple addition to existing methods to significantly improve date-wise TLS, achieving new state-of-the-art results",Algorithms/ Methods Construction or Optimization
4337,We present a new TLS dataset that is larger than previous datasets and spans longer time ranges,Algorithms/ Methods Construction or Optimization
4338,", we explore improving the truthfulness in abstractive summarization on two datasets, English Gigaword and JApanese MUlti-Length Headline Corpus (JAMUL)",Dataset Creation or Resources
4339,we analyze headlines generated by the state-of-the-art encoder-decoder model and show that the model sometimes generates unexpected words,Dataset Creation or Resources
4340,"we conjecture that one of the reasons why the model sometimes exhibits such an untruthful behavior lies in untruthful article-headline pairs, which are used for training the model",Model Construction or Optimization
4341,"First, to better measure the semantic overlap between source documents and machine-generated summaries, we propose to use state-of-the-art contextualized text encoders and its variant SentenceBERT (SBERT) ",Model Construction or Optimization
4342,We present a guided copy mechanism based on source word centrality that is obtained by the indegree or outdegree centrality measures,Model Construction or Optimization
4343,We propose a centrality-aware attention and a guidance loss to encourage the model to pay attention to important source word,Model Construction or Optimization
4344,We achieve state-of-the-art on the public text summarization dataset,Dataset Creation or Resources
4345,we take on the challenge of calibrating a large number of noisy self-reported user ratings to build better dialog evaluation models,Dataset Creation or Resources
4346,"we focus on the static embedding, for it is flexible and efficient. The previous works learn the embedding from intra-sentence within a single space, which is not enough for dialog systems",Performance Evaluation
4347,we propose a new method to learn the conversational word embedding from human dialogue in two different vector spaces,Algorithms/ Methods Construction or Optimization
4348,We propose a few-shot CRF framework for slot tagging that computes emission score as wordlabel similarity and estimate transition score by transferring previously learned label dependencie,Algorithms/ Methods Construction or Optimization
4349,we address two key-questions that arise when training RL dialog agents with expert demonstrations:,Performance Evaluation
4350,"we can evaluate reasoning ability in chatbots, which can potentially allow us to bridge the gap between high performance on leader-board and unsatisfactory practical performance",Performance Evaluation
4351,we develop an open domain Multi-Turn dialogue reasoning dataset (MuTual) to facilitate conversation model reasoning capabilities,Model Construction or Optimization
4352,"we propose Persona Perception Bot (P 2 BOT), explicitly modeling the understanding between interlocutors with a transmitter-receiver framework",Model Construction or Optimization
4353,we formalize bridging anaphora resolution as a question answering problem and propose a QA model to solve the task,Model Construction or Optimization
4354,we explore a new method to generate a large amount of вЂњquasi-bridgingвЂќ training dataset and demonstrate its value for bridging anaphora resolution,Algorithms/ Methods Construction or Optimization
4355,we carefully carry out a series of experiments on two referential bridging corpora and provide some error analysis to verify the effectiveness of our QA model to resolve the context-dependent bridging anaphors in ISNotes,Model Construction or Optimization
4356,"proposing an MTL-based approach for dialogue coherence assessment using DAP as an auxiliary task, yielding more informative utterance representations for coherence assessment",Theory Proposal
4357,alleviating the need for DA labels for dialogue coherence assessment during evaluations,Performance Evaluation
4358,"an empirical evaluation on two benchmark dialogue corpora, showing that our model substantially outperforms the state-of-theart coherence model on DailyDialog, and performs on par with it on SwitchBoard",Performance Evaluation
4359," we tackle linearization decoding in a different way, by casting it as a Traveling Salesman Problem (TSP)",Theory Proposal
4360,"we solve the dependency tree linearization task as a TSP. With the help of TreeLSTM to encode the tree and biaffine attention as a bigram language model, we can use a greedy TSP solver to linearize the tree effectively",Model Construction or Optimization
4361," we propose the problem of Deep Question Generation (DQG), which aims to generate questions that require reasoning over multiple pieces of information in the passage",Theory Proposal
4362,"the very first work, to the best of our knowledge, to investigate deep question generation",Performance Evaluation
4363,"a novel framework which combines a semantic graph with the input passage to generate deep questions, and",Model Construction or Optimization
4364,a novel graph encoder that incorporates attention into a GGNN approach,Model Construction or Optimization
4365,"We introduce a fresh perspective to revisit the relational triple extraction task with a principled problem formulation, which implies a general algorithmic framework that addresses the overlapping triple problem by design.",Algorithms/ Methods Construction or Optimization
4366,We instantiate the above framework as a novel cascade binary tagging model on top of a Transformer encoder,Model Construction or Optimization
4367,"Extensive experiments on two public datasets show that the proposed framework overwhelmingly outperforms state-of-the-art methods, achieving 17.5 and 30.2 absolute gain in F1-score on the two datasets respectively",Algorithms/ Methods Construction or Optimization
4368,"we propose the problem of Deep Question Generation (DQG), which aims to generate questions that require reasoning over multiple pieces of information in the passage.",Theory Proposal
4369,a novel framework which combines a semantic graph with the input passage to generate deep questions,Model Construction or Optimization
4370,a novel graph encoder that incorporates attention into a GGNN approach.,Model Construction or Optimization
4371," We introduce a fresh perspective to revisit the relational triple extraction task with a principled problem formulation, which implies a general algorithmic framework that addresses the overlapping triple problem by design",Algorithms/ Methods Construction or Optimization
4372,We instantiate the above framework as a novel cascade binary tagging model on top of a Transformer encode,Model Construction or Optimization
4373,". Extensive experiments on two public datasets show that the proposed framework overwhelmingly outperforms state-of-the-art methods, achieving 17.5 and 30.2 absolute gain in F1-score on the two datasets respectively",Algorithms/ Methods Construction or Optimization
4374,This work aims to enable rapid comprehension of a large scientific document by identifying a) the central concepts in a text,Theory Proposal
4375,"We formulate a noisy sequence labeling problem, where the input undergoes an unknown noising process (В§2.2), and we introduce a model to estimate the real error distribution",Model Construction or Optimization
4376,вЂў We propose a data augmentation algorithm (В§3.3) that directly induces noise in the input data to perform training of the neural model using a mixture of noisy and clean samples,Model Construction or Optimization
4377,"We implement a stability training method (Zheng et al., 2016), adapted to the sequence labeling scenario, which explicitly addresses the noisy input data problem by encouraging the model to produce a noise-invariant latent representation",Algorithms/ Methods Construction or Optimization
4378,We evaluate our methods on real OCR errors and misspellings against state-of-the-art baseline models,Performance Evaluation
4379,"To support future research in this area and to make our experiments reproducible, we make our code and data publicly available",Dataset Creation or Resources
4380,"A broad collection of labelling functions for NER, including neural models trained on various textual domains, gazetteers, heuristic functions, and document-level constraint",Model Construction or Optimization
4381,. A novel weak supervision model suited for sequence labelling tasks and able to include probabilistic labelling predictions,Model Construction or Optimization
4382,. An open-source implementation of these labelling functions and aggregation model that can scale to large datasets,Model Construction or Optimization
4383,"Our goal in this paper is to understand which features of the input a model conditioned on relation extraction has learned as useful for the task, in order to be able to better interpret and explain model predictions",Model Construction or Optimization
4384,"We construct a document-level graph for inference in an end-to-end fashion without relying on co-references or rules, which may not always yield optimal structures",Theory Proposal
4385,"вЂў We perform quantitative and qualitative analyses to compare with the state-of-the-art mod1Our model is implemented in PyTorch (Paszke et al., 2017) els in various settings",Algorithms/ Methods Construction or Optimization
4386,"We validate the 5k most challenging examples in the TACRED development and test sets, and provide a revised dataset2 that will improve the accuracy and reliability of future RE method evaluations",Algorithms/ Methods Construction or Optimization
4387,"We evaluate the most challenging, incorrectly predicted examples of the revised test set, and develop a set of 9 categories for common RE errors, that will also aid evaluation on other datasets",Performance Evaluation
4388,We verify our error hypotheses on three stateof-the-art RE models and show that two groups of ambiguous relations are responsible for most of the remaining errors and that models exploit cues in the dataset when entities are unmasked,Model Construction or Optimization
4389,"A novel MT task is proposed which can only use the ground-truth bilingual dictionary and monolingual corpora, while is independent on parallel sentences",Theory Proposal
4390,AT is proposed as a solution to the task. AT uses the bilingual dictionary to place anchors that can encourage monolingual spaces of both languages to become closer so that translation becomes easier,Theory Proposal
4391," The detailed evaluation on various language pairs shows that AT, especially Bi-view AT, performs significantly better than various methods, including word-by-word translation, unsupervised MT, and cross-lingual embedding transformation",Algorithms/ Methods Construction or Optimization
4392,we perform an in-depth investigation of the suitability of self-attention models for character-level translation,Performance Evaluation
4393,вЂў introducing PASCAL: an effective parameterfree local self-attention mechanism to incorporate source-side syntax into Transformer,Algorithms/ Methods Construction or Optimization
4394,"вЂў adapting LISA (Strubell et al., 2018) to subword representations and applying it to NMT",Model Construction or Optimization
4395,"вЂў similar to concurrent work (Pham et al., 2019), we find that modeling linguistic knowledge into the self-attention mechanism leads to better translations than other approaches",Performance Evaluation
4396,Increasing the capacity of multilingual NMT yields large improvements and narrows the performance gap with bilingual models. Lowresource translation benefits more from the increased capacity,Algorithms/ Methods Construction or Optimization
4397,Language-specific modeling and deep NMT architectures can slightly improve zero-sho,Model Construction or Optimization
4398,"Finetuning multilingual NMT with ROBT substantially reduces the proportion of offtarget translations (by в€ј50%) and delivers an improvement of в€ј10 BLEU in zero-shot settings, approaching the conventional pivotbased method",Algorithms/ Methods Construction or Optimization
4399," we propose cross-mutual information (XMI), a new metric towards cross-linguistic comparability in NMT. In contrast to BLEU, this information-theoretic quantity no longer explicitly depends on language, model, and tokenization choices",Model Construction or Optimization
4400,we incorporate a language-aware Interlingua module into the Encoder-Decoder architecture,Theory Proposal
4401,"we comparatively evaluate a number of reference-free MT evaluation metrics that build on the most recent developments in multilingual representation learning, namely cross-lingual contextualized embeddings (Devlin et al., 2019) and cross-lingual sentence encoders",Performance Evaluation
4402,"we use demographicallyrepresentative author samples from five languages (Dutch, English, French, German, Italian), and translate them with three commercially available machine translation systems",Model Construction or Optimization
4403,"This paper presents MMPE, the first translation environment combining standard mouse & keyboard input with touch, pen, and speech interactions for PE of MT",Model Construction or Optimization
4404,we study the trade-off between quantity and quality of data for training contextualized representations,Model Construction or Optimization
4405,"we offer initial answers to these questions, systematically assessing the syntactic generalization abilities of neural language models on 34 targeted test suites (33 adapted from previously published work, and 1 novel) covering a wide range of syntactic phenomena",Algorithms/ Methods Construction or Optimization
4406,"In this paper, we examine German number inflection, which has been identified as a crucial test case 1746 for connectionist modeling",Model Construction or Optimization
4407,"This paper aims to model suspense in computational terms, with the ultimate goal of making it deployable in NLP systems that analyze or generate narrative fiction",Dataset Creation or Resources
4408,", we seek to address this area by building models to predict, understand, and interpret factors that could affect an articleвЂ™s reading tim",Model Construction or Optimization
4409,"r, we propose a generative model for Joint natural language Understanding and Generation (JUG), which couples NLU and NLG with a latent variable representing the shared intent between natural language and formal representations",Model Construction or Optimization
4410,"we study three popular random decoding strategiesвЂ”top-k, nucleus, and temperature samplingвЂ”applied to GPT-2",Theory Proposal
4411,"вЂў A comprehensive study of generated text detection systemsвЂ™ sensitivity to model structure, decoding strategy, and excerpt length",Model Construction or Optimization
4412,"An analysis of human ratersвЂ™ ability to identify machine-generated content, and how human raters differ from automatic detectors",Dataset Creation or Resources
4413,"вЂў This work is the first attempt that represents dialog transitions as a graph, and conducts graph grounded policy learning with RL",Dataset Creation or Resources
4414,"we explore the possibility of directly fine-tuning a pre-trained transformer language model on a sequential representation of AMR graphs,",Model Construction or Optimization
4415,) the task of automatically updating an existing comment based on source code changes,Theory Proposal
4416,novel approach for learning to relate edits between source code and natural language that outperforms multiple baselines on several automatic metrics and human evaluation,Model Construction or Optimization
4417,We introduce BPE-dropout вЂ“ a simple and effective subword regularization method,Algorithms/ Methods Construction or Optimization
4418,We show that our method outperforms both BPE and previous subword regularization on a wide range of translation task,Algorithms/ Methods Construction or Optimization
4419,We analyze how training with BPE-dropout affects a model and show that it leads to a better quality of learned token embeddings and to a model being more robust to noisy inpu,Dataset Creation or Resources
4420,We propose a novel seq2seq-based model to incorporate the salient clinical terms into the summarizer,Model Construction or Optimization
4421,Our model statistically significantly improves over the competitive baselines on MIMIC-CXR publicly available clinical dataset,Dataset Creation or Resources
4422,"First, intrinsic and extrinsic hallucinations happen frequently вЂ“ in more than 70% of single-sentence summaries",Theory Proposal
4423," the majority of hallucinations are extrinsic, which potentially could be valid abstractions that use background knowledge",Theory Proposal
4424,"we are interested in summarizing longer narratives, i.e., screenplays, whose form and structure is far removed from newspaper articles",Theory Proposal
4425,we develop methods for instilling knowledge about narrative structure into generic su- 1922 pervised and unsupervised summarization algorithms,Algorithms/ Methods Construction or Optimization
4426,we enable the use of supervised techniques for unsupervised summarization,Theory Proposal
4427,The objective of the current study is to quantify the extent to which the differences between neural LMs trained on language produced by DAT patients and controls reflect known deficits in language use in this disease - in particular the loss of access to relatively infrequent terms that occurs with disease progression,Model Construction or Optimization
4428,This paper introduces several novel probes for testing systematic generalization,Algorithms/ Methods Construction or Optimization
4429,we investigate whether neural networks can in fact prioritize simultaneous interpretations in a human-like way,Performance Evaluation
4430,", we present a measure of relative word confusability based on both a language model and psychoacoustic data",Model Construction or Optimization
4431,"The paper concludes with a discussion of what our results tell us about adjective order and related issues, and a look towards future work",Theory Proposal
4432,"The goal of this paper is to set a new direction for future task-oriented dialog system research: while retrieving the best candidate is crucial, it should be equally important to identify when the correct response (i.e. ground truth) is not present in the candidate set.",Model Construction or Optimization
4433,demonstrating that it is crucial to learn the relationship amongst the candidates as a set instead of looking at point-wise matching to solve the NOTA detection task,Performance Evaluation
4434,extensive experiments show that the raw output score (logits) is more informative in terms of representing model confidence than normalized probabilities after the Softmax laye,Model Construction or Optimization
4435,"we compare several ways to combine tasks designed to evaluate and improve a single conversational skill, ranging from multi-task training over several datasets to training a top-level classifier to play the role of a dialogue manage",Performance Evaluation
4436,we propose and explore the negative training framework to correct unwanted behaviors of a dialogue response generator,Theory Proposal
4437,negative training is used to address the malicious response problem and the frequent response problem  in open-domain dialogue response generation,Theory Proposal
4438,"We propose a recursive, hierarchical framebased representation that captures complex relationships between slots labels,",Theory Proposal
4439,We formulate frame generation as a templatebased tree-decoding task,Theory Proposal
4440,We extend (local) tree-based loss functions with global supervision optimize jointly for all loss functions end-to-end and show that this improves performance,Algorithms/ Methods Construction or Optimization
4441,we study the task of SQL parse correction with natural language feedback to enable text-to-SQL systems to seek and leverage human feedback to further improve the overall performance and user experience,Algorithms/ Methods Construction or Optimization
4442,we define the task of SQL parse correction with natural language feedback,Dataset Creation or Resources
4443,We create a framework for explaining SQL parse in natural language to allow text-to-SQL users (who may have a good idea of what kind of information resides on their databases but are not proficient in SQL Hendrix et al. (1978)) to provide feedback to correct inaccurate SQL parses,Model Construction or Optimization
4444,"we demonstrate that neural network models show high calibration errors for NLP tasks such as POS, NER and QA",Performance Evaluation
4445,we explore using natural language explanations (Figure 1) to generate features that can augment modern neural representations,Theory Proposal
4446,we extend the BERT training with unlabeled data in a generative adversarial setting,Dataset Creation or Resources
4447,"we propose a novel framework, named Consensus Network (CONNET), for sequence labeling with multi-source supervisions",Theory Proposal
4448,"we introduce a new data augmentation method, called TMix",Algorithms/ Methods Construction or Optimization
4449,"we propose MobileBERT to fill this gap. In practice, task-agnostic compression of BERT is desirable",Theory Proposal
4450,"we seek to fill in this missing knowledge, and put this practice on more rigorous footing",Theory Proposal
4451,", we review the theory of importance sampling, providing proof that importance sampled perplexity estimates are stochastic upper bounds of the true perplexityвЂ”a previously unnoted justification for this evaluation technique",Algorithms/ Methods Construction or Optimization
4452,Our proposed neural model directly encodes the structural information from a noisy graph into the embedding space,Model Construction or Optimization
4453,"Our study suggests that collecting data and training on the target tasks is a solution worth considering, especially in production environments where accuracy is not the only considered factor, rather inference latency is often just as crucial",Dataset Creation or Resources
4454,"First, we explain why BLI does not reflect downstream task accuracy",Theory Proposal
4455,we introduce two post-processing methods to improve downstream models by fitting the training dictionary better,Algorithms/ Methods Construction or Optimization
4456,Method: We propose a distillation method leveraging internal representations and parameter projection that is agnostic of teacher architecture,Algorithms/ Methods Construction or Optimization
4457,"Inference: To learn model parameters, we propose stage wise optimization schedule with gradual unfreezing outperforming prior schemes",Model Construction or Optimization
4458,Experiments: We perform distillation for multilingual NER on 41 languages with massive compression and comparable performance to huge models,Algorithms/ Methods Construction or Optimization
4459,"Study: We study the influence of several factors on distillation like the availability of annotation resources for different languages, model architecture, quality of multilingual word embeddings, memory footprint and inference latency",Model Construction or Optimization
4460,we investigate the stealthiness of state-of-the-art authorship obfuscation methods,Algorithms/ Methods Construction or Optimization
4461,We study the problem of obfuscation detection for state-of-the-art authorship obfuscation method,Algorithms/ Methods Construction or Optimization
4462,We explore 160 distinct BERT and GPT-2 based neural language model architectures designed to leverage text smoothness for obfuscation detection,Model Construction or Optimization
4463,"We conduct a comprehensive evaluation of these architectures on 2 different datasets. Our best architecture achieves F1 of 0.87, on average, demonstrating the serious lack of stealthiness of existing authorship obfuscation methods",Algorithms/ Methods Construction or Optimization
4464,"we conduct experiments on BERT and RoBERTa with six GLUE datasets, showing that DeeBERT is capable of accelerating model inference by up to в€ј40% with minimal model quality degradation on downstream tasks",Dataset Creation or Resources
4465,"A robust model for HTC, with few parameters and short training time, that follows the paradigm of sequence-to-sequence learning",Model Construction or Optimization
4466,The practical application of an auxiliary (and not expensive) task that strengthens the model capacity for prediction in a bottom-up scheme,Model Construction or Optimization
4467,An exploration of strategies that take advantage of external information about textual definition of the classes,Theory Proposal
4468,"We develop a multi-task framework that leverages inductive transfer between our main task (grading spoken language proficiency) and auxiliary objectives вЂ“ predicting morphosyntactic labels, the learnerвЂ™s first (вЂ�nativeвЂ™) language (L1) and language modeling (LM)",Algorithms/ Methods Construction or Optimization
4469,"We investigate the performance of two encoder types for the speech scoring task: bidirectional recurrent neural networks, and bidirectional representations from transformers",Performance Evaluation
4470,"We analyze model performance under different conditions: namely, with and without filled pauses included in the transcriptions, with varying rates of word error in the ASR transcriptions, and according to the proficiency of the student response",Algorithms/ Methods Construction or Optimization
4471,We make our code publicly available for others to use for benchmarking and replication experiments,Performance Evaluation
4472,we introduce a new method for learning general-purpose vector representations of scientific documents,Algorithms/ Methods Construction or Optimization
4473,"we focus on the Search-based Pseudocode to Code (SPoC) dataset (Kulal et al., 2019) due to its challenging multiline programs and availability of input-output test suites to evaluate denotation accuracy",Performance Evaluation
4474,We propose the use of semantic scaffolds to add semantic constraints to models for longform language-to-code generation tasks,Model Construction or Optimization
4475,"We introduce a hierarchical beam search algorithm that incorporates these constraints, resulting in heightened efficiency, better coverage of the search space, and stronger performance when compared with the standard approach",Performance Evaluation
4476,We achieve a new state-of-the-art accuracy of 55.1% on the SPoC pseudocode-to-code dataset.,Dataset Creation or Resources
4477," We propose the OLP task, an OLP evaluation protocol, and a method to create an OLP benchmark dataset",Algorithms/ Methods Construction or Optimization
4478,"We propose a new English natural language inference dataset, INFOTABS, to study the problem of reasoning about semi-structured data",Theory Proposal
4479," To differentiate modelsвЂ™ ability to reason about the premises from their memorization of spurious patterns, we created three challenge test sets with controlled differences that employ similar reasoning as the training set",Performance Evaluation
4480,"We show that several existing approaches for NLI underperform on our dataset, suggesting the need for new modeling strategies",Dataset Creation or Resources
4481,We describe a method to make MRC datasets interactive and formulate the new task as an RL problem,Algorithms/ Methods Construction or Optimization
4482,We develop a baseline agent that combines a top performing MRC model and two state-ofthe-art RL optimization algorithms and test it on iMRC task,Algorithms/ Methods Construction or Optimization
4483,We conduct experiments on several variants of iMRC and discuss the significant challenges posed by our setting,Dataset Creation or Resources
4484,We constructed augmentation sets by applying syntactic transformations to a small number of examples from MNL,Applications
4485,we aim to improve the generalization of the future frame prediction task by adding an auxiliary objective that serves as a regularization,Theory Proposal
4486,we present a successful framework for fine-tuning BERT and XLNet for multimodal inpu,Model Construction or Optimization
4487,We propose an efficient framework for finetuning BERT and XLNet for multimodal language data,Performance Evaluation
4488,MAG-BERT and MAG-XLNet set new state of the art in both CMU-MOSI and CMUMOSEI datasets,Dataset Creation or Resources
4489,Our model utilizes the online temporal alignment between the input audio signal and its raw ASR transcription,Model Construction or Optimization
4490,We achieve consistent and significant improvements from learning jointly from the two modalities compared to ASR transcriptions and audio only,Applications
4491,Our evaluation framework features a challenging real-world task with noisy inputs and realtime processing requirements,Performance Evaluation
4492,a fusion mechanism for audio and visual modalities based on the crossmodal scaled-dot product attention,Theory Proposal
4493,an end to end training procedure for multimodal grounding in ASR,Theory Proposal
4494,the use of a multiresolution training scheme for character and subword level recognition in a seq2seq setting without relying on explicit phonetic information,Theory Proposal
4495,"We carefully curate Selected Pairs Of Learnable ImprovisatioN (SPOLIN), the first largescale corpus of yes-and dialogue acts, sourced from improv and movie dialogues",Theory Proposal
4496,"We iteratively build a high-precision yes-and classifier, which we use to mine additional yesands from dialogue corpora with high volume but low yes-and densit",Theory Proposal
4497,We fine-tune existing open-domain conversational models with our corpus and confirm via human evaluations that this approach improves creative grounding,Performance Evaluation
4498,"We release our models and data for public use, including a 64,000 turn pair extension of the core SPOLIN",Dataset Creation or Resources
4499,"we take a step towards these goals by considering grounded dialogue involving openended discussion of a given image, a setting that is naturally fun for humans (Hu et al., 2014), and study neural conversational models for task",Model Construction or Optimization
4500," a completely unsupervised unreferenced metric MAUDE (Metric for automatic Unreferenced dialogue evaluation), which leverages state-of-the-art pretrained language model combined with a novel discoursestructure aware text encoder and contrastive training approach",Model Construction or Optimization
4501,w We propose a neural model for generating these response timings in SDSs,Model Construction or Optimization
4502,"First, we present how our dataset is structured and our training objective",Dataset Creation or Resources
4503,we present an overview of related work on automatic poetry generation,Theory Proposal
4504,We propose a dual encoding method to narrow the structural gap between data encoder and text decoder for data-to-text generation,Algorithms/ Methods Construction or Optimization
4505,"We propose a neural planner, which is more efficient and effective than previous method",Performance Evaluation
4506,Experiments show that our method outperforms all baselines on a variety of measure,Algorithms/ Methods Construction or Optimization
4507,"In this work, we present infilling by language modeling (ILM), a simple framework which en- 2493 ables LMs to infill variable-length spans while preserving their aforementioned benefits: generation quality, efficient sampling, and conceptual simplicity",Performance Evaluation
4508,"We study the task of sentence infilling, which requires the model to handle inter-sentential correlation and to predict missing semantic information",Model Construction or Optimization
4509,"Our approach decouples understanding, planning, generation, and leverages existing largescale pre-trained understanding and generation models (BERT, GPT-2",Model Construction or Optimization
4510,Our model predicts a feature vector in the latent semantic space for the missing sentence and maps the vector to text,Model Construction or Optimization
4511,Our model allows the generation to be of arbitrary length,Model Construction or Optimization
4512,"Compared with directly processing text, our approach significantly reduces computation time and memory usage during training, as (after pre-computing sentence features) the sequence length is the number of sentences rather than that of tokens",Theory Proposal
4513,we propose a model-based imitation-learning method to overcome the aforementioned issues in text-generation tasks,Model Construction or Optimization
4514,"we show that generation performance can be improved with a retrieve-edit-rerank approach that instead retrieves a set of outputs from  the training set, edits each independently",Applications
4515,we investigate another crucial aspect of following the instructions: can a VLN agent generalize to following longer instructions by learning from shorter ones?,Performance Evaluation
4516,"We propose a new task, MultiMedia Event Extraction, and construct the first annotated news dataset as a benchmark to support deep analysis of cross-media events",Theory Proposal
4517,"We develop a weakly supervised training framework, which utilizes existing singlemodal annotated corpora, and enables joint inference without cross-modal annotation",Model Construction or Optimization
4518," Our proposed method, WASE, is the first to leverage structured representations and graph-based neural networks for multimedia common space embedding",Algorithms/ Methods Construction or Optimization
4519," Generative models tend to do better than discriminative models of the same or similar model class at learning the full range of step types, which benefits action segmentation;",Model Construction or Optimization
4520,"Task structure affords strong, feature-agnostic baselines that are difficult for existing systems to surpass",Theory Proposal
4521,Reporting multiple metrics is necessary to understand each modelвЂ™s effectiveness for action segmentation,Dataset Creation or Resources
4522,we explore models for building an automated Builder agent,Model Construction or Optimization
4523,we propose the MemoryAugmented Recurrent Transformer (MART) model  a transformer-based model that uses a shared encoder-decoder architecture augmented with an external memory module to enable the modeling of the previous history of video segments and sentences,Model Construction or Optimization
4524,we analyze the Visually Grounded Neural Syntax Learner (VG-NSL) model of Shi et al. (2019),Dataset Creation or Resources
4525,In this paper we take a low-overhead approach to add limited interaction to intent classification,Algorithms/ Methods Construction or Optimization
4526,study the effect of interaction on the system performance,Applications
4527,avoid the cost and complexities of interactive data collection,Dataset Creation or Resources
4528,This work analyzes the contribution of various techniques proposed for transfer learning between languages for the task of sequence tagging,Theory Proposal
4529,"Our work studies the corresponding pseudo-loglikelihood scores (PLLs) from MLMs (Wang and Cho, 2019), given by summing the conditional log probabilities log PMLM(wt | W\t ) of each sentence token (Shin et al., 2019",Theory Proposal
4530,"a novel distance-based knowledge graph embedding called orthogonal transform embedding (OTE) with graph context is proposed to alleviate the 1-to-N, N-to-1 and N-to-N issues, while keeps the desired relation patterns as RotatE",Theory Proposal
4531,"A new orthogonal transform embedding OTE, is proposed to extend RotatE from 2D space to high dimensional space, which also models symmetry/antisymmery, inversion and compositional relation patterns",Model Construction or Optimization
4532,A directed graph context modeling method is proposed to integrate knowledge graph context (including both neighboring entity nodes and relation edges) into the distance scoring function,Algorithms/ Methods Construction or Optimization
4533,"Experimental results of OTE on standard benchmark FB15k-237 and WN18RR datasets show consistent improvements over RotatE, the state of art distance-based embedding model, especially on FB15k-237 with many high in-degree nodes. On WN18RR our results achieve the new state-of-the-art performance",Dataset Creation or Resources
4534,the classifierвЂ™s performance. We propose a simple but effective training technique called Posterior Calibrated (PosCal) training that optimizes the task objective while calibrating the posterior distribution in training,Theory Proposal
4535,This work proposes a method for augmenting any neural decoder architecture to incorporate finegrained control states,Algorithms/ Methods Construction or Optimization
4536,"In this work, we systematically study the OOD robustness of various NLP models, such as word embeddings averages, LSTMs, pretrained Transformers, and more",Model Construction or Optimization
4537,"Our primary contribution is robust encodings (RobEn), a framework to construct encodings that can make systems using any model robus",Theory Proposal
4538,"Our main contributions are as follows: First, we prove that their estimator is biased under weak conditions and provide an unbiased solution",Model Construction or Optimization
4539,Our main contribution is a new framing for the sentence ordering task as a constraint solving problem,Theory Proposal
4540,We also propose a new and simple approach for this task in this new framework,Theory Proposal
4541,we raise a question about this trend from a different angle: вЂњcould widespread adoption of the practice of downloading publicly distributed weights pose a security threat?вЂќ,Theory Proposal
4542,The ratio of the architecture design dimensions within a BERT encoder layer can be modified to obtain a layer with better performance. Transformer design dimensions suggested in Vaswani et al. (2017) are suboptimal,Algorithms/ Methods Construction or Optimization
4543,"When we aim to obtain a computationally lighter model, using a вЂ�tall and narrowвЂ™ architecture provides better performance than a вЂ�wide and shallowвЂ™ architecture",Model Construction or Optimization
4544,The fully-connected component applied to each token separately plays a much more significant role in the top layers as compared to the bottom layer,Theory Proposal
4545,", we propose to combine the beneficial effects of multilingual NMT with the selfsupervision from monolingual data",Theory Proposal
4546,Our contribution is an extensive empirical evaluation of top-performing NMT systems to validate or disproof some of the above conjectures,Performance Evaluation
4547,"In this paper, we propose to achieve an adaptive policy via a much simpler heuristic composition of a set of wait-k policies (e.g., k = 1 в€ј 10)",Theory Proposal
4548,". We introduce the novel structured logits mechanism, which enables the exploitation of concept relatedness as determined by LKB edges",Algorithms/ Methods Construction or Optimization
4549,"We generalise the sense vector dot product technique from EWISE, showing that off-theshelf pretrained embeddings can be used",Theory Proposal
4550,We show that the structured logits mechanism and the use of sense embeddings are orthogonal and can be exploited jointl,Theory Proposal
4551,In this work we propose to learn a joint functionspecific word vector space that accounts for the study eat need food help assistance support subject art researcher science chicken scientist implementation cat chicken different roles and functions a word can take in text,Theory Proposal
4552,"we first semi-automatically collect German specialized domain corpora to create a gold standard of term technicality across four domains: automotive, cooking, hunting and DIY",Theory Proposal
4553,we focus on how identification of verbal metaphors can be helped by verbal MWEs,Theory Proposal
4554,we aim to understand the bias in multilingual word embeddings,Theory Proposal
4555,We build datasets for studying the gender bias in multilingual NLP systems,Dataset Creation or Resources
4556,We analyze gender bias in multilingual word embeddings from both intrinsic and extrinsic perspectives,Dataset Creation or Resources
4557,We show that simple mitigation methods can help to reduce the bias in multilingual word embeddings and discuss directions for future work to further study the problem,Algorithms/ Methods Construction or Optimization
4558,"This paper aims to investigate this issue, focused around the examination of a paper recently published at EMNLP 2019 on automatic prison term prediction by Chen et al. (2019)",Performance Evaluation
4559,"Propose MORPHEUS, a method for generating plausible and semantically similar adversaries by perturbing the inflections in the clean examples",Algorithms/ Methods Construction or Optimization
4560,"Demonstrate its effectiveness on multiple machine comprehension and translation models, including BERT and Transforme",Performance Evaluation
4561,"Show that adversarially fine-tuning the model on an adversarial training set generated via weighted random sampling is sufficient for it to acquire significant robustness, while preserving performance on clean examples",Applications
4562,we conduct a systematic study to quantify the bias in the predicted distribution over labels,Dataset Creation or Resources
4563,we present an evaluation framework to analyze social bias in NRE models,Model Construction or Optimization
4564,"We create WikiGenderBias, a new dataset for evaluating gender bias in NRE systems",Dataset Creation or Resources
4565,We present an evaluation framework to demonstrate that gender bias is exhibited in NRE model outputs,Model Construction or Optimization
4566,We test several existing bias mitigation approaches to reducing gender bias in NRE system,Performance Evaluation
4567,we propose here a novel probabilistic generative model for analyzing extracted images of individual printed characters in historical document,Model Construction or Optimization
4568,. We draw from work on both deep generative modeling and interpretable models of the printing press to develop an approach that is both flexible and controllable вЂ“ the later being a critical requirement for such analysis tool,Model Construction or Optimization
4569,we propose an Attentive Pooling with Learnable Norms (APLN) approach to enhance the learning of text representations,Theory Proposal
4570,"Our contributions are a family of novel methods to compute the similarity of sequence tagging datasets, where the similarity values correlate with the change in multi-task learning performance when using one dataset as auxiliary data for training the other",Algorithms/ Methods Construction or Optimization
4571,SSANs can identify the improper word orders in both local (В§4.1) and global (В§4.2) ranges by learning to attend to the expected words,Theory Proposal
4572,SSANs produce more syntactic representations (В§5.1) with a better modeling of structure by selective attention,Performance Evaluation
4573,The selective mechanism improves SANs by paying more attention to content words that posses semantic content and contribute to the meaning of the sentence,Theory Proposal
4574,we design a new family of transformer models that follow a distinct sublayer ordering pattern: sandwich transformer,Model Construction or Optimization
4575,we propose a novel method that replicates the effects of the ensemble technique with a single model,Algorithms/ Methods Construction or Optimization
4576,We propose a self-training based method to leverage unlabeled data in zero-shot text classification,Algorithms/ Methods Construction or Optimization
4577,We propose a reinforcement learning framework to learn data selection policy automatically instead of using manually designed heuristic,Theory Proposal
4578,Experimental results on both benchmarks and a real-world e-commerce dataset show that our method outperforms previous methods with a large margin of 15.4% and 5.4% on average in generalized and non-generalized ZSL respectively,Algorithms/ Methods Construction or Optimization
4579,we propose a novel graph-based multi-modal fusion encoder for NMT,Theory Proposal
4580," We propose a unified graph to represent the input sentence and image, where various semantic relationships between multi-modal semantic units can be captured for NMT",Theory Proposal
4581," We propose a graph-based multi-modal fusion encoder to conduct graph encoding based on the above graph. To the best of our knowledge, our work is the first attempt to explore multimodal graph neural network (GNN) for NMT",Theory Proposal
4582,We conduct extensive experiments on Multi30k datasets of two language pairs,Dataset Creation or Resources
4583,We release the code at https://github.com/ DeepLearnXMU/GMNMT,Theory Proposal
4584,"Greedy algorithms: Wu et al. (2016) segment words by recursively selecting the longest subword prefix. Sennrich et al. (2016) recursively combine adjacent word fragments that co-occur most frequently, starting from characters",Algorithms/ Methods Construction or Optimization
4585,We view the subword segmentation of output sentences in machine translation as a latent variable that should be marginalized out to obtain the probability of the output sentence given the inpu,Theory Proposal
4586,we take this point of view and learn cross-lingual word alignment by finding alignment between the second order statistics of the source and the target language embedding space,Theory Proposal
4587,"We demonstrate the necessity of studying inference calibration for NMT, which can serve as useful indicators of translation error",Performance Evaluation
4588,"We reveal certain linguistic properties of miscalibrated predictions in NMT, which provides potentially useful information for the design of training procedures",Model Construction or Optimization
4589,"We revisit recent advances in architectures and regularization techniques, and provide variants that can boost translation performance by improving inference calibration",Model Construction or Optimization
4590," We propose a SIGNAL model in the contex of Chinese text spam detection, to address the imbalance, efficiency, and text camouflage problems",Model Construction or Optimization
4591,") We develop an end-to-end framework, i.e., LADAN, to solve the LJP task. It addresses the confusing charges issue by mining similarities between fact descriptions and law articles as well as the distinctions between confusing law articles",Model Construction or Optimization
4592,We propose a novel graph distillation operator (GDO) to extract discriminative features for effectively distinguishing confusing law articles,Theory Proposal
4593,We conduct extensive experiments on realworld datasets. The results show that our model outperforms all state-of-the-art methods,Algorithms/ Methods Construction or Optimization
4594,We propose a novel task of job posting generation that is defined as the conditional generation given a job description and basic company information to generate a job requiremen,Theory Proposal
4595,A data-driven generation approach SAMA is proposed to model the complex mapping relationships and generate informative and accurate job requirements,Model Construction or Optimization
4596,We build a real-world job posting dataset and conducte extensive experiments to validate the effectiveness and superiority of our proposed approach,Theory Proposal
4597,we propose a novel method termed as Hyperbolic and Co-graph Representation method (HyperCore,Algorithms/ Methods Construction or Optimization
4598,"We propose to connect CNN and RNN in parallel to simultaneously extract local and global contextual information, which would be complementary to each othe",Theory Proposal
4599,"HYPERCAPS with HDR are formulated to aggregate features in a label-aware manner, and hyperbolic capsules benefits from the representation capacity of the hyperbolic space",Algorithms/ Methods Construction or Optimization
4600,вЂў Adaptive routing is furthermore presented to improve the scalability of HYPERCAPS and fit the large label set of MLC,Algorithms/ Methods Construction or Optimization
4601,"Extensive experiments on four benchmark MLC datasets demonstrate the effectiveness of HYPERCAPS, especially on tail labels",Dataset Creation or Resources
4602,"We introduce a novel task towards understanding technical support problems, which has implications on a variety of downstream application",Theory Proposal
4603,". We benchmark the performance of state of the art sequence labelling models on the task, studying their performance and limitations",Applications
4604,"we present MOOCCube, a data repository that integrates courses, concepts, student behaviors, relationships, and external resources",Dataset Creation or Resources
4605,We propose a novel framework that stacks the Bayesian network ensembles on top of the entity-aware convolutional neural networks to bring interpretability into automatic diagnosis without compromising the accuracy of deep learning,Theory Proposal
4606,We bring forward three variants of Bayesian Networks for disease inference that provides interpretability,Model Construction or Optimization
4607,We publish the Chinese medical knowledge graph of Gynaecology and Respiration used in our Bayesian Network for disease inference with this paper for reproducibility,Theory Proposal
4608,This paper analyzes the persuasive effect of style in news editorial argumentation on readers with different political ideologies (conservative vs. liberal),Theory Proposal
4609,"we propose a new end-to-end ECPE solution, called ECPE-Two-Dimensional (ECPE-2D), to represent the emotion-cause pairs by a 2D representation scheme, and integrate the emotion-cause pair representation, interaction and prediction into a joint framework",Theory Proposal
4610,", we propose the first end-toend approach for emotion-cause pair extraction, which is a unified model to tackle this task from a ranking perspective",Model Construction or Optimization
4611,Our approach emphasizes inter-clause modeling by integrating inter-clause relationship modeling and kernel-based relative position enhanced clause pair ranking,Model Construction or Optimization
4612,"Experimental results demonstrate that our onestep approach significantly outperforms the current best-performing systems, especially in the condition of extracting multiple pairs in one document",Performance Evaluation
4613,"We construct a semantic-emotion heterogeneous graph from external semantic and emotion lexicons, and employ GCN to learn the semantic graph representation",Algorithms/ Methods Construction or Optimization
4614,"We extend the standard LSTM cell with an additional memory unit, effectively integrating external knowledge into the classifier for stance detection",Theory Proposal
4615,We conduct extensive experiments on a large dataset expanded from SemEval-2016 Task 6 to verify the effectiveness of our model for cross-domain stance detection,Dataset Creation or Resources
4616,"We propose KinGDOM, a domain-adversarial framework that uses an external KB (ConceptNet) for unsupervised domain adaptation",Theory Proposal
4617,"We demonstrate, through experiments, that KinGDOM surpasses state-of-the-art methods on the Amazon-reviews dataset (Blitzer et al., 2007b), thus validating our claim that external knowledge can aid the task of cross-domain SA",Algorithms/ Methods Construction or Optimization
4618,We propose the multi-channel CSAE model which distils grammatical aspects into contextualized features for improving sequential taggings,Model Construction or Optimization
4619,We contribute the LCFS-ASC which can analyze syntactical connections between words to better understand local contexts that are relevant to target aspect terms,Theory Proposal
4620,We study the importance of the SRD by exploring the attention score in the LCF layer,Theory Proposal
4621,", we propose to augment parallel data with three specific data augmentation methods to help improve the modelвЂ™s generalization ability and reduce the overfitting risk",Algorithms/ Methods Construction or Optimization
4622,We propose an aspect-oriented tree structure by reshaping and pruning ordinary dependency trees to focus on the target aspects,Theory Proposal
4623,We propose a new GAT model to encode the dependency relations and to establish the connections between aspects and opinion words,Model Construction or Optimization
4624,The source code of this work is released for future research,Theory Proposal
4625,"We propose an end-to-end model for a new task PAOTE. To the best of our knowledge, it is the first end-to-end model that can jointly extract the AT/OT and the pair-wise relations between them",Model Construction or Optimization
4626,We design a novel span-based multi-task neural network for PAOTE. It can overcome the drawbacks of sequence tagging methods by taking advantage of the span-level information,Algorithms/ Methods Construction or Optimization
4627,We conduct extensive experiments and the results show that our proposed model outperforms the state-of-the-art methods,Performance Evaluation
4628,"r, we present a novel model for nontree argument mining",Model Construction or Optimization
4629,", we propose a novel linearization of constituent trees tied on their span representations",Theory Proposal
4630,"we propose three standardized experimental settings with respect to data preprocessing, post-processing, evaluation metrics, and tuning.",Theory Proposal
4631,we propose a novel parsing approach that casts constituency parsing into a series of pointing problems,Theory Proposal
4632,We for the first time propose second-order TreeCRF for neural dependency parsing,Theory Proposal
4633,"We propose to batchify the inside algorithm via direct large tensor computation on GPUs, leading to very efficient TreeCRF loss computation",Performance Evaluation
4634,We conduct experiments on 27 datasets from 13 languages,Dataset Creation or Resources
4635,"we explore dynamic conversation recommendation, which can model the change of user interests over time",Model Construction or Optimization
4636,"We design the model to capture user interests from both what they said in the past, and how they interacted with each other in the conversation structure",Performance Evaluation
4637,"вЂў We propose a Multimodal Transformer model for the task of MNER, which empowers Transformer with a multimodal interaction module to capture the inter-modality dynamics between words and images",Model Construction or Optimization
4638,"we further design a unified architecture to incorporate a text-based entity span detection module, aiming to alleviate the bias of the visual context in MNER with the guidance of entity span predictions from this auxiliary module",Model Construction or Optimization
4639,"We model the leading political ideology (left, center or right bias) and the factuality of reporting (high, mixed, or low) of news media by modeling the textual content of what they publish vs. who reads it in social media (Twitter, Facebook, and YouTube)",Dataset Creation or Resources
4640," We combine a variety of information sources about the target medium, many of which have not been explored for our tasks, e.g., YouTube video channels, political bias estimates of their Facebook audience, and information from the profiles of the media followers on Twitter",Theory Proposal
4641,"We use features from different data modalities: text, metadata, and speech. The latter two are novel for these tasks",Model Construction or Optimization
4642,We achieve sizeable improvements over the current state-of-the-art for both tasks,Applications
4643,"We propose various ensembles to combine the different types of features, achieving further improvements, especially for bias detection",Theory Proposal
4644,"We release the data, the features, and the code necessary to replicate our result",Dataset Creation or Resources
4645,"we discuss some related work, followed by a description of our systemвЂ™s architecture and the information sources we use",Theory Proposal
4646,"In this paper, to obtain a new insight into the syntactic abilities of neural LMs, in particular RNNLMs, we perform a series of experiments under a different condition from the prior work",Performance Evaluation
4647,We propose a novel approach to simulating various grammatical errors,Theory Proposal
4648,We conduct a systematic analysis of the robustness of language encoders and enhance previous work by studying the performance of models on downstream tasks with various grammatical error type,Algorithms/ Methods Construction or Optimization
4649,We demonstrate the robustness of existing language encoders against grammatical errors varies,Performance Evaluation
4650,we suggest an analysis method which helps understand where linguistic properties are learned and represented along attention heads in transformer architectures,Algorithms/ Methods Construction or Optimization
4651,"we show that using analysis results, attention heads can be maximally utilized for performance gains during the fine-tuning process on the downstream tasks and for capturing linguistic properties",Applications
4652,"We argue that the attention scores (rather than attention weights) are able to capture the global, absolute importance of word tokens within a corpus",Theory Proposal
4653,We present R-MeN вЂ“ a novel KG embedding model to memorize and encode the potential dependencies among relations and entities for two real applications of triple classification and search personalization,Model Construction or Optimization
4654,"R-MeN obtains better performance than up-to-date embedding models, in which R-MeN produces new state-of-the-art results on SEARCH17 3430 for the search personalization task, and a new highest accuracy on WN11 and the secondhighest accuracy on FB13 for the triple classification task",Applications
4655,"we propose MC-Tailor, which can tailor the resulting density of model distribution by cutting the probability mass of over-estimated zones to under-estimated zones, leading to more realistic model distribution after fine-tuning",Model Construction or Optimization
4656,"we propose a new architecture, named Multi-source Word Aligned Attention (MWA)",Theory Proposal
4657,"we propose the Coupled-VAE approach, which couples the VAE model with a deterministic network with the same structure",Model Construction or Optimization
4658,We observe the encoder-decoder incompatibility in VAE and connect it to the posterior collapse problem,Theory Proposal
4659,"We propose the Coupled-VAE, which helps the encoder and the decoder to learn better parameterizations of the data manifold with a coupled deterministic network, via encoder weight sharing and decoder signal matching",Model Construction or Optimization
4660,we propose a general co-teaching framework with three specific teaching strategies that cover both teaching with loss functions and teaching with data curriculum.,Theory Proposal
4661,We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph,Model Construction or Optimization
4662,we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple,Theory Proposal
4663,"demonstrating that applying standard topic discovery algorithms such as NMF and LDA on aggregated
documents results in discovery of topics related
to the aggregation method.",Applications
4664,"we propose using tree-structured semantic representations, like those used in traditional rule-based NLG systems, for better discourse-level structuring and sentence-level planning;",Algorithms/ Methods Construction or Optimization
4665,"Our work explores the possibility that limited
training data could be better exploited by including attentive collocation information.",Theory Proposal
4666,"we compare the improvements
obtained on these two tasks in three South
Slavic languages (Slovenian, Croatian and Serbian) by moving from traditional approaches to
the neural ones.",Performance Evaluation
4667,"contextualized word embeddings have enhanced previous word embedding techniques by computing
word vector representations dependent on the
sentence they appear in.",Algorithms/ Methods Construction or Optimization
4668,"we propose
aspects of NLI and of the annotation task itself
that should be taken into account when designing future NLI corpora and annotation guidelines.",Algorithms/ Methods Construction or Optimization
4669,"We use distributed event representation based on the Role Factored Tensor Model
(RFTM) (Weber et al., 2018) to realize a robust
matching of event causality relations, even if these
causalities are not included in the extracted event
causality pairs",Model Construction or Optimization
4670,"we also
show that the neural encoder-decoder architecture trained to predict the minimum edit operations can produce considerably better results than the architecture trained to predict the
characters in lemmata directly as in previous
studies.",Algorithms/ Methods Construction or Optimization
4671,we propose a novel approach to estimate WER per sentence and to aggregate them to provide WER estimation per recording or for a whole test set,Algorithms/ Methods Construction or Optimization
4672,We investigate two pragmatic inferencetypes that are known to differ from classical en-tailment: scalar implicatures and presuppositions,Theory Proposal
4673,we propose a novel approach to filter out noisysentence pairs from web-crawled corpora viapre-trained language models.,Algorithms/ Methods Construction or Optimization
4674,"we introduce a new loss func-tion for CVAEs that counteracts posterior collapse,motivated by our analysis of CVAEвЂ™s evidencelower bound objective (ELBO).",Algorithms/ Methods Construction or Optimization
4675,we make the first steps towards the adoption of MI as a measure of semantic similarity between dense word embeddings,Performance Evaluation
4676,"we propose two improvements to active learning for coreference resolution. First, we introduce the notion of discrete annotation. Second, we introduce mention clustering (Section 4).",Performance Evaluation
4677,The degree of correction of the neural GEC model can be controlled using the WER,Model Construction or Optimization
4678,"the basic ideas around how modern
NLP and NLG techniques could be applied to describe and summarize textual data in format that is
non-linguistic in nature or has some structure",Theory Proposal
4679,"it focuses on the
copula construction and its negation and
the case-stacking phenomenon thereof.",Theory Proposal
4680,"we show that facial expressions, voice, eyes
and body movements are the top three channels
among which the emotion is expressed,",Theory Proposal
4681,"we present an analysis of user responses to a September 27, 2018 announcement about the quarantine policy on Reddit as
a case study of to what extent the discourse
on content moderation is polarized by usersвЂ™
ideological viewpoint.",Applications
4682,"we present an open
source desktop application for the annotation process.",Applications
4683,we provide the introduction of a new NLP task: identifying actionable feedback in collaborative work conversations,Theory Proposal
4684,We explore theusefulness ofinterpolatedtreebank vectors whichare computed via a weighted combination of thepredefined fixed ones,Performance Evaluation
4685,"we focus on investigating and re-ducing biases in the task of Natural Language In-ference (NLI), where the target of the model isto classify the relations between a pair of sen-tences into three categories: entailment, neutraland contradiction",Algorithms/ Methods Construction or Optimization
4686,"We show thatby preventing models from being overconfident onbiased examples, they are less likely to exploit thesimple cues from these examples",Model Construction or Optimization
4687,Our new system achievesstate-of-the-art resultsfor FEVERand we present anevaluation of ourmodelsincluding ablation studies (Section 6). Dataand code will be released to the community.,Model Construction or Optimization
4688,"we first present a comprehensiveanalysis of the trade-offs and limitations of multi-lingual language models at scale, inspired by re-cent monolingual scaling efforts (Liu et al., 2019).",Theory Proposal
4689,"We present the first joint UDS parser, whichlearns to extract both graph structures and attributesfrom natural language input.",Model Construction or Optimization
4690,"we present TABERT, a pretrained LM that jointlylearns representations for NL sentences and(semi-)structured tables.",Model Construction or Optimization
4691,we present a structured tuning framework to improve models using softened constraints only at training time,Model Construction or Optimization
4692,we show that the benefits from taskadaptive pretraining increase when we have additional unlabeled data from the task distribution that has been manually curated by task designers or annotators,Performance Evaluation
4693,we complement previous work targeting possession existence with two attributes: duration (for how long does the possession hold true?) and co-possession (are there other possessors possessing the possessee concurrently?),Theory Proposal
4694,"We conduct experiments across several sample selection algorithms using existing gold data for user labels and show that both of our contributions significantly improve performance on the CoNLL2012 dataset (Pradhan et al., 2012).",Algorithms/ Methods Construction or Optimization
4695,"we do so by building on Time Biased Gain (TBG, Smucker and Clarke, 2012),an IR evaluation measure that models the expected number of relevant items a user can find in a ranked list given a time budget",Performance Evaluation
4696,"I propose that our focus shifts towards interpreting the language together with its userdependent, contextual personal and social aspects, in order to truly process the вЂњnaturalвЂќ language of a user",Theory Proposal
4697,we conduct a corpus analysis of papers published in recent ACL venues to determine whether the community is collectively forgetting about older papers as it experiences a period of rapid growth,Dataset Creation or Resources
4698,"We then investigate what happens when the input is an original sentence in the source language and the modelвЂ™s output is also biased to be original, a scenario never observed in training.",Theory Proposal
4699,"we introduce a procedure for generating synthetic training examples by recombining real ones, such that (2a) is assigned non-negligible probability because it already appears in the training dataset",Algorithms/ Methods Construction or Optimization
4700,"We collect a high-quality annotated dataset
for coreference resolution and information
completion in multi-turn dialogues, which
might benefit future related research.",Dataset Creation or Resources
4701,we explore acoustic-prosodic and linguistic indicators of information concealment by collecting a unique corpus of professionals practicing for oral exams while concealing information.,Dataset Creation or Resources
4702,"we introduce a new dataset constructed
from Wikipedia and Wikidata - DocRED annotates both named entities and relations, and is the largest humanannotated dataset for document-level RE from
plain text",Dataset Creation or Resources
4703,introduce a challenging dataset using this representation for the weather domain,Dataset Creation or Resources
4704,"we compare the parsing performances between Abstract Meaning Representation (AMR) and Minimal Recursion Semantics (MRS), and provide an in-depth analysis of what factors contributed to the discrepancy in their parsing accuracy.",Theory Proposal
4705,"we propose a new type of semantic representation of Construction Grammar
that combines constructions with the vector
representations used in Distributional Semantics.",Algorithms/ Methods Construction or Optimization
4706,"we describe the creation of a data set
that contains news articles and corresponding
comments from Croatian news outlet 24 sata.",Dataset Creation or Resources
4707,"We propose a way to effectively
construct a huge amount of silver data for the con-text reconstruction task.",Algorithms/ Methods Construction or Optimization
4708,we propose a straightforward active learning strategies for both traditional and overnight data collection that significantly reduce data annotation requirements,Algorithms/ Methods Construction or Optimization
4709,We propose a reinforcement learning based framework for medical DS. Experiment results on our dataset show that our dialogue system is able to collect symptoms from patients via conversation and improve the accuracy for automatic diagnosis,Algorithms/ Methods Construction or Optimization
4710,We use a neural generative model for slot filling on the data without word-level annotations which has received less attention,Model Construction or Optimization
4711,"We conclude that scalar annotation protocols should beadopted in future NLI-style dataset creation, whichshould enable new work in modeling a richer spaceof interesting inferences",Model Construction or Optimization
4712,we introduce the task of automati-cally generating To-Do items from email contextand meta-data to assist users with following up ontheir promised actions (also referred to as commit-ments in this work).,Algorithms/ Methods Construction or Optimization
4713,we investigate different end-to-end models tolearn label distributions on crowd-sourced dataand capture inter-subjectivity across all annota-tions,Model Construction or Optimization
4714,we focus on the task of mapping from natural language utterances to SQL queries executable in a database. Most prior work in mapping from natural language to SQL queries train and test the system on a single database,Algorithms/ Methods Construction or Optimization
4715,"We collect TVQA+, a large-scale spatiotemporal video question answering dataset, which augments the original TVQA dataset with frame-level bounding box annotations",Dataset Creation or Resources
4716,"An innovative semantic parsing framework
based on dual learning is introduced, which
can fully exploit data (labeled or unlabeled)
and incorporate various prior-knowledge as
feedback signals. We are the first to introduce dual learning in semantic parsing to the
best of our knowledge",Algorithms/ Methods Construction or Optimization
4717,"We aim to further leverage this promising
methodology into more sophisticated and critical neural models, i.e., neural machine translation (NMT) models, since NMT models recently
play one of the central roles in the NLP research
community",Algorithms/ Methods Construction or Optimization
4718,"develop an adaptive inference scheme
for NMT ensembles by extending Bayesian Interpolation (BI) (Allauzen and Riley, 2011) to
sequence-to-sequence models.",Algorithms/ Methods Construction or Optimization
4719,"we propose an alternative to the
self-attention layer to reduce the computational
burden of a Transformer. Our layer learns its optimal context size, resulting in a network where
each attention layer gathers information on their
own context.",Algorithms/ Methods Construction or Optimization
4720,"We build on a state-of-theart convolutional neural encoder-decoder model
and incorporate cross-sentence context from previous sentences using an auxiliary encoder.",Model Construction or Optimization
4721,"our new loss function effectively reduces
gender bias in the language models during training by equalizing the probabilities of male and
female words in the output;",Theory Proposal
4722,"A semantically-based framework for mention identification and coreference resolution
as a layer of UCCA (В§3). Reusing UCCA
units as mentions facilitates efficient and consistent multilayer annotation.",Algorithms/ Methods Construction or Optimization
4723,"we propose models which generate
more diverse and interesting outputs by 
training models to focus attention on important keyphrases of the story",Model Construction or Optimization
4724,"The approach adopted consists
of two key components: fine-tuning the BERT
language representation model (Devlin et al.,
2018) and the usage of external datasets during the training process",Algorithms/ Methods Construction or Optimization
4725,"By developing a generic approach for restricting the predictions of a seq2seq model to grammatically permissible continuations, we arrive at a widely applicable technique for speeding up semantic parsing",Algorithms/ Methods Construction or Optimization
4726,"Twenty teams participated, developing a range of neural network
models, including some that successfully incorporated external data to boost performance.",Model Construction or Optimization
4727,we aim to improve topic quality with LDA by increasing the importance of named entities in the mode,Model Construction or Optimization
4728,"we proposed Se-qVAT, a variant of VAT that can be used alongwith CRF.",Algorithms/ Methods Construction or Optimization
4729,We propose two end-to-end debiasing techniquesthat can be used when the existing bias patterns areidentified.,Algorithms/ Methods Construction or Optimization
4730,we explore multilingual transfer learning to de-tect multiple frames from just the news head-line in a genuinely low-resource context wherethere are few/no frame annotations in the tar-get language,Dataset Creation or Resources
4731,"we propose amethod for using the interpretable output of theattention layers of a neural AES for source-basedessay writing, with the goal of extracting TCs.",Algorithms/ Methods Construction or Optimization
4732,we propose two additional mea-sures for robustness which quantify the changesin translation when perturbations are added to theinput.,Algorithms/ Methods Construction or Optimization
4733,"we introduce вЂњentity triggers,вЂќ aneffective proxy of human explanations for fa-cilitating label-efficient learning of NER mod-els.",Model Construction or Optimization
4734,"We propose a neural architecture for NER tai-lored to these three experimental setups, based onthe popular BiLSTM-CRF architecture (Lampleet al., 2016).",Algorithms/ Methods Construction or Optimization
4735,"we present a model for handling lexicalized and non-lexicalized features jointly. We use a sequence-to-sequence architecture, with different parameter sharing strategies at the encoder and decoder sides for the different features.",Model Construction or Optimization
4736,We propose to tackle this problem by leveraging richer training signals that can guide our model for preserving input information.,Model Construction or Optimization
4737,"we propose to use the recent, highly successful self-supervised pre-trained language models, e.g. Devlin et al. (2019); Liu et al. (2019) for domain data selection.",Model Construction or Optimization
4738,"we examine how pre-trained language models generalize on the Winograd Schema Challenge (WSC). Named after Terry Winograd, the WSC, in its current form, was proposed by Levesque et al. (2012) as an alternative to the Turing Test.",Performance Evaluation
4739,"We introduce a
novel weakly supervised learning approach, learning with partial labels, that exploits the modular
structure to reduce the supervision effort.",Algorithms/ Methods Construction or Optimization
4740,"we propose a goal-directed endto-end deep reinforcement learning framework to
resolve coreference.Specifically, we leverage the neural architecture",Algorithms/ Methods Construction or Optimization
4741,"We design a model controlling specificity of generated questions, unlike prior work on QA generation",Model Construction or Optimization
4742,We describe a neural PCFG inducer which employs context embeddings in a normalizing flow model to extend PCFG induction to use semantic and morphological information,Theory Proposal
4743,"We propose to model reviewer biases from their review texts and rating distributions, and learn a bias-aware opinion representation.",Model Construction or Optimization
4744,"we present MoNoise, an easy-touse normalization system, consisting of an online
demo as well a more elaborate command line interface.",Algorithms/ Methods Construction or Optimization
4745,"We present a prototype coaching system, Level-Up, that applies the method to English learnersвЂ™ essays in order to assist them in
writing and reading",Algorithms/ Methods Construction or Optimization
4746,"We demonstrate how fine-tuning large pretrained language models, the latest breakthrough in NLP, enhance state of the art on few
of the abusive language datasets, and show
that the domain shift isnвЂ™t considerable when
applied to abusive language datasets.",Model Construction or Optimization
4747,"introduces a theoretical
model for explaining aggressive online
comments from a sociological perspective",Theory Proposal
4748,"Demonstrating that standard debiasing approaches like those introduced in (Bolukbasi et al., 2016) actually worsen the bias
of downstream tasks by providing a denoised
channel for communicating demographic information.",Theory Proposal
4749,"We devise a fully data-driven neural conversational model that leverages conversation history and topic information in the response generation process through a hierarchical joint attention mechanism; making the
dialogue more diverse and engaging.",Model Construction or Optimization
4750,we propose a new model calledScriptWriterto address theproblem of script generation/selection with the helpof a narrative,Model Construction or Optimization
4751,We propose learning contextualized representa-tions that leverage both free text and informationfrom knowledge bases.,Theory Proposal
4752,we pro-pose a framework forcategory-specificattributevalue extraction that is both efficient and effective.,Algorithms/ Methods Construction or Optimization
4753,we propose an architecture consisting of a candi-date generator and a list-wise ranker based onBERT.,Algorithms/ Methods Construction or Optimization
4754,We propose a concept normalization frame-work consisting of a candidate generator anda list-wise classifier.,Algorithms/ Methods Construction or Optimization
4755,"we therefore propose a neural framework, WMSEG, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS.",Algorithms/ Methods Construction or Optimization
4756,"We propose Frugal Paradigm Completion, an approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible",Algorithms/ Methods Construction or Optimization
4757,"we show that competitive results on VisDial can indeed be achieved by replicating the top performing model for VQA (Yu et al., 2019b) вЂ“ and effectively treating visual dialog as multiple rounds of question-answering, without taking history into account",Model Construction or Optimization
4758,"we propose a novel deep learning model for RE that uses the dependency trees to extract the syntax-based importance scores for the words, serving as a tree representation to introduce syntactic information into the models with greater generalization",Model Construction or Optimization
4759,We first propose a recurrent generative model that generates multiple keyphrases as delimiter-separated sequences. Generation diversity is further enhanced with two novel techniques by manipulating decoder hidden states,Model Construction or Optimization
4760,we suggest a new NLG task where a model is tasked with generating natural language statements that can be logically entailed by the facts in an open-domain semi-structured table.,Algorithms/ Methods Construction or Optimization
4761,"Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations.",Algorithms/ Methods Construction or Optimization
4762,"We introduce a new framework for incorporating first-order logic rules into neural network design in order to guide both training
and prediction.",Algorithms/ Methods Construction or Optimization
4763,"we use text simplification
methods to improve the understandability of clinical letters.",Performance Evaluation
4764,"we propose a novel attention-based graph decoder that walks an optimal path within a large commonsense KG (100K entities, 1.1M facts) to effectively prune unlikely candidate entities,",Algorithms/ Methods Construction or Optimization
4765,"We propose Two novel methods to train NLI models that
are more robust to dataset-specific artifacts.",Model Construction or Optimization
4766,"We propose a novel multi-hop retrieval approach, which we believe is imperative for
truly solving the open-domain multi-hop QA
task.",Algorithms/ Methods Construction or Optimization
4767,"describes the methods developed by team TMRLeiden for the
2019 Social Media Mining for Health Applications (SMM4H) Shared Task.",Algorithms/ Methods Construction or Optimization
4768,presents an effort to build a general purpose AMR-annotated corpus for Brazilian Portuguese by translating and adapting AMR English guidelines.,Dataset Creation or Resources
4769,"We therefore propose Natural-language Infer-ence over Label-specific Explanations (NILE)1,which we train and evaluate on English languageexamples",Model Construction or Optimization
4770,we address this shortcoming by in-troducing a novel debiasing method that improvesmodelsвЂ™ performance on the out-of-distribution ex-amples while preserves the in-distribution accu-racy,Algorithms/ Methods Construction or Optimization
4771,"we propose a novel multi-perspective cross-lingual neural framework forcodeвЂ“text matching, inspired in part by a previ-ous model for monolingual text-to-text match-ing, to capture both global and local similari-ties",Algorithms/ Methods Construction or Optimization
4772,we propose a method that instead automatically learns howto weight training data through a data scorerthat is optimized to maximize performance onall test languages.,Algorithms/ Methods Construction or Optimization
4773,"We propose a novel methodthat takes the explicit ontology structure into ac-count, by amulti-level learning to rankapproachthat ranks the candidate types conditioned on thegiven entity mention.",Algorithms/ Methods Construction or Optimization
4774,we propose a novel iterative set expansion framework that leverages automatically generated class names to address the semantic drift issue,Algorithms/ Methods Construction or Optimization
4775,"we propose a method of вЂњsoft gazetteersвЂќ that incorporates ubiquitously available information from English knowledge bases, such as Wikipedia, into neural named entity recognition models through cross-lingual entity linking.",Algorithms/ Methods Construction or Optimization
4776,"we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence",Algorithms/ Methods Construction or Optimization
4777,"We propose ESPRIT, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events",Algorithms/ Methods Construction or Optimization
4778,we propose to apply the VNMT framework to the state-of-the-art Transformer and introduce a more flexible approximate posterior based on normalizing flows.,Applications
4779,"we reproduce a comparison of NMT and PBSMT in different data conditions, showing
that when following our best practices, NMT
outperforms PBSMT with as little as 100 000
words of parallel training data",Performance Evaluation
4780,"we propose and evaluate two strategies for automatically changing the gaps of a C-test
in order to reach a given target difficulty",Performance Evaluation
4781,"an approach determining the entire argument structure
based on just the relations between the four functional components of proposition across three heterogeneous corpora of which two are monological
and the other is dialogical",Algorithms/ Methods Construction or Optimization
4782,"We firstly propose to leverage both semantic and phonetic features of Chinese characters
in NLP tasks by introducing Pinyin Romanization and Wubi Input embeddings, which are easily accessible and effective in representing semantic and phonetic feature.",Algorithms/ Methods Construction or Optimization
4783,"We evaluate the proposed multiembedding scheme on Bakeoff2005 and CTB6
corpora.",Performance Evaluation
4784,"Conducting preliminaries experiments on
multi-label abusive language and hate speech
detection (including hate speech target, category, and level detection) in Indonesian Twitter using machine learning approaches.",Applications
4785,"Comparing the efficacy of embedding based
debiasing techniques to manual word scrubbing techniques on both overall model performance and fairness.",Model Construction or Optimization
4786,the first study to introduce the shuffle languages to analyze the computational power of neural networks,Theory Proposal
4787,"a metric definition, its validation with six real projects over the course of one year (2018.Q2 through 2019.Q1), as well as an extensible implementation1 and testing plan, which is described in вЂњMetric DefinitionвЂќ below.",Theory Proposal
4788,"We investigate the problem of choosing tree-bank embedding vectors for new, possibly out-of-domain, sentence",Theory Proposal
4789,"Our evaluation demonstrates that Seq-VAT brings significant improvements in supervisedsettings, rather than marginal improvements re-ported from previous VAT-based approaches Clarket al..",Performance Evaluation
4790,we test rigorously the hypothesisof the utility of second-order features,Performance Evaluation
4791,We perform evaluation of the different strate-gies on the MWE-Aware English Dependency Cor-pus and treebanks for five additional languagesfrom the Universal Dependencies 2.2 corpus thathave frequent multi-word headless constructions,Performance Evaluation
4792,"We also show that neural representation sharingthrough MTL is an effective strategy, as it ac-counts for a large portion of our observed im-provements",Algorithms/ Methods Construction or Optimization
4793,"Finally, in our analysis we iden-tify general guidelines for strong cross-lingualembedding baselines, that extend to languagepairs that do not include English",Theory Proposal
4794,"We evaluate the proposed method on the WMT2018 Parallel Corpus Filtering shared task, andon our own web-crawled Japanese-Chinese parallel corpus.",Performance Evaluation
4795,"we propose a more holistic analysis and evaluation setup for XSP. We propose to evaluate a semantic parsing system not only on evaluation data designed for XSP, but also on datasets that have only been studied in the SSP setting",Performance Evaluation
4796,We investigate the benefits of automatically learning related tasks to boost the performance of diacritic restoration,Performance Evaluation
4797,"We find that their improved accuracy does not actually emerge from proper visual grounding, but from regularization effects, where the model forgets the linguistic priors in the train set, thereby performing better on the test set.",Model Construction or Optimization
4798,"we advance the stateof-the-art on HTM by means of the design and evaluation of CluHTM, a novel nonprobabilistic hierarchical matrix factorization aimed at solving the specific issues of HTM",Model Construction or Optimization
4799,We propose two separate metrics to evaluate both the clustering of attested forms into paradigms and cells and the prediction of unseen inflected forms,Algorithms/ Methods Construction or Optimization
4800,a creation of a simple technique for integration of structured information into an ED system with graph embeddings,Algorithms/ Methods Construction or Optimization
4801,"The program is
used to generate a segmentation of a sentence
corpus, whose consistency is calculated and
compared with the current morpheme-based
segmentation of the same corpus",Algorithms/ Methods Construction or Optimization
4802,"As a benchmark model for scenario detection,
we present a two-stage model that combines
established methods from topic segmentation
and text classification",Model Construction or Optimization
4803,"we extract the task-specific features from the optimal layer of BERT for coreference resolution where we observe pronouns
strongly attend to the corresponding candidate entities.",Algorithms/ Methods Construction or Optimization
4804,"We demonstrate the effectiveness of NILEcompared to existing systems, in terms of la-bel and explanation accuracy",Model Construction or Optimization
4805,"we consider attribute value extrac-tion for real-world hierarchical taxonomies withthousands of product categories, where directly applying previous approaches presents limitations.",Theory Proposal
4806,we experiment with neural networks to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the network,Algorithms/ Methods Construction or Optimization
4807,"We first investigate how end-toend neural sequence models (with pre-trained language model representations) perform on document-level role filler extraction, as well as how the length of context captured affects the modelsвЂ™ performance",Performance Evaluation
4808,"Our paper presents a concrete formalization of the PDP. Then, as a baseline for future work, we introduce a heuristic benchmark system.",Algorithms/ Methods Construction or Optimization
4809,"we propose to search for Hardware-Aware Transformers (HAT) by directly involving the latency feedback into the design loop. In this way, we do not need FLOPs as the latency proxy and can search specialized models for various hardware",Algorithms/ Methods Construction or Optimization
4810,"we deviate from learning a linear projection matrix (i.e., a parametric model) and propose a non-parametric model which translates vectors by estimating instance-specific geometric translations.",Model Construction or Optimization
4811,"The trained utterance rewriter, when integrated into two real-life online chatbots, is
shown to bring significant improvement over
the original system.",Algorithms/ Methods Construction or Optimization
4812,"to the best of our knowledge, we conduct the first systematic exploration on learning general-purpose binarized (memory-efficient)
sentence representations, and four different strategies are proposed;",Algorithms/ Methods Construction or Optimization
4813,"we study one type of domain adaptation for NER, denoted here heterogeneous tagsets.",Theory Proposal
4814,"We adapt sequentially across two SpanishEnglish and three English-German tasks, comparing unregularized fine-tuning, L2 and Elastic Weight Consolidation",Performance Evaluation
4815,"we
focus on zero-shot generalization: training parsers
on a single treebank and evaluating
on a range of broad-coverage, out-of-domain treebanks , Genia the English Web Treebank",Algorithms/ Methods Construction or Optimization
4816,We demonstrate that automatic domain adaptation performs better at predicting financial outcomes than previous work based on manual domain adaptation,Performance Evaluation
4817,describe our work towards an unsupervised approach to classify documents into a set of categories described by a short sentence,Algorithms/ Methods Construction or Optimization
4818,"to study the
impact of both verbal and vocal features on financial markets, specifically, stock volatility.",Theory Proposal
4819,we analyze gender stereotypes directly from writings under different metrics.,Theory Proposal
4820,"This research
work proposes an improved framework for
social media feed pre-processing that
leverages on the combination of integrated
local knowledge bases and adapted Lesk
algorithm to facilitate pre-processing of
social media feeds",Algorithms/ Methods Construction or Optimization
4821,We have proposed an annotation scheme for EUs and its relations for ChangeMyView;,Theory Proposal
4822,"describes the MARDY tool, an interactive annotation environment for political claims analysis in computational political science (see Pado et al. Вґ (2019) for a task analysis and initial modeling results)",Algorithms/ Methods Construction or Optimization
4823,"A discussion of multilayer design principles
informed by existing semantically annotated
corpora",Theory Proposal
4824,"diversification of the research on
hate speech by provision of a new dataset of
hate speech in another language than English,
namely Portuguese",Theory Proposal
4825,"we want to show how to deal with
this problem for one of these languages: Polish, without having a large dedicated data set
and using solutions prepared for other NLP tasks",Theory Proposal
4826,"a novel two-step procedure for eliciting
discourse connective insertions from naВЁД±ve
workers;",Algorithms/ Methods Construction or Optimization
4827,"Our focus is on
building an annotation schema which can help
writers recognise appropriate intentions in writing their Related Work section, and indicate when
these are missing.",Algorithms/ Methods Construction or Optimization
4828,"focused on
building an implementation using AllenNLP
with out-of-the-box methods to facilitate easy
operation and reuse",Algorithms/ Methods Construction or Optimization
4829,the identification of the schemes for which available tools are readily available for use;,Theory Proposal
4830,we propose a novel simple abstract feature representation which is surprisingly effective,Theory Proposal
4831,"We proposeUncertain Natural Language Infer-ence(UNLI), a refinement of NLI that capturesmore subtle distinctions in meaning by shiftingaway from categorical labels to the direct predic-tion of human subjective probability assessments",Theory Proposal
4832,"We propose NILE, an NLI system which gen-erates and processes label-specific explana-tions to infer the task label, naturally provid-ing explanations for its decisions",Algorithms/ Methods Construction or Optimization
4833,we investigate the utilization ofnarratives in a special case of text generation вЂ“movie script generation.,Theory Proposal
4834,we aim to learn associations be-tween visual attributes of fonts and the verbalcontext of the texts they are typically appliedto.,Algorithms/ Methods Construction or Optimization
4835,"We design a novel video question answering framework, Spatio-Temporal Answerer with Grounded Evidence (STAGE), to jointly localize moments, ground objects, and answer questions",Algorithms/ Methods Construction or Optimization
4836,"we study a relatively new setting in which we predict relations between entities based on the global co-occurrence statistics aggregated from a text corpus, and focus on medical relations and clinical texts in Electronic Medical Records (EMRs).",Theory Proposal
4837,we propose the task of learning interpretable relationships from open domain facts to enrich and refine concept graphs,Theory Proposal
4838,"we present BART, which pre-trains a model combining Bidirectional and Auto-Regressive Transformers. BART is a denoising autoencoder built with a sequence-to-sequence model that is applicable to a very wide range of end tasks",Theory Proposal
4839,we investigate this capability of PLMs in the context of (1) negation and what we call (2) mispriming.,Theory Proposal
4840,"we reflect on the progress of Automated Writing Evaluation (AWE), using Ellis PageвЂ™s seminal 1966 paper to frame the presentation",Theory Proposal
4841,"We then investigate diagonal alignments with auto-encoders over real languages and randomly generated sequences, finding even randomly generated sequences as parents yield noticeable but smaller gains.",Theory Proposal
4842,"we study the temporal aspects of text data, focusing on the information extraction task of named entity recognition in the Twitter domain.",Theory Proposal
4843,"We further propose a novel validity reward focusing on the surface and semantics of logical forms, which is a feedback signal indicating whether the generated logical form is well-formed. It involves the prior- knowledge about structures of logical forms predefined in a domain.15:15",Algorithms/ Methods Construction or Optimization
4844,"We propose a GNN
architecture based on extending the self-attention
mechanism of the Transformer (Vaswani et al.,
2017) to make use of relations between input elements.",Algorithms/ Methods Construction or Optimization
4845,"we propose to approximate the
content information by bag-of-words (BoW) features, where we focus on style-neutral, nonstopwords. Along with traditional style-oriented
auxiliary losses, our BoW multi-task loss and
BoW adversarial loss enable better disentanglement of the style and content spaces",Algorithms/ Methods Construction or Optimization
4846,"We evaluate (i) by testing for
noise reduction in a control condition, (ii) on
large and controlled artificial data and (iii) on
a manually annotated LSC testset.",Performance Evaluation
4847,"In this paper, we fill a gap in the literature by proposing a thorough evaluation of Pereira et al. (2018), using previously untried evaluation metrics.",Theory Proposal
4848,"The goal of this work is to study the use of deep neural models i.e., contextualized word represen-tation model BERT (Devlin et al., 2018) and Gated
Recurrent Units (GRU) (Cho et al., 2014) with
an attention mechanism, paired with word2vec
word embeddings and contextualized ELMo embeddings (Peters et al., 2018).",Applications
4849,"we introduce an open-source
toolkit, NeuralClassifier4
, a neural hierarchical
multi-label text classification toolkit based on
PyTorch. It is designed for solving the hierarchical multi-label text classification problem
with effective and efficient neural models",Model Construction or Optimization
4850,"we introduce Parallax1
, a tool explicitly
designed for this task. Parallax allows the user
to use both state-of-the-art embedding analysis methods (PCA and t-SNE) and a simple yet
effective task-oriented approach where users
can explicitly define the axes of the projection
through algebraic formulae",Algorithms/ Methods Construction or Optimization
4851,"Conduct an empirical study to deepen our understanding of current datasets that focus on
different types of abusive language, which
are sometimes overlapping (racism, sexism,
hate speech, offensive language and personal
attacks). Show that our stacked Bidirectional
Long Short Term Memory architecture with
contextual attention is comparable to or out-performs state of the art approaches on all the
existing datasets.",Theory Proposal
4852,"we investigate the
performance of a multi-dimension Capsule network as opposed to using a fixed dimension Capsule network for capturing a sentence representation and we shall discuss how well it captures
features necessary for classification of such sentences",Performance Evaluation
4853,"we manually reannotated the Turkish PUD treebank for consistency in the annotation. As we do not fully agree
with the annotation scheme of previous Turkish
treebanks, we had incorporated a more strict view
of the SD scheme and tried to balance the six directives of ManningвЂ™s Law",Model Construction or Optimization
4854,"Instead of only training models for each treebank separately, we use a two-stage training
process to incorporate cross-linguistic information present in other treebanks, training
multilingually over all treebanks in the first
stage and then monolingually using saved
multilingual weights in the second stage",Model Construction or Optimization
4855,we propose a hierarchical multi-scale language model in which short time-scale dependencies are encoded in the hidden state of a lower-level recurrent neural network while longer time-scale dependencies are encoded in the dynamic of the lower-level network by having a meta-learner update the weights of the lower-level neural network in an online meta-learning fashion,Model Construction or Optimization
4856,"we focus on the Multi-Genre Natural Language Inference (MNLI)dataset (Williams et al., 2018) in English, and ontwo specific kinds of dataset bias: Contradiction Word Bias (CWB) and Word Overlapping Bias (WOB)",Dataset Creation or Resources
4857,"We propose a new neural structurefor this and name the resulting implementation s-QUASE, where вЂњsвЂќ stands for вЂњsingle;вЂќ in con-trast, we name the straightforward implementationmentioned above p-QUASEfor вЂњpaired.вЂќ Resultsshow that s-QUASEoutperforms p-QUASEsignif-icantly on3single-sentence tasksвЂ”SRL, NER, andsemantic dependency parsing (SDP)вЂ”indicatingthe importance of this distinction",Algorithms/ Methods Construction or Optimization
4858,"We evaluate our models on challenging bench-marks in textual entailment and fact verification, in-cluding HANS (Heuristic Analysis for NLI Systems)(McCoy et al., 2019b), hard NLI sets (Gururanganet al., 2018) of Stanford Natural Language Inference(SNLI) (Bowman et al., 2015) and MultiNLI (MNLI)(Williams et al., 2018), and FEVER Symmetric testset (Schuster et al., 2019).",Performance Evaluation
4859,"we attempt to explore the possibility of gaining plausi-ble judgments of how well an NLP model canperform under an experimental setting,with-out actually training or testing the model",Performance Evaluation
4860,we propose a probabilistic model whose loss function is derived from external su-pervision as regularization for the context gates.,Model Construction or Optimization
4861,"we study the problem in a real-world scenario where we crawl a large Japanese-Chinese parallel corpus from various websites and build open-domain machine translation systems between Japanese and Chinese, by filtering theweb crawled parallel corpus",Algorithms/ Methods Construction or Optimization
4862,"we focus on one class of meth-ods, subword regularization, which addresses NMT robustness without introducing any changes tothe architectures or to the training regime, solelythrough dynamic segmentation of input into sub-words (Kudo, 2018; Provilkov et al., 2019).",Theory Proposal
4863,"we ask the question: вЂњis it possi-ble tolearnan optimal strategy to automaticallybalance the usage of data in multilingual modeltraining?вЂќ To this effect, we propose a method that learns a language scorer that can be used through-out training to improve the model performanceonalllanguages.",Algorithms/ Methods Construction or Optimization
4864,"we focus on decoding informally romanized texts back into their original scripts. We view the task as a decipherment problem and propose an unsupervised approach, which allows us to save annotation effort since parallel data for informal transliteration does not occur naturally.",Model Construction or Optimization
4865,"we propose a neural model named TWASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character.",Model Construction or Optimization
4866,"we improve the performance of diacritic restoration by building a multitask learning model (i.e. joint modeling). Multitask learning refers to models that learn more than one task at the same time, and has recently been shown to provide good solutions for a number of NLP tasks",Model Construction or Optimization
4867,we investigate how to utilize visual content for disambiguation and promoting latent space alignment in unsupervised MMT. Our model employs multimodal back-translation and features pseudo visual pivoting in which we learn a shared multilingual visual-semantic embedding space and incorporate visuallypivoted captioning as additional weak supervision,Applications
4868,"we create PIXELHELP, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in HowTo instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces",Dataset Creation or Resources
4869,"we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification",Algorithms/ Methods Construction or Optimization
4870,"we propose a solution for вЂњzero-shotвЂќ open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals",Theory Proposal
4871,we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters,Performance Evaluation
4872,"we approach event understanding as a form of linking, more akin to coreference resolution than sentence-level SRL. An event trigger evokes a set of roles regarded as latent arguments, with these implicit arguments then potentially linked to explicit mentions in the text",Applications
4873,"we aim at adapting monolingual models to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., NepaliEnglish, Spanish-English, and Hindi-English) using the task of language identification",Model Construction or Optimization
4874,"We propose an unsupervised approach for sarcasm generation based on a non-sarcastic input sentence. Our method employs a retrieve-andedit framework to instantiate two major characteristics of sarcasm: reversal of valence and semantic incongruity with the context, which could include shared commonsense or world knowledge between the speaker and the listener",Algorithms/ Methods Construction or Optimization
4875,"We also introduce a new dataset (ST A C KEX) that expands beyond the only existing genre (i.e., academic writing) in keyphrase generation tasks.",Dataset Creation or Resources
4876,We further propose two evaluation metrics tailored towards the variable-number generation.,Algorithms/ Methods Construction or Optimization
4877,We propose a novel neural CRF alignment model which not only leverages the sequential nature of sentences in parallel documents but also utilizes a neural sentence pair model to capture semantic similarity. Experiments demonstrate that our proposed approach outperforms all the previous work on monolingual sentence alignment task by more than 5 points in F1.,Model Construction or Optimization
4878,"we propose an iterative, editbased unsupervised sentence simplification approach, motivated by the shortcomings of existing work. We first design a scoring function that measures the quality of a candidate sentence based on the key characteristics of the simplification task, namely, fluency, simplicity, and meaning preservation.",Algorithms/ Methods Construction or Optimization
4879,"we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance.",Model Construction or Optimization
4880,"We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize",Model Construction or Optimization
4881,we examine female first author percentages and the citations to their papers in Natural Language Processing (1965 to 2019). We determine aggregatelevel statistics using an existing manually curated authorвЂ“gender list as well as first names strongly associated with a gender,Theory Proposal
4882,"we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehensionвЂ”a TEMPLATE OF UNDERSTANDINGвЂ”for a widely useful class of texts, namely short narratives",Theory Proposal
4883,"We analyze the age of outgoing citations in papers published at selected ACL venues between 2010 and 2019, finding that there is indeed a tendency for recent papers to cite more recent work, but the rate at which papers older than 15 years are cited has remained relatively stable.",Theory Proposal
4884,"We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries",Model Construction or Optimization
4885,We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents.,Model Construction or Optimization
4886,"We propose two methods to train translationese classifiers using only monolingual text, coupled with synthetic text produced by machine translation.Using only originalв†’translationese and translationeseв†’original training pairs, we apply techniques from zero-shot multilingual MT to enable originalв†’original translation",Algorithms/ Methods Construction or Optimization
4887,"we propose treating gender debiasing as a domain adaptation problem, since NMT models can very quickly adapt to a new domain (Freitag and Al-Onaizan, 2016). To the best of our knowledge this work is the first to attempt NMT bias reduction by fine-tuning, rather than retraining",Model Construction or Optimization
4888,This paper presents a dynamic data selection method to multi-domain NMT. Things we do differently from previous work in mixing data are the choice of instance-level features and the employment of a multi-domain curriculum that is additionally able to denoise.,Algorithms/ Methods Construction or Optimization
4889,"we take this direction to an extreme by developing a variant of MHA without any learned parameters (Section 3). Concretely,we replace each attention head with a вЂњhard-codedвЂќ version, which is simply a standard normal distribution centered around a particular position in the sequence (Figure 1).1",Dataset Creation or Resources
4890,"we aim at making agents communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data.",Model Construction or Optimization
4891,"we learn representations directly based on the relevance score inspired by the ideas from IR models. In contrast to the attention mechanism and Transformer models, we claim that the relevance patterns are as important. With proper alignment of the representation spaces of different input modalities, matching can be applied to those spaces.",Theory Proposal
4892,"we propose GROLLA вЂ“ a multitask evaluation framework for Grounded Language Learning with Attributes that expands a goal-oriented evaluation вЂ“ based on the standard final task measure, with two auxiliary tasks: 1) Object attribute prediction (AP), and 2) Zero-shot evaluation (ZS).",Algorithms/ Methods Construction or Optimization
4893,"we try to leverage annotated training data from other domains. Motivated by the hypothesis that events, despite being domain/ task-specific, often occur in similar contextual patterns, we try to inject lexical domain-invariance into supervised models, improving generalization, while not overpredicting events",Theory Proposal
4894,This work proposes an augmented pre-training for language models to improve their understanding of several important temporal phenomena. We address two kinds of reporting biases by effectively acquiring weak supervision from free-form text and utilizing it to learn multiple temporal dimensions jointly,Algorithms/ Methods Construction or Optimization
4895,"we present a unified framework, called RAT-SQL,1 for encoding relational structure in the database schema and a given question. It uses relation-aware self-attention to combine global reasoning over the schema entities and question words with structured reasoning over predefined schema relations.",Algorithms/ Methods Construction or Optimization
4896,"One of the challenges we face is to provide information on visual cues to the BERT model. We overcome this challenge by extracting densecap captions(densecaps) (Johnson et al., 2016) to provide textual information about the image objects, their properties, and interactions. This is motivated by the approaches of Visual Question Answering (VQA)",Model Construction or Optimization
4897,"we introduce a novel Information-theoretic Disentangled Embedding Learning method (IDEL) for text, based on guidance from information theory. Inspired by Variation of Information (VI), we introduce a novel information theoretic objective to measure how well the learned representations are disentangled.",Algorithms/ Methods Construction or Optimization
4898,"we investigate a simple question: can we use short-range attention for the majority of layers in the Transformer and recover the same performance? The hypothesis is that this should be possible, because many steps of reasoning will only involve short-range correlations, i.e. to piece characters together to form words or phrases. We find indeed it is possible.",Theory Proposal
4899,"we propose to use minimal existing supervision for learning a commonsense-aware representation. Specifically, we provide the model with a supervision level identical to the test time of the Winograd challenge. For that, we introduce a self-supervised pre-training task, which only requires pair of sentences that differ in as few as one word (namely, вЂњtriggerвЂќ words).",Model Construction or Optimization
4900,"In this paper, we introduce SCIREX, a new comprehensive dataset for information extraction from scientific articles. Our dataset focuses on the task of identifying the main results of a scientific article as a tuple (Dataset, Metric, Task, Method) from raw text. It consists of three major subtasks, identifying individual entities, their document level relationships, and predicting their saliency in the document (i.e., entities that take part in the results of the article and are not merely, for example, mentioned in Related Work).",Dataset Creation or Resources
4901,we present a simple URE approach relying only on entity types that can obtain improved performance compared to current methods,Algorithms/ Methods Construction or Optimization
4902,We address this issue by extending the recurrent units with multiple blocks along with a trainable routing network. T,Performance Evaluation
4907,"For document
level, we reused last yearХs English-French data
for training and validation, but introduced a new
test set from the same corpus",Performance Evaluation
4910,"reusing the same test English-German set used last year, the evaluation framework allows us for a direct comparison with the last yearХs outcomes at least on one language",Performance Evaluation
4919,we propose a ТbilingualУ BERT using multi-task learning for translation quality estimation (called the QE BERT).,Algorithms/ Methods Construction or Optimization
4935,we present HuaweiХs practices on adapting our NMT systems from general-domain to in-domain,Applications
4940,in this article we aimed to determine whether the neural or the statistical approach is a better one to solve the given problem.,Model Construction or Optimization
4958,"In order to gain further insight into the performance of individual MT systems, we organized a call for dedicated Тtest suitesУ, each focussing on some particular aspect of translation quality",Performance Evaluation
4960,"The goal of this shared task is to provide a testbed for improving MT modelsХ robustness to orthographic variations, grammatical errors, and other linguistic phenomena common in usergenerated content, via better modelling, training, adaptation techniques, or leveraging monolingual training data",Model Construction or Optimization
4965,examine transfer learning for the KazakhРEnglish language pair using additional parallel data from TurkishРEnglish.,Performance Evaluation
4967,Lingua CustodiaХs submission to the WMTХ19 news shared task for German-to-French on the topic of the EU elections,Dataset Creation or Resources
4970,"we describe all the systems for Kazakh_English, Gujarati_English, Chinese_English, and English_Finnish, that we developed and submitted for WMT 2019 under the team name ТNICT.",Theory Proposal
4973,"describes the systems and experiments conducted to participate in the news translation tasks of WMT 2019 for GujaratiР English (guРen, low-resourced language pair) and GermanРEnglish (deРen, document-level evaluation).",Theory Proposal
4976,"we refine our approach to training popular neural machine translation toolkits, experiment with a new domain adaptation technique and again measure improvements in performance on the RussianРEnglish language pair",Model Construction or Optimization
4978,"In this edition, we have submitted systems for the German _ English and German _ French language pairs, participating in both directions of each pair",Theory Proposal
4981,This paper describes our submitted systems with embeddings pre-trained on monolingual corpora,Algorithms/ Methods Construction or Optimization
4989,we describe our joint submission (JU-Saarland) from Jadavpur University and Saarland University in the WMT 2019 news translation shared task for EnglishРGujarati language pair within the translation task subtrack,Theory Proposal
4990,"We participate with the methods for shared news translation task in four language
directions, English _ German and English
_ Russian in both directions",Algorithms/ Methods Construction or Optimization
4993,"I describe a rule-based, bidirectional machine translation system for the FinnishСEnglish language pair.",Theory Proposal
4994,We describe our NMT systems submitted to the WMT19 shared task in English_Czech news translation.,Theory Proposal
4995,"describes the neural machine translation systems developed at the RWTH Aachen University for the De_En, Zh_En and Kk_En news translation tasks",Theory Proposal
4998,"To incorporate document-level context in a light-weight fashion, we propose a modification to the Transformer (Vaswani et al., 2017) that has separate attention layers for inter- and intra-sentential context.",Algorithms/ Methods Construction or Optimization
5002,"neural machine translation (NMT) systems for English_Kazakh
(henceforth referred to as EN_KK) constrained
tasks.",Theory Proposal
5003,we describe the system we developed at the LMU Munich Center for Information and Language Processing,Theory Proposal
5005,"we present the University of Helsinki submissions to the WMT 2019 shared task on news translation in three language pairs: EnglishРGerman, EnglishРFinnish and FinnishРEnglish",Dataset Creation or Resources
5007,"This paper is based on Transformer, a neural machine translation network structure, to develop a two-way evaluation task between Russian and English.",Model Construction or Optimization
5009,"we use the DFKI test suite for German_English MT (Burchardt et al., 2017) in order to analyze the performance of the 16 MT Systems that took part at the translation task",Model Construction or Optimization
5011,We present a test set for evaluating an MT systemХs capability to translate ambiguous conjunctions depending on the sentence structure,Algorithms/ Methods Construction or Optimization
5013,"a machine translation test set of documents from the auditing domain and its use as one of the Тtest suitesУ in the WMT19 News Translation Task for translation directions involving Czech, English and German.",Performance Evaluation
5014,we propose WMDO (metric) Р an extension to WMD that incorporates word order,Performance Evaluation
5020,we describe our neural machine translation (NMT) systems for Japanese_English translation which we submitted to the translation robustness task,Theory Proposal
5024,we built straightforward 6-layer Transformer models and experimented with a handful of variables including subword processing (FRРEN) and a handful of hyperparameters settings (JA_EN),Model Construction or Optimization
5026,We found that Тsocial-media-styleУ sentences can be generated by training a translation model with different Тstart-of-sentenceУ symbols for sentences in different domains in the decoder side,Model Construction or Optimization
5034,We improve the BLEU of top submissions of the recent WMT evaluation campaigns,Performance Evaluation
5041,"We study in depth the effect of translationese on test data, using the test sets from the last three editions of WMTХs news shared task, containing 17 translation directions.",Performance Evaluation
5046,We report a positive impact of our modification on the modelХs ability to perform word sense disambiguation,Model Construction or Optimization
5055,This paper presents a systematic evaluation of twelve AMs Сboth symmetric and directionalС which have been proposed for collocation extraction.,Theory Proposal
5057,we present the distribution and treatment of MultiWord Expressions (MWEs) within BTB-WN С a data-driven Bulgarian WordNet.,Model Construction or Optimization
5079,we develop a simple measure of sentence importance and demonstrate its effectiveness in interpreting a complex LSTM modelХs decision making process,Algorithms/ Methods Construction or Optimization
5093,We present a simple and computationally efficient approach using a widely-available Тoff-theshelfУ retrofitting algorithm to align pretrained embeddings according to semantic verb clusters,Model Construction or Optimization
5115,"An analysis of the performance of state-of-the-art models in Portuguese clinical NER, namely BiLSTM-CRF neural networks (Lample et al., 2016), tested on the labelled collection, either using the previous word embeddings or general-language word embeddings",Performance Evaluation
5132,"In this paper, we describe the tasks, the datasets, and the participantsХ approaches and results of shared task.",Theory Proposal
5138,"we propose a hybrid approach to biomedical NLI, which includes three main components",Model Construction or Optimization
5167,"One approach to explainable VQA is to generate visual explanations, which highlight image regions that most contributed to the systemХs answer, as determined by attention mechanisms or gradient analysis",Theory Proposal
5181,we propose a white-box attack algorithm called ТGlobal SearchУ method and compare it with a simple misspelling noise and a more sophisticated and common white-box attack approach called ТGreedy Search,Algorithms/ Methods Construction or Optimization
5182,We propose a simple attention-based metric called the confusion score that captures BERTХs response to syntactic distortions in an input sentence,Algorithms/ Methods Construction or Optimization
5185,we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERTХs attention,Model Construction or Optimization
5186,"We introduce novel computational models for modeling semantic bleaching, a widespread category of change in which words become more abstract or lose elements of meaning, like the development of arrive from its earlier meaning Фbecome at shore.Х",Model Construction or Optimization
5212,we show that our learned cosine threshold approach can significantly improve the temporal one-to-X analogies performance by filtering out false positives.,Theory Proposal
5218,we propose to focus on a specific conceptСthat of Circular Economy (CE).,Theory Proposal
5222,we implement a new query strategy for selecting ТunlabeledУ instances from a target domain and investigate its effect on fine-tuning a generic NMT model,Dataset Creation or Resources
5249,We propose a simple classification approach that only utilizes word and character n-grams using Na¬хve Bayes learning model.,Model Construction or Optimization
5256,"This is done by building on the Word MoverХs Distance (WMD) metric, which measures the distance between two texts in a word embeddings space. Another contribution is the extension of WMD to allow for multiple references to be used to model object importance",Performance Evaluation
5264,Ґ An end-to-end architecture for goal-oriented visual dialogue combining Information Gain with Reinforcement Learning. Ґ A novel reward function for goal-oriented visual question generation to model long-term dependencies in dialogue. Ґ Both versions of our model outperform the current baselines on the GuessWhat?! dataset for the task of identifying an undisclosed object in an image by asking a series of questions.,Model Construction or Optimization
5268,"our latent variable MMT formulation improves considerably over strong baselines, and compares favourably to the state-of-the-art. Ґ we exploit correlations between both modalities at training time through a joint generative approach and do not require images at prediction time.",Theory Proposal
5270,"We introduce a uniqueness measure to evaluate topic quality more wholistically. Ґ W-LDA produces significantly better quality topics than existing topic models in terms of topic coherence and uniqueness. Ґ We experiment with both the WAE-GAN and WAE-MMD variants (Tolstikhin et al., 2017) for distribution matching and demonstrate key performance advantage of the latter with a carefully chosen kernel, especially in high dimensional settings. Ґ We discover a novel technique of adding noise to W-LDA to significantly boost topic coherence. This technique can potentially be applied to WAE in general and is of independent interest.",Performance Evaluation
5287,We empirically study how pre-trained embeddings and language models perform when used to analyze text from social media.,Theory Proposal
5291,"we explore and evaluate several sub-word unit based embedding strategies Р character n-grams, lemmatization provided by an NLP-pipeline, and segments obtained in unsupervised learning (morfessor) Р to boost semantic consistency in Hungarian word vectors.",Algorithms/ Methods Construction or Optimization
5306,"we  explore the use of computational linguistic methods to investigate how taskappropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers.",Algorithms/ Methods Construction or Optimization
5307,In this paper we present a model for automatic scoring of summaries based on analysing a rhetorical structure of a studentХs summary compared to that of reference summaries.,Model Construction or Optimization
5309,This paper addresses automatic correction of spelling errors where the misspelled string is not a valid word in the language.,Theory Proposal
5316,"We propose a new method for combining systems (¤4) that can combine many systems and relies solely on their output, i.e., it uses systems as a black-box.",Algorithms/ Methods Construction or Optimization
5322,"In the following, we present our low-resource approach to GEC, which ranked as the 6th best performing system in the low-resource 192 track of the BEA 2019 shared task.",Performance Evaluation
5328,we suggest an alternative approach for GEC with ТMulti-headedУ architecture that uses BERT as Encoder and specialized ТHeadsУ networks enabling additional text processing based on particular error types.,Algorithms/ Methods Construction or Optimization
5331,The experiments presented in this paper aim to analyze how much each of these phenomena reveal about the L2 speakerХs native language,Theory Proposal
5334,we propose an automated algorithm which provides feedback about the specific content of non-native English speakersХ spoken responses.,Algorithms/ Methods Construction or Optimization
5335,This paper provides an analytical assessment of student short answer responses with a view to potential benefits in pedagogical contexts.,Theory Proposal
5336,we discuss leveraging this observation in our efforts to build audio-visual content for young learnersХ vocabulary learning.,Algorithms/ Methods Construction or Optimization
5337,"we discuss our system, Curio SmartChat for self-paced K-12 learning through Question Answering as a mode",Model Construction or Optimization
5338,This paper proposes a support tool for evaluating student summaries in terms of their contents by suggesting the links between the ideas of a source text and its summary.,Theory Proposal
5339,"we take first steps towards understanding the relation between expert annotations, reader proficiency and comprehension for automatic readability assessment research by conducting a web-based reading study with over 100 participants in a natural reading environment.",Dataset Creation or Resources
5342,We track the development of writing complexity and accuracy in German studentsХ early academic language development from first to eighth grade.,Applications
5343,We developed an automated oral proficiency scoring system for non-native English speakersХ spontaneous speech,Algorithms/ Methods Construction or Optimization
5345,"we study several simplistic machine understanding systems, described in ¤ 2.4 and empirically examine the correlation between their performance and the actual complexity of texts, measured by humans (see ¤ 3).",Algorithms/ Methods Construction or Optimization
5352,"we present a simple and effective method for assessing the proficiency of language learners, as well as the difficulty of linguistic concepts, by utilizing the Elo formula, (Elo, 1978)С in an unsupervised fashion.",Algorithms/ Methods Construction or Optimization
5365,"We introduce a ТCo-curricular learningУ, for transfer learning across data quality. It extends the single curriculum learning work in NMT and makes
the existing domain-data selection method
work better with noisy data.",Theory Proposal
5371,"we attempt to obtain diverse translations by using sentence codes to condition the sentence generation. We describe two methods to extract the codes, either with or without the help of syntax information.",Theory Proposal
5381,"Based on BERT, we introduce target word embedding dropout for helping substitute candidate proposal, and a substitute candidate validation method based on the substitutionХs influence on the global contexts.",Algorithms/ Methods Construction or Optimization
5406,"we use adversarial training across tasks, to ТsoftcodeУ shared and private spaces, to avoid the shared space gets too sparse.",Theory Proposal
5431,we have manually annotated 100 sentences from the Turkish translation of the novel ТThe Little PrinceУ with AMRs to describe the differences between these annotations and their English counterparts,Theory Proposal
5449,we conduct comprehensive experiments on a large benchmark dataset to compare different Open IE systems to show the neural approachХs promising potential,Performance Evaluation
5485,"To address real-world, large-scale application scenarios and to facilitate the possibility of adopting modern Фdata-hungryХ language models in this domain, we collect a new largescale book review dataset from goodreads.com.",Dataset Creation or Resources
5493,we build a corpus of New Zealand English tweets containing Maori loan- ш words,Theory Proposal
5509,we incorporate knowledge of the lexico-syntactic fixedness of VNCs С automatically acquired from corpora using the method of Fazly et al. (2009) С into our various embedding-based approaches,Theory Proposal
5540,"We introduce LSTMEmbed, an RNN model based on a bidirectional LSTM for learning word and sense embeddings in the same semantic space, which Р in contrast to the most popular approaches to the task Р takes word ordering into account.",Model Construction or Optimization
5553,we analyze the usefulness of a userХs network information over the userХs tweets for predicting its occupational group. We extend the existing dataset for occupation classification by introducing the network information about a user,Theory Proposal
5582,"We propose the novel AGGCNs that learn a
Тsoft pruningУ strategy in an end-to-end fashion, which learns how to select and discard
information. Combining with dense connections, our AGGCN model is able to learn a
better graph representation",Model Construction or Optimization
5588,"We propose a generic hierarchical fusion strategy, termed Фdivide, conquer and combineХ, to explore both local and global interactions in multiple stages each focusing on
different dynamics.",Algorithms/ Methods Construction or Optimization
5597,"We propose a knowledge attention module,
which helps to select the most related and helpful knowledge from different KGs",Model Construction or Optimization
5615,"we introduce a novel Фcontinual architecture searchХ (CAS) approach, where the model parameters evolves and adapts when trained sequentially on a new task while maintaining the performance on the previously learned tasks.",Algorithms/ Methods Construction or Optimization
5677,"we propose a novel method for
zero-shot multilingual transfer, inspired by research in truth inference in crowd-sourcing, a related problem, in which the Фground truthХ must be
inferred from the outputs of several unreliable annotators",Algorithms/ Methods Construction or Optimization
5698,we propose an approach based on dynamic linear combination of layers (DLCL) to memorizing the features extracted from all preceding layers.,Model Construction or Optimization
5699,"we propose a new and simpler method without a priori parallel corpora. Our premise is that NMT systems Сeither sequence to sequence models with RNNs, transformers, or any architecture based on encoderРdecoder models",Algorithms/ Methods Construction or Optimization
5700,we introduce a novel constraint-driven approach to learning a document-level (ФglobalХ) co-reference model without using any document-level annotation;,Model Construction or Optimization
5719,We introduce methods based on sentence moverХs similarity; our automatic metrics evaluate text in a continuous space using word and sentence embeddings.,Algorithms/ Methods Construction or Optimization
5756,"we propose the new task of automatic article commenting, and introduces a large-scale Chinese dataset1 with millions of real comments and a humanannotated subset characterizing the commentsХ varying quality",Algorithms/ Methods Construction or Optimization
5778,"We provide a comprehensive
comparative evaluation of a wide range of stateof-the-artСboth supervised and unsupervisedС
projection-based CLE models.",Performance Evaluation
5800,"we aim to combine the power of neural networks with the dataefficiency of logical forms by pre-learning abstractions in a semi-supervised way, satiating part of the networkХs data hunger on cheaper unlabeled data from the environment.",Theory Proposal
5832,"we perform an analytic comparison of these methods, and introduce our own results. By fine-tuning GoogleХs
recently published transformer-based architecture, BERT, on the fake review detection task",Theory Proposal
5846,"We demonstrate favorable trade-offs to those of wait-k strategies at many latency values, and provide evidence that MILkХs advantage extends from its ability to adapt based on source content",Theory Proposal
5874,"we build on extensions of HarrisХ distributional hypothesis to relations, as well as recent advances in learning text representations to build task agnostic relation representations solely from entity-linked text.",Algorithms/ Methods Construction or Optimization
5898,"we examine analystsХ decision making behavior as it pertains to the
language content of earnings calls.",Performance Evaluation
5911,"we take a step towards closing this gap, by introducing the task of Debate Topic Expansion Р finding related topics that can enrich our arguments and strengthen our case when debating a given topic.",Theory Proposal
5941,We show empirical evidence that constructiveness scores are not always related to positive user feedback such as ТLikeУ-button clicks,Theory Proposal
5946,To analyse into the authorХs demographic traits that are related to usage preference of textimage relationship types,Theory Proposal
5960,"This research proposal consequently explores this question in the context of a neural morphological analyzer for a polysynthetic language, St",Theory Proposal
6002,"We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system.",Dataset Creation or Resources
6007,"We propose a novel hierarchical fusion model
to address the challenging multi-modal sarcasm detection task in Twitter. To the best
of our knowledge, we are the first to deeply
fuse the three modalities of image, attribute
and text, rather than na¬хve concatenation, for
Twitter sarcasm detection",Model Construction or Optimization
6017,"we design and construct a real-world online platform that offers PhD graduates a dedicated job search functionality, as well as helps governments, universities, and employers in increasing the understanding of different industriesХ absorption of PhD graduates.",Algorithms/ Methods Construction or Optimization
125,"we have created a new dataset with more than 100,000 algebraic word problems that includes both answers and natural language answer rationales (Â§2)",Dataset Creation or Resources
126,We develop a new dataset VERBPHYSICS that compiles crowdsourced knowledge of actions and objects.,Dataset Creation or Resources
127,We analyze time expressions from four datasets and make four findings. The findings provide evidence in terms of time expression for the principle of least effort.,Dataset Creation or Resources
128,we point out the deficiencies in the MC datasets with respect to the compositionality of morphemes and introduce our own dataset free of these deficiencies.,Dataset Creation or Resources
129,"Grounded in psychological theory of emotions, we build a large-scale, high quality dataset of tweets labeled with emotions. Key to this are methods to ensure data quality",Dataset Creation or Resources
130,". We annotate six existing RC datasets, compared to the two datasets considered in Sugawara and Aizawa (2016), with our organized metrics being used in the comparison. We have made the results publicly available1 and report on the characteristics of the datasets and the differences between them.",Dataset Creation or Resources
131,"To equip learning about common entities through comparison comprehension, we have crowdsourced a dataset of more than 14K comparison paragraphs comparing entities from nine broad categories. This resource will be expanded over time and will be released to the public",Dataset Creation or Resources
132,We improve the annotation guidelines in MR and contribute with a new Wikipedia-based MR dataset called ReLocaR to address the training data shortage.,Dataset Creation or Resources
133,"we present the first rigorously annotated dataset for detection of human trafficking, called Trafficking-10k, which includes more than 10,000 trafficking ads labeled with likelihoods of having been posted by traffickers.",Dataset Creation or Resources
134,"In addition to the automatically gathered large-scale (but noisy) dataset, we present a clean, human-annotated subset of 1975 question-document-answer triples whose documents are certified to contain all facts required to answer the questions.",Dataset Creation or Resources
135,"Construction of a dataset, first of its kind, that consists of 3000 tweets each augmented with five non-sarcastic interpretations generated by human experts.",Dataset Creation or Resources
136,We release a new ATIS semantic dataset annotated in two new languages.,Dataset Creation or Resources
137,we release the first broad-coverage dataset for evaluation of lexical dialectology models,Dataset Creation or Resources
138,"We constructed a large-scale Japanese image caption dataset, STAIR Captions, which consists of Japanese captions for all the images in MS-COCO (Lin et al., 2014) (Section 3).",Dataset Creation or Resources
139,"a new formalism, model, and annotated dataset for studying connotation frames from large-scale natural language data and statistics",Dataset Creation or Resources
140,we benchmark a state of the art parser on our dataset and estimate the influence of grammatical errors on the accuracy of automatic POS tagging and dependency parsing,Dataset Creation or Resources
141,"We introduce two datasets with the goldstandard mappings between medical concepts and social media texts extracted from tweets and blog posts, respectively.",Dataset Creation or Resources
142,we build datasets for supervised learning and evaluation for this task.,Dataset Creation or Resources
143,a new dataset created using a distant supervision approach and new features for causality identification. One major advantage is that our method requires very little prior knowledge about the data and requires only a small seed set of known connectives.,Dataset Creation or Resources
144,"large annotated dataset consisting of 16k argument pairs with 56k reasons in natural language (700k tokens),",Dataset Creation or Resources
145,we also present and release a forum dataset annotated with a standard speech act tagset.,Dataset Creation or Resources
146,"we have created and plan to release the first ever significantly large corpus for image caption generation for the Japanese language, forming a comparable corpus with existing English datasets.",Dataset Creation or Resources
147,we have created a very simple model based on neural image caption generation for Japanese that can exploit the English portion of the dataset.,Dataset Creation or Resources
148,"in order to enable the VQG research, we carefully created three datasets with a total of 75,000 questions, which range from object- to event-centric images, where we show that VQG covers a wide range of abstract terms including events and states (Section 3)",Dataset Creation or Resources
149,"we collected 25,000 gold captions for our eventcentric dataset and show that this dataset presents challenges to the state-of-the-art image captioning models (Section 3.3).",Dataset Creation or Resources
150,"Datasets: In addition to the standard Wall Street Journal corpus (WSJ) (Ratnaparkhi et al., 1994), we labeled two new datasets for testing purposes, one from Wikipedia (WKP), and another from the New York Times Corpus (NYTC). We make these datasets freely available for future research.",Dataset Creation or Resources
151,"A new dataset of 3,425 factoid-annotated sentences for scientific articles in 7 topics.",Dataset Creation or Resources
152,"We have manually annotated CTB tags for 1, 000 PD sentences, which is the first dataset with two-side annotations and can be used for annotation-conversion evaluation. Experiments on the newly annotated data show that our coupled model also works effectively on the annotation conversion task, improving conversion accuracy from 90.59% to 93.90% (+3.31%).",Dataset Creation or Resources
153,"we create fifteen cross-lingual word similarity datasets based on RG-65, covering six languages, by proposing an improved version of the approach of Kennedy and Hirst (2012) for the automatic construction of cross-lingual datasets from aligned monolingual datasets.",Dataset Creation or Resources
154,"Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations.",Dataset Creation or Resources
155,We present a large-scale dataset for this task gathered from various structured and unstructured social media sources.,Dataset Creation or Resources
156,the definition of a new summarization task that corresponds to exploratory search behavior and the contribution of a novel dataset containing human summaries.,Dataset Creation or Resources
157,This dataset is annotated with Wikipedia and UMLS terms for over 30% of the tokens.,Dataset Creation or Resources
158,"We create a dataset of grammatical and ungrammatical sentences written by English language learners, labeled on an ordinal scale for grammaticality. With this unique data set, which we will release to the research community, it is now possible to conduct realistic evaluations for predicting sentence-level grammaticality",Dataset Creation or Resources
159,"We have developed multilingual metaphorrich datasets in English, Spanish, Russian and Farsi that contain annotations of the Positive and Negative polarity and the valence (from â3 to +3 scale) corresponding to the intensity of the affect conveyed in the metaphor.",Dataset Creation or Resources
160,to develop required resources for Bengali and thereby providing them to GuiTAR for anaphora resolution. Our contribution also includes extension of the ICON2011 AR dataset for Bengali so that evaluation could be done on a bigger sized dataset.,Dataset Creation or Resources
161,We present the largest Arabic sentiment analysis dataset to-date (up to our knowledge),Dataset Creation or Resources
162,We provide standard splits for the dataset into training and testing sets.,Dataset Creation or Resources
163,"we have applied our model to over 4 million 5-tuples of the form {n0, v, n1, p, n2}, and we also make this dataset available1 for research into ternary relation extraction beyond spatial and temporal scoping.",Dataset Creation or Resources
164,"publicly available code, resources and models ",Dataset Creation or Resources
165,"We add a concrete, interpretable semantics to the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013), the largest paraphrase resource currently available. We give each entry in the database a label describing the entailment relationship between the phrases.",Dataset Creation or Resources
166,Our approach uses simple models which can be easily reproduced by both CV and NLP researchers. We provide resources to enable comparison against future systems.,Dataset Creation or Resources
167,We create a large-scale resource made up of semantic predicates.,Dataset Creation or Resources
168,We make our annotation available to the NLP community. T,Dataset Creation or Resources
169,The corpus and the automatic classifier are both made publicly available.,Dataset Creation or Resources
170,A free distribution of our implementation is publicly available,Dataset Creation or Resources
171,"a SVM model and end-to-end BLSTM model. The annotated data, licensed under CC-BY-SA license, and the experimental code are publicly available",Dataset Creation or Resources
172,"Our implementation is freely available in the widely used open-source MT toolkit Moses, enabling other researchers to explore discriminative modelling with target context in MT.",Dataset Creation or Resources
173,"Our model outperforms state-of-the-art topic models when evaluated on a large real-world microblog dataset containing over 60K conversation trees, which is publicly available.",Dataset Creation or Resources
174,We annotate the publicly available AddSub corpus with the correct formula and its associated variables;,Dataset Creation or Resources
175,We make the code publicly available.,Dataset Creation or Resources
176," in order to stimulate further research on this task, we make our annotations publicly available.",Dataset Creation or Resources
177,we make both the parallel corpora and the code publicly available.,Dataset Creation or Resources
178,"We make our software available for future research, functioning as a kind of GIZA for non-parallel data.",Dataset Creation or Resources
179,"we make the POS tagging models for 100 languages publicly available and extend the mappings in Petrov et al. (2011) for six new languages (Hindi, Croatian, Icelandic, Norwegian, Persian, and Serbian).",Dataset Creation or Resources
180,"in order to stimulate further research on this task, we make our data set consisting of prompt adherence annotations of 830 essays publicly available.",Dataset Creation or Resources
181,"New Sentiment Analysis Resources â We have generated sentiment lexicons for 136 major languages via graph propagation which are now publicly available1 . We validate our own work through other publicly available, human annotated sentiment lexicons.",Dataset Creation or Resources
182,"We hope the publicly available collection of annotated requests enables further study of politeness and its relation to social factors, as this paper has only begun to explore this area.",Dataset Creation or Resources
183,we make our data set consisting of thesis clarity annotations of 830 essays publicly available in order to stimulate further research on this task.,Dataset Creation or Resources
184,"we propose an alternative approach for parsing constituency-based grammars. Instead of using manually-crafted transformation rules, this approach relies on a small amount of annotations in the target formalism. Frequently, such annotations are available in linguistic texts that introduce the formalism.",Dataset Creation or Resources
185,we make the developed software and complete tool-chain publicly available for further experimentation.,Dataset Creation or Resources
186,We make our implementation publicly available,Dataset Creation or Resources
187,"We show how AL can be used to guide an unsupervised generative model, and we will make our code available to the research community",Dataset Creation or Resources
188,"We make an annotated subset of the CoNLL 2003 (NER) Shared Task available for extra MR training data, alongside models, tools and other data.",Dataset Creation or Resources
189,"provide several methods for paragraph- and sentence alignment of parallel texts, and for assessing similarity level between pairs of text snippets, as freely available software",Dataset Creation or Resources
190,"in order to stimulate further research on this task, we make our data set consisting of argument strength annotations of 1000 essays publicly available.",Dataset Creation or Resources
191,"to facilitate comparison with future work on this task, we release the source code of our system",Dataset Creation or Resources
192,We release the human annotation data for use in future research.,Dataset Creation or Resources
193,"we release the full annotation guidelines, the annotated corpora, and the improved parser model to the public",Dataset Creation or Resources
194,We generate PropBanks for each of these languages and release them to the research community.,Dataset Creation or Resources
195,"we release FrameNet+, a huge, manually-vetted extension to the current FrameNet. FrameNet+ provides over 22,000 new frame/LU mappings in a format that can be readily incorporated into existing systems.We demonstrate that the expanded resource provides a 40% improvement in lexical coverage in a practical setting.",Dataset Creation or Resources
196,"to spark further research on this facet of the QE problem, our adaptive QE infrastructure (integrating all the components and the algorithms described in this paper) has been released as open source. I",Dataset Creation or Resources
197,"We conduct a large crowd-sourced user study to collect a dataset of intended selections and simulated user selections, which we release to the academic community;",Dataset Creation or Resources
198,we have annotated a significant amount of Chinese patent data and we plan to release this data once the copyright issues have been cleared.,Dataset Creation or Resources
199,"We develop a robust algorithm, ImpAr, that obtains very competitive results with respect to existing supervised systems. We release an open source prototype implementing this algorithm",Dataset Creation or Resources
200,Introducing two new NER test sets for Arabic that include recent news as well as microblogs. We plan to release these test sets.,Dataset Creation or Resources
201,We trained an Egyptian/MSA transformation model to make Egyptian look similar to MSA. We publicly released the training data.,Dataset Creation or Resources
202,"We release our implementation as the first open-source monolingual aligner, which we hope to be of benefit to other researchers in the rapidly expanding area of natural language inference.",Dataset Creation or Resources
203,"To our knowledge, it is the first work to automatically label data for large scale EE via world knowledge and linguistic knowledge. All the labeled data in this paper have been released and can be downloaded freely",Dataset Creation or Resources
204,We release all data and models.,Dataset Creation or Resources
205,"We release the sentiment-specific word embedding learned from 10 million tweets, which can be adopted off-the-shell in other sentiment analysis tasks.",Dataset Creation or Resources
206,"Creation of additional resources: We create a synthetic test set of negative sentences extracted from Simple English Wikipedia (Â§ 5) and annotated according to the guidelines released during the *SEM2012 shared task (Morante et al., 2011), that we hope will guide future work in the field.",Dataset Creation or Resources
207,"The release of the set of dependencies used in our experiments, the test outputs from all parsers, and the parser-specific models.",Dataset Creation or Resources
208,we present preliminary experiments showing that missing data techniques can be used to recover the score matrix from a sample of its entries despite the low inter-rater agreement (Section 4).,Applications
209,"we construct a fully labelled corpus, which can be used to evaluate systems that perform the task described above. To build this corpus we employed three annotators, one of whom is an author, while the other two were hired using the outsourcing website Freelancer.",Dataset Creation or Resources
210,We describe several optimizations which allow target-side features to be used efficiently in the context of phrase-based decoding.,Applications
211,we show that this architecture can be used for domain adaptation.,Applications
212,"We conducted experiments with the proposed strategies on multimodal translation and automatic post-editing tasks, and we showed that the flat and hierarchical attention combination can be applied to these tasks with maintaining competitive score to previously used techniques.",Applications
213,"we present a phrase structure annotation scheme for dealing with learner English consistently and reliably. For this, we propose five principles which can be applied to creating a novel annotation scheme for learner corpora.",Applications
214,"our insight that a low-dimensional ontological document representation can be used as an intermediary for retrieving and generalizing high-level question templates to new documents,",Applications
215,the learned entity types can be used to predict selectional restrictions with high accuracy,Applications
216,we presented an empirical attempt to tackle the problem of partial textual entailment. We demonstrated that existing methods for recognizing (complete) textual entailment can be successfully adapted to this setting.,Applications
217,"support language compositionality, we augment the standard seq2seq model with a key-variable memory to save and reuse intermediate execution results.This is a novel application of pointer networks to compositional semantics.",Applications
218,We demonstrate the effectiveness of taking discourse modes into account for automatic essay scoring. A higher ratio of description and emotion expressing can indicate essay quality to a certain extent. Discourse modes can be potentially used as features for other NLP applications.,Applications
219,"the novel extension of signed clustering to the multiclass (K-cluster), and the application of this method to create semantic word clusters that are agnostic to vector space representations and thesauri.",Applications
220,to design an architecture that learns to skim text and show that it is both faster and more accurate in practical applications of text processing. Our model is simple and flexible enough that we anticipate it would be able to incorporate to recurrent nets with more sophisticated structures to achieve even better performance in the future.,Applications
221,We launched AliMe Chat for a real-world industrial application.,Applications
222,"In our knowledge, this is the first application of curriculum learning to the task of QA and one of the first in NLP. We hope to make the NLP and ML communities aware of the benefits of CL for non-convex optimization.",Applications
223,"We are the first to provide a joint wordand supersense-embedding model, which we make publicly available1 for the research community. This provides an insight into the word and supersense positions in the vector space through similarity queries and visualizations, and can be readily used in any word embedding application.",Applications
224,an application of GCCA to learning vector representations of social media users that best accounts for all aspects of a userâs online life,Applications
225,we propose for the first time an application-oriented extrinsic evaluation of ASR QE,Applications
226,Modeling contributions:New application of unsupervised grammar induction: low-resource SRL.,Applications
227,"n introducing Gaussian Processes to the NLP community, a technique that has great potential to further performance in a wider range of NLP applications. Moreover, the algorithms proposed herein can be adapted to improve future annotation efforts, and subsequent use of noisy crowd-sourced data.",Applications
228,"we propose modifications to existing algorithms. First, we identify a new application of logistic model trees to text data. Next, we define a modification of confidence-based ensemble voting which encourages minority class labeling.",Applications
229,"we introduce the Linking-Tweets-toNews task as well as a dataset of linked tweet-news pairs, which can benefit many NLP applications",Applications
230,"we explore a flexible application of dependency paths that overcomes this difficulty. We reduce paths to chains of words called catenae (Osborne and GroÃ, 2012) that capture salient semantic content in an underspecified manner",Applications
231,the application of RNNLMs and FLMs to the challenging task of Code-Switching.,Applications
232,A novel approaches to sequential summarization and corresponding evaluation criteria for this new application.,Applications
233,the application of discriminative reranking to conceptto-text generation is novel to our knowledge and as our experiments show beneficial.,Applications
234,We model the application of a formula and present a novel method to learn to apply a formula;,Applications
235,"we apply these embeddings to a standard document classification task and show that they outperform the current published state of the art (Hermann and Blunsom, 2014b)",Applications
237,We apply the proposed model to ChineseEnglish phrase-based MT and demonstrate promising BLEU improvements and TER reductions on the NIST evaluation data,Applications
238,"we explores applying deep neural network for word alignment task. Our model integrates a multi-layer neural network into an HMM-like framework, where context dependent lexical translation score is computed by neural network, and distortion is modeled by a simple jump-distance scheme.",Applications
239,We apply an existing supervised training algorithm for semantic parsing to a labeled data set.,Applications
240,"We apply schema matching techniques to the problem of finding correspondences between English words w and ontological symbols s. And we apply pattern learning techniques to incorporate new (w, s) pairs into the lexicon of the trained semantic parser",Applications
241,We apply the third-order feature models of Koo and Collins (2010) to non-projective parsing.,Applications
242,"we propose to apply an RNN-based generative model to keyphrase prediction, as well as incorporate a copying mechanism in RNN, which enables the model to successfully predict phrases that rarely occur.",Applications
243,We successfully apply the attention scheme to detect word senses and learn representations according to contexts with the favor of the sememe annotation in HowNet,Applications
244,"To our best of our knowledge, this work is the first attempt to apply LSH technique on sequence generation tasks on GPU other than single-step classification on CPU.",Applications
245,"First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective",Applications
246,applying it successfully to an entity resolution system.,Applications
247,"We apply S-MART to tweet entity linking. Building on top of S-MART, we propose a novel inference algorithm for nonoverlapping structure with the goal of preventing conflicting entity assignments.",Applications
248,"we apply our model to both phrasebased and hierarchical phrase-based (HPB) systems and achieve an average improvement of 0.9 BLEU points with much slimmer translation models in hypergraph reranking task (Huang, 2008).",Applications
249,"From the perspective of relation extraction applications, we identify âsuper relationsâ- the key relations that can facilitate clinical decision making (Table 1). We also present approaches to collect training data for these relations with a small amount of labeling effort.",Applications
250,we use character string embeddings for UNK and incomplete tokens.,Applications
251,"We use a medium-sized, back-translated multi-modal in-domain data set and large general-domain text-only MT corpora to pretrain our models and show that our MNMT model can efficiently exploit both",Applications
252,"we use zeroinflated kernel density estimated plots to show how distributions of different language features (words, LDA topics, and hand-curated word sets) vary with level of analysis (message, user, and county). ",Applications
253,we use the modelâs embeddings for extraction of local terms and show that it outperforms two baselines.,Applications
254,"we propose to use images as a hub to automatically discover comparable corpora. Then we will apply Entity Discovery and Linking (EDL) techniques in HLs to extract entity knowledge, and project results back to LLs by leveraging multi-source multi-media techniques.",Applications
255,use our classifiers to study job-related discourse on social media using data-driven ethnography.,Applications
256,We use Occamâs Razor to regulate the attention weights which shows advantage in long sentence representation.,Applications
257,"We use our approximation to define a mathematically principled discrete optimization problem for sentence selection. We empirically evaluate our framework on two DUC datasets, demonstrating the validity of our approximation, as well as its ability to achieve competitive ROUGE scores in comparison to several strong baselines.",Applications
258,We use frame-to-frame relations to find antecedents from those explicit semantic roles.,Applications
259,we propose to use an encoder-decoder-based neural network to generate a response in STC;,Applications
260,"we propose the use of Modified Adsorption (Talukdar and Crammer, 2009) as a baseline network-based geolocation model, and show that it outperforms previous network-based approaches (Jurgens, 2013; Rahimi et al., 2015)",Applications
261,"the use of GP, illustrated by STS-GP-PL, VES-GP-PL and Our model. The major effect is to multiply the impacts of the bilingual knowledge through the similarity graph. The graph vertices (types)10, without any supervisions, can learn the word boundary information from their similar types (neighborhoods) having the empirical boundary probabilities.",Applications
262,"we provide preliminary evidence that cross-modal projections can be used effectively to simulate a fast mapping scenario, thus strengthening the claims of this approach as a full-fledged, fully inductive theory of meaning acquisition.",Applications
263,"We used efficient L1 regularization for feature selection, obviating the need for the feature scaling and heuristic filtering common in prior work. Those comfortable with implementing vanilla SGD should find our method easy to implement. Even basic discriminative features were effective, so we believe that our work enables fresh approaches to more sophisticated MT feature engineering.",Applications
264,"We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data.",Applications
265,we represent parse derivations compactly using hypergraphs and illustrate the use of an algorithm for generating (rather than parsing) in this framework,Applications
297,A new consensus mechanism Proof-of-contribution was proposed for public blockchain.,Applications
298,User behaviors were quantified as blockchain contribution values through an algorithm.,Applications
299,The highest contribution node gets the right of bookkeeping in each consensus round.,Applications
300,PoC exhibited many advanced properties than PoW and is applicable for public blockchains.,Applications
301,The design of an intellectual property protection blockchain applied PoC was described.,Applications
302,We used the character n-gram method to predict topic changes in search engine queries.,Applications
303,"We obtained more successful estimations than previous studies, and made remarkable contributions.",Applications
304,We compared the character n-gram method with the Levenshtein edit-distance method.,Applications
305,"We analyzed ASPELL, Google and Bing search engines as pre-processed spelling correction methods.",Applications
306,We conclude that Google could be used as a pre-processed spelling correction method.,Applications
307,Question recommendation is used to facilitate users in UIQA systems to obtain interesting information,Applications
308,The topic-based user interest model is proposed for question recommendation,Applications
309,The topic model narrows down the semantic gap between questions in UIQA systems.,Applications
310,"This paper describes an applied document filtering system embedded in an operational watch center that monitors disease outbreaks worldwide. At the initial time of this writing, the system effectively supported monitoring of 23 geographic regions by filtering documents in several thousand daily news sources in 11 different languages.",Applications
311,suggests lessons learned for other applications of document filtering technology,Applications
312,"The applications include negated terms in Boolean queries, more specifically in the presence of metrical constraints, but also negated characters used in the definition of extended keywords by means of regular expressions",Applications
313,"The purpose of this study is to investigate the properties of a specific topic identification methodology in detail, and to test its validity. The topic identification algorithms performance becomes doubtful in various cases. These cases are explored and the reasons underlying the inconsistent performance of automatic topic identification are investigated with statistical analysis and experimental design techniques.",Applications
314,"In this paper, we envisage a Digital Library not only as an information resource where users may submit queries to satisfy their daily information need, but also as a collaborative working and meeting space of people sharing common interests",Applications
315,"We first propose a specification on HTML titles, that is, a definition on HTML titles.",Applications
316,"As application, we consider web page retrieval. We use the TREC Web Track data for evaluation. ",Applications
317,"The proposed method is applied to 11,000 relationships between verbs and nouns extracted from a large tagged corpus. By using this new method both recall and precision have improved by 33% and 18% respectively, over the positive weight method.",Applications
318,"We propose a lemmatization method for Mongolian. The advantage of our lemmatization method is that it does not rely on noun dictionaries, enabling us to lemmatize out-of-dictionary words.",Applications
319,We also apply our method to indexing for information retrieval. We use newspaper articles and technical abstracts in experiments that show the effectiveness of our method,Applications
320,"This model has generated useful retrieval systems, but in the end is lacking essentially because it isolates information seeking behavior of the individual from how the resources are evaluated and applied within a social
group, and clouds the users interpretation of potential resources",Applications
321,"This work describes an online application
that uses Natural Language Generation
(NLG) methods to generate walking directions in combination with dynamic 2D
visualisation",Applications
322,"We apply the method to
the MaltParser system, resulting in a Java
parser that parses over 50 sentences per second on modest hardware without loss of accuracy (a 30 time speedup over existing methods). The method implementation is available
as the open-source splitSVM Java library",Applications
323,"We applied the learning models to three problems
in incremental dependency parsing, the last of which
being prediction of full labeled dependency trees",Applications
324,"This paper presents an application of PageRank, a random-walk model originally devised for ranking Web search results, to
ranking WordNet synsets in terms of how
strongly they possess a given semantic property",Applications
325,"The semantic properties we use for exemplifying the approach are positivity and
negativity, two properties of central importance in sentiment analysis",Applications
326,We propose WIDL-expressions as a flexible formalism that facilitates the integration of a generic sentence realization system within end-to-end language processing applications,Applications
327,"This paper describes a method for incorporating
priming into an incremental probabilistic parser. Three models are compared,
which involve priming of rules between
sentences, within sentences, and within
coordinate structures",Applications
328,"In conclusion, we discuss the application of INTENTION relations to Q&A.",Applications
329,"In this paper, we report on experiments in learning edit distance costs using
Dynamic Bayesian Networks and present
results on a pronunciation classification
task.",Applications
330,"By exploiting the ability within the
DBN framework to rapidly explore a large
model space, we obtain a 40% reduction in error rate ",Applications
331,"We also explore a
potential application in document clustering that is based upon different types
of lexical changes",Applications
332,"In this paper, we investigate a range of graphbased ranking algorithms, and evaluate their application to automatic unsupervised sentence extraction in
the context of a text summarization task",Applications
333,"The structure of the variable memory models is induced from a
manually annotated corpus through a decision tree learning algorithm",Applications
335,"A series of
comparative experiments show the resulting models outperform uniform memory
Markov models in a part-of-speech tagging task.",Applications
336,"we apply an automatically generated encyclopedia to a question answering
system targeting the Japanese InformationTechnology Engineers Examination.",Applications
337,Then we use linguistic patterns and HTML structures to extract text fragments describing the term,Applications
338,The transformation of Word-Net glosses into logic forms is useful for theorem proving and other applications. The paper demonstrates the utility of the WordNet axioms in a question answering system to rank and extract answers.,Applications
339,"We present a generic approach to parallel chart parsing that
meets this requirement, and show
that an implementation of this technique for LinGO achieves considerable speedups.",Applications
340,This paper presents several techniques for performing automatic coreference annotation and performance results for each of them.,Applications
341,"We have applied to real world data, we have bult a simple question-answering system which uses the techniques.",Applications
342,"This paper presents the first-ever
results of applying statistical parsing models to the newly-available
Chinese Treebank.",Applications
343,"We have employed two models, one extracted
and adapted from BBN's SIFT System (Miller et al., 1998)",Applications
344,"a. The data produced by this system have been used in several tasks, such as training NLP tools (such
as Supertaggers)",Applications
345,"estimating the coverage
of harid-crafted grammars.",Applications
